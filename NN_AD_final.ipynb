{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN_AD_final.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "V3zYmVIvFiMd",
        "gkiHctAKJxOd"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mong-head/machine_learning/blob/master/NN_AD_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-5rKiJSFWCc",
        "colab_type": "text"
      },
      "source": [
        "# drive 저장 및 set up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBba8RfrFUyi",
        "colab_type": "code",
        "outputId": "11c0d37c-9d7a-4146-ca74-80e3a3c3965d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYqmNGRLKzP8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "\n",
        "from pandas import Series, DataFrame\n",
        "\n",
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "try:\n",
        "    # %tensorflow_version only exists in Colab.\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# TensorFlow ≥2.0 is required\n",
        "import tensorflow as tf\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3zYmVIvFiMd",
        "colab_type": "text"
      },
      "source": [
        "# * data 처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uh-ummzBFq3q",
        "colab_type": "text"
      },
      "source": [
        "Load TADPOLE* dataset (csv file) from Google Drive\n",
        "-------------------------------------------------------\n",
        "*The Alzheimer's Disease Prediction Of Longitudinal Evolution\n",
        "(https://tadpole.grand-challenge.org/)\n",
        "\n",
        "### -Subjects: 1707 (1363 Train (80%) + 344 Test (20%))\n",
        "### -Features: 72\n",
        "*   2 demographic feature: MMSE, ADAS13\n",
        "*   70 mean values of cortical thickness"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1HB0gX2F5SU",
        "colab_type": "text"
      },
      "source": [
        "데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0Xr3SiaFoPT",
        "colab_type": "code",
        "outputId": "bf10e763-d848-4fb7-e385-a06c06d163ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "csv_file_train = '/content/gdrive/My Drive/BNCS401_Midterm_Project/Train_data_reupdated.csv'  # Set your path\n",
        "train_data = pd.read_csv(csv_file_train)\n",
        "train_data\n",
        "\n",
        "# DXCHANGE: clinical label (1-CN, 2-MCI, 3-AD)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RID</th>\n",
              "      <th>DXCHANGE</th>\n",
              "      <th>AGE</th>\n",
              "      <th>MMSE</th>\n",
              "      <th>ADAS13</th>\n",
              "      <th>ST102TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST103TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST104TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST105TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST106TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST107TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST108TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST109TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST110TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST111TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST113TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST114TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST115TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST116TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST117TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST118TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST119TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST121TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST123TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST129TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST130TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST13TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST14TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST15TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST23TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST24TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST25TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST26TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST31TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST32TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST34TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST35TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST36TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST38TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST39TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST40TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST43TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST44TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST45TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST46TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST47TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST48TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST49TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST50TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST51TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST52TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST54TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST55TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST56TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST57TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST58TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST59TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST60TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST62TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST64TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST72TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST73TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST74TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST82TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST83TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST84TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST85TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST90TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST91TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST93TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST94TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST95TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST97TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST98TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "      <th>ST99TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4084</td>\n",
              "      <td>1</td>\n",
              "      <td>68.4</td>\n",
              "      <td>30</td>\n",
              "      <td>10.00</td>\n",
              "      <td>2.700</td>\n",
              "      <td>2.635</td>\n",
              "      <td>2.613</td>\n",
              "      <td>2.904</td>\n",
              "      <td>2.311</td>\n",
              "      <td>1.647</td>\n",
              "      <td>2.139</td>\n",
              "      <td>2.652</td>\n",
              "      <td>2.604</td>\n",
              "      <td>2.480</td>\n",
              "      <td>3.095</td>\n",
              "      <td>2.144</td>\n",
              "      <td>2.792</td>\n",
              "      <td>2.207</td>\n",
              "      <td>2.903</td>\n",
              "      <td>2.617</td>\n",
              "      <td>4.117</td>\n",
              "      <td>2.701</td>\n",
              "      <td></td>\n",
              "      <td>3.127</td>\n",
              "      <td>3.051</td>\n",
              "      <td>2.305</td>\n",
              "      <td>2.872</td>\n",
              "      <td>2.732</td>\n",
              "      <td>2.026</td>\n",
              "      <td>3.756</td>\n",
              "      <td>2.813</td>\n",
              "      <td>2.762</td>\n",
              "      <td>2.556</td>\n",
              "      <td>2.916</td>\n",
              "      <td>2.695</td>\n",
              "      <td>2.259</td>\n",
              "      <td>2.690</td>\n",
              "      <td>2.017</td>\n",
              "      <td>2.421</td>\n",
              "      <td>2.949</td>\n",
              "      <td>2.570</td>\n",
              "      <td>2.370</td>\n",
              "      <td>2.674</td>\n",
              "      <td>3.004</td>\n",
              "      <td>2.369</td>\n",
              "      <td>1.599</td>\n",
              "      <td>2.208</td>\n",
              "      <td>2.650</td>\n",
              "      <td>2.739</td>\n",
              "      <td>2.544</td>\n",
              "      <td>3.018</td>\n",
              "      <td>2.377</td>\n",
              "      <td>2.880</td>\n",
              "      <td>2.322</td>\n",
              "      <td>2.657</td>\n",
              "      <td>2.489</td>\n",
              "      <td>3.620</td>\n",
              "      <td>2.711</td>\n",
              "      <td></td>\n",
              "      <td>2.593</td>\n",
              "      <td>2.792</td>\n",
              "      <td>2.660</td>\n",
              "      <td>1.993</td>\n",
              "      <td>3.734</td>\n",
              "      <td>2.390</td>\n",
              "      <td>2.817</td>\n",
              "      <td>2.471</td>\n",
              "      <td>2.990</td>\n",
              "      <td>2.667</td>\n",
              "      <td>2.490</td>\n",
              "      <td>2.523</td>\n",
              "      <td>2.254</td>\n",
              "      <td>2.171</td>\n",
              "      <td>2.862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2196</td>\n",
              "      <td>2</td>\n",
              "      <td>68.2</td>\n",
              "      <td>30</td>\n",
              "      <td>13.00</td>\n",
              "      <td>2.453</td>\n",
              "      <td>2.992</td>\n",
              "      <td>2.470</td>\n",
              "      <td>2.965</td>\n",
              "      <td>2.438</td>\n",
              "      <td>1.584</td>\n",
              "      <td>1.910</td>\n",
              "      <td>2.900</td>\n",
              "      <td>2.451</td>\n",
              "      <td>2.335</td>\n",
              "      <td>2.771</td>\n",
              "      <td>2.354</td>\n",
              "      <td>2.712</td>\n",
              "      <td>2.001</td>\n",
              "      <td>2.729</td>\n",
              "      <td>2.363</td>\n",
              "      <td>3.613</td>\n",
              "      <td>2.475</td>\n",
              "      <td></td>\n",
              "      <td>3.196</td>\n",
              "      <td>3.334</td>\n",
              "      <td>2.343</td>\n",
              "      <td>2.729</td>\n",
              "      <td>2.627</td>\n",
              "      <td>1.742</td>\n",
              "      <td>3.383</td>\n",
              "      <td>2.647</td>\n",
              "      <td>2.758</td>\n",
              "      <td>2.394</td>\n",
              "      <td>2.634</td>\n",
              "      <td>2.334</td>\n",
              "      <td>2.241</td>\n",
              "      <td>2.824</td>\n",
              "      <td>1.865</td>\n",
              "      <td>2.383</td>\n",
              "      <td>2.866</td>\n",
              "      <td>2.334</td>\n",
              "      <td>2.793</td>\n",
              "      <td>2.413</td>\n",
              "      <td>2.874</td>\n",
              "      <td>2.316</td>\n",
              "      <td>1.478</td>\n",
              "      <td>1.909</td>\n",
              "      <td>2.780</td>\n",
              "      <td>2.589</td>\n",
              "      <td>2.133</td>\n",
              "      <td>3.036</td>\n",
              "      <td>2.329</td>\n",
              "      <td>2.687</td>\n",
              "      <td>2.070</td>\n",
              "      <td>2.783</td>\n",
              "      <td>2.594</td>\n",
              "      <td>3.405</td>\n",
              "      <td>2.367</td>\n",
              "      <td></td>\n",
              "      <td>2.582</td>\n",
              "      <td>2.977</td>\n",
              "      <td>2.489</td>\n",
              "      <td>1.868</td>\n",
              "      <td>3.220</td>\n",
              "      <td>2.683</td>\n",
              "      <td>2.569</td>\n",
              "      <td>2.372</td>\n",
              "      <td>2.854</td>\n",
              "      <td>2.867</td>\n",
              "      <td>2.233</td>\n",
              "      <td>2.793</td>\n",
              "      <td>1.987</td>\n",
              "      <td>2.428</td>\n",
              "      <td>2.943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>657</td>\n",
              "      <td>1</td>\n",
              "      <td>77.7</td>\n",
              "      <td>29</td>\n",
              "      <td>15.33</td>\n",
              "      <td>2.249</td>\n",
              "      <td>2.296</td>\n",
              "      <td>2.315</td>\n",
              "      <td>2.681</td>\n",
              "      <td>2.420</td>\n",
              "      <td>1.386</td>\n",
              "      <td>1.830</td>\n",
              "      <td>2.466</td>\n",
              "      <td>2.327</td>\n",
              "      <td>2.193</td>\n",
              "      <td>2.415</td>\n",
              "      <td>2.270</td>\n",
              "      <td>2.559</td>\n",
              "      <td>2.008</td>\n",
              "      <td>2.495</td>\n",
              "      <td>2.418</td>\n",
              "      <td>4.210</td>\n",
              "      <td>2.167</td>\n",
              "      <td>1.08</td>\n",
              "      <td>3.362</td>\n",
              "      <td>3.077</td>\n",
              "      <td>2.648</td>\n",
              "      <td>2.759</td>\n",
              "      <td>2.442</td>\n",
              "      <td>1.717</td>\n",
              "      <td>2.886</td>\n",
              "      <td>2.380</td>\n",
              "      <td>2.737</td>\n",
              "      <td>2.402</td>\n",
              "      <td>3.012</td>\n",
              "      <td>2.418</td>\n",
              "      <td>2.056</td>\n",
              "      <td>2.805</td>\n",
              "      <td>1.950</td>\n",
              "      <td>2.318</td>\n",
              "      <td>3.025</td>\n",
              "      <td>2.270</td>\n",
              "      <td>1.831</td>\n",
              "      <td>2.507</td>\n",
              "      <td>2.908</td>\n",
              "      <td>2.335</td>\n",
              "      <td>1.389</td>\n",
              "      <td>1.765</td>\n",
              "      <td>2.397</td>\n",
              "      <td>2.187</td>\n",
              "      <td>2.188</td>\n",
              "      <td>2.889</td>\n",
              "      <td>2.318</td>\n",
              "      <td>2.504</td>\n",
              "      <td>2.028</td>\n",
              "      <td>2.657</td>\n",
              "      <td>2.309</td>\n",
              "      <td>3.880</td>\n",
              "      <td>1.832</td>\n",
              "      <td>1.1</td>\n",
              "      <td>2.338</td>\n",
              "      <td>2.343</td>\n",
              "      <td>2.363</td>\n",
              "      <td>1.601</td>\n",
              "      <td>3.683</td>\n",
              "      <td>2.786</td>\n",
              "      <td>2.385</td>\n",
              "      <td>2.365</td>\n",
              "      <td>2.784</td>\n",
              "      <td>2.415</td>\n",
              "      <td>2.252</td>\n",
              "      <td>2.583</td>\n",
              "      <td>1.850</td>\n",
              "      <td>2.488</td>\n",
              "      <td>2.828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4526</td>\n",
              "      <td>3</td>\n",
              "      <td>79.4</td>\n",
              "      <td>22</td>\n",
              "      <td>24.00</td>\n",
              "      <td>2.197</td>\n",
              "      <td>2.289</td>\n",
              "      <td>2.258</td>\n",
              "      <td>2.413</td>\n",
              "      <td>2.124</td>\n",
              "      <td>1.473</td>\n",
              "      <td>1.729</td>\n",
              "      <td>2.680</td>\n",
              "      <td>2.184</td>\n",
              "      <td>2.144</td>\n",
              "      <td>2.680</td>\n",
              "      <td>2.218</td>\n",
              "      <td>2.407</td>\n",
              "      <td>1.923</td>\n",
              "      <td>2.542</td>\n",
              "      <td>2.296</td>\n",
              "      <td>3.135</td>\n",
              "      <td>2.157</td>\n",
              "      <td></td>\n",
              "      <td>2.671</td>\n",
              "      <td>2.925</td>\n",
              "      <td>2.288</td>\n",
              "      <td>3.322</td>\n",
              "      <td>2.336</td>\n",
              "      <td>1.691</td>\n",
              "      <td>2.399</td>\n",
              "      <td>2.940</td>\n",
              "      <td>2.178</td>\n",
              "      <td>2.079</td>\n",
              "      <td>2.411</td>\n",
              "      <td>2.083</td>\n",
              "      <td>1.904</td>\n",
              "      <td>2.400</td>\n",
              "      <td>1.750</td>\n",
              "      <td>2.122</td>\n",
              "      <td>2.493</td>\n",
              "      <td>2.122</td>\n",
              "      <td>2.244</td>\n",
              "      <td>2.399</td>\n",
              "      <td>2.308</td>\n",
              "      <td>2.073</td>\n",
              "      <td>1.506</td>\n",
              "      <td>1.777</td>\n",
              "      <td>2.334</td>\n",
              "      <td>2.319</td>\n",
              "      <td>2.087</td>\n",
              "      <td>2.560</td>\n",
              "      <td>2.056</td>\n",
              "      <td>2.410</td>\n",
              "      <td>2.058</td>\n",
              "      <td>2.403</td>\n",
              "      <td>2.269</td>\n",
              "      <td>3.085</td>\n",
              "      <td>2.080</td>\n",
              "      <td></td>\n",
              "      <td>2.503</td>\n",
              "      <td>2.784</td>\n",
              "      <td>2.372</td>\n",
              "      <td>1.757</td>\n",
              "      <td>2.651</td>\n",
              "      <td>2.665</td>\n",
              "      <td>2.578</td>\n",
              "      <td>2.305</td>\n",
              "      <td>2.514</td>\n",
              "      <td>2.515</td>\n",
              "      <td>2.050</td>\n",
              "      <td>2.537</td>\n",
              "      <td>1.958</td>\n",
              "      <td>2.455</td>\n",
              "      <td>2.591</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>362</td>\n",
              "      <td>2</td>\n",
              "      <td>70.5</td>\n",
              "      <td>24</td>\n",
              "      <td>20.33</td>\n",
              "      <td>1.765</td>\n",
              "      <td>2.081</td>\n",
              "      <td>2.406</td>\n",
              "      <td>2.461</td>\n",
              "      <td>2.140</td>\n",
              "      <td>1.466</td>\n",
              "      <td>1.749</td>\n",
              "      <td>2.025</td>\n",
              "      <td>2.021</td>\n",
              "      <td>1.938</td>\n",
              "      <td>2.266</td>\n",
              "      <td>2.114</td>\n",
              "      <td>2.368</td>\n",
              "      <td>1.811</td>\n",
              "      <td>2.227</td>\n",
              "      <td>2.191</td>\n",
              "      <td>3.188</td>\n",
              "      <td>1.708</td>\n",
              "      <td>1.013</td>\n",
              "      <td>2.548</td>\n",
              "      <td>2.569</td>\n",
              "      <td>2.280</td>\n",
              "      <td>2.313</td>\n",
              "      <td>2.291</td>\n",
              "      <td>1.821</td>\n",
              "      <td>2.293</td>\n",
              "      <td>2.248</td>\n",
              "      <td>2.414</td>\n",
              "      <td>2.164</td>\n",
              "      <td>2.619</td>\n",
              "      <td>2.012</td>\n",
              "      <td>1.916</td>\n",
              "      <td>2.451</td>\n",
              "      <td>1.959</td>\n",
              "      <td>2.519</td>\n",
              "      <td>2.405</td>\n",
              "      <td>1.968</td>\n",
              "      <td>2.466</td>\n",
              "      <td>2.201</td>\n",
              "      <td>2.711</td>\n",
              "      <td>2.287</td>\n",
              "      <td>1.753</td>\n",
              "      <td>1.644</td>\n",
              "      <td>2.209</td>\n",
              "      <td>1.941</td>\n",
              "      <td>2.050</td>\n",
              "      <td>2.745</td>\n",
              "      <td>2.102</td>\n",
              "      <td>2.519</td>\n",
              "      <td>1.919</td>\n",
              "      <td>2.272</td>\n",
              "      <td>2.099</td>\n",
              "      <td>2.864</td>\n",
              "      <td>2.191</td>\n",
              "      <td>0.922</td>\n",
              "      <td>2.317</td>\n",
              "      <td>2.139</td>\n",
              "      <td>2.273</td>\n",
              "      <td>1.662</td>\n",
              "      <td>2.790</td>\n",
              "      <td>2.504</td>\n",
              "      <td>2.348</td>\n",
              "      <td>2.197</td>\n",
              "      <td>2.596</td>\n",
              "      <td>1.844</td>\n",
              "      <td>2.057</td>\n",
              "      <td>2.121</td>\n",
              "      <td>1.951</td>\n",
              "      <td>2.262</td>\n",
              "      <td>2.245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1358</th>\n",
              "      <td>4187</td>\n",
              "      <td>2</td>\n",
              "      <td>62.0</td>\n",
              "      <td>29</td>\n",
              "      <td>17.00</td>\n",
              "      <td>2.441</td>\n",
              "      <td>2.813</td>\n",
              "      <td>2.614</td>\n",
              "      <td>2.523</td>\n",
              "      <td>2.354</td>\n",
              "      <td>1.830</td>\n",
              "      <td>2.056</td>\n",
              "      <td>2.479</td>\n",
              "      <td>2.555</td>\n",
              "      <td>2.395</td>\n",
              "      <td>2.923</td>\n",
              "      <td>2.005</td>\n",
              "      <td>2.571</td>\n",
              "      <td>2.312</td>\n",
              "      <td>2.923</td>\n",
              "      <td>2.596</td>\n",
              "      <td>3.972</td>\n",
              "      <td>2.793</td>\n",
              "      <td></td>\n",
              "      <td>3.396</td>\n",
              "      <td>3.230</td>\n",
              "      <td>2.417</td>\n",
              "      <td>2.855</td>\n",
              "      <td>2.544</td>\n",
              "      <td>1.938</td>\n",
              "      <td>3.513</td>\n",
              "      <td>2.713</td>\n",
              "      <td>2.846</td>\n",
              "      <td>2.371</td>\n",
              "      <td>2.907</td>\n",
              "      <td>2.434</td>\n",
              "      <td>2.259</td>\n",
              "      <td>2.717</td>\n",
              "      <td>2.096</td>\n",
              "      <td>2.335</td>\n",
              "      <td>2.996</td>\n",
              "      <td>2.317</td>\n",
              "      <td>2.851</td>\n",
              "      <td>2.610</td>\n",
              "      <td>2.411</td>\n",
              "      <td>2.426</td>\n",
              "      <td>1.769</td>\n",
              "      <td>2.097</td>\n",
              "      <td>2.476</td>\n",
              "      <td>2.625</td>\n",
              "      <td>2.357</td>\n",
              "      <td>3.116</td>\n",
              "      <td>2.263</td>\n",
              "      <td>2.681</td>\n",
              "      <td>2.270</td>\n",
              "      <td>2.702</td>\n",
              "      <td>2.533</td>\n",
              "      <td>3.715</td>\n",
              "      <td>2.815</td>\n",
              "      <td></td>\n",
              "      <td>2.464</td>\n",
              "      <td>2.634</td>\n",
              "      <td>2.531</td>\n",
              "      <td>2.035</td>\n",
              "      <td>3.865</td>\n",
              "      <td>2.568</td>\n",
              "      <td>2.850</td>\n",
              "      <td>2.524</td>\n",
              "      <td>3.213</td>\n",
              "      <td>2.489</td>\n",
              "      <td>2.455</td>\n",
              "      <td>2.634</td>\n",
              "      <td>2.209</td>\n",
              "      <td>2.310</td>\n",
              "      <td>2.935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1359</th>\n",
              "      <td>4928</td>\n",
              "      <td>2</td>\n",
              "      <td>77.8</td>\n",
              "      <td>27</td>\n",
              "      <td>17.00</td>\n",
              "      <td>2.301</td>\n",
              "      <td>2.246</td>\n",
              "      <td>2.556</td>\n",
              "      <td>2.392</td>\n",
              "      <td>2.158</td>\n",
              "      <td>1.686</td>\n",
              "      <td>1.914</td>\n",
              "      <td>2.318</td>\n",
              "      <td>2.297</td>\n",
              "      <td>2.268</td>\n",
              "      <td>2.908</td>\n",
              "      <td>2.136</td>\n",
              "      <td>2.445</td>\n",
              "      <td>2.067</td>\n",
              "      <td>2.385</td>\n",
              "      <td>2.458</td>\n",
              "      <td>2.749</td>\n",
              "      <td>2.360</td>\n",
              "      <td></td>\n",
              "      <td>2.855</td>\n",
              "      <td>2.919</td>\n",
              "      <td>2.063</td>\n",
              "      <td>2.426</td>\n",
              "      <td>2.284</td>\n",
              "      <td>1.906</td>\n",
              "      <td>3.070</td>\n",
              "      <td>2.408</td>\n",
              "      <td>2.386</td>\n",
              "      <td>2.235</td>\n",
              "      <td>2.685</td>\n",
              "      <td>2.419</td>\n",
              "      <td>1.953</td>\n",
              "      <td>2.660</td>\n",
              "      <td>1.815</td>\n",
              "      <td>2.303</td>\n",
              "      <td>2.681</td>\n",
              "      <td>2.349</td>\n",
              "      <td>2.211</td>\n",
              "      <td>2.330</td>\n",
              "      <td>2.018</td>\n",
              "      <td>2.196</td>\n",
              "      <td>1.565</td>\n",
              "      <td>1.845</td>\n",
              "      <td>2.281</td>\n",
              "      <td>2.255</td>\n",
              "      <td>2.266</td>\n",
              "      <td>2.893</td>\n",
              "      <td>2.167</td>\n",
              "      <td>2.420</td>\n",
              "      <td>1.934</td>\n",
              "      <td>2.468</td>\n",
              "      <td>2.420</td>\n",
              "      <td>3.288</td>\n",
              "      <td>2.411</td>\n",
              "      <td></td>\n",
              "      <td>2.147</td>\n",
              "      <td>2.478</td>\n",
              "      <td>2.319</td>\n",
              "      <td>2.057</td>\n",
              "      <td>2.106</td>\n",
              "      <td>2.742</td>\n",
              "      <td>2.369</td>\n",
              "      <td>2.221</td>\n",
              "      <td>2.485</td>\n",
              "      <td>2.162</td>\n",
              "      <td>2.152</td>\n",
              "      <td>2.375</td>\n",
              "      <td>1.917</td>\n",
              "      <td>2.199</td>\n",
              "      <td>2.709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1360</th>\n",
              "      <td>4887</td>\n",
              "      <td>3</td>\n",
              "      <td>73.8</td>\n",
              "      <td>26</td>\n",
              "      <td>27.00</td>\n",
              "      <td>1.996</td>\n",
              "      <td>2.545</td>\n",
              "      <td>2.196</td>\n",
              "      <td>2.263</td>\n",
              "      <td>2.099</td>\n",
              "      <td>1.343</td>\n",
              "      <td>1.858</td>\n",
              "      <td>2.676</td>\n",
              "      <td>2.135</td>\n",
              "      <td>1.955</td>\n",
              "      <td>2.882</td>\n",
              "      <td>2.042</td>\n",
              "      <td>2.448</td>\n",
              "      <td>1.874</td>\n",
              "      <td>2.486</td>\n",
              "      <td>2.061</td>\n",
              "      <td>3.193</td>\n",
              "      <td>1.800</td>\n",
              "      <td></td>\n",
              "      <td>3.054</td>\n",
              "      <td>2.921</td>\n",
              "      <td>2.170</td>\n",
              "      <td>2.629</td>\n",
              "      <td>2.119</td>\n",
              "      <td>1.730</td>\n",
              "      <td>3.190</td>\n",
              "      <td>2.839</td>\n",
              "      <td>2.443</td>\n",
              "      <td>1.948</td>\n",
              "      <td>2.381</td>\n",
              "      <td>2.567</td>\n",
              "      <td>1.854</td>\n",
              "      <td>2.713</td>\n",
              "      <td>1.646</td>\n",
              "      <td>2.698</td>\n",
              "      <td>2.424</td>\n",
              "      <td>1.969</td>\n",
              "      <td>2.428</td>\n",
              "      <td>2.231</td>\n",
              "      <td>2.447</td>\n",
              "      <td>2.340</td>\n",
              "      <td>1.472</td>\n",
              "      <td>1.775</td>\n",
              "      <td>2.832</td>\n",
              "      <td>2.014</td>\n",
              "      <td>2.200</td>\n",
              "      <td>2.720</td>\n",
              "      <td>2.320</td>\n",
              "      <td>2.427</td>\n",
              "      <td>1.849</td>\n",
              "      <td>2.362</td>\n",
              "      <td>2.122</td>\n",
              "      <td>3.244</td>\n",
              "      <td>2.270</td>\n",
              "      <td></td>\n",
              "      <td>2.577</td>\n",
              "      <td>2.239</td>\n",
              "      <td>2.084</td>\n",
              "      <td>1.682</td>\n",
              "      <td>2.797</td>\n",
              "      <td>3.351</td>\n",
              "      <td>2.529</td>\n",
              "      <td>2.057</td>\n",
              "      <td>2.585</td>\n",
              "      <td>2.596</td>\n",
              "      <td>1.919</td>\n",
              "      <td>2.683</td>\n",
              "      <td>1.701</td>\n",
              "      <td>2.749</td>\n",
              "      <td>2.777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1361</th>\n",
              "      <td>1205</td>\n",
              "      <td>3</td>\n",
              "      <td>83.0</td>\n",
              "      <td>23</td>\n",
              "      <td>29.33</td>\n",
              "      <td>1.822</td>\n",
              "      <td>2.508</td>\n",
              "      <td>2.174</td>\n",
              "      <td>2.406</td>\n",
              "      <td>2.000</td>\n",
              "      <td>1.374</td>\n",
              "      <td>1.465</td>\n",
              "      <td>2.589</td>\n",
              "      <td>1.677</td>\n",
              "      <td>1.932</td>\n",
              "      <td>2.710</td>\n",
              "      <td>2.018</td>\n",
              "      <td>2.215</td>\n",
              "      <td>1.617</td>\n",
              "      <td>2.066</td>\n",
              "      <td>1.910</td>\n",
              "      <td>3.069</td>\n",
              "      <td>1.536</td>\n",
              "      <td>1.043</td>\n",
              "      <td>2.902</td>\n",
              "      <td>2.809</td>\n",
              "      <td>1.875</td>\n",
              "      <td>2.716</td>\n",
              "      <td>2.001</td>\n",
              "      <td>1.396</td>\n",
              "      <td>2.681</td>\n",
              "      <td>1.613</td>\n",
              "      <td>2.239</td>\n",
              "      <td>1.966</td>\n",
              "      <td>2.561</td>\n",
              "      <td>2.520</td>\n",
              "      <td>1.648</td>\n",
              "      <td>2.414</td>\n",
              "      <td>1.736</td>\n",
              "      <td>1.962</td>\n",
              "      <td>2.296</td>\n",
              "      <td>1.784</td>\n",
              "      <td>2.468</td>\n",
              "      <td>1.769</td>\n",
              "      <td>2.079</td>\n",
              "      <td>1.926</td>\n",
              "      <td>1.232</td>\n",
              "      <td>1.501</td>\n",
              "      <td>2.476</td>\n",
              "      <td>1.831</td>\n",
              "      <td>1.939</td>\n",
              "      <td>3.250</td>\n",
              "      <td>1.900</td>\n",
              "      <td>2.403</td>\n",
              "      <td>1.680</td>\n",
              "      <td>2.193</td>\n",
              "      <td>1.968</td>\n",
              "      <td>3.351</td>\n",
              "      <td>1.494</td>\n",
              "      <td>0.997</td>\n",
              "      <td>1.828</td>\n",
              "      <td>3.025</td>\n",
              "      <td>1.852</td>\n",
              "      <td>1.463</td>\n",
              "      <td>2.982</td>\n",
              "      <td>2.109</td>\n",
              "      <td>2.408</td>\n",
              "      <td>1.849</td>\n",
              "      <td>2.449</td>\n",
              "      <td>2.574</td>\n",
              "      <td>1.784</td>\n",
              "      <td>2.515</td>\n",
              "      <td>1.806</td>\n",
              "      <td>2.071</td>\n",
              "      <td>2.248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1362</th>\n",
              "      <td>2099</td>\n",
              "      <td>2</td>\n",
              "      <td>83.7</td>\n",
              "      <td>30</td>\n",
              "      <td>12.00</td>\n",
              "      <td>2.245</td>\n",
              "      <td>2.351</td>\n",
              "      <td>2.305</td>\n",
              "      <td>2.475</td>\n",
              "      <td>2.155</td>\n",
              "      <td>1.676</td>\n",
              "      <td>1.857</td>\n",
              "      <td>2.525</td>\n",
              "      <td>2.085</td>\n",
              "      <td>2.136</td>\n",
              "      <td>2.712</td>\n",
              "      <td>2.161</td>\n",
              "      <td>2.295</td>\n",
              "      <td>1.948</td>\n",
              "      <td>2.424</td>\n",
              "      <td>2.267</td>\n",
              "      <td>2.958</td>\n",
              "      <td>1.778</td>\n",
              "      <td></td>\n",
              "      <td>2.672</td>\n",
              "      <td>2.507</td>\n",
              "      <td>2.109</td>\n",
              "      <td>2.693</td>\n",
              "      <td>2.315</td>\n",
              "      <td>1.637</td>\n",
              "      <td>3.445</td>\n",
              "      <td>2.396</td>\n",
              "      <td>2.432</td>\n",
              "      <td>2.265</td>\n",
              "      <td>2.568</td>\n",
              "      <td>2.378</td>\n",
              "      <td>2.021</td>\n",
              "      <td>2.350</td>\n",
              "      <td>1.699</td>\n",
              "      <td>2.257</td>\n",
              "      <td>2.625</td>\n",
              "      <td>2.034</td>\n",
              "      <td>2.488</td>\n",
              "      <td>2.237</td>\n",
              "      <td>2.236</td>\n",
              "      <td>2.314</td>\n",
              "      <td>1.386</td>\n",
              "      <td>1.868</td>\n",
              "      <td>2.380</td>\n",
              "      <td>2.072</td>\n",
              "      <td>2.060</td>\n",
              "      <td>2.581</td>\n",
              "      <td>2.155</td>\n",
              "      <td>2.376</td>\n",
              "      <td>1.894</td>\n",
              "      <td>2.400</td>\n",
              "      <td>2.330</td>\n",
              "      <td>3.177</td>\n",
              "      <td>2.054</td>\n",
              "      <td></td>\n",
              "      <td>2.403</td>\n",
              "      <td>2.433</td>\n",
              "      <td>2.206</td>\n",
              "      <td>1.785</td>\n",
              "      <td>3.093</td>\n",
              "      <td>2.310</td>\n",
              "      <td>2.408</td>\n",
              "      <td>2.229</td>\n",
              "      <td>2.428</td>\n",
              "      <td>2.460</td>\n",
              "      <td>2.097</td>\n",
              "      <td>2.381</td>\n",
              "      <td>1.817</td>\n",
              "      <td>2.121</td>\n",
              "      <td>2.586</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1363 rows × 75 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       RID  ...  ST99TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16\n",
              "0     4084  ...                                       2.862\n",
              "1     2196  ...                                       2.943\n",
              "2      657  ...                                       2.828\n",
              "3     4526  ...                                       2.591\n",
              "4      362  ...                                       2.245\n",
              "...    ...  ...                                         ...\n",
              "1358  4187  ...                                       2.935\n",
              "1359  4928  ...                                       2.709\n",
              "1360  4887  ...                                       2.777\n",
              "1361  1205  ...                                       2.248\n",
              "1362  2099  ...                                       2.586\n",
              "\n",
              "[1363 rows x 75 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9YXxbthGCEV",
        "colab_type": "text"
      },
      "source": [
        "train_data.info()로 확인하니, 빠져있는 데이터도 있고(예측값인 ADAS13, cortical값 중에 1개), 실제로는 NaN값이지만 ' '로 채워진 데이터가 2개가 있었다.\n",
        "\n",
        "' '로 채워져 있어 object인 두 cortical값\n",
        "*   ST64TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16\n",
        "*   ST123TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16\n",
        "\n",
        "데이터 처리 순서\n",
        "1. object 처리 : space to NaN\n",
        "2. imputer : median으로 빠져있는 값들 채우기\n",
        "3. feature scaling - RobustScaler : cortical, age 값의 범위를 같게 맞춘다.\n",
        "\n",
        "** StandardScaler안쓰고 RobustScaler하는 이유 : 실제로 이게 더 나았음- outlier제거가 되기때문임\n",
        "\n",
        "2,3을 pipeline으로 하고, 2 전에 AD_tr(cortical값들, age),y(reg/cls)로 나누고,\n",
        "\n",
        "AD_tr만 pipeline해서 X로 만들고, y는 imputer만 한다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxeqPNHiLa6B",
        "colab_type": "text"
      },
      "source": [
        "1) object처리\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jd3Vp4OKLrEU",
        "colab_type": "code",
        "outputId": "43ec26df-703f-4679-ad07-2fc95cb948f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "#2개의 cortical feature가 float이 아니라 object이고, ' '로 채워져있다.\n",
        "ob1 = train_data[\"ST64TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16\"]\n",
        "ob2 = train_data[\"ST123TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16\"]\n",
        "print(len(train_data[ob1.isnull()]), ob1.dtypes)\n",
        "print(len(train_data[ob2.isnull()]),ob2.dtypes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 object\n",
            "0 object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGK2gPstLUv1",
        "colab_type": "code",
        "outputId": "03746cda-ecec-449d-ecfc-b6d5af0058f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "#그냥 ' '로 뜬다.\n",
        "train_data[\"ST64TA_UCSFFSX_11_02_15_UCSFFSX51_08_01_16\"][0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2YObSwZF6-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def object_to_float(o): #o = train_data[\"~~\"] 형태\n",
        "  for i in range(1363):\n",
        "    if o[i] == ' ':\n",
        "      o[i] = np.nan #nan으로 채움"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07BKTvJ9Li1A",
        "colab_type": "code",
        "outputId": "e9d1427c-bf7c-4db1-ac27-c0ca0f1f55d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "object_to_float(ob1)\n",
        "object_to_float(ob2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjOoWsxVL5OF",
        "colab_type": "code",
        "outputId": "90a75424-bf8a-47df-bbbc-6328acbf8988",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "print(len(train_data[ob1.isnull()]), ob1.dtypes)\n",
        "print(len(train_data[ob2.isnull()]),ob2.dtypes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "724 object\n",
            "724 object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Leqdxx1PMAFu",
        "colab_type": "text"
      },
      "source": [
        "**train, test set나누기\n",
        "---\n",
        "AD_train, AD_test = "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r74XRsriOckn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#RID는 버림\n",
        "train_data = train_data.drop(\"RID\",axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cK2I-QAbLOM",
        "colab_type": "text"
      },
      "source": [
        "** trian, test set 나누기\n",
        "---\n",
        "train set에서 model들의 train loss와 validation loss등을 보며 model을 결정하고\n",
        "\n",
        "test set에서 마지막으로 검사해보았을 때에도 최적의 모델이라면 \n",
        "\n",
        "그 모델을 선택하고, 마지막에는 train, test set 나누기 전의 X로 최종으로 선택했던 모델로 마지막 training시킨다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dh0HjDkEL_FT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "AD_train, AD_test = train_test_split(train_data,test_size=0.2,random_state= 42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xKAz8T8R1Hc",
        "colab_type": "text"
      },
      "source": [
        "** AD_tr, y나누고, y에는 imputer\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LWik7raS1LC",
        "colab_type": "text"
      },
      "source": [
        "RID는 버린다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T592RMMTPH6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer(strategy=\"median\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rksVotP_R5oU",
        "colab_type": "code",
        "outputId": "02b8156a-7bc1-4ca9-f9fa-7bde92dcae47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "##input 해당\n",
        "X_prepipeline = train_data.drop(\"MMSE\",axis = 1).drop(\"ADAS13\",axis = 1).drop(\"DXCHANGE\",axis = 1)\n",
        "X_train_prepipeline = AD_train.drop(\"MMSE\",axis = 1).drop(\"ADAS13\",axis = 1).drop(\"DXCHANGE\",axis = 1)\n",
        "X_test_prepipeline = AD_test.drop(\"MMSE\",axis = 1).drop(\"ADAS13\",axis = 1).drop(\"DXCHANGE\",axis = 1)\n",
        "\n",
        "#classification input\n",
        "X_plus_prepipeline = train_data.drop(\"DXCHANGE\",axis = 1)\n",
        "X_plus_train_prepipeline = AD_train.drop(\"DXCHANGE\",axis = 1)\n",
        "X_plus_test_prepipeline = AD_test.drop(\"DXCHANGE\",axis = 1)\n",
        "\n",
        "##output 해당\n",
        "AD_label_reg = DataFrame({\"MMSE\":train_data[\"MMSE\"].copy(),\n",
        "                         \"ADAS13\":train_data[\"ADAS13\"].copy()})\n",
        "AD_label_reg_tr = DataFrame({\"MMSE\":AD_train[\"MMSE\"].copy(),\n",
        "                         \"ADAS13\":AD_train[\"ADAS13\"].copy()})\n",
        "AD_label_reg_test = DataFrame({\"MMSE\":AD_test[\"MMSE\"].copy(),\n",
        "                         \"ADAS13\":AD_test[\"ADAS13\"].copy()})\n",
        "\n",
        "imputer.fit(AD_label_reg)\n",
        "temp = imputer.transform(AD_label_reg)\n",
        "y_reg = pd.DataFrame(temp, columns=AD_label_reg.columns,\n",
        "                             index=AD_label_reg.index)\n",
        "\n",
        "imputer.fit(AD_label_reg_tr)\n",
        "temp = imputer.transform(AD_label_reg_tr)\n",
        "y_reg_train = pd.DataFrame(temp, columns=AD_label_reg_tr.columns,\n",
        "                             index=AD_label_reg_tr.index)\n",
        "imputer.fit(AD_label_reg_test)\n",
        "temp = imputer.transform(AD_label_reg_test)\n",
        "y_reg_test = pd.DataFrame(temp, columns=AD_label_reg_test.columns,\n",
        "                             index=AD_label_reg_test.index)\n",
        "\n",
        "y_mmse =  DataFrame({\"MMSE\":y_reg[\"MMSE\"].copy()})\n",
        "y_mmse_train = DataFrame({\"MMSE\":y_reg_train[\"MMSE\"].copy()})\n",
        "y_mmse_test = DataFrame({\"MMSE\":y_reg_test[\"MMSE\"].copy()})\n",
        "\n",
        "y_ada =  DataFrame({\"ADAS13\":y_reg[\"ADAS13\"].copy()})\n",
        "y_ada_train = DataFrame({\"ADAS13\":y_reg_train[\"ADAS13\"].copy()})\n",
        "y_ada_test = DataFrame({\"ADAS13\":y_reg_test[\"ADAS13\"].copy()})\n",
        "\n",
        "y_cls =  DataFrame({\"DXCHANGE\":train_data[\"DXCHANGE\"]})\n",
        "y_cls_train = DataFrame({\"DXCHANGE\":AD_train[\"DXCHANGE\"]})\n",
        "y_cls_test = DataFrame({\"DXCHANGE\":AD_test[\"DXCHANGE\"]})\n",
        "\n",
        "incomplete_rows_before = AD_label_reg_tr[AD_label_reg_tr.isnull().any(axis=1)]#.head()\n",
        "incomplete_rows_after = y_reg_train[y_reg_train.isnull().any(axis=1)]\n",
        "print(\"1. before imputer:\\n\", incomplete_rows_before)\n",
        "print(\"\\n2. after imputer : \\n\", incomplete_rows_after)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1. before imputer:\n",
            "       MMSE  ADAS13\n",
            "522     23     NaN\n",
            "25      21     NaN\n",
            "1311    18     NaN\n",
            "999     20     NaN\n",
            "426     25     NaN\n",
            "946     29     NaN\n",
            "431     22     NaN\n",
            "\n",
            "2. after imputer : \n",
            " Empty DataFrame\n",
            "Columns: [MMSE, ADAS13]\n",
            "Index: []\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-quVvnc0PzUw",
        "colab_type": "text"
      },
      "source": [
        "2) pipeline : imputer,RobustScaler\n",
        "---\n",
        "* imputer - 빈데이터 채우기\n",
        "* RobustScaler - 값 범위 같게 만들기, Standard보다는 outlier다루는데 더 괜찮을 거 같아서 이것을 썼다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjpD4AEZV4zQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer(strategy=\"median\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ks17w2kiP4TI",
        "colab_type": "code",
        "outputId": "58537929-658d-4698-de3b-97eed3f254bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "#빈데이터 모두 보기\n",
        "incomplete_rows = X_prepipeline[X_prepipeline.isnull().any(axis=1)]#.head()\n",
        "print(\"빈데이터 개수: \",len(incomplete_rows))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "빈데이터 개수:  724\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULsAzfZKVc_G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_pipeline = Pipeline([\n",
        "                     ('imputer',SimpleImputer(strategy=\"median\")),\n",
        "                     ('rb_scaler',RobustScaler()),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDuq6oD7WXkw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = data_pipeline.fit_transform(X_prepipeline)\n",
        "X_train = data_pipeline.fit_transform(X_train_prepipeline)\n",
        "X_test = data_pipeline.fit_transform(X_test_prepipeline)\n",
        "\n",
        "X_plus = data_pipeline.fit_transform(X_plus_prepipeline)\n",
        "X_plus_train = data_pipeline.fit_transform(X_plus_train_prepipeline)\n",
        "X_plus_test = data_pipeline.fit_transform(X_plus_test_prepipeline)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcR2bKipGRMT",
        "colab_type": "text"
      },
      "source": [
        "# 1- NN regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enT4CUYHGaTN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8auxXvGH5XY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
        "                                                  restore_best_weights=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuBxVLSpGTmj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[71]):\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
        "    for layer in range(n_hidden):\n",
        "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
        "    model.add(keras.layers.Dense(2,activation= \"relu\"))\n",
        "\n",
        "    loss = tf.losses.Huber(delta=1.0)\n",
        "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
        "    model.compile(loss=tf.losses.Huber(delta=1.0), optimizer=optimizer)\n",
        "    return model\n",
        "\n",
        "model_reg = keras.wrappers.scikit_learn.KerasRegressor(build_fn=build_model,\n",
        "                                                      epochs=35)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5lqBXeMGYYK",
        "colab_type": "code",
        "outputId": "4f7b1ce2-297f-42ee-c96d-c9769fc99a74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "kfold = KFold(n_splits=5, random_state=42)\n",
        "scores = cross_val_score(model_reg,X,y_reg.values,\n",
        "                         scoring=\"neg_mean_squared_error\",\n",
        "                         cv=kfold)\n",
        "keras_reg_scores = np.sqrt(-scores).mean()\n",
        "print('keras_reg validation score(rmse) :', keras_reg_scores)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1090 samples\n",
            "Epoch 1/35\n",
            "1090/1090 [==============================] - 0s 412us/sample - loss: 21.1891\n",
            "Epoch 2/35\n",
            "1090/1090 [==============================] - 0s 118us/sample - loss: 21.0180\n",
            "Epoch 3/35\n",
            "1090/1090 [==============================] - 0s 94us/sample - loss: 20.7940\n",
            "Epoch 4/35\n",
            "1090/1090 [==============================] - 0s 113us/sample - loss: 20.5124\n",
            "Epoch 5/35\n",
            "1090/1090 [==============================] - 0s 93us/sample - loss: 20.1310\n",
            "Epoch 6/35\n",
            "1090/1090 [==============================] - 0s 92us/sample - loss: 19.6539\n",
            "Epoch 7/35\n",
            "1090/1090 [==============================] - 0s 88us/sample - loss: 19.0428\n",
            "Epoch 8/35\n",
            "1090/1090 [==============================] - 0s 86us/sample - loss: 18.2766\n",
            "Epoch 9/35\n",
            "1090/1090 [==============================] - 0s 95us/sample - loss: 17.3531\n",
            "Epoch 10/35\n",
            "1090/1090 [==============================] - 0s 109us/sample - loss: 16.3032\n",
            "Epoch 11/35\n",
            "1090/1090 [==============================] - 0s 89us/sample - loss: 15.2096\n",
            "Epoch 12/35\n",
            "1090/1090 [==============================] - 0s 94us/sample - loss: 14.1994\n",
            "Epoch 13/35\n",
            "1090/1090 [==============================] - 0s 92us/sample - loss: 13.2856\n",
            "Epoch 14/35\n",
            "1090/1090 [==============================] - 0s 89us/sample - loss: 12.5043\n",
            "Epoch 15/35\n",
            "1090/1090 [==============================] - 0s 92us/sample - loss: 11.8220\n",
            "Epoch 16/35\n",
            "1090/1090 [==============================] - 0s 90us/sample - loss: 11.2228\n",
            "Epoch 17/35\n",
            "1090/1090 [==============================] - 0s 89us/sample - loss: 10.7052\n",
            "Epoch 18/35\n",
            "1090/1090 [==============================] - 0s 96us/sample - loss: 10.3322\n",
            "Epoch 19/35\n",
            "1090/1090 [==============================] - 0s 91us/sample - loss: 10.0560\n",
            "Epoch 20/35\n",
            "1090/1090 [==============================] - 0s 103us/sample - loss: 9.8656\n",
            "Epoch 21/35\n",
            "1090/1090 [==============================] - 0s 92us/sample - loss: 9.7092\n",
            "Epoch 22/35\n",
            "1090/1090 [==============================] - 0s 91us/sample - loss: 9.5657\n",
            "Epoch 23/35\n",
            "1090/1090 [==============================] - 0s 105us/sample - loss: 9.4430\n",
            "Epoch 24/35\n",
            "1090/1090 [==============================] - 0s 96us/sample - loss: 9.3211\n",
            "Epoch 25/35\n",
            "1090/1090 [==============================] - 0s 101us/sample - loss: 9.2005\n",
            "Epoch 26/35\n",
            "1090/1090 [==============================] - 0s 87us/sample - loss: 9.0810\n",
            "Epoch 27/35\n",
            "1090/1090 [==============================] - 0s 94us/sample - loss: 8.9573\n",
            "Epoch 28/35\n",
            "1090/1090 [==============================] - 0s 91us/sample - loss: 8.8347\n",
            "Epoch 29/35\n",
            "1090/1090 [==============================] - 0s 96us/sample - loss: 8.7090\n",
            "Epoch 30/35\n",
            "1090/1090 [==============================] - 0s 104us/sample - loss: 8.5795\n",
            "Epoch 31/35\n",
            "1090/1090 [==============================] - 0s 90us/sample - loss: 8.4481\n",
            "Epoch 32/35\n",
            "1090/1090 [==============================] - 0s 93us/sample - loss: 8.3117\n",
            "Epoch 33/35\n",
            "1090/1090 [==============================] - 0s 92us/sample - loss: 8.1747\n",
            "Epoch 34/35\n",
            "1090/1090 [==============================] - 0s 92us/sample - loss: 8.0373\n",
            "Epoch 35/35\n",
            "1090/1090 [==============================] - 0s 91us/sample - loss: 7.8976\n",
            "Train on 1090 samples\n",
            "Epoch 1/35\n",
            "1090/1090 [==============================] - 0s 393us/sample - loss: 21.3123\n",
            "Epoch 2/35\n",
            "1090/1090 [==============================] - 0s 92us/sample - loss: 21.2237\n",
            "Epoch 3/35\n",
            "1090/1090 [==============================] - 0s 99us/sample - loss: 21.1002\n",
            "Epoch 4/35\n",
            "1090/1090 [==============================] - 0s 94us/sample - loss: 20.9606\n",
            "Epoch 5/35\n",
            "1090/1090 [==============================] - 0s 90us/sample - loss: 20.7919\n",
            "Epoch 6/35\n",
            "1090/1090 [==============================] - 0s 95us/sample - loss: 20.5859\n",
            "Epoch 7/35\n",
            "1090/1090 [==============================] - 0s 96us/sample - loss: 20.3037\n",
            "Epoch 8/35\n",
            "1090/1090 [==============================] - 0s 106us/sample - loss: 19.8913\n",
            "Epoch 9/35\n",
            "1090/1090 [==============================] - 0s 97us/sample - loss: 19.3168\n",
            "Epoch 10/35\n",
            "1090/1090 [==============================] - 0s 106us/sample - loss: 18.5714\n",
            "Epoch 11/35\n",
            "1090/1090 [==============================] - 0s 90us/sample - loss: 17.7253\n",
            "Epoch 12/35\n",
            "1090/1090 [==============================] - 0s 95us/sample - loss: 16.8794\n",
            "Epoch 13/35\n",
            "1090/1090 [==============================] - 0s 90us/sample - loss: 16.1762\n",
            "Epoch 14/35\n",
            "1090/1090 [==============================] - 0s 94us/sample - loss: 15.6451\n",
            "Epoch 15/35\n",
            "1090/1090 [==============================] - 0s 98us/sample - loss: 15.2458\n",
            "Epoch 16/35\n",
            "1090/1090 [==============================] - 0s 95us/sample - loss: 14.9219\n",
            "Epoch 17/35\n",
            "1090/1090 [==============================] - 0s 91us/sample - loss: 14.6565\n",
            "Epoch 18/35\n",
            "1090/1090 [==============================] - 0s 95us/sample - loss: 14.3955\n",
            "Epoch 19/35\n",
            "1090/1090 [==============================] - 0s 105us/sample - loss: 14.1406\n",
            "Epoch 20/35\n",
            "1090/1090 [==============================] - 0s 96us/sample - loss: 13.8622\n",
            "Epoch 21/35\n",
            "1090/1090 [==============================] - 0s 96us/sample - loss: 13.5806\n",
            "Epoch 22/35\n",
            "1090/1090 [==============================] - 0s 97us/sample - loss: 13.2864\n",
            "Epoch 23/35\n",
            "1090/1090 [==============================] - 0s 92us/sample - loss: 12.9825\n",
            "Epoch 24/35\n",
            "1090/1090 [==============================] - 0s 94us/sample - loss: 12.6601\n",
            "Epoch 25/35\n",
            "1090/1090 [==============================] - 0s 88us/sample - loss: 12.3123\n",
            "Epoch 26/35\n",
            "1090/1090 [==============================] - 0s 90us/sample - loss: 11.9176\n",
            "Epoch 27/35\n",
            "1090/1090 [==============================] - 0s 91us/sample - loss: 11.4888\n",
            "Epoch 28/35\n",
            "1090/1090 [==============================] - 0s 105us/sample - loss: 11.0187\n",
            "Epoch 29/35\n",
            "1090/1090 [==============================] - 0s 103us/sample - loss: 10.5251\n",
            "Epoch 30/35\n",
            "1090/1090 [==============================] - 0s 97us/sample - loss: 10.0123\n",
            "Epoch 31/35\n",
            "1090/1090 [==============================] - 0s 91us/sample - loss: 9.5880\n",
            "Epoch 32/35\n",
            "1090/1090 [==============================] - 0s 96us/sample - loss: 9.2474\n",
            "Epoch 33/35\n",
            "1090/1090 [==============================] - 0s 98us/sample - loss: 8.9817\n",
            "Epoch 34/35\n",
            "1090/1090 [==============================] - 0s 102us/sample - loss: 8.7436\n",
            "Epoch 35/35\n",
            "1090/1090 [==============================] - 0s 98us/sample - loss: 8.5262\n",
            "Train on 1090 samples\n",
            "Epoch 1/35\n",
            "1090/1090 [==============================] - 0s 392us/sample - loss: 21.0598\n",
            "Epoch 2/35\n",
            "1090/1090 [==============================] - 0s 99us/sample - loss: 20.7739\n",
            "Epoch 3/35\n",
            "1090/1090 [==============================] - 0s 89us/sample - loss: 20.3992\n",
            "Epoch 4/35\n",
            "1090/1090 [==============================] - 0s 92us/sample - loss: 19.9471\n",
            "Epoch 5/35\n",
            "1090/1090 [==============================] - 0s 98us/sample - loss: 19.4067\n",
            "Epoch 6/35\n",
            "1090/1090 [==============================] - 0s 94us/sample - loss: 18.7513\n",
            "Epoch 7/35\n",
            "1090/1090 [==============================] - 0s 107us/sample - loss: 17.9401\n",
            "Epoch 8/35\n",
            "1090/1090 [==============================] - 0s 102us/sample - loss: 17.0465\n",
            "Epoch 9/35\n",
            "1090/1090 [==============================] - 0s 103us/sample - loss: 16.1923\n",
            "Epoch 10/35\n",
            "1090/1090 [==============================] - 0s 90us/sample - loss: 15.4958\n",
            "Epoch 11/35\n",
            "1090/1090 [==============================] - 0s 90us/sample - loss: 14.9384\n",
            "Epoch 12/35\n",
            "1090/1090 [==============================] - 0s 99us/sample - loss: 14.4436\n",
            "Epoch 13/35\n",
            "1090/1090 [==============================] - 0s 93us/sample - loss: 13.9481\n",
            "Epoch 14/35\n",
            "1090/1090 [==============================] - 0s 96us/sample - loss: 13.4420\n",
            "Epoch 15/35\n",
            "1090/1090 [==============================] - 0s 92us/sample - loss: 12.9171\n",
            "Epoch 16/35\n",
            "1090/1090 [==============================] - 0s 94us/sample - loss: 12.4137\n",
            "Epoch 17/35\n",
            "1090/1090 [==============================] - 0s 110us/sample - loss: 11.9842\n",
            "Epoch 18/35\n",
            "1090/1090 [==============================] - 0s 100us/sample - loss: 11.6764\n",
            "Epoch 19/35\n",
            "1090/1090 [==============================] - 0s 91us/sample - loss: 11.4492\n",
            "Epoch 20/35\n",
            "1090/1090 [==============================] - 0s 89us/sample - loss: 11.2881\n",
            "Epoch 21/35\n",
            "1090/1090 [==============================] - 0s 97us/sample - loss: 11.1584\n",
            "Epoch 22/35\n",
            "1090/1090 [==============================] - 0s 96us/sample - loss: 11.0433\n",
            "Epoch 23/35\n",
            "1090/1090 [==============================] - 0s 92us/sample - loss: 10.9478\n",
            "Epoch 24/35\n",
            "1090/1090 [==============================] - 0s 102us/sample - loss: 10.8398\n",
            "Epoch 25/35\n",
            "1090/1090 [==============================] - 0s 92us/sample - loss: 10.7346\n",
            "Epoch 26/35\n",
            "1090/1090 [==============================] - 0s 97us/sample - loss: 10.6256\n",
            "Epoch 27/35\n",
            "1090/1090 [==============================] - 0s 90us/sample - loss: 10.5059\n",
            "Epoch 28/35\n",
            "1090/1090 [==============================] - 0s 113us/sample - loss: 10.3559\n",
            "Epoch 29/35\n",
            "1090/1090 [==============================] - 0s 94us/sample - loss: 10.1043\n",
            "Epoch 30/35\n",
            "1090/1090 [==============================] - 0s 96us/sample - loss: 9.5505\n",
            "Epoch 31/35\n",
            "1090/1090 [==============================] - 0s 98us/sample - loss: 9.0876\n",
            "Epoch 32/35\n",
            "1090/1090 [==============================] - 0s 94us/sample - loss: 8.7556\n",
            "Epoch 33/35\n",
            "1090/1090 [==============================] - 0s 97us/sample - loss: 8.5331\n",
            "Epoch 34/35\n",
            "1090/1090 [==============================] - 0s 93us/sample - loss: 8.3565\n",
            "Epoch 35/35\n",
            "1090/1090 [==============================] - 0s 92us/sample - loss: 8.2044\n",
            "Train on 1091 samples\n",
            "Epoch 1/35\n",
            "1091/1091 [==============================] - 0s 419us/sample - loss: 20.9360\n",
            "Epoch 2/35\n",
            "1091/1091 [==============================] - 0s 86us/sample - loss: 20.6659\n",
            "Epoch 3/35\n",
            "1091/1091 [==============================] - 0s 90us/sample - loss: 20.3062\n",
            "Epoch 4/35\n",
            "1091/1091 [==============================] - 0s 89us/sample - loss: 19.7959\n",
            "Epoch 5/35\n",
            "1091/1091 [==============================] - 0s 105us/sample - loss: 19.1700\n",
            "Epoch 6/35\n",
            "1091/1091 [==============================] - 0s 89us/sample - loss: 18.3866\n",
            "Epoch 7/35\n",
            "1091/1091 [==============================] - 0s 99us/sample - loss: 17.4660\n",
            "Epoch 8/35\n",
            "1091/1091 [==============================] - 0s 94us/sample - loss: 16.3945\n",
            "Epoch 9/35\n",
            "1091/1091 [==============================] - 0s 96us/sample - loss: 15.2387\n",
            "Epoch 10/35\n",
            "1091/1091 [==============================] - 0s 97us/sample - loss: 14.0917\n",
            "Epoch 11/35\n",
            "1091/1091 [==============================] - 0s 89us/sample - loss: 13.1338\n",
            "Epoch 12/35\n",
            "1091/1091 [==============================] - 0s 93us/sample - loss: 12.3462\n",
            "Epoch 13/35\n",
            "1091/1091 [==============================] - 0s 93us/sample - loss: 11.6705\n",
            "Epoch 14/35\n",
            "1091/1091 [==============================] - 0s 92us/sample - loss: 11.1413\n",
            "Epoch 15/35\n",
            "1091/1091 [==============================] - 0s 99us/sample - loss: 10.7423\n",
            "Epoch 16/35\n",
            "1091/1091 [==============================] - 0s 108us/sample - loss: 10.4859\n",
            "Epoch 17/35\n",
            "1091/1091 [==============================] - 0s 107us/sample - loss: 10.2938\n",
            "Epoch 18/35\n",
            "1091/1091 [==============================] - 0s 93us/sample - loss: 10.1384\n",
            "Epoch 19/35\n",
            "1091/1091 [==============================] - 0s 89us/sample - loss: 10.0111\n",
            "Epoch 20/35\n",
            "1091/1091 [==============================] - 0s 95us/sample - loss: 9.8963\n",
            "Epoch 21/35\n",
            "1091/1091 [==============================] - 0s 90us/sample - loss: 9.7907\n",
            "Epoch 22/35\n",
            "1091/1091 [==============================] - 0s 95us/sample - loss: 9.6825\n",
            "Epoch 23/35\n",
            "1091/1091 [==============================] - 0s 98us/sample - loss: 9.5750\n",
            "Epoch 24/35\n",
            "1091/1091 [==============================] - 0s 99us/sample - loss: 9.4640\n",
            "Epoch 25/35\n",
            "1091/1091 [==============================] - 0s 95us/sample - loss: 9.3548\n",
            "Epoch 26/35\n",
            "1091/1091 [==============================] - 0s 91us/sample - loss: 9.2446\n",
            "Epoch 27/35\n",
            "1091/1091 [==============================] - 0s 104us/sample - loss: 9.1253\n",
            "Epoch 28/35\n",
            "1091/1091 [==============================] - 0s 89us/sample - loss: 9.0083\n",
            "Epoch 29/35\n",
            "1091/1091 [==============================] - 0s 89us/sample - loss: 8.8869\n",
            "Epoch 30/35\n",
            "1091/1091 [==============================] - 0s 100us/sample - loss: 8.7620\n",
            "Epoch 31/35\n",
            "1091/1091 [==============================] - 0s 90us/sample - loss: 8.6350\n",
            "Epoch 32/35\n",
            "1091/1091 [==============================] - 0s 95us/sample - loss: 8.4972\n",
            "Epoch 33/35\n",
            "1091/1091 [==============================] - 0s 89us/sample - loss: 8.3636\n",
            "Epoch 34/35\n",
            "1091/1091 [==============================] - 0s 95us/sample - loss: 8.2273\n",
            "Epoch 35/35\n",
            "1091/1091 [==============================] - 0s 109us/sample - loss: 8.0931\n",
            "Train on 1091 samples\n",
            "Epoch 1/35\n",
            "1091/1091 [==============================] - 0s 368us/sample - loss: 21.1442\n",
            "Epoch 2/35\n",
            "1091/1091 [==============================] - 0s 86us/sample - loss: 20.9974\n",
            "Epoch 3/35\n",
            "1091/1091 [==============================] - 0s 94us/sample - loss: 20.8082\n",
            "Epoch 4/35\n",
            "1091/1091 [==============================] - 0s 90us/sample - loss: 20.5802\n",
            "Epoch 5/35\n",
            "1091/1091 [==============================] - 0s 96us/sample - loss: 20.3036\n",
            "Epoch 6/35\n",
            "1091/1091 [==============================] - 0s 91us/sample - loss: 19.9545\n",
            "Epoch 7/35\n",
            "1091/1091 [==============================] - 0s 105us/sample - loss: 19.5230\n",
            "Epoch 8/35\n",
            "1091/1091 [==============================] - 0s 99us/sample - loss: 18.9932\n",
            "Epoch 9/35\n",
            "1091/1091 [==============================] - 0s 95us/sample - loss: 18.3552\n",
            "Epoch 10/35\n",
            "1091/1091 [==============================] - 0s 93us/sample - loss: 17.5502\n",
            "Epoch 11/35\n",
            "1091/1091 [==============================] - 0s 92us/sample - loss: 16.6760\n",
            "Epoch 12/35\n",
            "1091/1091 [==============================] - 0s 103us/sample - loss: 15.8378\n",
            "Epoch 13/35\n",
            "1091/1091 [==============================] - 0s 95us/sample - loss: 15.1882\n",
            "Epoch 14/35\n",
            "1091/1091 [==============================] - 0s 92us/sample - loss: 14.7756\n",
            "Epoch 15/35\n",
            "1091/1091 [==============================] - 0s 98us/sample - loss: 14.4667\n",
            "Epoch 16/35\n",
            "1091/1091 [==============================] - 0s 110us/sample - loss: 14.1704\n",
            "Epoch 17/35\n",
            "1091/1091 [==============================] - 0s 92us/sample - loss: 13.8412\n",
            "Epoch 18/35\n",
            "1091/1091 [==============================] - 0s 96us/sample - loss: 13.5060\n",
            "Epoch 19/35\n",
            "1091/1091 [==============================] - 0s 95us/sample - loss: 13.1586\n",
            "Epoch 20/35\n",
            "1091/1091 [==============================] - 0s 92us/sample - loss: 12.7832\n",
            "Epoch 21/35\n",
            "1091/1091 [==============================] - 0s 90us/sample - loss: 12.3911\n",
            "Epoch 22/35\n",
            "1091/1091 [==============================] - 0s 94us/sample - loss: 11.9486\n",
            "Epoch 23/35\n",
            "1091/1091 [==============================] - 0s 94us/sample - loss: 11.4728\n",
            "Epoch 24/35\n",
            "1091/1091 [==============================] - 0s 91us/sample - loss: 10.9336\n",
            "Epoch 25/35\n",
            "1091/1091 [==============================] - 0s 100us/sample - loss: 10.3964\n",
            "Epoch 26/35\n",
            "1091/1091 [==============================] - 0s 135us/sample - loss: 9.9155\n",
            "Epoch 27/35\n",
            "1091/1091 [==============================] - 0s 94us/sample - loss: 9.5549\n",
            "Epoch 28/35\n",
            "1091/1091 [==============================] - 0s 97us/sample - loss: 9.2709\n",
            "Epoch 29/35\n",
            "1091/1091 [==============================] - 0s 98us/sample - loss: 9.0660\n",
            "Epoch 30/35\n",
            "1091/1091 [==============================] - 0s 98us/sample - loss: 8.8854\n",
            "Epoch 31/35\n",
            "1091/1091 [==============================] - 0s 97us/sample - loss: 8.7289\n",
            "Epoch 32/35\n",
            "1091/1091 [==============================] - 0s 95us/sample - loss: 8.5860\n",
            "Epoch 33/35\n",
            "1091/1091 [==============================] - 0s 91us/sample - loss: 8.4512\n",
            "Epoch 34/35\n",
            "1091/1091 [==============================] - 0s 97us/sample - loss: 8.3224\n",
            "Epoch 35/35\n",
            "1091/1091 [==============================] - 0s 113us/sample - loss: 8.1922\n",
            "keras_reg validation score(rmse) : 10.717752739952939\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eT9hzF8bHB4Q",
        "colab_type": "code",
        "outputId": "31f43e7c-7a72-4dd9-c3a5-9d3a65946d2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from scipy.stats import reciprocal\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "param_distribs = {\n",
        "    \"n_hidden\": [0, 1, 2, 3,4,5],\n",
        "    \"n_neurons\": np.arange(1, 100),\n",
        "    \"learning_rate\": reciprocal(3e-4, 3e-2),\n",
        "}\n",
        "\n",
        "rnd_search_cv = RandomizedSearchCV(model_reg, param_distribs, n_iter=10,\n",
        "                                   cv=3, scoring=\"neg_mean_squared_error\",\n",
        "                                   verbose=2)\n",
        "rnd_search_cv.fit(X, y_reg.values, epochs=35,\n",
        "                  validation_split=0.1,\n",
        "                  callbacks=[early_stopping_cb])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
            "[CV] learning_rate=0.00031701627936568455, n_hidden=3, n_neurons=55 ..\n",
            "Train on 817 samples, validate on 91 samples\n",
            "Epoch 1/35\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "817/817 [==============================] - 1s 700us/sample - loss: 21.3269 - val_loss: 21.0306\n",
            "Epoch 2/35\n",
            "817/817 [==============================] - 0s 142us/sample - loss: 21.3132 - val_loss: 21.0134\n",
            "Epoch 3/35\n",
            "817/817 [==============================] - 0s 138us/sample - loss: 21.2986 - val_loss: 20.9956\n",
            "Epoch 4/35\n",
            "817/817 [==============================] - 0s 124us/sample - loss: 21.2834 - val_loss: 20.9770\n",
            "Epoch 5/35\n",
            "817/817 [==============================] - 0s 120us/sample - loss: 21.2675 - val_loss: 20.9576\n",
            "Epoch 6/35\n",
            "817/817 [==============================] - 0s 122us/sample - loss: 21.2508 - val_loss: 20.9374\n",
            "Epoch 7/35\n",
            "817/817 [==============================] - 0s 125us/sample - loss: 21.2333 - val_loss: 20.9164\n",
            "Epoch 8/35\n",
            "817/817 [==============================] - 0s 126us/sample - loss: 21.2150 - val_loss: 20.8946\n",
            "Epoch 9/35\n",
            "817/817 [==============================] - 0s 130us/sample - loss: 21.1958 - val_loss: 20.8720\n",
            "Epoch 10/35\n",
            "817/817 [==============================] - 0s 119us/sample - loss: 21.1759 - val_loss: 20.8487\n",
            "Epoch 11/35\n",
            "817/817 [==============================] - 0s 126us/sample - loss: 21.1554 - val_loss: 20.8246\n",
            "Epoch 12/35\n",
            "817/817 [==============================] - 0s 126us/sample - loss: 21.1340 - val_loss: 20.8000\n",
            "Epoch 13/35\n",
            "817/817 [==============================] - 0s 144us/sample - loss: 21.1120 - val_loss: 20.7748\n",
            "Epoch 14/35\n",
            "817/817 [==============================] - 0s 119us/sample - loss: 21.0895 - val_loss: 20.7487\n",
            "Epoch 15/35\n",
            "817/817 [==============================] - 0s 125us/sample - loss: 21.0662 - val_loss: 20.7220\n",
            "Epoch 16/35\n",
            "817/817 [==============================] - 0s 117us/sample - loss: 21.0423 - val_loss: 20.6947\n",
            "Epoch 17/35\n",
            "817/817 [==============================] - 0s 127us/sample - loss: 21.0179 - val_loss: 20.6664\n",
            "Epoch 18/35\n",
            "817/817 [==============================] - 0s 128us/sample - loss: 20.9927 - val_loss: 20.6372\n",
            "Epoch 19/35\n",
            "817/817 [==============================] - 0s 127us/sample - loss: 20.9666 - val_loss: 20.6071\n",
            "Epoch 20/35\n",
            "817/817 [==============================] - 0s 121us/sample - loss: 20.9396 - val_loss: 20.5758\n",
            "Epoch 21/35\n",
            "817/817 [==============================] - 0s 118us/sample - loss: 20.9116 - val_loss: 20.5434\n",
            "Epoch 22/35\n",
            "817/817 [==============================] - 0s 127us/sample - loss: 20.8826 - val_loss: 20.5099\n",
            "Epoch 23/35\n",
            "817/817 [==============================] - 0s 143us/sample - loss: 20.8524 - val_loss: 20.4751\n",
            "Epoch 24/35\n",
            "817/817 [==============================] - 0s 124us/sample - loss: 20.8210 - val_loss: 20.4386\n",
            "Epoch 25/35\n",
            "817/817 [==============================] - 0s 121us/sample - loss: 20.7881 - val_loss: 20.4007\n",
            "Epoch 26/35\n",
            "817/817 [==============================] - 0s 120us/sample - loss: 20.7537 - val_loss: 20.3611\n",
            "Epoch 27/35\n",
            "817/817 [==============================] - 0s 125us/sample - loss: 20.7179 - val_loss: 20.3190\n",
            "Epoch 28/35\n",
            "817/817 [==============================] - 0s 122us/sample - loss: 20.6799 - val_loss: 20.2748\n",
            "Epoch 29/35\n",
            "817/817 [==============================] - 0s 128us/sample - loss: 20.6400 - val_loss: 20.2283\n",
            "Epoch 30/35\n",
            "817/817 [==============================] - 0s 123us/sample - loss: 20.5978 - val_loss: 20.1793\n",
            "Epoch 31/35\n",
            "817/817 [==============================] - 0s 121us/sample - loss: 20.5533 - val_loss: 20.1276\n",
            "Epoch 32/35\n",
            "817/817 [==============================] - 0s 132us/sample - loss: 20.5060 - val_loss: 20.0730\n",
            "Epoch 33/35\n",
            "817/817 [==============================] - 0s 127us/sample - loss: 20.4551 - val_loss: 20.0139\n",
            "Epoch 34/35\n",
            "817/817 [==============================] - 0s 133us/sample - loss: 20.3987 - val_loss: 19.9480\n",
            "Epoch 35/35\n",
            "817/817 [==============================] - 0s 134us/sample - loss: 20.3342 - val_loss: 19.8728\n",
            "[CV]  learning_rate=0.00031701627936568455, n_hidden=3, n_neurons=55, total=   4.4s\n",
            "[CV] learning_rate=0.00031701627936568455, n_hidden=3, n_neurons=55 ..\n",
            "Train on 818 samples, validate on 91 samples\n",
            "Epoch 1/35\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.4s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "818/818 [==============================] - 1s 692us/sample - loss: 21.4865 - val_loss: 21.1540\n",
            "Epoch 2/35\n",
            "818/818 [==============================] - 0s 124us/sample - loss: 21.4855 - val_loss: 21.1527\n",
            "Epoch 3/35\n",
            "818/818 [==============================] - 0s 125us/sample - loss: 21.4844 - val_loss: 21.1513\n",
            "Epoch 4/35\n",
            "818/818 [==============================] - 0s 142us/sample - loss: 21.4833 - val_loss: 21.1497\n",
            "Epoch 5/35\n",
            "818/818 [==============================] - 0s 126us/sample - loss: 21.4820 - val_loss: 21.1479\n",
            "Epoch 6/35\n",
            "818/818 [==============================] - 0s 120us/sample - loss: 21.4806 - val_loss: 21.1461\n",
            "Epoch 7/35\n",
            "818/818 [==============================] - 0s 118us/sample - loss: 21.4790 - val_loss: 21.1441\n",
            "Epoch 8/35\n",
            "818/818 [==============================] - 0s 127us/sample - loss: 21.4773 - val_loss: 21.1419\n",
            "Epoch 9/35\n",
            "818/818 [==============================] - 0s 134us/sample - loss: 21.4755 - val_loss: 21.1395\n",
            "Epoch 10/35\n",
            "818/818 [==============================] - 0s 145us/sample - loss: 21.4735 - val_loss: 21.1368\n",
            "Epoch 11/35\n",
            "818/818 [==============================] - 0s 126us/sample - loss: 21.4713 - val_loss: 21.1339\n",
            "Epoch 12/35\n",
            "818/818 [==============================] - 0s 120us/sample - loss: 21.4689 - val_loss: 21.1309\n",
            "Epoch 13/35\n",
            "818/818 [==============================] - 0s 116us/sample - loss: 21.4664 - val_loss: 21.1276\n",
            "Epoch 14/35\n",
            "818/818 [==============================] - 0s 119us/sample - loss: 21.4636 - val_loss: 21.1241\n",
            "Epoch 15/35\n",
            "818/818 [==============================] - 0s 117us/sample - loss: 21.4606 - val_loss: 21.1204\n",
            "Epoch 16/35\n",
            "818/818 [==============================] - 0s 122us/sample - loss: 21.4573 - val_loss: 21.1164\n",
            "Epoch 17/35\n",
            "818/818 [==============================] - 0s 127us/sample - loss: 21.4536 - val_loss: 21.1119\n",
            "Epoch 18/35\n",
            "818/818 [==============================] - 0s 119us/sample - loss: 21.4496 - val_loss: 21.1069\n",
            "Epoch 19/35\n",
            "818/818 [==============================] - 0s 120us/sample - loss: 21.4452 - val_loss: 21.1016\n",
            "Epoch 20/35\n",
            "818/818 [==============================] - 0s 144us/sample - loss: 21.4404 - val_loss: 21.0961\n",
            "Epoch 21/35\n",
            "818/818 [==============================] - 0s 136us/sample - loss: 21.4352 - val_loss: 21.0902\n",
            "Epoch 22/35\n",
            "818/818 [==============================] - 0s 136us/sample - loss: 21.4295 - val_loss: 21.0841\n",
            "Epoch 23/35\n",
            "818/818 [==============================] - 0s 122us/sample - loss: 21.4235 - val_loss: 21.0775\n",
            "Epoch 24/35\n",
            "818/818 [==============================] - 0s 124us/sample - loss: 21.4168 - val_loss: 21.0703\n",
            "Epoch 25/35\n",
            "818/818 [==============================] - 0s 116us/sample - loss: 21.4096 - val_loss: 21.0628\n",
            "Epoch 26/35\n",
            "818/818 [==============================] - 0s 123us/sample - loss: 21.4019 - val_loss: 21.0547\n",
            "Epoch 27/35\n",
            "818/818 [==============================] - 0s 124us/sample - loss: 21.3936 - val_loss: 21.0457\n",
            "Epoch 28/35\n",
            "818/818 [==============================] - 0s 127us/sample - loss: 21.3843 - val_loss: 21.0354\n",
            "Epoch 29/35\n",
            "818/818 [==============================] - 0s 138us/sample - loss: 21.3740 - val_loss: 21.0240\n",
            "Epoch 30/35\n",
            "818/818 [==============================] - 0s 132us/sample - loss: 21.3625 - val_loss: 21.0115\n",
            "Epoch 31/35\n",
            "818/818 [==============================] - 0s 135us/sample - loss: 21.3498 - val_loss: 20.9979\n",
            "Epoch 32/35\n",
            "818/818 [==============================] - 0s 125us/sample - loss: 21.3361 - val_loss: 20.9823\n",
            "Epoch 33/35\n",
            "818/818 [==============================] - 0s 142us/sample - loss: 21.3213 - val_loss: 20.9654\n",
            "Epoch 34/35\n",
            "818/818 [==============================] - 0s 121us/sample - loss: 21.3050 - val_loss: 20.9467\n",
            "Epoch 35/35\n",
            "818/818 [==============================] - 0s 122us/sample - loss: 21.2868 - val_loss: 20.9264\n",
            "[CV]  learning_rate=0.00031701627936568455, n_hidden=3, n_neurons=55, total=   4.4s\n",
            "[CV] learning_rate=0.00031701627936568455, n_hidden=3, n_neurons=55 ..\n",
            "Train on 818 samples, validate on 91 samples\n",
            "Epoch 1/35\n",
            "818/818 [==============================] - 2s 2ms/sample - loss: 21.5636 - val_loss: 21.4471\n",
            "Epoch 2/35\n",
            "818/818 [==============================] - 0s 129us/sample - loss: 21.5620 - val_loss: 21.4459\n",
            "Epoch 3/35\n",
            "818/818 [==============================] - 0s 123us/sample - loss: 21.5601 - val_loss: 21.4445\n",
            "Epoch 4/35\n",
            "818/818 [==============================] - 0s 126us/sample - loss: 21.5581 - val_loss: 21.4428\n",
            "Epoch 5/35\n",
            "818/818 [==============================] - 0s 135us/sample - loss: 21.5558 - val_loss: 21.4410\n",
            "Epoch 6/35\n",
            "818/818 [==============================] - 0s 128us/sample - loss: 21.5533 - val_loss: 21.4390\n",
            "Epoch 7/35\n",
            "818/818 [==============================] - 0s 123us/sample - loss: 21.5506 - val_loss: 21.4369\n",
            "Epoch 8/35\n",
            "818/818 [==============================] - 0s 129us/sample - loss: 21.5477 - val_loss: 21.4347\n",
            "Epoch 9/35\n",
            "818/818 [==============================] - 0s 114us/sample - loss: 21.5446 - val_loss: 21.4323\n",
            "Epoch 10/35\n",
            "818/818 [==============================] - 0s 120us/sample - loss: 21.5413 - val_loss: 21.4296\n",
            "Epoch 11/35\n",
            "818/818 [==============================] - 0s 125us/sample - loss: 21.5377 - val_loss: 21.4267\n",
            "Epoch 12/35\n",
            "818/818 [==============================] - 0s 134us/sample - loss: 21.5337 - val_loss: 21.4236\n",
            "Epoch 13/35\n",
            "818/818 [==============================] - 0s 116us/sample - loss: 21.5294 - val_loss: 21.4202\n",
            "Epoch 14/35\n",
            "818/818 [==============================] - 0s 126us/sample - loss: 21.5249 - val_loss: 21.4166\n",
            "Epoch 15/35\n",
            "818/818 [==============================] - 0s 138us/sample - loss: 21.5202 - val_loss: 21.4129\n",
            "Epoch 16/35\n",
            "818/818 [==============================] - 0s 117us/sample - loss: 21.5152 - val_loss: 21.4089\n",
            "Epoch 17/35\n",
            "818/818 [==============================] - 0s 122us/sample - loss: 21.5101 - val_loss: 21.4047\n",
            "Epoch 18/35\n",
            "818/818 [==============================] - 0s 138us/sample - loss: 21.5048 - val_loss: 21.4004\n",
            "Epoch 19/35\n",
            "818/818 [==============================] - 0s 123us/sample - loss: 21.4993 - val_loss: 21.3958\n",
            "Epoch 20/35\n",
            "818/818 [==============================] - 0s 134us/sample - loss: 21.4935 - val_loss: 21.3910\n",
            "Epoch 21/35\n",
            "818/818 [==============================] - 0s 125us/sample - loss: 21.4875 - val_loss: 21.3860\n",
            "Epoch 22/35\n",
            "818/818 [==============================] - 0s 124us/sample - loss: 21.4813 - val_loss: 21.3808\n",
            "Epoch 23/35\n",
            "818/818 [==============================] - 0s 120us/sample - loss: 21.4748 - val_loss: 21.3755\n",
            "Epoch 24/35\n",
            "818/818 [==============================] - 0s 125us/sample - loss: 21.4681 - val_loss: 21.3701\n",
            "Epoch 25/35\n",
            "818/818 [==============================] - 0s 146us/sample - loss: 21.4612 - val_loss: 21.3644\n",
            "Epoch 26/35\n",
            "818/818 [==============================] - 0s 120us/sample - loss: 21.4539 - val_loss: 21.3584\n",
            "Epoch 27/35\n",
            "818/818 [==============================] - 0s 120us/sample - loss: 21.4463 - val_loss: 21.3517\n",
            "Epoch 28/35\n",
            "818/818 [==============================] - 0s 137us/sample - loss: 21.4385 - val_loss: 21.3448\n",
            "Epoch 29/35\n",
            "818/818 [==============================] - 0s 125us/sample - loss: 21.4304 - val_loss: 21.3375\n",
            "Epoch 30/35\n",
            "818/818 [==============================] - 0s 138us/sample - loss: 21.4220 - val_loss: 21.3297\n",
            "Epoch 31/35\n",
            "818/818 [==============================] - 0s 120us/sample - loss: 21.4133 - val_loss: 21.3217\n",
            "Epoch 32/35\n",
            "818/818 [==============================] - 0s 135us/sample - loss: 21.4042 - val_loss: 21.3133\n",
            "Epoch 33/35\n",
            "818/818 [==============================] - 0s 118us/sample - loss: 21.3947 - val_loss: 21.3045\n",
            "Epoch 34/35\n",
            "818/818 [==============================] - 0s 154us/sample - loss: 21.3850 - val_loss: 21.2951\n",
            "Epoch 35/35\n",
            "818/818 [==============================] - 0s 129us/sample - loss: 21.3748 - val_loss: 21.2851\n",
            "[CV]  learning_rate=0.00031701627936568455, n_hidden=3, n_neurons=55, total=   5.6s\n",
            "[CV] learning_rate=0.017592175885245052, n_hidden=1, n_neurons=79 ....\n",
            "Train on 817 samples, validate on 91 samples\n",
            "Epoch 1/35\n",
            "817/817 [==============================] - 0s 603us/sample - loss: 20.4236 - val_loss: 18.4560\n",
            "Epoch 2/35\n",
            "817/817 [==============================] - 0s 114us/sample - loss: 17.0999 - val_loss: 13.5364\n",
            "Epoch 3/35\n",
            "817/817 [==============================] - 0s 122us/sample - loss: 12.8135 - val_loss: 10.9567\n",
            "Epoch 4/35\n",
            "817/817 [==============================] - 0s 123us/sample - loss: 10.3539 - val_loss: 9.9642\n",
            "Epoch 5/35\n",
            "817/817 [==============================] - 0s 127us/sample - loss: 9.4312 - val_loss: 9.6178\n",
            "Epoch 6/35\n",
            "817/817 [==============================] - 0s 115us/sample - loss: 8.8284 - val_loss: 9.1419\n",
            "Epoch 7/35\n",
            "817/817 [==============================] - 0s 133us/sample - loss: 8.1930 - val_loss: 8.3894\n",
            "Epoch 8/35\n",
            "817/817 [==============================] - 0s 117us/sample - loss: 7.5303 - val_loss: 7.7456\n",
            "Epoch 9/35\n",
            "817/817 [==============================] - 0s 121us/sample - loss: 6.8409 - val_loss: 7.1069\n",
            "Epoch 10/35\n",
            "817/817 [==============================] - 0s 121us/sample - loss: 6.1829 - val_loss: 6.4947\n",
            "Epoch 11/35\n",
            "817/817 [==============================] - 0s 119us/sample - loss: 5.5391 - val_loss: 5.8279\n",
            "Epoch 12/35\n",
            "817/817 [==============================] - 0s 120us/sample - loss: 4.9571 - val_loss: 5.2325\n",
            "Epoch 13/35\n",
            "817/817 [==============================] - 0s 131us/sample - loss: 4.4165 - val_loss: 4.7086\n",
            "Epoch 14/35\n",
            "817/817 [==============================] - 0s 124us/sample - loss: 4.0284 - val_loss: 4.3031\n",
            "Epoch 15/35\n",
            "817/817 [==============================] - 0s 116us/sample - loss: 3.7692 - val_loss: 4.0459\n",
            "Epoch 16/35\n",
            "817/817 [==============================] - 0s 119us/sample - loss: 3.6139 - val_loss: 3.9038\n",
            "Epoch 17/35\n",
            "817/817 [==============================] - 0s 118us/sample - loss: 3.4922 - val_loss: 3.8095\n",
            "Epoch 18/35\n",
            "817/817 [==============================] - 0s 129us/sample - loss: 3.3908 - val_loss: 3.7447\n",
            "Epoch 19/35\n",
            "817/817 [==============================] - 0s 132us/sample - loss: 3.3130 - val_loss: 3.6462\n",
            "Epoch 20/35\n",
            "817/817 [==============================] - 0s 135us/sample - loss: 3.2405 - val_loss: 3.6255\n",
            "Epoch 21/35\n",
            "817/817 [==============================] - 0s 130us/sample - loss: 3.1764 - val_loss: 3.6091\n",
            "Epoch 22/35\n",
            "817/817 [==============================] - 0s 120us/sample - loss: 3.1391 - val_loss: 3.5600\n",
            "Epoch 23/35\n",
            "817/817 [==============================] - 0s 123us/sample - loss: 3.0833 - val_loss: 3.5752\n",
            "Epoch 24/35\n",
            "817/817 [==============================] - 0s 126us/sample - loss: 3.0457 - val_loss: 3.5572\n",
            "Epoch 25/35\n",
            "817/817 [==============================] - 0s 114us/sample - loss: 3.0232 - val_loss: 3.5749\n",
            "Epoch 26/35\n",
            "817/817 [==============================] - 0s 130us/sample - loss: 2.9807 - val_loss: 3.4991\n",
            "Epoch 27/35\n",
            "817/817 [==============================] - 0s 133us/sample - loss: 2.9468 - val_loss: 3.4978\n",
            "Epoch 28/35\n",
            "817/817 [==============================] - 0s 117us/sample - loss: 2.9242 - val_loss: 3.4795\n",
            "Epoch 29/35\n",
            "817/817 [==============================] - 0s 121us/sample - loss: 2.9177 - val_loss: 3.4594\n",
            "Epoch 30/35\n",
            "817/817 [==============================] - 0s 117us/sample - loss: 2.8837 - val_loss: 3.4737\n",
            "Epoch 31/35\n",
            "817/817 [==============================] - 0s 112us/sample - loss: 2.8710 - val_loss: 3.5236\n",
            "Epoch 32/35\n",
            "817/817 [==============================] - 0s 115us/sample - loss: 2.8547 - val_loss: 3.4623\n",
            "Epoch 33/35\n",
            "817/817 [==============================] - 0s 137us/sample - loss: 2.8227 - val_loss: 3.4248\n",
            "Epoch 34/35\n",
            "817/817 [==============================] - 0s 118us/sample - loss: 2.8120 - val_loss: 3.4204\n",
            "Epoch 35/35\n",
            "817/817 [==============================] - 0s 112us/sample - loss: 2.7938 - val_loss: 3.5096\n",
            "[CV]  learning_rate=0.017592175885245052, n_hidden=1, n_neurons=79, total=   4.2s\n",
            "[CV] learning_rate=0.017592175885245052, n_hidden=1, n_neurons=79 ....\n",
            "Train on 818 samples, validate on 91 samples\n",
            "Epoch 1/35\n",
            "818/818 [==============================] - 0s 592us/sample - loss: 20.4434 - val_loss: 18.4236\n",
            "Epoch 2/35\n",
            "818/818 [==============================] - 0s 122us/sample - loss: 16.9573 - val_loss: 13.2396\n",
            "Epoch 3/35\n",
            "818/818 [==============================] - 0s 136us/sample - loss: 12.2165 - val_loss: 10.5241\n",
            "Epoch 4/35\n",
            "818/818 [==============================] - 0s 134us/sample - loss: 9.9319 - val_loss: 10.2614\n",
            "Epoch 5/35\n",
            "818/818 [==============================] - 0s 117us/sample - loss: 9.1972 - val_loss: 9.7799\n",
            "Epoch 6/35\n",
            "818/818 [==============================] - 0s 109us/sample - loss: 8.6087 - val_loss: 9.1874\n",
            "Epoch 7/35\n",
            "818/818 [==============================] - 0s 115us/sample - loss: 7.9621 - val_loss: 8.5591\n",
            "Epoch 8/35\n",
            "818/818 [==============================] - 0s 121us/sample - loss: 7.2842 - val_loss: 7.8724\n",
            "Epoch 9/35\n",
            "818/818 [==============================] - 0s 126us/sample - loss: 6.6320 - val_loss: 7.1127\n",
            "Epoch 10/35\n",
            "818/818 [==============================] - 0s 115us/sample - loss: 6.0141 - val_loss: 6.4675\n",
            "Epoch 11/35\n",
            "818/818 [==============================] - 0s 122us/sample - loss: 5.4392 - val_loss: 5.9293\n",
            "Epoch 12/35\n",
            "818/818 [==============================] - 0s 114us/sample - loss: 4.9169 - val_loss: 5.4453\n",
            "Epoch 13/35\n",
            "818/818 [==============================] - 0s 127us/sample - loss: 4.4661 - val_loss: 4.9752\n",
            "Epoch 14/35\n",
            "818/818 [==============================] - 0s 111us/sample - loss: 4.1199 - val_loss: 4.6149\n",
            "Epoch 15/35\n",
            "818/818 [==============================] - 0s 132us/sample - loss: 3.8910 - val_loss: 4.4052\n",
            "Epoch 16/35\n",
            "818/818 [==============================] - 0s 120us/sample - loss: 3.7280 - val_loss: 4.1131\n",
            "Epoch 17/35\n",
            "818/818 [==============================] - 0s 113us/sample - loss: 3.5902 - val_loss: 4.0435\n",
            "Epoch 18/35\n",
            "818/818 [==============================] - 0s 120us/sample - loss: 3.4862 - val_loss: 3.9182\n",
            "Epoch 19/35\n",
            "818/818 [==============================] - 0s 125us/sample - loss: 3.4060 - val_loss: 3.8786\n",
            "Epoch 20/35\n",
            "818/818 [==============================] - 0s 119us/sample - loss: 3.3375 - val_loss: 3.7821\n",
            "Epoch 21/35\n",
            "818/818 [==============================] - 0s 112us/sample - loss: 3.3024 - val_loss: 3.8513\n",
            "Epoch 22/35\n",
            "818/818 [==============================] - 0s 120us/sample - loss: 3.2297 - val_loss: 3.7300\n",
            "Epoch 23/35\n",
            "818/818 [==============================] - 0s 129us/sample - loss: 3.1803 - val_loss: 3.8104\n",
            "Epoch 24/35\n",
            "818/818 [==============================] - 0s 119us/sample - loss: 3.1441 - val_loss: 3.7371\n",
            "Epoch 25/35\n",
            "818/818 [==============================] - 0s 112us/sample - loss: 3.1312 - val_loss: 3.7354\n",
            "Epoch 26/35\n",
            "818/818 [==============================] - 0s 122us/sample - loss: 3.0899 - val_loss: 3.6636\n",
            "Epoch 27/35\n",
            "818/818 [==============================] - 0s 112us/sample - loss: 3.0577 - val_loss: 3.7057\n",
            "Epoch 28/35\n",
            "818/818 [==============================] - 0s 129us/sample - loss: 3.0245 - val_loss: 3.6379\n",
            "Epoch 29/35\n",
            "818/818 [==============================] - 0s 125us/sample - loss: 3.0209 - val_loss: 3.6500\n",
            "Epoch 30/35\n",
            "818/818 [==============================] - 0s 116us/sample - loss: 2.9829 - val_loss: 3.6341\n",
            "Epoch 31/35\n",
            "818/818 [==============================] - 0s 133us/sample - loss: 2.9498 - val_loss: 3.6213\n",
            "Epoch 32/35\n",
            "818/818 [==============================] - 0s 114us/sample - loss: 2.9259 - val_loss: 3.7328\n",
            "Epoch 33/35\n",
            "818/818 [==============================] - 0s 146us/sample - loss: 2.9251 - val_loss: 3.6146\n",
            "Epoch 34/35\n",
            "818/818 [==============================] - 0s 115us/sample - loss: 2.9143 - val_loss: 3.6795\n",
            "Epoch 35/35\n",
            "818/818 [==============================] - 0s 115us/sample - loss: 2.9086 - val_loss: 3.6846\n",
            "[CV]  learning_rate=0.017592175885245052, n_hidden=1, n_neurons=79, total=   4.1s\n",
            "[CV] learning_rate=0.017592175885245052, n_hidden=1, n_neurons=79 ....\n",
            "Train on 818 samples, validate on 91 samples\n",
            "Epoch 1/35\n",
            "818/818 [==============================] - 0s 593us/sample - loss: 19.7366 - val_loss: 18.3038\n",
            "Epoch 2/35\n",
            "818/818 [==============================] - 0s 130us/sample - loss: 15.5423 - val_loss: 14.1898\n",
            "Epoch 3/35\n",
            "818/818 [==============================] - 0s 120us/sample - loss: 12.3904 - val_loss: 11.5039\n",
            "Epoch 4/35\n",
            "818/818 [==============================] - 0s 114us/sample - loss: 10.2679 - val_loss: 9.6186\n",
            "Epoch 5/35\n",
            "818/818 [==============================] - 0s 117us/sample - loss: 9.1897 - val_loss: 8.9485\n",
            "Epoch 6/35\n",
            "818/818 [==============================] - 0s 115us/sample - loss: 8.6261 - val_loss: 8.3497\n",
            "Epoch 7/35\n",
            "818/818 [==============================] - 0s 120us/sample - loss: 8.0547 - val_loss: 7.7356\n",
            "Epoch 8/35\n",
            "818/818 [==============================] - 0s 120us/sample - loss: 7.4731 - val_loss: 7.2057\n",
            "Epoch 9/35\n",
            "818/818 [==============================] - 0s 131us/sample - loss: 6.8773 - val_loss: 6.6934\n",
            "Epoch 10/35\n",
            "818/818 [==============================] - 0s 121us/sample - loss: 6.2722 - val_loss: 6.1404\n",
            "Epoch 11/35\n",
            "818/818 [==============================] - 0s 113us/sample - loss: 5.6801 - val_loss: 5.5916\n",
            "Epoch 12/35\n",
            "818/818 [==============================] - 0s 126us/sample - loss: 5.1532 - val_loss: 5.1476\n",
            "Epoch 13/35\n",
            "818/818 [==============================] - 0s 128us/sample - loss: 4.6864 - val_loss: 4.7621\n",
            "Epoch 14/35\n",
            "818/818 [==============================] - 0s 118us/sample - loss: 4.2994 - val_loss: 4.4966\n",
            "Epoch 15/35\n",
            "818/818 [==============================] - 0s 118us/sample - loss: 4.0184 - val_loss: 4.2490\n",
            "Epoch 16/35\n",
            "818/818 [==============================] - 0s 115us/sample - loss: 3.8254 - val_loss: 4.1361\n",
            "Epoch 17/35\n",
            "818/818 [==============================] - 0s 112us/sample - loss: 3.6838 - val_loss: 4.0465\n",
            "Epoch 18/35\n",
            "818/818 [==============================] - 0s 127us/sample - loss: 3.5824 - val_loss: 3.9147\n",
            "Epoch 19/35\n",
            "818/818 [==============================] - 0s 128us/sample - loss: 3.4648 - val_loss: 3.8678\n",
            "Epoch 20/35\n",
            "818/818 [==============================] - 0s 120us/sample - loss: 3.3989 - val_loss: 3.7061\n",
            "Epoch 21/35\n",
            "818/818 [==============================] - 0s 115us/sample - loss: 3.3358 - val_loss: 3.6444\n",
            "Epoch 22/35\n",
            "818/818 [==============================] - 0s 120us/sample - loss: 3.2860 - val_loss: 3.5963\n",
            "Epoch 23/35\n",
            "818/818 [==============================] - 0s 130us/sample - loss: 3.2383 - val_loss: 3.5840\n",
            "Epoch 24/35\n",
            "818/818 [==============================] - 0s 112us/sample - loss: 3.1858 - val_loss: 3.5369\n",
            "Epoch 25/35\n",
            "818/818 [==============================] - 0s 117us/sample - loss: 3.1522 - val_loss: 3.5037\n",
            "Epoch 26/35\n",
            "818/818 [==============================] - 0s 116us/sample - loss: 3.1149 - val_loss: 3.4591\n",
            "Epoch 27/35\n",
            "818/818 [==============================] - 0s 122us/sample - loss: 3.0904 - val_loss: 3.4149\n",
            "Epoch 28/35\n",
            "818/818 [==============================] - 0s 117us/sample - loss: 3.0574 - val_loss: 3.5728\n",
            "Epoch 29/35\n",
            "818/818 [==============================] - 0s 122us/sample - loss: 3.0656 - val_loss: 3.3946\n",
            "Epoch 30/35\n",
            "818/818 [==============================] - 0s 125us/sample - loss: 3.0008 - val_loss: 3.4000\n",
            "Epoch 31/35\n",
            "818/818 [==============================] - 0s 122us/sample - loss: 2.9805 - val_loss: 3.3778\n",
            "Epoch 32/35\n",
            "818/818 [==============================] - 0s 116us/sample - loss: 2.9657 - val_loss: 3.4387\n",
            "Epoch 33/35\n",
            "818/818 [==============================] - 0s 133us/sample - loss: 2.9595 - val_loss: 3.3920\n",
            "Epoch 34/35\n",
            "818/818 [==============================] - 0s 115us/sample - loss: 2.9337 - val_loss: 3.4114\n",
            "Epoch 35/35\n",
            "818/818 [==============================] - 0s 119us/sample - loss: 2.9118 - val_loss: 3.3749\n",
            "[CV]  learning_rate=0.017592175885245052, n_hidden=1, n_neurons=79, total=   4.1s\n",
            "[CV] learning_rate=0.002496620415935347, n_hidden=2, n_neurons=12 ....\n",
            "Train on 817 samples, validate on 91 samples\n",
            "Epoch 1/35\n",
            "817/817 [==============================] - 1s 635us/sample - loss: 21.3223 - val_loss: 21.0253\n",
            "Epoch 2/35\n",
            "817/817 [==============================] - 0s 144us/sample - loss: 21.2906 - val_loss: 20.9842\n",
            "Epoch 3/35\n",
            "817/817 [==============================] - 0s 118us/sample - loss: 21.2514 - val_loss: 20.9340\n",
            "Epoch 4/35\n",
            "817/817 [==============================] - 0s 121us/sample - loss: 21.2042 - val_loss: 20.8721\n",
            "Epoch 5/35\n",
            "817/817 [==============================] - 0s 122us/sample - loss: 21.1487 - val_loss: 20.8007\n",
            "Epoch 6/35\n",
            "817/817 [==============================] - 0s 126us/sample - loss: 21.0850 - val_loss: 20.7187\n",
            "Epoch 7/35\n",
            "817/817 [==============================] - 0s 131us/sample - loss: 21.0115 - val_loss: 20.6252\n",
            "Epoch 8/35\n",
            "817/817 [==============================] - 0s 141us/sample - loss: 20.9270 - val_loss: 20.5176\n",
            "Epoch 9/35\n",
            "817/817 [==============================] - 0s 132us/sample - loss: 20.8286 - val_loss: 20.3928\n",
            "Epoch 10/35\n",
            "817/817 [==============================] - 0s 121us/sample - loss: 20.7147 - val_loss: 20.2491\n",
            "Epoch 11/35\n",
            "817/817 [==============================] - 0s 125us/sample - loss: 20.5825 - val_loss: 20.0802\n",
            "Epoch 12/35\n",
            "817/817 [==============================] - 0s 122us/sample - loss: 20.4247 - val_loss: 19.8789\n",
            "Epoch 13/35\n",
            "817/817 [==============================] - 0s 115us/sample - loss: 20.2303 - val_loss: 19.6273\n",
            "Epoch 14/35\n",
            "817/817 [==============================] - 0s 126us/sample - loss: 19.9764 - val_loss: 19.2867\n",
            "Epoch 15/35\n",
            "817/817 [==============================] - 0s 125us/sample - loss: 19.6441 - val_loss: 18.8459\n",
            "Epoch 16/35\n",
            "817/817 [==============================] - 0s 123us/sample - loss: 19.2115 - val_loss: 18.2687\n",
            "Epoch 17/35\n",
            "817/817 [==============================] - 0s 131us/sample - loss: 18.6215 - val_loss: 17.4774\n",
            "Epoch 18/35\n",
            "817/817 [==============================] - 0s 118us/sample - loss: 17.7897 - val_loss: 16.3638\n",
            "Epoch 19/35\n",
            "817/817 [==============================] - 0s 129us/sample - loss: 16.6219 - val_loss: 14.7710\n",
            "Epoch 20/35\n",
            "817/817 [==============================] - 0s 120us/sample - loss: 15.0588 - val_loss: 13.3388\n",
            "Epoch 21/35\n",
            "817/817 [==============================] - 0s 135us/sample - loss: 13.5811 - val_loss: 12.5900\n",
            "Epoch 22/35\n",
            "817/817 [==============================] - 0s 135us/sample - loss: 12.5131 - val_loss: 12.1808\n",
            "Epoch 23/35\n",
            "817/817 [==============================] - 0s 137us/sample - loss: 11.9408 - val_loss: 12.0177\n",
            "Epoch 24/35\n",
            "817/817 [==============================] - 0s 125us/sample - loss: 11.6278 - val_loss: 12.0401\n",
            "Epoch 25/35\n",
            "817/817 [==============================] - 0s 121us/sample - loss: 11.4273 - val_loss: 12.0406\n",
            "Epoch 26/35\n",
            "817/817 [==============================] - 0s 120us/sample - loss: 11.2556 - val_loss: 11.8508\n",
            "Epoch 27/35\n",
            "817/817 [==============================] - 0s 123us/sample - loss: 10.7632 - val_loss: 11.2755\n",
            "Epoch 28/35\n",
            "817/817 [==============================] - 0s 117us/sample - loss: 10.2239 - val_loss: 10.8765\n",
            "Epoch 29/35\n",
            "817/817 [==============================] - 0s 130us/sample - loss: 9.8370 - val_loss: 10.5652\n",
            "Epoch 30/35\n",
            "817/817 [==============================] - 0s 118us/sample - loss: 9.5580 - val_loss: 10.3784\n",
            "Epoch 31/35\n",
            "817/817 [==============================] - 0s 131us/sample - loss: 9.3203 - val_loss: 10.2325\n",
            "Epoch 32/35\n",
            "817/817 [==============================] - 0s 127us/sample - loss: 9.1105 - val_loss: 10.0849\n",
            "Epoch 33/35\n",
            "817/817 [==============================] - 0s 131us/sample - loss: 8.9043 - val_loss: 9.8799\n",
            "Epoch 34/35\n",
            "817/817 [==============================] - 0s 120us/sample - loss: 8.6923 - val_loss: 9.7294\n",
            "Epoch 35/35\n",
            "817/817 [==============================] - 0s 126us/sample - loss: 8.4854 - val_loss: 9.5427\n",
            "[CV]  learning_rate=0.002496620415935347, n_hidden=2, n_neurons=12, total=   4.3s\n",
            "[CV] learning_rate=0.002496620415935347, n_hidden=2, n_neurons=12 ....\n",
            "Train on 818 samples, validate on 91 samples\n",
            "Epoch 1/35\n",
            "818/818 [==============================] - 1s 659us/sample - loss: 21.4351 - val_loss: 21.0753\n",
            "Epoch 2/35\n",
            "818/818 [==============================] - 0s 123us/sample - loss: 21.4085 - val_loss: 21.0358\n",
            "Epoch 3/35\n",
            "818/818 [==============================] - 0s 126us/sample - loss: 21.3710 - val_loss: 20.9857\n",
            "Epoch 4/35\n",
            "818/818 [==============================] - 0s 126us/sample - loss: 21.3239 - val_loss: 20.9252\n",
            "Epoch 5/35\n",
            "818/818 [==============================] - 0s 120us/sample - loss: 21.2670 - val_loss: 20.8535\n",
            "Epoch 6/35\n",
            "818/818 [==============================] - 0s 116us/sample - loss: 21.2000 - val_loss: 20.7713\n",
            "Epoch 7/35\n",
            "818/818 [==============================] - 0s 120us/sample - loss: 21.1225 - val_loss: 20.6754\n",
            "Epoch 8/35\n",
            "818/818 [==============================] - 0s 136us/sample - loss: 21.0331 - val_loss: 20.5608\n",
            "Epoch 9/35\n",
            "818/818 [==============================] - 0s 128us/sample - loss: 20.9271 - val_loss: 20.4219\n",
            "Epoch 10/35\n",
            "818/818 [==============================] - 0s 128us/sample - loss: 20.7962 - val_loss: 20.2497\n",
            "Epoch 11/35\n",
            "818/818 [==============================] - 0s 119us/sample - loss: 20.6328 - val_loss: 20.0339\n",
            "Epoch 12/35\n",
            "818/818 [==============================] - 0s 129us/sample - loss: 20.4240 - val_loss: 19.7563\n",
            "Epoch 13/35\n",
            "818/818 [==============================] - 0s 121us/sample - loss: 20.1589 - val_loss: 19.4015\n",
            "Epoch 14/35\n",
            "818/818 [==============================] - 0s 128us/sample - loss: 19.8243 - val_loss: 18.9548\n",
            "Epoch 15/35\n",
            "818/818 [==============================] - 0s 120us/sample - loss: 19.3994 - val_loss: 18.3805\n",
            "Epoch 16/35\n",
            "818/818 [==============================] - 0s 118us/sample - loss: 18.8490 - val_loss: 17.6287\n",
            "Epoch 17/35\n",
            "818/818 [==============================] - 0s 119us/sample - loss: 18.1269 - val_loss: 16.6872\n",
            "Epoch 18/35\n",
            "818/818 [==============================] - 0s 129us/sample - loss: 17.3167 - val_loss: 15.9686\n",
            "Epoch 19/35\n",
            "818/818 [==============================] - 0s 142us/sample - loss: 16.6150 - val_loss: 15.6202\n",
            "Epoch 20/35\n",
            "818/818 [==============================] - 0s 123us/sample - loss: 16.1237 - val_loss: 15.3686\n",
            "Epoch 21/35\n",
            "818/818 [==============================] - 0s 122us/sample - loss: 15.7253 - val_loss: 15.0699\n",
            "Epoch 22/35\n",
            "818/818 [==============================] - 0s 124us/sample - loss: 15.2935 - val_loss: 14.6449\n",
            "Epoch 23/35\n",
            "818/818 [==============================] - 0s 120us/sample - loss: 14.7529 - val_loss: 14.2700\n",
            "Epoch 24/35\n",
            "818/818 [==============================] - 0s 115us/sample - loss: 14.2341 - val_loss: 14.0777\n",
            "Epoch 25/35\n",
            "818/818 [==============================] - 0s 128us/sample - loss: 13.8388 - val_loss: 14.0214\n",
            "Epoch 26/35\n",
            "818/818 [==============================] - 0s 119us/sample - loss: 13.5845 - val_loss: 13.9712\n",
            "Epoch 27/35\n",
            "818/818 [==============================] - 0s 125us/sample - loss: 13.4104 - val_loss: 13.9334\n",
            "Epoch 28/35\n",
            "818/818 [==============================] - 0s 130us/sample - loss: 13.2614 - val_loss: 13.8522\n",
            "Epoch 29/35\n",
            "818/818 [==============================] - 0s 165us/sample - loss: 13.1323 - val_loss: 13.7368\n",
            "Epoch 30/35\n",
            "818/818 [==============================] - 0s 125us/sample - loss: 13.0079 - val_loss: 13.6383\n",
            "Epoch 31/35\n",
            "818/818 [==============================] - 0s 121us/sample - loss: 12.8796 - val_loss: 13.5197\n",
            "Epoch 32/35\n",
            "818/818 [==============================] - 0s 120us/sample - loss: 12.7421 - val_loss: 13.3770\n",
            "Epoch 33/35\n",
            "818/818 [==============================] - 0s 129us/sample - loss: 12.6016 - val_loss: 13.2134\n",
            "Epoch 34/35\n",
            "818/818 [==============================] - 0s 119us/sample - loss: 12.4551 - val_loss: 13.0667\n",
            "Epoch 35/35\n",
            "818/818 [==============================] - 0s 116us/sample - loss: 12.3003 - val_loss: 12.9212\n",
            "[CV]  learning_rate=0.002496620415935347, n_hidden=2, n_neurons=12, total=   4.3s\n",
            "[CV] learning_rate=0.002496620415935347, n_hidden=2, n_neurons=12 ....\n",
            "Train on 818 samples, validate on 91 samples\n",
            "Epoch 1/35\n",
            "818/818 [==============================] - 1s 663us/sample - loss: 21.4400 - val_loss: 21.2743\n",
            "Epoch 2/35\n",
            "818/818 [==============================] - 0s 129us/sample - loss: 21.3921 - val_loss: 21.2150\n",
            "Epoch 3/35\n",
            "818/818 [==============================] - 0s 130us/sample - loss: 21.3306 - val_loss: 21.1425\n",
            "Epoch 4/35\n",
            "818/818 [==============================] - 0s 115us/sample - loss: 21.2539 - val_loss: 21.0561\n",
            "Epoch 5/35\n",
            "818/818 [==============================] - 0s 121us/sample - loss: 21.1615 - val_loss: 20.9525\n",
            "Epoch 6/35\n",
            "818/818 [==============================] - 0s 129us/sample - loss: 21.0567 - val_loss: 20.8329\n",
            "Epoch 7/35\n",
            "818/818 [==============================] - 0s 153us/sample - loss: 20.9379 - val_loss: 20.6979\n",
            "Epoch 8/35\n",
            "818/818 [==============================] - 0s 132us/sample - loss: 20.8025 - val_loss: 20.5436\n",
            "Epoch 9/35\n",
            "818/818 [==============================] - 0s 126us/sample - loss: 20.6465 - val_loss: 20.3642\n",
            "Epoch 10/35\n",
            "818/818 [==============================] - 0s 121us/sample - loss: 20.4625 - val_loss: 20.1513\n",
            "Epoch 11/35\n",
            "818/818 [==============================] - 0s 132us/sample - loss: 20.2409 - val_loss: 19.8944\n",
            "Epoch 12/35\n",
            "818/818 [==============================] - 0s 120us/sample - loss: 19.9695 - val_loss: 19.5767\n",
            "Epoch 13/35\n",
            "818/818 [==============================] - 0s 117us/sample - loss: 19.6292 - val_loss: 19.1763\n",
            "Epoch 14/35\n",
            "818/818 [==============================] - 0s 131us/sample - loss: 19.1935 - val_loss: 18.6629\n",
            "Epoch 15/35\n",
            "818/818 [==============================] - 0s 122us/sample - loss: 18.6236 - val_loss: 17.9866\n",
            "Epoch 16/35\n",
            "818/818 [==============================] - 0s 129us/sample - loss: 17.8555 - val_loss: 17.0652\n",
            "Epoch 17/35\n",
            "818/818 [==============================] - 0s 138us/sample - loss: 16.8050 - val_loss: 15.9625\n",
            "Epoch 18/35\n",
            "818/818 [==============================] - 0s 122us/sample - loss: 15.6252 - val_loss: 14.9495\n",
            "Epoch 19/35\n",
            "818/818 [==============================] - 0s 120us/sample - loss: 14.6628 - val_loss: 14.1342\n",
            "Epoch 20/35\n",
            "818/818 [==============================] - 0s 128us/sample - loss: 14.0811 - val_loss: 13.6054\n",
            "Epoch 21/35\n",
            "818/818 [==============================] - 0s 142us/sample - loss: 13.7805 - val_loss: 13.3321\n",
            "Epoch 22/35\n",
            "818/818 [==============================] - 0s 132us/sample - loss: 13.6311 - val_loss: 13.2080\n",
            "Epoch 23/35\n",
            "818/818 [==============================] - 0s 127us/sample - loss: 13.5249 - val_loss: 13.1175\n",
            "Epoch 24/35\n",
            "818/818 [==============================] - 0s 117us/sample - loss: 13.4264 - val_loss: 13.0232\n",
            "Epoch 25/35\n",
            "818/818 [==============================] - 0s 122us/sample - loss: 13.3281 - val_loss: 12.9275\n",
            "Epoch 26/35\n",
            "818/818 [==============================] - 0s 130us/sample - loss: 13.2274 - val_loss: 12.8255\n",
            "Epoch 27/35\n",
            "818/818 [==============================] - 0s 142us/sample - loss: 13.1171 - val_loss: 12.7201\n",
            "Epoch 28/35\n",
            "818/818 [==============================] - 0s 120us/sample - loss: 13.0014 - val_loss: 12.6083\n",
            "Epoch 29/35\n",
            "818/818 [==============================] - 0s 121us/sample - loss: 12.8791 - val_loss: 12.4953\n",
            "Epoch 30/35\n",
            "818/818 [==============================] - 0s 119us/sample - loss: 12.7489 - val_loss: 12.3702\n",
            "Epoch 31/35\n",
            "818/818 [==============================] - 0s 126us/sample - loss: 12.6062 - val_loss: 12.2452\n",
            "Epoch 32/35\n",
            "818/818 [==============================] - 0s 128us/sample - loss: 12.4560 - val_loss: 12.1092\n",
            "Epoch 33/35\n",
            "818/818 [==============================] - 0s 124us/sample - loss: 12.2966 - val_loss: 11.9693\n",
            "Epoch 34/35\n",
            "818/818 [==============================] - 0s 119us/sample - loss: 12.1263 - val_loss: 11.8222\n",
            "Epoch 35/35\n",
            "818/818 [==============================] - 0s 142us/sample - loss: 11.9502 - val_loss: 11.6639\n",
            "[CV]  learning_rate=0.002496620415935347, n_hidden=2, n_neurons=12, total=   4.4s\n",
            "[CV] learning_rate=0.015618437282778579, n_hidden=1, n_neurons=72 ....\n",
            "Train on 817 samples, validate on 91 samples\n",
            "Epoch 1/35\n",
            "817/817 [==============================] - 1s 632us/sample - loss: 20.6446 - val_loss: 19.3304\n",
            "Epoch 2/35\n",
            "817/817 [==============================] - 0s 125us/sample - loss: 18.4507 - val_loss: 15.7703\n",
            "Epoch 3/35\n",
            "817/817 [==============================] - 0s 118us/sample - loss: 14.5116 - val_loss: 11.3356\n",
            "Epoch 4/35\n",
            "817/817 [==============================] - 0s 121us/sample - loss: 10.9112 - val_loss: 10.1870\n",
            "Epoch 5/35\n",
            "817/817 [==============================] - 0s 125us/sample - loss: 9.7342 - val_loss: 9.9833\n",
            "Epoch 6/35\n",
            "817/817 [==============================] - 0s 118us/sample - loss: 9.1917 - val_loss: 9.5561\n",
            "Epoch 7/35\n",
            "817/817 [==============================] - 0s 119us/sample - loss: 8.6783 - val_loss: 9.1104\n",
            "Epoch 8/35\n",
            "817/817 [==============================] - 0s 118us/sample - loss: 8.1332 - val_loss: 8.5352\n",
            "Epoch 9/35\n",
            "817/817 [==============================] - 0s 116us/sample - loss: 7.5507 - val_loss: 7.9767\n",
            "Epoch 10/35\n",
            "817/817 [==============================] - 0s 122us/sample - loss: 6.9417 - val_loss: 7.3981\n",
            "Epoch 11/35\n",
            "817/817 [==============================] - 0s 125us/sample - loss: 6.3503 - val_loss: 6.7867\n",
            "Epoch 12/35\n",
            "817/817 [==============================] - 0s 122us/sample - loss: 5.7487 - val_loss: 6.1643\n",
            "Epoch 13/35\n",
            "817/817 [==============================] - 0s 121us/sample - loss: 5.2020 - val_loss: 5.6120\n",
            "Epoch 14/35\n",
            "817/817 [==============================] - 0s 146us/sample - loss: 4.7191 - val_loss: 5.2869\n",
            "Epoch 15/35\n",
            "817/817 [==============================] - 0s 134us/sample - loss: 4.3368 - val_loss: 4.8256\n",
            "Epoch 16/35\n",
            "817/817 [==============================] - 0s 120us/sample - loss: 4.0305 - val_loss: 4.5249\n",
            "Epoch 17/35\n",
            "817/817 [==============================] - 0s 120us/sample - loss: 3.8409 - val_loss: 4.3915\n",
            "Epoch 18/35\n",
            "817/817 [==============================] - 0s 116us/sample - loss: 3.6987 - val_loss: 4.2769\n",
            "Epoch 19/35\n",
            "817/817 [==============================] - 0s 116us/sample - loss: 3.5855 - val_loss: 4.0859\n",
            "Epoch 20/35\n",
            "817/817 [==============================] - 0s 116us/sample - loss: 3.4874 - val_loss: 4.1075\n",
            "Epoch 21/35\n",
            "817/817 [==============================] - 0s 114us/sample - loss: 3.4235 - val_loss: 4.0364\n",
            "Epoch 22/35\n",
            "817/817 [==============================] - 0s 127us/sample - loss: 3.3544 - val_loss: 3.9122\n",
            "Epoch 23/35\n",
            "817/817 [==============================] - 0s 113us/sample - loss: 3.2943 - val_loss: 3.7958\n",
            "Epoch 24/35\n",
            "817/817 [==============================] - 0s 113us/sample - loss: 3.2363 - val_loss: 3.8048\n",
            "Epoch 25/35\n",
            "817/817 [==============================] - 0s 131us/sample - loss: 3.1955 - val_loss: 3.7309\n",
            "Epoch 26/35\n",
            "817/817 [==============================] - 0s 120us/sample - loss: 3.1513 - val_loss: 3.7364\n",
            "Epoch 27/35\n",
            "817/817 [==============================] - 0s 131us/sample - loss: 3.1194 - val_loss: 3.7034\n",
            "Epoch 28/35\n",
            "817/817 [==============================] - 0s 120us/sample - loss: 3.0735 - val_loss: 3.7117\n",
            "Epoch 29/35\n",
            "817/817 [==============================] - 0s 110us/sample - loss: 3.0598 - val_loss: 3.6239\n",
            "Epoch 30/35\n",
            "817/817 [==============================] - 0s 127us/sample - loss: 3.0237 - val_loss: 3.5760\n",
            "Epoch 31/35\n",
            "817/817 [==============================] - 0s 124us/sample - loss: 2.9877 - val_loss: 3.5913\n",
            "Epoch 32/35\n",
            "817/817 [==============================] - 0s 122us/sample - loss: 2.9720 - val_loss: 3.5482\n",
            "Epoch 33/35\n",
            "817/817 [==============================] - 0s 124us/sample - loss: 2.9378 - val_loss: 3.5494\n",
            "Epoch 34/35\n",
            "817/817 [==============================] - 0s 127us/sample - loss: 2.9211 - val_loss: 3.5382\n",
            "Epoch 35/35\n",
            "817/817 [==============================] - 0s 132us/sample - loss: 2.9039 - val_loss: 3.5295\n",
            "[CV]  learning_rate=0.015618437282778579, n_hidden=1, n_neurons=72, total=   4.2s\n",
            "[CV] learning_rate=0.015618437282778579, n_hidden=1, n_neurons=72 ....\n",
            "Train on 818 samples, validate on 91 samples\n",
            "Epoch 1/35\n",
            "818/818 [==============================] - 0s 549us/sample - loss: 21.1850 - val_loss: 20.2405\n",
            "Epoch 2/35\n",
            "818/818 [==============================] - 0s 109us/sample - loss: 19.8517 - val_loss: 17.9967\n",
            "Epoch 3/35\n",
            "818/818 [==============================] - 0s 113us/sample - loss: 17.1967 - val_loss: 15.1019\n",
            "Epoch 4/35\n",
            "818/818 [==============================] - 0s 113us/sample - loss: 14.6543 - val_loss: 14.3078\n",
            "Epoch 5/35\n",
            "818/818 [==============================] - 0s 138us/sample - loss: 13.2435 - val_loss: 13.1127\n",
            "Epoch 6/35\n",
            "818/818 [==============================] - 0s 121us/sample - loss: 11.7382 - val_loss: 11.2196\n",
            "Epoch 7/35\n",
            "818/818 [==============================] - 0s 134us/sample - loss: 9.8056 - val_loss: 9.4304\n",
            "Epoch 8/35\n",
            "818/818 [==============================] - 0s 119us/sample - loss: 8.4408 - val_loss: 8.8790\n",
            "Epoch 9/35\n",
            "818/818 [==============================] - 0s 112us/sample - loss: 7.7247 - val_loss: 8.3778\n",
            "Epoch 10/35\n",
            "818/818 [==============================] - 0s 120us/sample - loss: 7.1497 - val_loss: 7.8342\n",
            "Epoch 11/35\n",
            "818/818 [==============================] - 0s 123us/sample - loss: 6.6200 - val_loss: 7.3287\n",
            "Epoch 12/35\n",
            "818/818 [==============================] - 0s 114us/sample - loss: 6.1313 - val_loss: 6.8407\n",
            "Epoch 13/35\n",
            "818/818 [==============================] - 0s 120us/sample - loss: 5.6607 - val_loss: 6.3311\n",
            "Epoch 14/35\n",
            "818/818 [==============================] - 0s 113us/sample - loss: 5.2237 - val_loss: 5.8349\n",
            "Epoch 15/35\n",
            "818/818 [==============================] - 0s 134us/sample - loss: 4.8437 - val_loss: 5.4168\n",
            "Epoch 16/35\n",
            "818/818 [==============================] - 0s 116us/sample - loss: 4.4941 - val_loss: 5.0336\n",
            "Epoch 17/35\n",
            "818/818 [==============================] - 0s 117us/sample - loss: 4.2319 - val_loss: 4.6855\n",
            "Epoch 18/35\n",
            "818/818 [==============================] - 0s 127us/sample - loss: 3.9800 - val_loss: 4.4354\n",
            "Epoch 19/35\n",
            "818/818 [==============================] - 0s 124us/sample - loss: 3.7990 - val_loss: 4.1450\n",
            "Epoch 20/35\n",
            "818/818 [==============================] - 0s 120us/sample - loss: 3.6547 - val_loss: 4.0839\n",
            "Epoch 21/35\n",
            "818/818 [==============================] - 0s 129us/sample - loss: 3.5475 - val_loss: 3.9274\n",
            "Epoch 22/35\n",
            "818/818 [==============================] - 0s 116us/sample - loss: 3.4650 - val_loss: 3.8559\n",
            "Epoch 23/35\n",
            "818/818 [==============================] - 0s 126us/sample - loss: 3.4009 - val_loss: 3.8976\n",
            "Epoch 24/35\n",
            "818/818 [==============================] - 0s 125us/sample - loss: 3.3296 - val_loss: 3.8261\n",
            "Epoch 25/35\n",
            "818/818 [==============================] - 0s 142us/sample - loss: 3.2776 - val_loss: 3.7084\n",
            "Epoch 26/35\n",
            "818/818 [==============================] - 0s 123us/sample - loss: 3.2354 - val_loss: 3.7014\n",
            "Epoch 27/35\n",
            "818/818 [==============================] - 0s 112us/sample - loss: 3.1861 - val_loss: 3.7262\n",
            "Epoch 28/35\n",
            "818/818 [==============================] - 0s 125us/sample - loss: 3.1481 - val_loss: 3.6610\n",
            "Epoch 29/35\n",
            "818/818 [==============================] - 0s 136us/sample - loss: 3.1053 - val_loss: 3.6220\n",
            "Epoch 30/35\n",
            "818/818 [==============================] - 0s 120us/sample - loss: 3.0807 - val_loss: 3.7622\n",
            "Epoch 31/35\n",
            "818/818 [==============================] - 0s 117us/sample - loss: 3.0516 - val_loss: 3.5486\n",
            "Epoch 32/35\n",
            "818/818 [==============================] - 0s 121us/sample - loss: 3.0204 - val_loss: 3.5938\n",
            "Epoch 33/35\n",
            "818/818 [==============================] - 0s 123us/sample - loss: 3.0030 - val_loss: 3.5465\n",
            "Epoch 34/35\n",
            "818/818 [==============================] - 0s 126us/sample - loss: 2.9685 - val_loss: 3.6092\n",
            "Epoch 35/35\n",
            "818/818 [==============================] - 0s 135us/sample - loss: 2.9455 - val_loss: 3.6226\n",
            "[CV]  learning_rate=0.015618437282778579, n_hidden=1, n_neurons=72, total=   4.1s\n",
            "[CV] learning_rate=0.015618437282778579, n_hidden=1, n_neurons=72 ....\n",
            "Train on 818 samples, validate on 91 samples\n",
            "Epoch 1/35\n",
            "818/818 [==============================] - 0s 589us/sample - loss: 21.0025 - val_loss: 20.5700\n",
            "Epoch 2/35\n",
            "818/818 [==============================] - 0s 120us/sample - loss: 19.6556 - val_loss: 19.0266\n",
            "Epoch 3/35\n",
            "818/818 [==============================] - 0s 119us/sample - loss: 17.6244 - val_loss: 16.2143\n",
            "Epoch 4/35\n",
            "818/818 [==============================] - 0s 140us/sample - loss: 13.7750 - val_loss: 11.7837\n",
            "Epoch 5/35\n",
            "818/818 [==============================] - 0s 135us/sample - loss: 10.6896 - val_loss: 9.9366\n",
            "Epoch 6/35\n",
            "818/818 [==============================] - 0s 119us/sample - loss: 9.6821 - val_loss: 9.4210\n",
            "Epoch 7/35\n",
            "818/818 [==============================] - 0s 115us/sample - loss: 9.1555 - val_loss: 9.0153\n",
            "Epoch 8/35\n",
            "818/818 [==============================] - 0s 126us/sample - loss: 8.6785 - val_loss: 8.5633\n",
            "Epoch 9/35\n",
            "818/818 [==============================] - 0s 115us/sample - loss: 8.1719 - val_loss: 8.1082\n",
            "Epoch 10/35\n",
            "818/818 [==============================] - 0s 113us/sample - loss: 7.6490 - val_loss: 7.6290\n",
            "Epoch 11/35\n",
            "818/818 [==============================] - 0s 113us/sample - loss: 7.1373 - val_loss: 7.0912\n",
            "Epoch 12/35\n",
            "818/818 [==============================] - 0s 121us/sample - loss: 6.6203 - val_loss: 6.5861\n",
            "Epoch 13/35\n",
            "818/818 [==============================] - 0s 118us/sample - loss: 6.1125 - val_loss: 6.1477\n",
            "Epoch 14/35\n",
            "818/818 [==============================] - 0s 136us/sample - loss: 5.6183 - val_loss: 5.6492\n",
            "Epoch 15/35\n",
            "818/818 [==============================] - 0s 116us/sample - loss: 5.1579 - val_loss: 5.1931\n",
            "Epoch 16/35\n",
            "818/818 [==============================] - 0s 127us/sample - loss: 4.7344 - val_loss: 4.7498\n",
            "Epoch 17/35\n",
            "818/818 [==============================] - 0s 133us/sample - loss: 4.3732 - val_loss: 4.4783\n",
            "Epoch 18/35\n",
            "818/818 [==============================] - 0s 129us/sample - loss: 4.0964 - val_loss: 4.2142\n",
            "Epoch 19/35\n",
            "818/818 [==============================] - 0s 124us/sample - loss: 3.8937 - val_loss: 4.0981\n",
            "Epoch 20/35\n",
            "818/818 [==============================] - 0s 125us/sample - loss: 3.7650 - val_loss: 3.9558\n",
            "Epoch 21/35\n",
            "818/818 [==============================] - 0s 124us/sample - loss: 3.6464 - val_loss: 3.8553\n",
            "Epoch 22/35\n",
            "818/818 [==============================] - 0s 117us/sample - loss: 3.5615 - val_loss: 3.7840\n",
            "Epoch 23/35\n",
            "818/818 [==============================] - 0s 127us/sample - loss: 3.4757 - val_loss: 3.7366\n",
            "Epoch 24/35\n",
            "818/818 [==============================] - 0s 128us/sample - loss: 3.4034 - val_loss: 3.7125\n",
            "Epoch 25/35\n",
            "818/818 [==============================] - 0s 115us/sample - loss: 3.3606 - val_loss: 3.6649\n",
            "Epoch 26/35\n",
            "818/818 [==============================] - 0s 121us/sample - loss: 3.2903 - val_loss: 3.6414\n",
            "Epoch 27/35\n",
            "818/818 [==============================] - 0s 120us/sample - loss: 3.2499 - val_loss: 3.5792\n",
            "Epoch 28/35\n",
            "818/818 [==============================] - 0s 121us/sample - loss: 3.2079 - val_loss: 3.5148\n",
            "Epoch 29/35\n",
            "818/818 [==============================] - 0s 117us/sample - loss: 3.1773 - val_loss: 3.4913\n",
            "Epoch 30/35\n",
            "818/818 [==============================] - 0s 138us/sample - loss: 3.1299 - val_loss: 3.4366\n",
            "Epoch 31/35\n",
            "818/818 [==============================] - 0s 119us/sample - loss: 3.1045 - val_loss: 3.4362\n",
            "Epoch 32/35\n",
            "818/818 [==============================] - 0s 116us/sample - loss: 3.0758 - val_loss: 3.3778\n",
            "Epoch 33/35\n",
            "818/818 [==============================] - 0s 119us/sample - loss: 3.0533 - val_loss: 3.4260\n",
            "Epoch 34/35\n",
            "818/818 [==============================] - 0s 132us/sample - loss: 3.0319 - val_loss: 3.4785\n",
            "Epoch 35/35\n",
            "818/818 [==============================] - 0s 114us/sample - loss: 3.0221 - val_loss: 3.3842\n",
            "[CV]  learning_rate=0.015618437282778579, n_hidden=1, n_neurons=72, total=   4.2s\n",
            "[CV] learning_rate=0.01872949342149064, n_hidden=4, n_neurons=57 .....\n",
            "Train on 817 samples, validate on 91 samples\n",
            "Epoch 1/35\n",
            "817/817 [==============================] - 1s 743us/sample - loss: 16.2076 - val_loss: 8.3796\n",
            "Epoch 2/35\n",
            "817/817 [==============================] - 0s 149us/sample - loss: 5.9470 - val_loss: 5.9810\n",
            "Epoch 3/35\n",
            "817/817 [==============================] - 0s 122us/sample - loss: 5.0673 - val_loss: 6.2110\n",
            "Epoch 4/35\n",
            "817/817 [==============================] - 0s 121us/sample - loss: 4.7071 - val_loss: 5.4943\n",
            "Epoch 5/35\n",
            "817/817 [==============================] - 0s 126us/sample - loss: 4.7557 - val_loss: 5.0293\n",
            "Epoch 6/35\n",
            "817/817 [==============================] - 0s 141us/sample - loss: 4.4672 - val_loss: 5.0814\n",
            "Epoch 7/35\n",
            "817/817 [==============================] - 0s 124us/sample - loss: 4.4096 - val_loss: 4.4820\n",
            "Epoch 8/35\n",
            "817/817 [==============================] - 0s 124us/sample - loss: 4.1842 - val_loss: 4.5140\n",
            "Epoch 9/35\n",
            "817/817 [==============================] - 0s 128us/sample - loss: 4.2229 - val_loss: 4.8226\n",
            "Epoch 10/35\n",
            "817/817 [==============================] - 0s 124us/sample - loss: 3.9392 - val_loss: 4.9652\n",
            "Epoch 11/35\n",
            "817/817 [==============================] - 0s 140us/sample - loss: 3.9969 - val_loss: 5.0081\n",
            "Epoch 12/35\n",
            "817/817 [==============================] - 0s 118us/sample - loss: 3.7499 - val_loss: 4.6508\n",
            "Epoch 13/35\n",
            "817/817 [==============================] - 0s 126us/sample - loss: 3.9461 - val_loss: 4.7579\n",
            "Epoch 14/35\n",
            "817/817 [==============================] - 0s 124us/sample - loss: 3.4164 - val_loss: 3.8034\n",
            "Epoch 15/35\n",
            "817/817 [==============================] - 0s 125us/sample - loss: 3.4527 - val_loss: 4.0475\n",
            "Epoch 16/35\n",
            "817/817 [==============================] - 0s 128us/sample - loss: 3.6444 - val_loss: 4.3521\n",
            "Epoch 17/35\n",
            "817/817 [==============================] - 0s 151us/sample - loss: 3.3903 - val_loss: 3.6273\n",
            "Epoch 18/35\n",
            "817/817 [==============================] - 0s 132us/sample - loss: 3.3628 - val_loss: 4.3185\n",
            "Epoch 19/35\n",
            "817/817 [==============================] - 0s 128us/sample - loss: 3.4780 - val_loss: 3.6259\n",
            "Epoch 20/35\n",
            "817/817 [==============================] - 0s 138us/sample - loss: 3.1340 - val_loss: 5.0973\n",
            "Epoch 21/35\n",
            "817/817 [==============================] - 0s 139us/sample - loss: 3.1881 - val_loss: 4.8071\n",
            "Epoch 22/35\n",
            "817/817 [==============================] - 0s 123us/sample - loss: 3.0246 - val_loss: 4.5612\n",
            "Epoch 23/35\n",
            "817/817 [==============================] - 0s 115us/sample - loss: 3.2201 - val_loss: 4.0419\n",
            "Epoch 24/35\n",
            "817/817 [==============================] - 0s 122us/sample - loss: 3.0485 - val_loss: 5.1275\n",
            "Epoch 25/35\n",
            "817/817 [==============================] - 0s 121us/sample - loss: 3.1164 - val_loss: 3.9389\n",
            "Epoch 26/35\n",
            "817/817 [==============================] - 0s 133us/sample - loss: 2.9920 - val_loss: 4.7386\n",
            "Epoch 27/35\n",
            "817/817 [==============================] - 0s 119us/sample - loss: 2.8637 - val_loss: 4.4095\n",
            "Epoch 28/35\n",
            "817/817 [==============================] - 0s 135us/sample - loss: 3.1215 - val_loss: 3.5116\n",
            "Epoch 29/35\n",
            "817/817 [==============================] - 0s 123us/sample - loss: 2.8905 - val_loss: 4.6322\n",
            "Epoch 30/35\n",
            "817/817 [==============================] - 0s 144us/sample - loss: 2.7347 - val_loss: 4.3253\n",
            "Epoch 31/35\n",
            "817/817 [==============================] - 0s 124us/sample - loss: 2.7354 - val_loss: 3.7654\n",
            "Epoch 32/35\n",
            "817/817 [==============================] - 0s 124us/sample - loss: 2.6272 - val_loss: 3.8500\n",
            "Epoch 33/35\n",
            "817/817 [==============================] - 0s 121us/sample - loss: 2.5998 - val_loss: 4.1238\n",
            "Epoch 34/35\n",
            "817/817 [==============================] - 0s 126us/sample - loss: 2.7883 - val_loss: 3.7194\n",
            "Epoch 35/35\n",
            "817/817 [==============================] - 0s 128us/sample - loss: 2.4656 - val_loss: 4.4597\n",
            "[CV]  learning_rate=0.01872949342149064, n_hidden=4, n_neurons=57, total=   4.5s\n",
            "[CV] learning_rate=0.01872949342149064, n_hidden=4, n_neurons=57 .....\n",
            "Train on 818 samples, validate on 91 samples\n",
            "Epoch 1/35\n",
            "818/818 [==============================] - 1s 733us/sample - loss: 21.2281 - val_loss: 20.1694\n",
            "Epoch 2/35\n",
            "818/818 [==============================] - 0s 133us/sample - loss: 16.3819 - val_loss: 12.1133\n",
            "Epoch 3/35\n",
            "818/818 [==============================] - 0s 127us/sample - loss: 10.6702 - val_loss: 9.7232\n",
            "Epoch 4/35\n",
            "818/818 [==============================] - 0s 151us/sample - loss: 9.7985 - val_loss: 9.6522\n",
            "Epoch 5/35\n",
            "818/818 [==============================] - 0s 122us/sample - loss: 9.5759 - val_loss: 9.7831\n",
            "Epoch 6/35\n",
            "818/818 [==============================] - 0s 118us/sample - loss: 9.4101 - val_loss: 9.7979\n",
            "Epoch 7/35\n",
            "818/818 [==============================] - 0s 139us/sample - loss: 9.5821 - val_loss: 9.1294\n",
            "Epoch 8/35\n",
            "818/818 [==============================] - 0s 120us/sample - loss: 9.4665 - val_loss: 9.9427\n",
            "Epoch 9/35\n",
            "818/818 [==============================] - 0s 123us/sample - loss: 9.3664 - val_loss: 9.4372\n",
            "Epoch 10/35\n",
            "818/818 [==============================] - 0s 120us/sample - loss: 9.2181 - val_loss: 9.6260\n",
            "Epoch 11/35\n",
            "818/818 [==============================] - 0s 125us/sample - loss: 9.2412 - val_loss: 9.6262\n",
            "Epoch 12/35\n",
            "818/818 [==============================] - 0s 128us/sample - loss: 9.4185 - val_loss: 9.4881\n",
            "Epoch 13/35\n",
            "818/818 [==============================] - 0s 119us/sample - loss: 9.3286 - val_loss: 9.8330\n",
            "Epoch 14/35\n",
            "818/818 [==============================] - 0s 136us/sample - loss: 9.3392 - val_loss: 9.0426\n",
            "Epoch 15/35\n",
            "818/818 [==============================] - 0s 138us/sample - loss: 9.2673 - val_loss: 9.1109\n",
            "Epoch 16/35\n",
            "818/818 [==============================] - 0s 130us/sample - loss: 9.1793 - val_loss: 8.7687\n",
            "Epoch 17/35\n",
            "818/818 [==============================] - 0s 139us/sample - loss: 9.0285 - val_loss: 9.1638\n",
            "Epoch 18/35\n",
            "818/818 [==============================] - 0s 121us/sample - loss: 9.1874 - val_loss: 9.6655\n",
            "Epoch 19/35\n",
            "818/818 [==============================] - 0s 130us/sample - loss: 9.3350 - val_loss: 9.1562\n",
            "Epoch 20/35\n",
            "818/818 [==============================] - 0s 124us/sample - loss: 9.1999 - val_loss: 9.2867\n",
            "Epoch 21/35\n",
            "818/818 [==============================] - 0s 134us/sample - loss: 9.2285 - val_loss: 8.7474\n",
            "Epoch 22/35\n",
            "818/818 [==============================] - 0s 129us/sample - loss: 9.1881 - val_loss: 9.5165\n",
            "Epoch 23/35\n",
            "818/818 [==============================] - 0s 146us/sample - loss: 9.3059 - val_loss: 9.1586\n",
            "Epoch 24/35\n",
            "818/818 [==============================] - 0s 131us/sample - loss: 9.1267 - val_loss: 9.1212\n",
            "Epoch 25/35\n",
            "818/818 [==============================] - 0s 124us/sample - loss: 9.0951 - val_loss: 9.8371\n",
            "Epoch 26/35\n",
            "818/818 [==============================] - 0s 136us/sample - loss: 9.1481 - val_loss: 9.5273\n",
            "Epoch 27/35\n",
            "818/818 [==============================] - 0s 134us/sample - loss: 8.9685 - val_loss: 9.1711\n",
            "Epoch 28/35\n",
            "818/818 [==============================] - 0s 125us/sample - loss: 9.0088 - val_loss: 9.2078\n",
            "Epoch 29/35\n",
            "818/818 [==============================] - 0s 129us/sample - loss: 9.1239 - val_loss: 9.0822\n",
            "Epoch 30/35\n",
            "818/818 [==============================] - 0s 171us/sample - loss: 9.1435 - val_loss: 9.1355\n",
            "Epoch 31/35\n",
            "818/818 [==============================] - 0s 131us/sample - loss: 9.0382 - val_loss: 8.7227\n",
            "Epoch 32/35\n",
            "818/818 [==============================] - 0s 131us/sample - loss: 9.0246 - val_loss: 9.4262\n",
            "Epoch 33/35\n",
            "818/818 [==============================] - 0s 123us/sample - loss: 9.1108 - val_loss: 8.8270\n",
            "Epoch 34/35\n",
            "818/818 [==============================] - 0s 126us/sample - loss: 9.0577 - val_loss: 8.8664\n",
            "Epoch 35/35\n",
            "818/818 [==============================] - 0s 118us/sample - loss: 8.9342 - val_loss: 9.3362\n",
            "[CV]  learning_rate=0.01872949342149064, n_hidden=4, n_neurons=57, total=   4.6s\n",
            "[CV] learning_rate=0.01872949342149064, n_hidden=4, n_neurons=57 .....\n",
            "Train on 818 samples, validate on 91 samples\n",
            "Epoch 1/35\n",
            "818/818 [==============================] - 1s 727us/sample - loss: 21.0232 - val_loss: 19.7328\n",
            "Epoch 2/35\n",
            "818/818 [==============================] - 0s 136us/sample - loss: 17.6556 - val_loss: 16.2287\n",
            "Epoch 3/35\n",
            "818/818 [==============================] - 0s 145us/sample - loss: 16.3397 - val_loss: 16.0675\n",
            "Epoch 4/35\n",
            "818/818 [==============================] - 0s 122us/sample - loss: 16.0360 - val_loss: 16.0956\n",
            "Epoch 5/35\n",
            "818/818 [==============================] - 0s 126us/sample - loss: 15.8868 - val_loss: 16.1261\n",
            "Epoch 6/35\n",
            "818/818 [==============================] - 0s 121us/sample - loss: 15.7803 - val_loss: 16.1011\n",
            "Epoch 7/35\n",
            "818/818 [==============================] - 0s 130us/sample - loss: 15.7428 - val_loss: 16.1169\n",
            "Epoch 8/35\n",
            "818/818 [==============================] - 0s 120us/sample - loss: 15.6713 - val_loss: 16.0769\n",
            "Epoch 9/35\n",
            "818/818 [==============================] - 0s 134us/sample - loss: 15.6444 - val_loss: 16.0387\n",
            "Epoch 10/35\n",
            "818/818 [==============================] - 0s 129us/sample - loss: 15.5928 - val_loss: 15.9748\n",
            "Epoch 11/35\n",
            "818/818 [==============================] - 0s 126us/sample - loss: 15.5701 - val_loss: 16.0970\n",
            "Epoch 12/35\n",
            "818/818 [==============================] - 0s 122us/sample - loss: 15.5350 - val_loss: 16.1962\n",
            "Epoch 13/35\n",
            "818/818 [==============================] - 0s 131us/sample - loss: 15.4981 - val_loss: 16.0880\n",
            "Epoch 14/35\n",
            "818/818 [==============================] - 0s 122us/sample - loss: 15.5040 - val_loss: 16.0603\n",
            "Epoch 15/35\n",
            "818/818 [==============================] - 0s 124us/sample - loss: 15.4470 - val_loss: 16.1018\n",
            "Epoch 16/35\n",
            "818/818 [==============================] - 0s 121us/sample - loss: 15.4021 - val_loss: 16.0919\n",
            "Epoch 17/35\n",
            "818/818 [==============================] - 0s 140us/sample - loss: 15.3782 - val_loss: 16.2014\n",
            "Epoch 18/35\n",
            "818/818 [==============================] - 0s 125us/sample - loss: 15.3544 - val_loss: 16.3265\n",
            "Epoch 19/35\n",
            "818/818 [==============================] - 0s 137us/sample - loss: 15.2921 - val_loss: 16.1297\n",
            "Epoch 20/35\n",
            "818/818 [==============================] - 0s 136us/sample - loss: 15.2656 - val_loss: 16.2374\n",
            "[CV]  learning_rate=0.01872949342149064, n_hidden=4, n_neurons=57, total=   2.9s\n",
            "[CV] learning_rate=0.0231813960861234, n_hidden=3, n_neurons=13 ......\n",
            "Train on 817 samples, validate on 91 samples\n",
            "Epoch 1/35\n",
            "817/817 [==============================] - 1s 677us/sample - loss: 18.9527 - val_loss: 13.1642\n",
            "Epoch 2/35\n",
            "817/817 [==============================] - 0s 127us/sample - loss: 12.1089 - val_loss: 10.7396\n",
            "Epoch 3/35\n",
            "817/817 [==============================] - 0s 117us/sample - loss: 9.9835 - val_loss: 9.7031\n",
            "Epoch 4/35\n",
            "817/817 [==============================] - 0s 123us/sample - loss: 9.5258 - val_loss: 9.5084\n",
            "Epoch 5/35\n",
            "817/817 [==============================] - 0s 139us/sample - loss: 9.3543 - val_loss: 9.3616\n",
            "Epoch 6/35\n",
            "817/817 [==============================] - 0s 128us/sample - loss: 9.1991 - val_loss: 9.1026\n",
            "Epoch 7/35\n",
            "817/817 [==============================] - 0s 121us/sample - loss: 9.1413 - val_loss: 9.3603\n",
            "Epoch 8/35\n",
            "817/817 [==============================] - 0s 120us/sample - loss: 8.9786 - val_loss: 9.3953\n",
            "Epoch 9/35\n",
            "817/817 [==============================] - 0s 143us/sample - loss: 9.0784 - val_loss: 8.8799\n",
            "Epoch 10/35\n",
            "817/817 [==============================] - 0s 123us/sample - loss: 8.8990 - val_loss: 8.7616\n",
            "Epoch 11/35\n",
            "817/817 [==============================] - 0s 130us/sample - loss: 8.9013 - val_loss: 8.7365\n",
            "Epoch 12/35\n",
            "817/817 [==============================] - 0s 123us/sample - loss: 8.8953 - val_loss: 8.7951\n",
            "Epoch 13/35\n",
            "817/817 [==============================] - 0s 135us/sample - loss: 8.8501 - val_loss: 8.8168\n",
            "Epoch 14/35\n",
            "817/817 [==============================] - 0s 118us/sample - loss: 8.8121 - val_loss: 8.9084\n",
            "Epoch 15/35\n",
            "817/817 [==============================] - 0s 136us/sample - loss: 8.8880 - val_loss: 9.2021\n",
            "Epoch 16/35\n",
            "817/817 [==============================] - 0s 117us/sample - loss: 8.8187 - val_loss: 8.8939\n",
            "Epoch 17/35\n",
            "817/817 [==============================] - 0s 119us/sample - loss: 8.7905 - val_loss: 9.2308\n",
            "Epoch 18/35\n",
            "817/817 [==============================] - 0s 129us/sample - loss: 8.8619 - val_loss: 8.6997\n",
            "Epoch 19/35\n",
            "817/817 [==============================] - 0s 120us/sample - loss: 8.7338 - val_loss: 8.8389\n",
            "Epoch 20/35\n",
            "817/817 [==============================] - 0s 127us/sample - loss: 8.8017 - val_loss: 9.0116\n",
            "Epoch 21/35\n",
            "817/817 [==============================] - 0s 120us/sample - loss: 8.8686 - val_loss: 9.0324\n",
            "Epoch 22/35\n",
            "817/817 [==============================] - 0s 123us/sample - loss: 8.7646 - val_loss: 8.5953\n",
            "Epoch 23/35\n",
            "817/817 [==============================] - 0s 113us/sample - loss: 8.7253 - val_loss: 8.8799\n",
            "Epoch 24/35\n",
            "817/817 [==============================] - 0s 131us/sample - loss: 8.8637 - val_loss: 8.7270\n",
            "Epoch 25/35\n",
            "817/817 [==============================] - 0s 140us/sample - loss: 8.6830 - val_loss: 8.6323\n",
            "Epoch 26/35\n",
            "817/817 [==============================] - 0s 121us/sample - loss: 8.6560 - val_loss: 9.1549\n",
            "Epoch 27/35\n",
            "817/817 [==============================] - 0s 118us/sample - loss: 8.7771 - val_loss: 8.6762\n",
            "Epoch 28/35\n",
            "817/817 [==============================] - 0s 120us/sample - loss: 8.7477 - val_loss: 9.0300\n",
            "Epoch 29/35\n",
            "817/817 [==============================] - 0s 126us/sample - loss: 8.8266 - val_loss: 8.6883\n",
            "Epoch 30/35\n",
            "817/817 [==============================] - 0s 134us/sample - loss: 8.7921 - val_loss: 9.0439\n",
            "Epoch 31/35\n",
            "817/817 [==============================] - 0s 146us/sample - loss: 8.7870 - val_loss: 8.5489\n",
            "Epoch 32/35\n",
            "817/817 [==============================] - 0s 128us/sample - loss: 8.7372 - val_loss: 8.6849\n",
            "Epoch 33/35\n",
            "817/817 [==============================] - 0s 125us/sample - loss: 8.6748 - val_loss: 8.7527\n",
            "Epoch 34/35\n",
            "817/817 [==============================] - 0s 131us/sample - loss: 8.8254 - val_loss: 8.8029\n",
            "Epoch 35/35\n",
            "817/817 [==============================] - 0s 122us/sample - loss: 8.7344 - val_loss: 9.0879\n",
            "[CV]  learning_rate=0.0231813960861234, n_hidden=3, n_neurons=13, total=   4.4s\n",
            "[CV] learning_rate=0.0231813960861234, n_hidden=3, n_neurons=13 ......\n",
            "Train on 818 samples, validate on 91 samples\n",
            "Epoch 1/35\n",
            "818/818 [==============================] - 1s 673us/sample - loss: 21.1591 - val_loss: 19.9942\n",
            "Epoch 2/35\n",
            "818/818 [==============================] - 0s 148us/sample - loss: 18.3984 - val_loss: 16.9663\n",
            "Epoch 3/35\n",
            "818/818 [==============================] - 0s 126us/sample - loss: 16.5801 - val_loss: 16.7860\n",
            "Epoch 4/35\n",
            "818/818 [==============================] - 0s 120us/sample - loss: 16.2025 - val_loss: 16.4696\n",
            "Epoch 5/35\n",
            "818/818 [==============================] - 0s 142us/sample - loss: 16.0343 - val_loss: 16.2531\n",
            "Epoch 6/35\n",
            "818/818 [==============================] - 0s 127us/sample - loss: 15.9086 - val_loss: 16.2383\n",
            "Epoch 7/35\n",
            "818/818 [==============================] - 0s 125us/sample - loss: 15.8104 - val_loss: 16.1921\n",
            "Epoch 8/35\n",
            "818/818 [==============================] - 0s 125us/sample - loss: 15.7703 - val_loss: 16.1218\n",
            "Epoch 9/35\n",
            "818/818 [==============================] - 0s 125us/sample - loss: 15.6940 - val_loss: 16.2392\n",
            "Epoch 10/35\n",
            "818/818 [==============================] - 0s 126us/sample - loss: 15.6776 - val_loss: 16.0792\n",
            "Epoch 11/35\n",
            "818/818 [==============================] - 0s 124us/sample - loss: 15.6004 - val_loss: 16.0429\n",
            "Epoch 12/35\n",
            "818/818 [==============================] - 0s 141us/sample - loss: 15.6107 - val_loss: 16.1070\n",
            "Epoch 13/35\n",
            "818/818 [==============================] - 0s 119us/sample - loss: 15.5293 - val_loss: 16.0181\n",
            "Epoch 14/35\n",
            "818/818 [==============================] - 0s 113us/sample - loss: 15.5193 - val_loss: 16.1257\n",
            "Epoch 15/35\n",
            "818/818 [==============================] - 0s 123us/sample - loss: 15.5030 - val_loss: 16.1040\n",
            "Epoch 16/35\n",
            "818/818 [==============================] - 0s 124us/sample - loss: 15.4540 - val_loss: 16.1113\n",
            "Epoch 17/35\n",
            "818/818 [==============================] - 0s 146us/sample - loss: 15.4437 - val_loss: 16.0694\n",
            "Epoch 18/35\n",
            "818/818 [==============================] - 0s 122us/sample - loss: 15.4352 - val_loss: 16.0371\n",
            "Epoch 19/35\n",
            "818/818 [==============================] - 0s 131us/sample - loss: 15.3942 - val_loss: 16.1883\n",
            "Epoch 20/35\n",
            "818/818 [==============================] - 0s 127us/sample - loss: 15.3910 - val_loss: 16.2906\n",
            "Epoch 21/35\n",
            "818/818 [==============================] - 0s 118us/sample - loss: 15.3482 - val_loss: 16.1317\n",
            "Epoch 22/35\n",
            "818/818 [==============================] - 0s 150us/sample - loss: 15.3408 - val_loss: 16.1091\n",
            "Epoch 23/35\n",
            "818/818 [==============================] - 0s 124us/sample - loss: 15.3640 - val_loss: 16.0969\n",
            "[CV]  learning_rate=0.0231813960861234, n_hidden=3, n_neurons=13, total=   3.2s\n",
            "[CV] learning_rate=0.0231813960861234, n_hidden=3, n_neurons=13 ......\n",
            "Train on 818 samples, validate on 91 samples\n",
            "Epoch 1/35\n",
            "818/818 [==============================] - 2s 2ms/sample - loss: 19.1599 - val_loss: 11.9826\n",
            "Epoch 2/35\n",
            "818/818 [==============================] - 0s 136us/sample - loss: 8.6251 - val_loss: 6.9881\n",
            "Epoch 3/35\n",
            "818/818 [==============================] - 0s 134us/sample - loss: 5.8892 - val_loss: 5.6026\n",
            "Epoch 4/35\n",
            "818/818 [==============================] - 0s 127us/sample - loss: 4.8632 - val_loss: 4.6089\n",
            "Epoch 5/35\n",
            "818/818 [==============================] - 0s 122us/sample - loss: 4.4865 - val_loss: 4.5467\n",
            "Epoch 6/35\n",
            "818/818 [==============================] - 0s 121us/sample - loss: 4.2753 - val_loss: 4.0998\n",
            "Epoch 7/35\n",
            "818/818 [==============================] - 0s 121us/sample - loss: 3.9101 - val_loss: 4.6293\n",
            "Epoch 8/35\n",
            "818/818 [==============================] - 0s 117us/sample - loss: 3.9666 - val_loss: 4.1231\n",
            "Epoch 9/35\n",
            "818/818 [==============================] - 0s 121us/sample - loss: 3.7678 - val_loss: 4.2713\n",
            "Epoch 10/35\n",
            "818/818 [==============================] - 0s 145us/sample - loss: 3.5627 - val_loss: 3.6294\n",
            "Epoch 11/35\n",
            "818/818 [==============================] - 0s 129us/sample - loss: 3.5563 - val_loss: 3.6627\n",
            "Epoch 12/35\n",
            "818/818 [==============================] - 0s 119us/sample - loss: 3.5189 - val_loss: 3.9153\n",
            "Epoch 13/35\n",
            "818/818 [==============================] - 0s 119us/sample - loss: 3.3664 - val_loss: 4.0528\n",
            "Epoch 14/35\n",
            "818/818 [==============================] - 0s 122us/sample - loss: 3.4595 - val_loss: 4.0447\n",
            "Epoch 15/35\n",
            "818/818 [==============================] - 0s 124us/sample - loss: 3.5155 - val_loss: 4.2235\n",
            "Epoch 16/35\n",
            "818/818 [==============================] - 0s 118us/sample - loss: 3.4182 - val_loss: 4.2678\n",
            "Epoch 17/35\n",
            "818/818 [==============================] - 0s 121us/sample - loss: 3.6334 - val_loss: 3.6433\n",
            "Epoch 18/35\n",
            "818/818 [==============================] - 0s 113us/sample - loss: 3.4623 - val_loss: 4.2379\n",
            "Epoch 19/35\n",
            "818/818 [==============================] - 0s 128us/sample - loss: 3.3499 - val_loss: 3.7895\n",
            "Epoch 20/35\n",
            "818/818 [==============================] - 0s 135us/sample - loss: 3.2312 - val_loss: 3.9546\n",
            "[CV]  learning_rate=0.0231813960861234, n_hidden=3, n_neurons=13, total=   3.9s\n",
            "[CV] learning_rate=0.019033072069957586, n_hidden=2, n_neurons=30 ....\n",
            "Train on 817 samples, validate on 91 samples\n",
            "Epoch 1/35\n",
            "817/817 [==============================] - 1s 653us/sample - loss: 20.5084 - val_loss: 18.0532\n",
            "Epoch 2/35\n",
            "817/817 [==============================] - 0s 124us/sample - loss: 13.7960 - val_loss: 10.2008\n",
            "Epoch 3/35\n",
            "817/817 [==============================] - 0s 117us/sample - loss: 8.8877 - val_loss: 8.2707\n",
            "Epoch 4/35\n",
            "817/817 [==============================] - 0s 144us/sample - loss: 6.8594 - val_loss: 6.5402\n",
            "Epoch 5/35\n",
            "817/817 [==============================] - 0s 130us/sample - loss: 5.3381 - val_loss: 5.3710\n",
            "Epoch 6/35\n",
            "817/817 [==============================] - 0s 136us/sample - loss: 4.6233 - val_loss: 4.9538\n",
            "Epoch 7/35\n",
            "817/817 [==============================] - 0s 129us/sample - loss: 4.3115 - val_loss: 4.5212\n",
            "Epoch 8/35\n",
            "817/817 [==============================] - 0s 119us/sample - loss: 4.0808 - val_loss: 4.5745\n",
            "Epoch 9/35\n",
            "817/817 [==============================] - 0s 117us/sample - loss: 3.8876 - val_loss: 4.0378\n",
            "Epoch 10/35\n",
            "817/817 [==============================] - 0s 124us/sample - loss: 3.6428 - val_loss: 3.8066\n",
            "Epoch 11/35\n",
            "817/817 [==============================] - 0s 122us/sample - loss: 3.5021 - val_loss: 3.7192\n",
            "Epoch 12/35\n",
            "817/817 [==============================] - 0s 119us/sample - loss: 3.3814 - val_loss: 3.6132\n",
            "Epoch 13/35\n",
            "817/817 [==============================] - 0s 142us/sample - loss: 3.2205 - val_loss: 3.6712\n",
            "Epoch 14/35\n",
            "817/817 [==============================] - 0s 134us/sample - loss: 3.1909 - val_loss: 4.1125\n",
            "Epoch 15/35\n",
            "817/817 [==============================] - 0s 138us/sample - loss: 3.1589 - val_loss: 3.5175\n",
            "Epoch 16/35\n",
            "817/817 [==============================] - 0s 125us/sample - loss: 3.1301 - val_loss: 3.4177\n",
            "Epoch 17/35\n",
            "817/817 [==============================] - 0s 128us/sample - loss: 3.0493 - val_loss: 3.5772\n",
            "Epoch 18/35\n",
            "817/817 [==============================] - 0s 123us/sample - loss: 2.9467 - val_loss: 3.3986\n",
            "Epoch 19/35\n",
            "817/817 [==============================] - 0s 128us/sample - loss: 3.0546 - val_loss: 3.4106\n",
            "Epoch 20/35\n",
            "817/817 [==============================] - 0s 120us/sample - loss: 2.9020 - val_loss: 3.3894\n",
            "Epoch 21/35\n",
            "817/817 [==============================] - 0s 132us/sample - loss: 2.8978 - val_loss: 3.4189\n",
            "Epoch 22/35\n",
            "817/817 [==============================] - 0s 121us/sample - loss: 2.8613 - val_loss: 3.3708\n",
            "Epoch 23/35\n",
            "817/817 [==============================] - 0s 138us/sample - loss: 2.8738 - val_loss: 3.9905\n",
            "Epoch 24/35\n",
            "817/817 [==============================] - 0s 116us/sample - loss: 2.8899 - val_loss: 3.4404\n",
            "Epoch 25/35\n",
            "817/817 [==============================] - 0s 119us/sample - loss: 2.8509 - val_loss: 3.4323\n",
            "Epoch 26/35\n",
            "817/817 [==============================] - 0s 132us/sample - loss: 2.8164 - val_loss: 3.4439\n",
            "Epoch 27/35\n",
            "817/817 [==============================] - 0s 116us/sample - loss: 2.7707 - val_loss: 3.2459\n",
            "Epoch 28/35\n",
            "817/817 [==============================] - 0s 113us/sample - loss: 2.7833 - val_loss: 3.4990\n",
            "Epoch 29/35\n",
            "817/817 [==============================] - 0s 120us/sample - loss: 2.7363 - val_loss: 3.5037\n",
            "Epoch 30/35\n",
            "817/817 [==============================] - 0s 126us/sample - loss: 2.7827 - val_loss: 3.2616\n",
            "Epoch 31/35\n",
            "817/817 [==============================] - 0s 119us/sample - loss: 2.6827 - val_loss: 3.2811\n",
            "Epoch 32/35\n",
            "817/817 [==============================] - 0s 118us/sample - loss: 2.7262 - val_loss: 3.3260\n",
            "Epoch 33/35\n",
            "817/817 [==============================] - 0s 143us/sample - loss: 2.6583 - val_loss: 3.3393\n",
            "Epoch 34/35\n",
            "817/817 [==============================] - 0s 118us/sample - loss: 2.6671 - val_loss: 3.8590\n",
            "Epoch 35/35\n",
            "817/817 [==============================] - 0s 129us/sample - loss: 2.7336 - val_loss: 3.4084\n",
            "[CV]  learning_rate=0.019033072069957586, n_hidden=2, n_neurons=30, total=   4.3s\n",
            "[CV] learning_rate=0.019033072069957586, n_hidden=2, n_neurons=30 ....\n",
            "Train on 818 samples, validate on 91 samples\n",
            "Epoch 1/35\n",
            "818/818 [==============================] - 1s 632us/sample - loss: 18.8199 - val_loss: 13.6350\n",
            "Epoch 2/35\n",
            "818/818 [==============================] - 0s 127us/sample - loss: 10.6842 - val_loss: 9.1153\n",
            "Epoch 3/35\n",
            "818/818 [==============================] - 0s 119us/sample - loss: 7.5303 - val_loss: 7.1876\n",
            "Epoch 4/35\n",
            "818/818 [==============================] - 0s 127us/sample - loss: 5.9444 - val_loss: 5.7000\n",
            "Epoch 5/35\n",
            "818/818 [==============================] - 0s 121us/sample - loss: 4.8470 - val_loss: 4.8736\n",
            "Epoch 6/35\n",
            "818/818 [==============================] - 0s 114us/sample - loss: 4.2949 - val_loss: 4.4156\n",
            "Epoch 7/35\n",
            "818/818 [==============================] - 0s 148us/sample - loss: 3.9606 - val_loss: 4.2581\n",
            "Epoch 8/35\n",
            "818/818 [==============================] - 0s 120us/sample - loss: 3.7906 - val_loss: 3.9337\n",
            "Epoch 9/35\n",
            "818/818 [==============================] - 0s 121us/sample - loss: 3.4933 - val_loss: 3.8766\n",
            "Epoch 10/35\n",
            "818/818 [==============================] - 0s 122us/sample - loss: 3.4299 - val_loss: 3.8321\n",
            "Epoch 11/35\n",
            "818/818 [==============================] - 0s 122us/sample - loss: 3.4488 - val_loss: 4.8938\n",
            "Epoch 12/35\n",
            "818/818 [==============================] - 0s 127us/sample - loss: 3.3847 - val_loss: 3.6228\n",
            "Epoch 13/35\n",
            "818/818 [==============================] - 0s 114us/sample - loss: 3.2010 - val_loss: 3.5203\n",
            "Epoch 14/35\n",
            "818/818 [==============================] - 0s 133us/sample - loss: 3.1375 - val_loss: 3.4982\n",
            "Epoch 15/35\n",
            "818/818 [==============================] - 0s 115us/sample - loss: 3.1116 - val_loss: 3.6010\n",
            "Epoch 16/35\n",
            "818/818 [==============================] - 0s 118us/sample - loss: 3.1061 - val_loss: 3.5899\n",
            "Epoch 17/35\n",
            "818/818 [==============================] - 0s 117us/sample - loss: 3.0945 - val_loss: 3.6078\n",
            "Epoch 18/35\n",
            "818/818 [==============================] - 0s 117us/sample - loss: 3.0411 - val_loss: 3.8505\n",
            "Epoch 19/35\n",
            "818/818 [==============================] - 0s 137us/sample - loss: 3.0653 - val_loss: 3.4922\n",
            "Epoch 20/35\n",
            "818/818 [==============================] - 0s 117us/sample - loss: 2.9383 - val_loss: 4.0195\n",
            "Epoch 21/35\n",
            "818/818 [==============================] - 0s 125us/sample - loss: 2.9751 - val_loss: 3.6126\n",
            "Epoch 22/35\n",
            "818/818 [==============================] - 0s 110us/sample - loss: 2.9110 - val_loss: 3.7685\n",
            "Epoch 23/35\n",
            "818/818 [==============================] - 0s 128us/sample - loss: 2.9756 - val_loss: 3.4245\n",
            "Epoch 24/35\n",
            "818/818 [==============================] - 0s 117us/sample - loss: 2.9654 - val_loss: 3.4628\n",
            "Epoch 25/35\n",
            "818/818 [==============================] - 0s 139us/sample - loss: 2.8152 - val_loss: 3.7045\n",
            "Epoch 26/35\n",
            "818/818 [==============================] - 0s 121us/sample - loss: 2.8003 - val_loss: 3.5685\n",
            "Epoch 27/35\n",
            "818/818 [==============================] - 0s 120us/sample - loss: 2.7991 - val_loss: 3.7712\n",
            "Epoch 28/35\n",
            "818/818 [==============================] - 0s 119us/sample - loss: 2.8339 - val_loss: 3.9081\n",
            "Epoch 29/35\n",
            "818/818 [==============================] - 0s 122us/sample - loss: 2.7921 - val_loss: 3.7285\n",
            "Epoch 30/35\n",
            "818/818 [==============================] - 0s 127us/sample - loss: 2.7138 - val_loss: 3.5550\n",
            "Epoch 31/35\n",
            "818/818 [==============================] - 0s 133us/sample - loss: 2.6732 - val_loss: 3.8599\n",
            "Epoch 32/35\n",
            "818/818 [==============================] - 0s 133us/sample - loss: 2.7024 - val_loss: 3.4532\n",
            "Epoch 33/35\n",
            "818/818 [==============================] - 0s 117us/sample - loss: 2.7086 - val_loss: 3.7955\n",
            "[CV]  learning_rate=0.019033072069957586, n_hidden=2, n_neurons=30, total=   4.1s\n",
            "[CV] learning_rate=0.019033072069957586, n_hidden=2, n_neurons=30 ....\n",
            "Train on 818 samples, validate on 91 samples\n",
            "Epoch 1/35\n",
            "818/818 [==============================] - 1s 617us/sample - loss: 20.9312 - val_loss: 19.8342\n",
            "Epoch 2/35\n",
            "818/818 [==============================] - 0s 131us/sample - loss: 16.5697 - val_loss: 9.9894\n",
            "Epoch 3/35\n",
            "818/818 [==============================] - 0s 129us/sample - loss: 9.0664 - val_loss: 7.8930\n",
            "Epoch 4/35\n",
            "818/818 [==============================] - 0s 130us/sample - loss: 7.4085 - val_loss: 6.3268\n",
            "Epoch 5/35\n",
            "818/818 [==============================] - 0s 137us/sample - loss: 5.9818 - val_loss: 5.3818\n",
            "Epoch 6/35\n",
            "818/818 [==============================] - 0s 126us/sample - loss: 4.9406 - val_loss: 4.7302\n",
            "Epoch 7/35\n",
            "818/818 [==============================] - 0s 120us/sample - loss: 4.3968 - val_loss: 4.3650\n",
            "Epoch 8/35\n",
            "818/818 [==============================] - 0s 119us/sample - loss: 4.0478 - val_loss: 4.1410\n",
            "Epoch 9/35\n",
            "818/818 [==============================] - 0s 122us/sample - loss: 3.8952 - val_loss: 3.9448\n",
            "Epoch 10/35\n",
            "818/818 [==============================] - 0s 122us/sample - loss: 3.6996 - val_loss: 3.8360\n",
            "Epoch 11/35\n",
            "818/818 [==============================] - 0s 116us/sample - loss: 3.6267 - val_loss: 3.8311\n",
            "Epoch 12/35\n",
            "818/818 [==============================] - 0s 131us/sample - loss: 3.4774 - val_loss: 3.7094\n",
            "Epoch 13/35\n",
            "818/818 [==============================] - 0s 118us/sample - loss: 3.4454 - val_loss: 3.6657\n",
            "Epoch 14/35\n",
            "818/818 [==============================] - 0s 132us/sample - loss: 3.3239 - val_loss: 3.5948\n",
            "Epoch 15/35\n",
            "818/818 [==============================] - 0s 122us/sample - loss: 3.2895 - val_loss: 3.6407\n",
            "Epoch 16/35\n",
            "818/818 [==============================] - 0s 128us/sample - loss: 3.2395 - val_loss: 3.6312\n",
            "Epoch 17/35\n",
            "818/818 [==============================] - 0s 114us/sample - loss: 3.2929 - val_loss: 3.7011\n",
            "Epoch 18/35\n",
            "818/818 [==============================] - 0s 118us/sample - loss: 3.1127 - val_loss: 3.9587\n",
            "Epoch 19/35\n",
            "818/818 [==============================] - 0s 133us/sample - loss: 3.1753 - val_loss: 3.5419\n",
            "Epoch 20/35\n",
            "818/818 [==============================] - 0s 116us/sample - loss: 3.1319 - val_loss: 3.5566\n",
            "Epoch 21/35\n",
            "818/818 [==============================] - 0s 135us/sample - loss: 3.1300 - val_loss: 3.8802\n",
            "Epoch 22/35\n",
            "818/818 [==============================] - 0s 128us/sample - loss: 3.0119 - val_loss: 3.5064\n",
            "Epoch 23/35\n",
            "818/818 [==============================] - 0s 124us/sample - loss: 3.0338 - val_loss: 3.4580\n",
            "Epoch 24/35\n",
            "818/818 [==============================] - 0s 117us/sample - loss: 3.0194 - val_loss: 3.7185\n",
            "Epoch 25/35\n",
            "818/818 [==============================] - 0s 119us/sample - loss: 2.9282 - val_loss: 3.8823\n",
            "Epoch 26/35\n",
            "818/818 [==============================] - 0s 144us/sample - loss: 2.9615 - val_loss: 3.4367\n",
            "Epoch 27/35\n",
            "818/818 [==============================] - 0s 120us/sample - loss: 2.9694 - val_loss: 3.3871\n",
            "Epoch 28/35\n",
            "818/818 [==============================] - 0s 122us/sample - loss: 3.0073 - val_loss: 3.5572\n",
            "Epoch 29/35\n",
            "818/818 [==============================] - 0s 113us/sample - loss: 2.8130 - val_loss: 3.6680\n",
            "Epoch 30/35\n",
            "818/818 [==============================] - 0s 117us/sample - loss: 2.7805 - val_loss: 3.6997\n",
            "Epoch 31/35\n",
            "818/818 [==============================] - 0s 136us/sample - loss: 2.8250 - val_loss: 3.4687\n",
            "Epoch 32/35\n",
            "818/818 [==============================] - 0s 110us/sample - loss: 2.8243 - val_loss: 3.4830\n",
            "Epoch 33/35\n",
            "818/818 [==============================] - 0s 116us/sample - loss: 2.8773 - val_loss: 3.4995\n",
            "Epoch 34/35\n",
            "818/818 [==============================] - 0s 111us/sample - loss: 2.7465 - val_loss: 3.5093\n",
            "Epoch 35/35\n",
            "818/818 [==============================] - 0s 120us/sample - loss: 2.7188 - val_loss: 3.6922\n",
            "[CV]  learning_rate=0.019033072069957586, n_hidden=2, n_neurons=30, total=   4.3s\n",
            "[CV] learning_rate=0.020869758587495273, n_hidden=3, n_neurons=89 ....\n",
            "Train on 817 samples, validate on 91 samples\n",
            "Epoch 1/35\n",
            "817/817 [==============================] - 1s 709us/sample - loss: 20.0764 - val_loss: 15.5240\n",
            "Epoch 2/35\n",
            "817/817 [==============================] - 0s 134us/sample - loss: 12.5520 - val_loss: 12.0068\n",
            "Epoch 3/35\n",
            "817/817 [==============================] - 0s 133us/sample - loss: 6.9634 - val_loss: 5.6824\n",
            "Epoch 4/35\n",
            "817/817 [==============================] - 0s 133us/sample - loss: 4.8180 - val_loss: 5.1778\n",
            "Epoch 5/35\n",
            "817/817 [==============================] - 0s 123us/sample - loss: 4.5484 - val_loss: 4.8096\n",
            "Epoch 6/35\n",
            "817/817 [==============================] - 0s 124us/sample - loss: 4.2840 - val_loss: 4.6528\n",
            "Epoch 7/35\n",
            "817/817 [==============================] - 0s 131us/sample - loss: 4.0279 - val_loss: 4.5784\n",
            "Epoch 8/35\n",
            "817/817 [==============================] - 0s 138us/sample - loss: 3.7607 - val_loss: 4.0810\n",
            "Epoch 9/35\n",
            "817/817 [==============================] - 0s 148us/sample - loss: 3.5971 - val_loss: 3.9660\n",
            "Epoch 10/35\n",
            "817/817 [==============================] - 0s 121us/sample - loss: 3.4616 - val_loss: 4.3691\n",
            "Epoch 11/35\n",
            "817/817 [==============================] - 0s 127us/sample - loss: 3.3160 - val_loss: 3.9769\n",
            "Epoch 12/35\n",
            "817/817 [==============================] - 0s 123us/sample - loss: 3.2454 - val_loss: 3.8441\n",
            "Epoch 13/35\n",
            "817/817 [==============================] - 0s 127us/sample - loss: 3.2863 - val_loss: 3.8296\n",
            "Epoch 14/35\n",
            "817/817 [==============================] - 0s 133us/sample - loss: 3.2076 - val_loss: 3.9013\n",
            "Epoch 15/35\n",
            "817/817 [==============================] - 0s 145us/sample - loss: 3.1401 - val_loss: 3.6055\n",
            "Epoch 16/35\n",
            "817/817 [==============================] - 0s 140us/sample - loss: 3.0665 - val_loss: 4.4678\n",
            "Epoch 17/35\n",
            "817/817 [==============================] - 0s 130us/sample - loss: 3.1398 - val_loss: 3.8192\n",
            "Epoch 18/35\n",
            "817/817 [==============================] - 0s 136us/sample - loss: 3.0099 - val_loss: 4.6165\n",
            "Epoch 19/35\n",
            "817/817 [==============================] - 0s 130us/sample - loss: 2.9956 - val_loss: 4.2339\n",
            "Epoch 20/35\n",
            "817/817 [==============================] - 0s 124us/sample - loss: 2.9469 - val_loss: 3.9352\n",
            "Epoch 21/35\n",
            "817/817 [==============================] - 0s 114us/sample - loss: 2.9475 - val_loss: 4.0155\n",
            "Epoch 22/35\n",
            "817/817 [==============================] - 0s 118us/sample - loss: 3.0124 - val_loss: 4.1802\n",
            "Epoch 23/35\n",
            "817/817 [==============================] - 0s 123us/sample - loss: 2.8228 - val_loss: 3.7346\n",
            "Epoch 24/35\n",
            "817/817 [==============================] - 0s 127us/sample - loss: 2.8162 - val_loss: 4.9360\n",
            "Epoch 25/35\n",
            "817/817 [==============================] - 0s 138us/sample - loss: 2.7450 - val_loss: 3.6697\n",
            "[CV]  learning_rate=0.020869758587495273, n_hidden=3, n_neurons=89, total=   3.4s\n",
            "[CV] learning_rate=0.020869758587495273, n_hidden=3, n_neurons=89 ....\n",
            "Train on 818 samples, validate on 91 samples\n",
            "Epoch 1/35\n",
            "818/818 [==============================] - 1s 694us/sample - loss: 21.0940 - val_loss: 19.0384\n",
            "Epoch 2/35\n",
            "818/818 [==============================] - 0s 139us/sample - loss: 12.0327 - val_loss: 7.5360\n",
            "Epoch 3/35\n",
            "818/818 [==============================] - 0s 125us/sample - loss: 6.0706 - val_loss: 5.7667\n",
            "Epoch 4/35\n",
            "818/818 [==============================] - 0s 123us/sample - loss: 4.9587 - val_loss: 4.9858\n",
            "Epoch 5/35\n",
            "818/818 [==============================] - 0s 138us/sample - loss: 4.2953 - val_loss: 4.5513\n",
            "Epoch 6/35\n",
            "818/818 [==============================] - 0s 150us/sample - loss: 4.0298 - val_loss: 4.1995\n",
            "Epoch 7/35\n",
            "818/818 [==============================] - 0s 119us/sample - loss: 3.7813 - val_loss: 4.4477\n",
            "Epoch 8/35\n",
            "818/818 [==============================] - 0s 120us/sample - loss: 3.5818 - val_loss: 4.1817\n",
            "Epoch 9/35\n",
            "818/818 [==============================] - 0s 126us/sample - loss: 3.5015 - val_loss: 4.4519\n",
            "Epoch 10/35\n",
            "818/818 [==============================] - 0s 125us/sample - loss: 3.4397 - val_loss: 3.9032\n",
            "Epoch 11/35\n",
            "818/818 [==============================] - 0s 122us/sample - loss: 3.3385 - val_loss: 4.2599\n",
            "Epoch 12/35\n",
            "818/818 [==============================] - 0s 126us/sample - loss: 3.3920 - val_loss: 3.7913\n",
            "Epoch 13/35\n",
            "818/818 [==============================] - 0s 124us/sample - loss: 3.3222 - val_loss: 4.2745\n",
            "Epoch 14/35\n",
            "818/818 [==============================] - 0s 121us/sample - loss: 3.2417 - val_loss: 4.2138\n",
            "Epoch 15/35\n",
            "818/818 [==============================] - 0s 129us/sample - loss: 3.1407 - val_loss: 4.0351\n",
            "Epoch 16/35\n",
            "818/818 [==============================] - 0s 127us/sample - loss: 3.0439 - val_loss: 3.8535\n",
            "Epoch 17/35\n",
            "818/818 [==============================] - 0s 122us/sample - loss: 3.0301 - val_loss: 3.8119\n",
            "Epoch 18/35\n",
            "818/818 [==============================] - 0s 115us/sample - loss: 2.9496 - val_loss: 4.4200\n",
            "Epoch 19/35\n",
            "818/818 [==============================] - 0s 125us/sample - loss: 3.0912 - val_loss: 4.5697\n",
            "Epoch 20/35\n",
            "818/818 [==============================] - 0s 125us/sample - loss: 3.0102 - val_loss: 4.3804\n",
            "Epoch 21/35\n",
            "818/818 [==============================] - 0s 143us/sample - loss: 2.9598 - val_loss: 4.3601\n",
            "Epoch 22/35\n",
            "818/818 [==============================] - 0s 145us/sample - loss: 2.9237 - val_loss: 4.1534\n",
            "[CV]  learning_rate=0.020869758587495273, n_hidden=3, n_neurons=89, total=   3.1s\n",
            "[CV] learning_rate=0.020869758587495273, n_hidden=3, n_neurons=89 ....\n",
            "Train on 818 samples, validate on 91 samples\n",
            "Epoch 1/35\n",
            "818/818 [==============================] - 1s 683us/sample - loss: 20.8995 - val_loss: 19.3017\n",
            "Epoch 2/35\n",
            "818/818 [==============================] - 0s 127us/sample - loss: 15.1531 - val_loss: 11.1580\n",
            "Epoch 3/35\n",
            "818/818 [==============================] - 0s 126us/sample - loss: 10.7223 - val_loss: 9.7899\n",
            "Epoch 4/35\n",
            "818/818 [==============================] - 0s 131us/sample - loss: 9.8350 - val_loss: 9.4188\n",
            "Epoch 5/35\n",
            "818/818 [==============================] - 0s 127us/sample - loss: 9.5799 - val_loss: 9.4036\n",
            "Epoch 6/35\n",
            "818/818 [==============================] - 0s 137us/sample - loss: 9.5017 - val_loss: 9.2528\n",
            "Epoch 7/35\n",
            "818/818 [==============================] - 0s 114us/sample - loss: 9.3454 - val_loss: 9.3646\n",
            "Epoch 8/35\n",
            "818/818 [==============================] - 0s 133us/sample - loss: 9.3019 - val_loss: 9.2184\n",
            "Epoch 9/35\n",
            "818/818 [==============================] - 0s 135us/sample - loss: 9.2572 - val_loss: 9.1851\n",
            "Epoch 10/35\n",
            "818/818 [==============================] - 0s 139us/sample - loss: 9.2085 - val_loss: 9.2873\n",
            "Epoch 11/35\n",
            "818/818 [==============================] - 0s 127us/sample - loss: 9.1455 - val_loss: 9.1078\n",
            "Epoch 12/35\n",
            "818/818 [==============================] - 0s 123us/sample - loss: 9.0869 - val_loss: 9.4635\n",
            "Epoch 13/35\n",
            "818/818 [==============================] - 0s 137us/sample - loss: 9.1129 - val_loss: 9.1602\n",
            "Epoch 14/35\n",
            "818/818 [==============================] - 0s 122us/sample - loss: 9.0461 - val_loss: 9.1539\n",
            "Epoch 15/35\n",
            "818/818 [==============================] - 0s 149us/sample - loss: 9.0116 - val_loss: 9.1423\n",
            "Epoch 16/35\n",
            "818/818 [==============================] - 0s 132us/sample - loss: 9.0996 - val_loss: 9.2436\n",
            "Epoch 17/35\n",
            "818/818 [==============================] - 0s 125us/sample - loss: 8.9956 - val_loss: 9.3325\n",
            "Epoch 18/35\n",
            "818/818 [==============================] - 0s 118us/sample - loss: 9.0655 - val_loss: 9.2121\n",
            "Epoch 19/35\n",
            "818/818 [==============================] - 0s 134us/sample - loss: 9.0379 - val_loss: 9.0399\n",
            "Epoch 20/35\n",
            "818/818 [==============================] - 0s 125us/sample - loss: 9.0552 - val_loss: 9.0133\n",
            "Epoch 21/35\n",
            "818/818 [==============================] - 0s 117us/sample - loss: 8.9716 - val_loss: 9.6131\n",
            "Epoch 22/35\n",
            "818/818 [==============================] - 0s 132us/sample - loss: 9.0878 - val_loss: 9.0614\n",
            "Epoch 23/35\n",
            "818/818 [==============================] - 0s 136us/sample - loss: 8.9147 - val_loss: 9.0560\n",
            "Epoch 24/35\n",
            "818/818 [==============================] - 0s 140us/sample - loss: 9.0108 - val_loss: 8.9324\n",
            "Epoch 25/35\n",
            "818/818 [==============================] - 0s 137us/sample - loss: 8.8985 - val_loss: 9.1104\n",
            "Epoch 26/35\n",
            "818/818 [==============================] - 0s 116us/sample - loss: 8.9841 - val_loss: 9.1900\n",
            "Epoch 27/35\n",
            "818/818 [==============================] - 0s 116us/sample - loss: 9.0720 - val_loss: 9.0925\n",
            "Epoch 28/35\n",
            "818/818 [==============================] - 0s 124us/sample - loss: 9.0096 - val_loss: 8.9713\n",
            "Epoch 29/35\n",
            "818/818 [==============================] - 0s 139us/sample - loss: 8.9157 - val_loss: 9.4810\n",
            "Epoch 30/35\n",
            "818/818 [==============================] - 0s 126us/sample - loss: 8.8993 - val_loss: 9.0040\n",
            "Epoch 31/35\n",
            "818/818 [==============================] - 0s 123us/sample - loss: 8.9861 - val_loss: 9.1678\n",
            "Epoch 32/35\n",
            "818/818 [==============================] - 0s 127us/sample - loss: 8.8427 - val_loss: 9.2533\n",
            "Epoch 33/35\n",
            "818/818 [==============================] - 0s 124us/sample - loss: 9.1011 - val_loss: 9.3838\n",
            "Epoch 34/35\n",
            "818/818 [==============================] - 0s 130us/sample - loss: 8.9845 - val_loss: 9.3710\n",
            "[CV]  learning_rate=0.020869758587495273, n_hidden=3, n_neurons=89, total=   4.3s\n",
            "[CV] learning_rate=0.02285600107008809, n_hidden=4, n_neurons=40 .....\n",
            "Train on 817 samples, validate on 91 samples\n",
            "Epoch 1/35\n",
            "817/817 [==============================] - 1s 733us/sample - loss: 19.6249 - val_loss: 17.0353\n",
            "Epoch 2/35\n",
            "817/817 [==============================] - 0s 138us/sample - loss: 16.6295 - val_loss: 16.5964\n",
            "Epoch 3/35\n",
            "817/817 [==============================] - 0s 147us/sample - loss: 16.1292 - val_loss: 16.2502\n",
            "Epoch 4/35\n",
            "817/817 [==============================] - 0s 130us/sample - loss: 15.9162 - val_loss: 16.1156\n",
            "Epoch 5/35\n",
            "817/817 [==============================] - 0s 119us/sample - loss: 15.8089 - val_loss: 16.1788\n",
            "Epoch 6/35\n",
            "817/817 [==============================] - 0s 137us/sample - loss: 15.7673 - val_loss: 16.0451\n",
            "Epoch 7/35\n",
            "817/817 [==============================] - 0s 122us/sample - loss: 15.7116 - val_loss: 16.0554\n",
            "Epoch 8/35\n",
            "817/817 [==============================] - 0s 123us/sample - loss: 15.5951 - val_loss: 16.0747\n",
            "Epoch 9/35\n",
            "817/817 [==============================] - 0s 121us/sample - loss: 15.5797 - val_loss: 16.0695\n",
            "Epoch 10/35\n",
            "817/817 [==============================] - 0s 131us/sample - loss: 15.5101 - val_loss: 16.5228\n",
            "Epoch 11/35\n",
            "817/817 [==============================] - 0s 136us/sample - loss: 15.4660 - val_loss: 15.9430\n",
            "Epoch 12/35\n",
            "817/817 [==============================] - 0s 135us/sample - loss: 15.4549 - val_loss: 15.9928\n",
            "Epoch 13/35\n",
            "817/817 [==============================] - 0s 136us/sample - loss: 15.3885 - val_loss: 16.0249\n",
            "Epoch 14/35\n",
            "817/817 [==============================] - 0s 128us/sample - loss: 15.3472 - val_loss: 16.1088\n",
            "Epoch 15/35\n",
            "817/817 [==============================] - 0s 126us/sample - loss: 15.3230 - val_loss: 16.0799\n",
            "Epoch 16/35\n",
            "817/817 [==============================] - 0s 119us/sample - loss: 15.3155 - val_loss: 16.2305\n",
            "Epoch 17/35\n",
            "817/817 [==============================] - 0s 133us/sample - loss: 15.2732 - val_loss: 16.1073\n",
            "Epoch 18/35\n",
            "817/817 [==============================] - 0s 129us/sample - loss: 15.1908 - val_loss: 16.0539\n",
            "Epoch 19/35\n",
            "817/817 [==============================] - 0s 118us/sample - loss: 15.2507 - val_loss: 16.0041\n",
            "Epoch 20/35\n",
            "817/817 [==============================] - 0s 143us/sample - loss: 15.1294 - val_loss: 16.3503\n",
            "Epoch 21/35\n",
            "817/817 [==============================] - 0s 153us/sample - loss: 15.1293 - val_loss: 16.1097\n",
            "[CV]  learning_rate=0.02285600107008809, n_hidden=4, n_neurons=40, total=   3.1s\n",
            "[CV] learning_rate=0.02285600107008809, n_hidden=4, n_neurons=40 .....\n",
            "Train on 818 samples, validate on 91 samples\n",
            "Epoch 1/35\n",
            "818/818 [==============================] - 1s 746us/sample - loss: 16.3398 - val_loss: 7.7713\n",
            "Epoch 2/35\n",
            "818/818 [==============================] - 0s 131us/sample - loss: 6.1222 - val_loss: 5.3985\n",
            "Epoch 3/35\n",
            "818/818 [==============================] - 0s 143us/sample - loss: 5.3160 - val_loss: 5.2547\n",
            "Epoch 4/35\n",
            "818/818 [==============================] - 0s 126us/sample - loss: 5.1321 - val_loss: 5.0350\n",
            "Epoch 5/35\n",
            "818/818 [==============================] - 0s 125us/sample - loss: 4.7012 - val_loss: 5.5034\n",
            "Epoch 6/35\n",
            "818/818 [==============================] - 0s 133us/sample - loss: 4.6857 - val_loss: 5.7681\n",
            "Epoch 7/35\n",
            "818/818 [==============================] - 0s 128us/sample - loss: 4.5760 - val_loss: 4.7311\n",
            "Epoch 8/35\n",
            "818/818 [==============================] - 0s 121us/sample - loss: 4.4945 - val_loss: 5.4317\n",
            "Epoch 9/35\n",
            "818/818 [==============================] - 0s 141us/sample - loss: 4.0553 - val_loss: 5.0056\n",
            "Epoch 10/35\n",
            "818/818 [==============================] - 0s 125us/sample - loss: 4.2096 - val_loss: 3.8563\n",
            "Epoch 11/35\n",
            "818/818 [==============================] - 0s 124us/sample - loss: 3.9976 - val_loss: 4.0044\n",
            "Epoch 12/35\n",
            "818/818 [==============================] - 0s 127us/sample - loss: 3.9454 - val_loss: 5.7938\n",
            "Epoch 13/35\n",
            "818/818 [==============================] - 0s 143us/sample - loss: 3.9894 - val_loss: 5.6213\n",
            "Epoch 14/35\n",
            "818/818 [==============================] - 0s 120us/sample - loss: 3.8811 - val_loss: 5.2552\n",
            "Epoch 15/35\n",
            "818/818 [==============================] - 0s 126us/sample - loss: 3.7426 - val_loss: 4.9108\n",
            "Epoch 16/35\n",
            "818/818 [==============================] - 0s 117us/sample - loss: 3.8406 - val_loss: 5.0509\n",
            "Epoch 17/35\n",
            "818/818 [==============================] - 0s 126us/sample - loss: 3.5860 - val_loss: 4.2217\n",
            "Epoch 18/35\n",
            "818/818 [==============================] - 0s 122us/sample - loss: 3.6213 - val_loss: 5.1471\n",
            "Epoch 19/35\n",
            "818/818 [==============================] - 0s 130us/sample - loss: 3.5470 - val_loss: 4.1558\n",
            "Epoch 20/35\n",
            "818/818 [==============================] - 0s 127us/sample - loss: 3.4294 - val_loss: 4.0162\n",
            "[CV]  learning_rate=0.02285600107008809, n_hidden=4, n_neurons=40, total=   2.9s\n",
            "[CV] learning_rate=0.02285600107008809, n_hidden=4, n_neurons=40 .....\n",
            "Train on 818 samples, validate on 91 samples\n",
            "Epoch 1/35\n",
            "818/818 [==============================] - 1s 736us/sample - loss: 20.5232 - val_loss: 14.6646\n",
            "Epoch 2/35\n",
            "818/818 [==============================] - 0s 131us/sample - loss: 12.1979 - val_loss: 10.4258\n",
            "Epoch 3/35\n",
            "818/818 [==============================] - 0s 123us/sample - loss: 10.3039 - val_loss: 9.8234\n",
            "Epoch 4/35\n",
            "818/818 [==============================] - 0s 133us/sample - loss: 9.8234 - val_loss: 9.4806\n",
            "Epoch 5/35\n",
            "818/818 [==============================] - 0s 147us/sample - loss: 9.6127 - val_loss: 9.8279\n",
            "Epoch 6/35\n",
            "818/818 [==============================] - 0s 122us/sample - loss: 9.8556 - val_loss: 10.4665\n",
            "Epoch 7/35\n",
            "818/818 [==============================] - 0s 128us/sample - loss: 9.8334 - val_loss: 10.0312\n",
            "Epoch 8/35\n",
            "818/818 [==============================] - 0s 123us/sample - loss: 9.5898 - val_loss: 9.9780\n",
            "Epoch 9/35\n",
            "818/818 [==============================] - 0s 137us/sample - loss: 9.6657 - val_loss: 10.2803\n",
            "Epoch 10/35\n",
            "818/818 [==============================] - 0s 146us/sample - loss: 9.6578 - val_loss: 9.1630\n",
            "Epoch 11/35\n",
            "818/818 [==============================] - 0s 145us/sample - loss: 9.4692 - val_loss: 9.8848\n",
            "Epoch 12/35\n",
            "818/818 [==============================] - 0s 124us/sample - loss: 9.7177 - val_loss: 9.4171\n",
            "Epoch 13/35\n",
            "818/818 [==============================] - 0s 122us/sample - loss: 9.6319 - val_loss: 9.2506\n",
            "Epoch 14/35\n",
            "818/818 [==============================] - 0s 143us/sample - loss: 9.5015 - val_loss: 9.6211\n",
            "Epoch 15/35\n",
            "818/818 [==============================] - 0s 132us/sample - loss: 9.6143 - val_loss: 9.5761\n",
            "Epoch 16/35\n",
            "818/818 [==============================] - 0s 138us/sample - loss: 9.4365 - val_loss: 10.3698\n",
            "Epoch 17/35\n",
            "818/818 [==============================] - 0s 141us/sample - loss: 9.4238 - val_loss: 9.4673\n",
            "Epoch 18/35\n",
            "818/818 [==============================] - 0s 133us/sample - loss: 9.5429 - val_loss: 9.7326\n",
            "Epoch 19/35\n",
            "818/818 [==============================] - 0s 125us/sample - loss: 9.3646 - val_loss: 9.9578\n",
            "Epoch 20/35\n",
            "818/818 [==============================] - 0s 126us/sample - loss: 9.2335 - val_loss: 9.4662\n",
            "[CV]  learning_rate=0.02285600107008809, n_hidden=4, n_neurons=40, total=   3.0s\n",
            "[CV] learning_rate=0.0070353107068940905, n_hidden=3, n_neurons=46 ...\n",
            "Train on 817 samples, validate on 91 samples\n",
            "Epoch 1/35\n",
            "817/817 [==============================] - 1s 690us/sample - loss: 21.2997 - val_loss: 20.8776\n",
            "Epoch 2/35\n",
            "817/817 [==============================] - 0s 121us/sample - loss: 20.9109 - val_loss: 20.1695\n",
            "Epoch 3/35\n",
            "817/817 [==============================] - 0s 123us/sample - loss: 19.9239 - val_loss: 18.3736\n",
            "Epoch 4/35\n",
            "817/817 [==============================] - 0s 125us/sample - loss: 16.7153 - val_loss: 12.3839\n",
            "Epoch 5/35\n",
            "817/817 [==============================] - 0s 119us/sample - loss: 10.2605 - val_loss: 9.5899\n",
            "Epoch 6/35\n",
            "817/817 [==============================] - 0s 124us/sample - loss: 8.0003 - val_loss: 8.1952\n",
            "Epoch 7/35\n",
            "817/817 [==============================] - 0s 130us/sample - loss: 6.6522 - val_loss: 6.6746\n",
            "Epoch 8/35\n",
            "817/817 [==============================] - 0s 150us/sample - loss: 5.6115 - val_loss: 5.6177\n",
            "Epoch 9/35\n",
            "817/817 [==============================] - 0s 123us/sample - loss: 4.9802 - val_loss: 5.1556\n",
            "Epoch 10/35\n",
            "817/817 [==============================] - 0s 127us/sample - loss: 4.5823 - val_loss: 4.8236\n",
            "Epoch 11/35\n",
            "817/817 [==============================] - 0s 121us/sample - loss: 4.3252 - val_loss: 4.6338\n",
            "Epoch 12/35\n",
            "817/817 [==============================] - 0s 123us/sample - loss: 4.1056 - val_loss: 4.5155\n",
            "Epoch 13/35\n",
            "817/817 [==============================] - 0s 120us/sample - loss: 3.9367 - val_loss: 4.4355\n",
            "Epoch 14/35\n",
            "817/817 [==============================] - 0s 120us/sample - loss: 3.7962 - val_loss: 4.3577\n",
            "Epoch 15/35\n",
            "817/817 [==============================] - 0s 131us/sample - loss: 3.6737 - val_loss: 4.2533\n",
            "Epoch 16/35\n",
            "817/817 [==============================] - 0s 124us/sample - loss: 3.5672 - val_loss: 4.1566\n",
            "Epoch 17/35\n",
            "817/817 [==============================] - 0s 116us/sample - loss: 3.4813 - val_loss: 4.1111\n",
            "Epoch 18/35\n",
            "817/817 [==============================] - 0s 131us/sample - loss: 3.3975 - val_loss: 4.1113\n",
            "Epoch 19/35\n",
            "817/817 [==============================] - 0s 126us/sample - loss: 3.3338 - val_loss: 4.0011\n",
            "Epoch 20/35\n",
            "817/817 [==============================] - 0s 124us/sample - loss: 3.2761 - val_loss: 3.9806\n",
            "Epoch 21/35\n",
            "817/817 [==============================] - 0s 122us/sample - loss: 3.1978 - val_loss: 3.9657\n",
            "Epoch 22/35\n",
            "817/817 [==============================] - 0s 119us/sample - loss: 3.1745 - val_loss: 3.9403\n",
            "Epoch 23/35\n",
            "817/817 [==============================] - 0s 119us/sample - loss: 3.1129 - val_loss: 3.9408\n",
            "Epoch 24/35\n",
            "817/817 [==============================] - 0s 130us/sample - loss: 3.0769 - val_loss: 3.8239\n",
            "Epoch 25/35\n",
            "817/817 [==============================] - 0s 128us/sample - loss: 3.0417 - val_loss: 3.8989\n",
            "Epoch 26/35\n",
            "817/817 [==============================] - 0s 141us/sample - loss: 3.0164 - val_loss: 3.8110\n",
            "Epoch 27/35\n",
            "817/817 [==============================] - 0s 131us/sample - loss: 2.9842 - val_loss: 3.7808\n",
            "Epoch 28/35\n",
            "817/817 [==============================] - 0s 126us/sample - loss: 2.9336 - val_loss: 3.7710\n",
            "Epoch 29/35\n",
            "817/817 [==============================] - 0s 119us/sample - loss: 2.9034 - val_loss: 3.8150\n",
            "Epoch 30/35\n",
            "817/817 [==============================] - 0s 117us/sample - loss: 2.8780 - val_loss: 3.8006\n",
            "Epoch 31/35\n",
            "817/817 [==============================] - 0s 124us/sample - loss: 2.8480 - val_loss: 3.7588\n",
            "Epoch 32/35\n",
            "817/817 [==============================] - 0s 119us/sample - loss: 2.8184 - val_loss: 3.7416\n",
            "Epoch 33/35\n",
            "817/817 [==============================] - 0s 120us/sample - loss: 2.8038 - val_loss: 3.6863\n",
            "Epoch 34/35\n",
            "817/817 [==============================] - 0s 116us/sample - loss: 2.7867 - val_loss: 3.7619\n",
            "Epoch 35/35\n",
            "817/817 [==============================] - 0s 164us/sample - loss: 2.7662 - val_loss: 3.8602\n",
            "[CV]  learning_rate=0.0070353107068940905, n_hidden=3, n_neurons=46, total=   4.4s\n",
            "[CV] learning_rate=0.0070353107068940905, n_hidden=3, n_neurons=46 ...\n",
            "Train on 818 samples, validate on 91 samples\n",
            "Epoch 1/35\n",
            "818/818 [==============================] - 1s 688us/sample - loss: 21.3644 - val_loss: 20.8273\n",
            "Epoch 2/35\n",
            "818/818 [==============================] - 0s 128us/sample - loss: 20.7599 - val_loss: 19.5679\n",
            "Epoch 3/35\n",
            "818/818 [==============================] - 0s 120us/sample - loss: 18.1318 - val_loss: 13.1978\n",
            "Epoch 4/35\n",
            "818/818 [==============================] - 0s 146us/sample - loss: 10.2666 - val_loss: 9.2165\n",
            "Epoch 5/35\n",
            "818/818 [==============================] - 0s 126us/sample - loss: 8.0352 - val_loss: 8.0443\n",
            "Epoch 6/35\n",
            "818/818 [==============================] - 0s 134us/sample - loss: 6.9558 - val_loss: 6.6475\n",
            "Epoch 7/35\n",
            "818/818 [==============================] - 0s 120us/sample - loss: 6.0195 - val_loss: 5.6926\n",
            "Epoch 8/35\n",
            "818/818 [==============================] - 0s 119us/sample - loss: 5.3822 - val_loss: 5.2024\n",
            "Epoch 9/35\n",
            "818/818 [==============================] - 0s 127us/sample - loss: 4.9297 - val_loss: 5.0162\n",
            "Epoch 10/35\n",
            "818/818 [==============================] - 0s 133us/sample - loss: 4.5973 - val_loss: 4.6056\n",
            "Epoch 11/35\n",
            "818/818 [==============================] - 0s 119us/sample - loss: 4.3534 - val_loss: 4.3694\n",
            "Epoch 12/35\n",
            "818/818 [==============================] - 0s 122us/sample - loss: 4.1579 - val_loss: 4.3221\n",
            "Epoch 13/35\n",
            "818/818 [==============================] - 0s 135us/sample - loss: 3.9750 - val_loss: 4.1135\n",
            "Epoch 14/35\n",
            "818/818 [==============================] - 0s 125us/sample - loss: 3.8493 - val_loss: 4.1696\n",
            "Epoch 15/35\n",
            "818/818 [==============================] - 0s 118us/sample - loss: 3.7546 - val_loss: 3.9794\n",
            "Epoch 16/35\n",
            "818/818 [==============================] - 0s 126us/sample - loss: 3.6398 - val_loss: 4.0712\n",
            "Epoch 17/35\n",
            "818/818 [==============================] - 0s 124us/sample - loss: 3.5897 - val_loss: 4.0301\n",
            "Epoch 18/35\n",
            "818/818 [==============================] - 0s 123us/sample - loss: 3.5007 - val_loss: 3.8763\n",
            "Epoch 19/35\n",
            "818/818 [==============================] - 0s 119us/sample - loss: 3.4583 - val_loss: 4.0131\n",
            "Epoch 20/35\n",
            "818/818 [==============================] - 0s 121us/sample - loss: 3.4019 - val_loss: 4.0184\n",
            "Epoch 21/35\n",
            "818/818 [==============================] - 0s 121us/sample - loss: 3.3584 - val_loss: 3.8576\n",
            "Epoch 22/35\n",
            "818/818 [==============================] - 0s 115us/sample - loss: 3.2899 - val_loss: 3.8473\n",
            "Epoch 23/35\n",
            "818/818 [==============================] - 0s 139us/sample - loss: 3.2567 - val_loss: 3.8404\n",
            "Epoch 24/35\n",
            "818/818 [==============================] - 0s 120us/sample - loss: 3.2045 - val_loss: 3.9028\n",
            "Epoch 25/35\n",
            "818/818 [==============================] - 0s 116us/sample - loss: 3.1853 - val_loss: 3.8245\n",
            "Epoch 26/35\n",
            "818/818 [==============================] - 0s 138us/sample - loss: 3.1146 - val_loss: 3.9361\n",
            "Epoch 27/35\n",
            "818/818 [==============================] - 0s 114us/sample - loss: 3.0905 - val_loss: 3.9447\n",
            "Epoch 28/35\n",
            "818/818 [==============================] - 0s 116us/sample - loss: 3.0722 - val_loss: 4.0800\n",
            "Epoch 29/35\n",
            "818/818 [==============================] - 0s 125us/sample - loss: 3.0561 - val_loss: 3.8498\n",
            "Epoch 30/35\n",
            "818/818 [==============================] - 0s 117us/sample - loss: 3.0186 - val_loss: 3.7817\n",
            "Epoch 31/35\n",
            "818/818 [==============================] - 0s 118us/sample - loss: 2.9745 - val_loss: 3.8576\n",
            "Epoch 32/35\n",
            "818/818 [==============================] - 0s 116us/sample - loss: 2.9718 - val_loss: 3.8200\n",
            "Epoch 33/35\n",
            "818/818 [==============================] - 0s 136us/sample - loss: 2.9539 - val_loss: 3.7683\n",
            "Epoch 34/35\n",
            "818/818 [==============================] - 0s 128us/sample - loss: 2.9146 - val_loss: 3.7992\n",
            "Epoch 35/35\n",
            "818/818 [==============================] - 0s 130us/sample - loss: 2.8776 - val_loss: 3.7518\n",
            "[CV]  learning_rate=0.0070353107068940905, n_hidden=3, n_neurons=46, total=   4.4s\n",
            "[CV] learning_rate=0.0070353107068940905, n_hidden=3, n_neurons=46 ...\n",
            "Train on 818 samples, validate on 91 samples\n",
            "Epoch 1/35\n",
            "818/818 [==============================] - 1s 648us/sample - loss: 20.8370 - val_loss: 19.8577\n",
            "Epoch 2/35\n",
            "818/818 [==============================] - 0s 134us/sample - loss: 17.7383 - val_loss: 13.7575\n",
            "Epoch 3/35\n",
            "818/818 [==============================] - 0s 132us/sample - loss: 10.2622 - val_loss: 8.2530\n",
            "Epoch 4/35\n",
            "818/818 [==============================] - 0s 122us/sample - loss: 7.9666 - val_loss: 7.2109\n",
            "Epoch 5/35\n",
            "818/818 [==============================] - 0s 132us/sample - loss: 6.9730 - val_loss: 6.4058\n",
            "Epoch 6/35\n",
            "818/818 [==============================] - 0s 134us/sample - loss: 6.1835 - val_loss: 5.8698\n",
            "Epoch 7/35\n",
            "818/818 [==============================] - 0s 129us/sample - loss: 5.6198 - val_loss: 5.4444\n",
            "Epoch 8/35\n",
            "818/818 [==============================] - 0s 125us/sample - loss: 5.2023 - val_loss: 5.3273\n",
            "Epoch 9/35\n",
            "818/818 [==============================] - 0s 119us/sample - loss: 4.9140 - val_loss: 5.0503\n",
            "Epoch 10/35\n",
            "818/818 [==============================] - 0s 131us/sample - loss: 4.6894 - val_loss: 4.8028\n",
            "Epoch 11/35\n",
            "818/818 [==============================] - 0s 165us/sample - loss: 4.4585 - val_loss: 4.6683\n",
            "Epoch 12/35\n",
            "818/818 [==============================] - 0s 125us/sample - loss: 4.2929 - val_loss: 4.4939\n",
            "Epoch 13/35\n",
            "818/818 [==============================] - 0s 128us/sample - loss: 4.1278 - val_loss: 4.4303\n",
            "Epoch 14/35\n",
            "818/818 [==============================] - 0s 135us/sample - loss: 4.0110 - val_loss: 4.2266\n",
            "Epoch 15/35\n",
            "818/818 [==============================] - 0s 125us/sample - loss: 3.8425 - val_loss: 4.1062\n",
            "Epoch 16/35\n",
            "818/818 [==============================] - 0s 122us/sample - loss: 3.7401 - val_loss: 4.1637\n",
            "Epoch 17/35\n",
            "818/818 [==============================] - 0s 117us/sample - loss: 3.6379 - val_loss: 3.9831\n",
            "Epoch 18/35\n",
            "818/818 [==============================] - 0s 111us/sample - loss: 3.5490 - val_loss: 3.9335\n",
            "Epoch 19/35\n",
            "818/818 [==============================] - 0s 121us/sample - loss: 3.4738 - val_loss: 3.8691\n",
            "Epoch 20/35\n",
            "818/818 [==============================] - 0s 124us/sample - loss: 3.4148 - val_loss: 3.8459\n",
            "Epoch 21/35\n",
            "818/818 [==============================] - 0s 148us/sample - loss: 3.3487 - val_loss: 3.7777\n",
            "Epoch 22/35\n",
            "818/818 [==============================] - 0s 125us/sample - loss: 3.2826 - val_loss: 3.7733\n",
            "Epoch 23/35\n",
            "818/818 [==============================] - 0s 117us/sample - loss: 3.2300 - val_loss: 3.8085\n",
            "Epoch 24/35\n",
            "818/818 [==============================] - 0s 123us/sample - loss: 3.1929 - val_loss: 3.7039\n",
            "Epoch 25/35\n",
            "818/818 [==============================] - 0s 123us/sample - loss: 3.1375 - val_loss: 3.8196\n",
            "Epoch 26/35\n",
            "818/818 [==============================] - 0s 115us/sample - loss: 3.1121 - val_loss: 3.7251\n",
            "Epoch 27/35\n",
            "818/818 [==============================] - 0s 135us/sample - loss: 3.0677 - val_loss: 3.6814\n",
            "Epoch 28/35\n",
            "818/818 [==============================] - 0s 125us/sample - loss: 3.0396 - val_loss: 3.6506\n",
            "Epoch 29/35\n",
            "818/818 [==============================] - 0s 138us/sample - loss: 3.0017 - val_loss: 3.6818\n",
            "Epoch 30/35\n",
            "818/818 [==============================] - 0s 131us/sample - loss: 2.9473 - val_loss: 3.6361\n",
            "Epoch 31/35\n",
            "818/818 [==============================] - 0s 136us/sample - loss: 2.9286 - val_loss: 3.5879\n",
            "Epoch 32/35\n",
            "818/818 [==============================] - 0s 117us/sample - loss: 2.9234 - val_loss: 3.6455\n",
            "Epoch 33/35\n",
            "818/818 [==============================] - 0s 120us/sample - loss: 2.8770 - val_loss: 3.5706\n",
            "Epoch 34/35\n",
            "818/818 [==============================] - 0s 122us/sample - loss: 2.8276 - val_loss: 3.5851\n",
            "Epoch 35/35\n",
            "818/818 [==============================] - 0s 130us/sample - loss: 2.8137 - val_loss: 3.6097\n",
            "[CV]  learning_rate=0.0070353107068940905, n_hidden=3, n_neurons=46, total=   4.4s\n",
            "Train on 1226 samples, validate on 137 samples\n",
            "Epoch 1/35\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  2.0min finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1226/1226 [==============================] - 1s 426us/sample - loss: 20.9921 - val_loss: 19.8729\n",
            "Epoch 2/35\n",
            "1226/1226 [==============================] - 0s 117us/sample - loss: 19.1581 - val_loss: 18.1086\n",
            "Epoch 3/35\n",
            "1226/1226 [==============================] - 0s 119us/sample - loss: 17.7727 - val_loss: 17.7140\n",
            "Epoch 4/35\n",
            "1226/1226 [==============================] - 0s 111us/sample - loss: 17.0877 - val_loss: 16.2894\n",
            "Epoch 5/35\n",
            "1226/1226 [==============================] - 0s 118us/sample - loss: 14.7794 - val_loss: 14.5875\n",
            "Epoch 6/35\n",
            "1226/1226 [==============================] - 0s 111us/sample - loss: 13.5202 - val_loss: 13.4342\n",
            "Epoch 7/35\n",
            "1226/1226 [==============================] - 0s 120us/sample - loss: 11.8610 - val_loss: 11.1496\n",
            "Epoch 8/35\n",
            "1226/1226 [==============================] - 0s 106us/sample - loss: 9.4486 - val_loss: 8.2914\n",
            "Epoch 9/35\n",
            "1226/1226 [==============================] - 0s 131us/sample - loss: 7.4805 - val_loss: 7.2193\n",
            "Epoch 10/35\n",
            "1226/1226 [==============================] - 0s 112us/sample - loss: 6.5349 - val_loss: 6.3280\n",
            "Epoch 11/35\n",
            "1226/1226 [==============================] - 0s 115us/sample - loss: 5.7105 - val_loss: 5.5137\n",
            "Epoch 12/35\n",
            "1226/1226 [==============================] - 0s 114us/sample - loss: 4.9615 - val_loss: 4.8324\n",
            "Epoch 13/35\n",
            "1226/1226 [==============================] - 0s 111us/sample - loss: 4.3698 - val_loss: 4.2647\n",
            "Epoch 14/35\n",
            "1226/1226 [==============================] - 0s 139us/sample - loss: 3.9941 - val_loss: 3.9898\n",
            "Epoch 15/35\n",
            "1226/1226 [==============================] - 0s 123us/sample - loss: 3.7476 - val_loss: 3.7359\n",
            "Epoch 16/35\n",
            "1226/1226 [==============================] - 0s 111us/sample - loss: 3.5925 - val_loss: 3.6466\n",
            "Epoch 17/35\n",
            "1226/1226 [==============================] - 0s 111us/sample - loss: 3.4825 - val_loss: 3.5360\n",
            "Epoch 18/35\n",
            "1226/1226 [==============================] - 0s 119us/sample - loss: 3.3909 - val_loss: 3.5173\n",
            "Epoch 19/35\n",
            "1226/1226 [==============================] - 0s 109us/sample - loss: 3.3258 - val_loss: 3.4037\n",
            "Epoch 20/35\n",
            "1226/1226 [==============================] - 0s 112us/sample - loss: 3.2696 - val_loss: 3.3629\n",
            "Epoch 21/35\n",
            "1226/1226 [==============================] - 0s 122us/sample - loss: 3.2150 - val_loss: 3.3193\n",
            "Epoch 22/35\n",
            "1226/1226 [==============================] - 0s 112us/sample - loss: 3.1679 - val_loss: 3.3031\n",
            "Epoch 23/35\n",
            "1226/1226 [==============================] - 0s 121us/sample - loss: 3.1417 - val_loss: 3.2774\n",
            "Epoch 24/35\n",
            "1226/1226 [==============================] - 0s 118us/sample - loss: 3.1156 - val_loss: 3.2792\n",
            "Epoch 25/35\n",
            "1226/1226 [==============================] - 0s 115us/sample - loss: 3.0753 - val_loss: 3.2596\n",
            "Epoch 26/35\n",
            "1226/1226 [==============================] - 0s 111us/sample - loss: 3.0539 - val_loss: 3.3412\n",
            "Epoch 27/35\n",
            "1226/1226 [==============================] - 0s 113us/sample - loss: 3.0392 - val_loss: 3.3029\n",
            "Epoch 28/35\n",
            "1226/1226 [==============================] - 0s 120us/sample - loss: 3.0136 - val_loss: 3.2431\n",
            "Epoch 29/35\n",
            "1226/1226 [==============================] - 0s 119us/sample - loss: 2.9903 - val_loss: 3.2018\n",
            "Epoch 30/35\n",
            "1226/1226 [==============================] - 0s 109us/sample - loss: 2.9721 - val_loss: 3.3057\n",
            "Epoch 31/35\n",
            "1226/1226 [==============================] - 0s 102us/sample - loss: 2.9666 - val_loss: 3.2502\n",
            "Epoch 32/35\n",
            "1226/1226 [==============================] - 0s 102us/sample - loss: 2.9462 - val_loss: 3.1513\n",
            "Epoch 33/35\n",
            "1226/1226 [==============================] - 0s 122us/sample - loss: 2.9329 - val_loss: 3.1964\n",
            "Epoch 34/35\n",
            "1226/1226 [==============================] - 0s 117us/sample - loss: 2.9284 - val_loss: 3.1998\n",
            "Epoch 35/35\n",
            "1226/1226 [==============================] - 0s 131us/sample - loss: 2.9257 - val_loss: 3.1738\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
              "                   estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7fab028f3208>,\n",
              "                   iid='warn', n_iter=10, n_jobs=None,\n",
              "                   param_distributions={'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7faae6af8860>,\n",
              "                                        'n_hidden': [0, 1, 2, 3, 4, 5],\n",
              "                                        'n_neurons': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9...\n",
              "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
              "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
              "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
              "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
              "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])},\n",
              "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "                   return_train_score=False, scoring='neg_mean_squared_error',\n",
              "                   verbose=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxK_WlV-JBtZ",
        "colab_type": "code",
        "outputId": "7e3b4910-f8f7-48f4-dc81-3c0a78d93646",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        }
      },
      "source": [
        "print('best parameter :',rnd_search_cv.best_params_)\n",
        "print('best score(rmse) :',np.sqrt(-rnd_search_cv.best_score_))\n",
        "print('best estimator :',rnd_search_cv.best_estimator_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best parameter : {'learning_rate': 0.015618437282778579, 'n_hidden': 1, 'n_neurons': 72}\n",
            "best score(rmse) : 5.326996526865439\n",
            "best estimator : <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7faae6a87c50>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwlddwPEQD_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hidden_num = rnd_search_cv.best_params_['n_hidden']\n",
        "neurons_num =  rnd_search_cv.best_params_['n_neurons']\n",
        "learning_r = rnd_search_cv.best_params_['learning_rate']\n",
        "loss = tf.losses.Huber(delta=1.0)\n",
        "def build_model(n_hidden=hidden_num, n_neurons=neurons_num, learning_rate=learning_r, input_shape=[71]):\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
        "    for layer in range(n_hidden):\n",
        "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
        "    model.add(keras.layers.Dense(2,activation= \"relu\"))\n",
        "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
        "    model.compile(loss=loss, optimizer=optimizer)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uX1cgvhDJTSe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_reg = keras.wrappers.scikit_learn.KerasRegressor(build_fn=build_model\n",
        "                                                      ,epochs=60)                                                      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3e8vpGskJkXH",
        "colab_type": "code",
        "outputId": "5edf39f6-6677-48b9-a79b-721723fc9941",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "kfold = KFold(n_splits=5, random_state=42)\n",
        "scores = cross_val_score(model_reg,X,y_reg.values,\n",
        "                         scoring=\"neg_mean_squared_error\",\n",
        "                         cv=kfold)\n",
        "keras_reg_scores = np.sqrt(-scores).mean()\n",
        "print('keras_reg validation score(rmse) :', keras_reg_scores)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1090 samples\n",
            "Epoch 1/60\n",
            "1090/1090 [==============================] - 0s 387us/sample - loss: 19.7490\n",
            "Epoch 2/60\n",
            "1090/1090 [==============================] - 0s 91us/sample - loss: 16.1036\n",
            "Epoch 3/60\n",
            "1090/1090 [==============================] - 0s 107us/sample - loss: 11.6312\n",
            "Epoch 4/60\n",
            "1090/1090 [==============================] - 0s 114us/sample - loss: 9.7305\n",
            "Epoch 5/60\n",
            "1090/1090 [==============================] - 0s 96us/sample - loss: 9.0649\n",
            "Epoch 6/60\n",
            "1090/1090 [==============================] - 0s 92us/sample - loss: 8.3633\n",
            "Epoch 7/60\n",
            "1090/1090 [==============================] - 0s 90us/sample - loss: 7.6374\n",
            "Epoch 8/60\n",
            "1090/1090 [==============================] - 0s 91us/sample - loss: 6.8299\n",
            "Epoch 9/60\n",
            "1090/1090 [==============================] - 0s 103us/sample - loss: 6.0563\n",
            "Epoch 10/60\n",
            "1090/1090 [==============================] - 0s 116us/sample - loss: 5.3164\n",
            "Epoch 11/60\n",
            "1090/1090 [==============================] - 0s 98us/sample - loss: 4.6459\n",
            "Epoch 12/60\n",
            "1090/1090 [==============================] - 0s 115us/sample - loss: 4.1715\n",
            "Epoch 13/60\n",
            "1090/1090 [==============================] - 0s 106us/sample - loss: 3.9036\n",
            "Epoch 14/60\n",
            "1090/1090 [==============================] - 0s 92us/sample - loss: 3.7027\n",
            "Epoch 15/60\n",
            "1090/1090 [==============================] - 0s 91us/sample - loss: 3.5655\n",
            "Epoch 16/60\n",
            "1090/1090 [==============================] - 0s 102us/sample - loss: 3.4750\n",
            "Epoch 17/60\n",
            "1090/1090 [==============================] - 0s 103us/sample - loss: 3.3886\n",
            "Epoch 18/60\n",
            "1090/1090 [==============================] - 0s 106us/sample - loss: 3.3354\n",
            "Epoch 19/60\n",
            "1090/1090 [==============================] - 0s 104us/sample - loss: 3.3453\n",
            "Epoch 20/60\n",
            "1090/1090 [==============================] - 0s 93us/sample - loss: 3.2076\n",
            "Epoch 21/60\n",
            "1090/1090 [==============================] - 0s 92us/sample - loss: 3.1794\n",
            "Epoch 22/60\n",
            "1090/1090 [==============================] - 0s 102us/sample - loss: 3.1363\n",
            "Epoch 23/60\n",
            "1090/1090 [==============================] - 0s 97us/sample - loss: 3.0959\n",
            "Epoch 24/60\n",
            "1090/1090 [==============================] - 0s 92us/sample - loss: 3.0837\n",
            "Epoch 25/60\n",
            "1090/1090 [==============================] - 0s 96us/sample - loss: 3.0376\n",
            "Epoch 26/60\n",
            "1090/1090 [==============================] - 0s 92us/sample - loss: 3.0231\n",
            "Epoch 27/60\n",
            "1090/1090 [==============================] - 0s 92us/sample - loss: 3.0026\n",
            "Epoch 28/60\n",
            "1090/1090 [==============================] - 0s 97us/sample - loss: 2.9969\n",
            "Epoch 29/60\n",
            "1090/1090 [==============================] - 0s 97us/sample - loss: 2.9579\n",
            "Epoch 30/60\n",
            "1090/1090 [==============================] - 0s 98us/sample - loss: 2.9339\n",
            "Epoch 31/60\n",
            "1090/1090 [==============================] - 0s 92us/sample - loss: 2.9401\n",
            "Epoch 32/60\n",
            "1090/1090 [==============================] - 0s 118us/sample - loss: 2.9240\n",
            "Epoch 33/60\n",
            "1090/1090 [==============================] - 0s 97us/sample - loss: 2.9104\n",
            "Epoch 34/60\n",
            "1090/1090 [==============================] - 0s 93us/sample - loss: 2.8955\n",
            "Epoch 35/60\n",
            "1090/1090 [==============================] - 0s 106us/sample - loss: 2.8732\n",
            "Epoch 36/60\n",
            "1090/1090 [==============================] - 0s 94us/sample - loss: 2.8883\n",
            "Epoch 37/60\n",
            "1090/1090 [==============================] - 0s 96us/sample - loss: 2.8486\n",
            "Epoch 38/60\n",
            "1090/1090 [==============================] - 0s 95us/sample - loss: 2.8515\n",
            "Epoch 39/60\n",
            "1090/1090 [==============================] - 0s 93us/sample - loss: 2.8186\n",
            "Epoch 40/60\n",
            "1090/1090 [==============================] - 0s 92us/sample - loss: 2.8087\n",
            "Epoch 41/60\n",
            "1090/1090 [==============================] - 0s 104us/sample - loss: 2.8263\n",
            "Epoch 42/60\n",
            "1090/1090 [==============================] - 0s 94us/sample - loss: 2.7981\n",
            "Epoch 43/60\n",
            "1090/1090 [==============================] - 0s 97us/sample - loss: 2.8020\n",
            "Epoch 44/60\n",
            "1090/1090 [==============================] - 0s 97us/sample - loss: 2.7934\n",
            "Epoch 45/60\n",
            "1090/1090 [==============================] - 0s 104us/sample - loss: 2.7806\n",
            "Epoch 46/60\n",
            "1090/1090 [==============================] - 0s 94us/sample - loss: 2.7732\n",
            "Epoch 47/60\n",
            "1090/1090 [==============================] - 0s 88us/sample - loss: 2.7622\n",
            "Epoch 48/60\n",
            "1090/1090 [==============================] - 0s 105us/sample - loss: 2.7475\n",
            "Epoch 49/60\n",
            "1090/1090 [==============================] - 0s 91us/sample - loss: 2.7613\n",
            "Epoch 50/60\n",
            "1090/1090 [==============================] - 0s 98us/sample - loss: 2.7446\n",
            "Epoch 51/60\n",
            "1090/1090 [==============================] - 0s 107us/sample - loss: 2.7304\n",
            "Epoch 52/60\n",
            "1090/1090 [==============================] - 0s 92us/sample - loss: 2.7369\n",
            "Epoch 53/60\n",
            "1090/1090 [==============================] - 0s 92us/sample - loss: 2.7309\n",
            "Epoch 54/60\n",
            "1090/1090 [==============================] - 0s 92us/sample - loss: 2.7093\n",
            "Epoch 55/60\n",
            "1090/1090 [==============================] - 0s 92us/sample - loss: 2.7144\n",
            "Epoch 56/60\n",
            "1090/1090 [==============================] - 0s 92us/sample - loss: 2.7434\n",
            "Epoch 57/60\n",
            "1090/1090 [==============================] - 0s 91us/sample - loss: 2.7152\n",
            "Epoch 58/60\n",
            "1090/1090 [==============================] - 0s 94us/sample - loss: 2.7040\n",
            "Epoch 59/60\n",
            "1090/1090 [==============================] - 0s 89us/sample - loss: 2.6826\n",
            "Epoch 60/60\n",
            "1090/1090 [==============================] - 0s 96us/sample - loss: 2.6729\n",
            "Train on 1090 samples\n",
            "Epoch 1/60\n",
            "1090/1090 [==============================] - 0s 393us/sample - loss: 20.0685\n",
            "Epoch 2/60\n",
            "1090/1090 [==============================] - 0s 96us/sample - loss: 17.0829\n",
            "Epoch 3/60\n",
            "1090/1090 [==============================] - 0s 110us/sample - loss: 13.9961\n",
            "Epoch 4/60\n",
            "1090/1090 [==============================] - 0s 95us/sample - loss: 10.7391\n",
            "Epoch 5/60\n",
            "1090/1090 [==============================] - 0s 105us/sample - loss: 9.1735\n",
            "Epoch 6/60\n",
            "1090/1090 [==============================] - 0s 102us/sample - loss: 8.3993\n",
            "Epoch 7/60\n",
            "1090/1090 [==============================] - 0s 92us/sample - loss: 7.5916\n",
            "Epoch 8/60\n",
            "1090/1090 [==============================] - 0s 93us/sample - loss: 6.8391\n",
            "Epoch 9/60\n",
            "1090/1090 [==============================] - 0s 90us/sample - loss: 6.0590\n",
            "Epoch 10/60\n",
            "1090/1090 [==============================] - 0s 93us/sample - loss: 5.3361\n",
            "Epoch 11/60\n",
            "1090/1090 [==============================] - 0s 89us/sample - loss: 4.6635\n",
            "Epoch 12/60\n",
            "1090/1090 [==============================] - 0s 92us/sample - loss: 4.1460\n",
            "Epoch 13/60\n",
            "1090/1090 [==============================] - 0s 93us/sample - loss: 3.8284\n",
            "Epoch 14/60\n",
            "1090/1090 [==============================] - 0s 93us/sample - loss: 3.6488\n",
            "Epoch 15/60\n",
            "1090/1090 [==============================] - 0s 114us/sample - loss: 3.5142\n",
            "Epoch 16/60\n",
            "1090/1090 [==============================] - 0s 99us/sample - loss: 3.4150\n",
            "Epoch 17/60\n",
            "1090/1090 [==============================] - 0s 88us/sample - loss: 3.3274\n",
            "Epoch 18/60\n",
            "1090/1090 [==============================] - 0s 91us/sample - loss: 3.2776\n",
            "Epoch 19/60\n",
            "1090/1090 [==============================] - 0s 96us/sample - loss: 3.2237\n",
            "Epoch 20/60\n",
            "1090/1090 [==============================] - 0s 95us/sample - loss: 3.1753\n",
            "Epoch 21/60\n",
            "1090/1090 [==============================] - 0s 92us/sample - loss: 3.1395\n",
            "Epoch 22/60\n",
            "1090/1090 [==============================] - 0s 97us/sample - loss: 3.1035\n",
            "Epoch 23/60\n",
            "1090/1090 [==============================] - 0s 108us/sample - loss: 3.0547\n",
            "Epoch 24/60\n",
            "1090/1090 [==============================] - 0s 93us/sample - loss: 3.0074\n",
            "Epoch 25/60\n",
            "1090/1090 [==============================] - 0s 105us/sample - loss: 3.0287\n",
            "Epoch 26/60\n",
            "1090/1090 [==============================] - 0s 90us/sample - loss: 3.0041\n",
            "Epoch 27/60\n",
            "1090/1090 [==============================] - 0s 89us/sample - loss: 2.9740\n",
            "Epoch 28/60\n",
            "1090/1090 [==============================] - 0s 93us/sample - loss: 2.9665\n",
            "Epoch 29/60\n",
            "1090/1090 [==============================] - 0s 91us/sample - loss: 2.9134\n",
            "Epoch 30/60\n",
            "1090/1090 [==============================] - 0s 109us/sample - loss: 2.9518\n",
            "Epoch 31/60\n",
            "1090/1090 [==============================] - 0s 90us/sample - loss: 2.8947\n",
            "Epoch 32/60\n",
            "1090/1090 [==============================] - 0s 94us/sample - loss: 2.8884\n",
            "Epoch 33/60\n",
            "1090/1090 [==============================] - 0s 93us/sample - loss: 2.8733\n",
            "Epoch 34/60\n",
            "1090/1090 [==============================] - 0s 97us/sample - loss: 2.8922\n",
            "Epoch 35/60\n",
            "1090/1090 [==============================] - 0s 103us/sample - loss: 2.8481\n",
            "Epoch 36/60\n",
            "1090/1090 [==============================] - 0s 96us/sample - loss: 2.8299\n",
            "Epoch 37/60\n",
            "1090/1090 [==============================] - 0s 95us/sample - loss: 2.8333\n",
            "Epoch 38/60\n",
            "1090/1090 [==============================] - 0s 91us/sample - loss: 2.8299\n",
            "Epoch 39/60\n",
            "1090/1090 [==============================] - 0s 107us/sample - loss: 2.8073\n",
            "Epoch 40/60\n",
            "1090/1090 [==============================] - 0s 94us/sample - loss: 2.7955\n",
            "Epoch 41/60\n",
            "1090/1090 [==============================] - 0s 94us/sample - loss: 2.7880\n",
            "Epoch 42/60\n",
            "1090/1090 [==============================] - 0s 107us/sample - loss: 2.7832\n",
            "Epoch 43/60\n",
            "1090/1090 [==============================] - 0s 98us/sample - loss: 2.7686\n",
            "Epoch 44/60\n",
            "1090/1090 [==============================] - 0s 106us/sample - loss: 2.7969\n",
            "Epoch 45/60\n",
            "1090/1090 [==============================] - 0s 88us/sample - loss: 2.7485\n",
            "Epoch 46/60\n",
            "1090/1090 [==============================] - 0s 90us/sample - loss: 2.7852\n",
            "Epoch 47/60\n",
            "1090/1090 [==============================] - 0s 109us/sample - loss: 2.7336\n",
            "Epoch 48/60\n",
            "1090/1090 [==============================] - 0s 91us/sample - loss: 2.7458\n",
            "Epoch 49/60\n",
            "1090/1090 [==============================] - 0s 95us/sample - loss: 2.7272\n",
            "Epoch 50/60\n",
            "1090/1090 [==============================] - 0s 89us/sample - loss: 2.7069\n",
            "Epoch 51/60\n",
            "1090/1090 [==============================] - 0s 93us/sample - loss: 2.7055\n",
            "Epoch 52/60\n",
            "1090/1090 [==============================] - 0s 97us/sample - loss: 2.6894\n",
            "Epoch 53/60\n",
            "1090/1090 [==============================] - 0s 91us/sample - loss: 2.6931\n",
            "Epoch 54/60\n",
            "1090/1090 [==============================] - 0s 113us/sample - loss: 2.7051\n",
            "Epoch 55/60\n",
            "1090/1090 [==============================] - 0s 90us/sample - loss: 2.6691\n",
            "Epoch 56/60\n",
            "1090/1090 [==============================] - 0s 93us/sample - loss: 2.6964\n",
            "Epoch 57/60\n",
            "1090/1090 [==============================] - 0s 95us/sample - loss: 2.6714\n",
            "Epoch 58/60\n",
            "1090/1090 [==============================] - 0s 90us/sample - loss: 2.6932\n",
            "Epoch 59/60\n",
            "1090/1090 [==============================] - 0s 102us/sample - loss: 2.6405\n",
            "Epoch 60/60\n",
            "1090/1090 [==============================] - 0s 104us/sample - loss: 2.6677\n",
            "Train on 1090 samples\n",
            "Epoch 1/60\n",
            "1090/1090 [==============================] - 0s 396us/sample - loss: 20.4641\n",
            "Epoch 2/60\n",
            "1090/1090 [==============================] - 0s 106us/sample - loss: 17.5109\n",
            "Epoch 3/60\n",
            "1090/1090 [==============================] - 0s 95us/sample - loss: 12.5849\n",
            "Epoch 4/60\n",
            "1090/1090 [==============================] - 0s 92us/sample - loss: 9.5050\n",
            "Epoch 5/60\n",
            "1090/1090 [==============================] - 0s 92us/sample - loss: 8.6578\n",
            "Epoch 6/60\n",
            "1090/1090 [==============================] - 0s 103us/sample - loss: 7.9512\n",
            "Epoch 7/60\n",
            "1090/1090 [==============================] - 0s 108us/sample - loss: 7.2472\n",
            "Epoch 8/60\n",
            "1090/1090 [==============================] - 0s 112us/sample - loss: 6.5687\n",
            "Epoch 9/60\n",
            "1090/1090 [==============================] - 0s 92us/sample - loss: 5.9028\n",
            "Epoch 10/60\n",
            "1090/1090 [==============================] - 0s 94us/sample - loss: 5.2762\n",
            "Epoch 11/60\n",
            "1090/1090 [==============================] - 0s 92us/sample - loss: 4.7446\n",
            "Epoch 12/60\n",
            "1090/1090 [==============================] - 0s 94us/sample - loss: 4.2972\n",
            "Epoch 13/60\n",
            "1090/1090 [==============================] - 0s 91us/sample - loss: 3.9919\n",
            "Epoch 14/60\n",
            "1090/1090 [==============================] - 0s 96us/sample - loss: 3.7889\n",
            "Epoch 15/60\n",
            "1090/1090 [==============================] - 0s 95us/sample - loss: 3.6595\n",
            "Epoch 16/60\n",
            "1090/1090 [==============================] - 0s 105us/sample - loss: 3.5478\n",
            "Epoch 17/60\n",
            "1090/1090 [==============================] - 0s 92us/sample - loss: 3.4637\n",
            "Epoch 18/60\n",
            "1090/1090 [==============================] - 0s 105us/sample - loss: 3.3928\n",
            "Epoch 19/60\n",
            "1090/1090 [==============================] - 0s 89us/sample - loss: 3.3359\n",
            "Epoch 20/60\n",
            "1090/1090 [==============================] - 0s 91us/sample - loss: 3.2915\n",
            "Epoch 21/60\n",
            "1090/1090 [==============================] - 0s 94us/sample - loss: 3.2375\n",
            "Epoch 22/60\n",
            "1090/1090 [==============================] - 0s 98us/sample - loss: 3.2023\n",
            "Epoch 23/60\n",
            "1090/1090 [==============================] - 0s 95us/sample - loss: 3.1981\n",
            "Epoch 24/60\n",
            "1090/1090 [==============================] - 0s 96us/sample - loss: 3.1310\n",
            "Epoch 25/60\n",
            "1090/1090 [==============================] - 0s 99us/sample - loss: 3.1400\n",
            "Epoch 26/60\n",
            "1090/1090 [==============================] - 0s 91us/sample - loss: 3.1341\n",
            "Epoch 27/60\n",
            "1090/1090 [==============================] - 0s 125us/sample - loss: 3.0798\n",
            "Epoch 28/60\n",
            "1090/1090 [==============================] - 0s 94us/sample - loss: 3.0389\n",
            "Epoch 29/60\n",
            "1090/1090 [==============================] - 0s 98us/sample - loss: 3.0239\n",
            "Epoch 30/60\n",
            "1090/1090 [==============================] - 0s 92us/sample - loss: 3.0232\n",
            "Epoch 31/60\n",
            "1090/1090 [==============================] - 0s 92us/sample - loss: 2.9989\n",
            "Epoch 32/60\n",
            "1090/1090 [==============================] - 0s 93us/sample - loss: 2.9841\n",
            "Epoch 33/60\n",
            "1090/1090 [==============================] - 0s 98us/sample - loss: 2.9661\n",
            "Epoch 34/60\n",
            "1090/1090 [==============================] - 0s 111us/sample - loss: 2.9332\n",
            "Epoch 35/60\n",
            "1090/1090 [==============================] - 0s 90us/sample - loss: 2.9315\n",
            "Epoch 36/60\n",
            "1090/1090 [==============================] - 0s 102us/sample - loss: 2.9276\n",
            "Epoch 37/60\n",
            "1090/1090 [==============================] - 0s 125us/sample - loss: 2.9036\n",
            "Epoch 38/60\n",
            "1090/1090 [==============================] - 0s 97us/sample - loss: 2.8855\n",
            "Epoch 39/60\n",
            "1090/1090 [==============================] - 0s 91us/sample - loss: 2.9095\n",
            "Epoch 40/60\n",
            "1090/1090 [==============================] - 0s 93us/sample - loss: 2.8769\n",
            "Epoch 41/60\n",
            "1090/1090 [==============================] - 0s 94us/sample - loss: 2.8626\n",
            "Epoch 42/60\n",
            "1090/1090 [==============================] - 0s 94us/sample - loss: 2.8749\n",
            "Epoch 43/60\n",
            "1090/1090 [==============================] - 0s 98us/sample - loss: 2.8480\n",
            "Epoch 44/60\n",
            "1090/1090 [==============================] - 0s 106us/sample - loss: 2.8494\n",
            "Epoch 45/60\n",
            "1090/1090 [==============================] - 0s 89us/sample - loss: 2.8317\n",
            "Epoch 46/60\n",
            "1090/1090 [==============================] - 0s 107us/sample - loss: 2.8309\n",
            "Epoch 47/60\n",
            "1090/1090 [==============================] - 0s 98us/sample - loss: 2.8162\n",
            "Epoch 48/60\n",
            "1090/1090 [==============================] - 0s 92us/sample - loss: 2.8116\n",
            "Epoch 49/60\n",
            "1090/1090 [==============================] - 0s 104us/sample - loss: 2.8027\n",
            "Epoch 50/60\n",
            "1090/1090 [==============================] - 0s 93us/sample - loss: 2.8061\n",
            "Epoch 51/60\n",
            "1090/1090 [==============================] - 0s 94us/sample - loss: 2.7908\n",
            "Epoch 52/60\n",
            "1090/1090 [==============================] - 0s 92us/sample - loss: 2.7907\n",
            "Epoch 53/60\n",
            "1090/1090 [==============================] - 0s 96us/sample - loss: 2.7615\n",
            "Epoch 54/60\n",
            "1090/1090 [==============================] - 0s 92us/sample - loss: 2.7692\n",
            "Epoch 55/60\n",
            "1090/1090 [==============================] - 0s 89us/sample - loss: 2.7436\n",
            "Epoch 56/60\n",
            "1090/1090 [==============================] - 0s 117us/sample - loss: 2.7580\n",
            "Epoch 57/60\n",
            "1090/1090 [==============================] - 0s 96us/sample - loss: 2.7503\n",
            "Epoch 58/60\n",
            "1090/1090 [==============================] - 0s 92us/sample - loss: 2.7373\n",
            "Epoch 59/60\n",
            "1090/1090 [==============================] - 0s 91us/sample - loss: 2.7459\n",
            "Epoch 60/60\n",
            "1090/1090 [==============================] - 0s 91us/sample - loss: 2.7327\n",
            "Train on 1091 samples\n",
            "Epoch 1/60\n",
            "1091/1091 [==============================] - 0s 403us/sample - loss: 20.0681\n",
            "Epoch 2/60\n",
            "1091/1091 [==============================] - 0s 93us/sample - loss: 15.9724\n",
            "Epoch 3/60\n",
            "1091/1091 [==============================] - 0s 92us/sample - loss: 11.1005\n",
            "Epoch 4/60\n",
            "1091/1091 [==============================] - 0s 90us/sample - loss: 9.5695\n",
            "Epoch 5/60\n",
            "1091/1091 [==============================] - 0s 91us/sample - loss: 8.8294\n",
            "Epoch 6/60\n",
            "1091/1091 [==============================] - 0s 98us/sample - loss: 8.0318\n",
            "Epoch 7/60\n",
            "1091/1091 [==============================] - 0s 103us/sample - loss: 7.2358\n",
            "Epoch 8/60\n",
            "1091/1091 [==============================] - 0s 93us/sample - loss: 6.4504\n",
            "Epoch 9/60\n",
            "1091/1091 [==============================] - 0s 91us/sample - loss: 5.6992\n",
            "Epoch 10/60\n",
            "1091/1091 [==============================] - 0s 97us/sample - loss: 5.0160\n",
            "Epoch 11/60\n",
            "1091/1091 [==============================] - 0s 97us/sample - loss: 4.4559\n",
            "Epoch 12/60\n",
            "1091/1091 [==============================] - 0s 110us/sample - loss: 4.0957\n",
            "Epoch 13/60\n",
            "1091/1091 [==============================] - 0s 101us/sample - loss: 3.8497\n",
            "Epoch 14/60\n",
            "1091/1091 [==============================] - 0s 93us/sample - loss: 3.6928\n",
            "Epoch 15/60\n",
            "1091/1091 [==============================] - 0s 96us/sample - loss: 3.5825\n",
            "Epoch 16/60\n",
            "1091/1091 [==============================] - 0s 95us/sample - loss: 3.4788\n",
            "Epoch 17/60\n",
            "1091/1091 [==============================] - 0s 108us/sample - loss: 3.4149\n",
            "Epoch 18/60\n",
            "1091/1091 [==============================] - 0s 90us/sample - loss: 3.3586\n",
            "Epoch 19/60\n",
            "1091/1091 [==============================] - 0s 92us/sample - loss: 3.2919\n",
            "Epoch 20/60\n",
            "1091/1091 [==============================] - 0s 101us/sample - loss: 3.2415\n",
            "Epoch 21/60\n",
            "1091/1091 [==============================] - 0s 96us/sample - loss: 3.1944\n",
            "Epoch 22/60\n",
            "1091/1091 [==============================] - 0s 108us/sample - loss: 3.1491\n",
            "Epoch 23/60\n",
            "1091/1091 [==============================] - 0s 111us/sample - loss: 3.1294\n",
            "Epoch 24/60\n",
            "1091/1091 [==============================] - 0s 97us/sample - loss: 3.0835\n",
            "Epoch 25/60\n",
            "1091/1091 [==============================] - 0s 96us/sample - loss: 3.0622\n",
            "Epoch 26/60\n",
            "1091/1091 [==============================] - 0s 92us/sample - loss: 3.0348\n",
            "Epoch 27/60\n",
            "1091/1091 [==============================] - 0s 93us/sample - loss: 3.0099\n",
            "Epoch 28/60\n",
            "1091/1091 [==============================] - 0s 93us/sample - loss: 2.9933\n",
            "Epoch 29/60\n",
            "1091/1091 [==============================] - 0s 104us/sample - loss: 2.9962\n",
            "Epoch 30/60\n",
            "1091/1091 [==============================] - 0s 92us/sample - loss: 2.9403\n",
            "Epoch 31/60\n",
            "1091/1091 [==============================] - 0s 95us/sample - loss: 2.9276\n",
            "Epoch 32/60\n",
            "1091/1091 [==============================] - 0s 90us/sample - loss: 2.9351\n",
            "Epoch 33/60\n",
            "1091/1091 [==============================] - 0s 98us/sample - loss: 2.9107\n",
            "Epoch 34/60\n",
            "1091/1091 [==============================] - 0s 94us/sample - loss: 2.8996\n",
            "Epoch 35/60\n",
            "1091/1091 [==============================] - 0s 90us/sample - loss: 2.8829\n",
            "Epoch 36/60\n",
            "1091/1091 [==============================] - 0s 99us/sample - loss: 2.8784\n",
            "Epoch 37/60\n",
            "1091/1091 [==============================] - 0s 92us/sample - loss: 2.8544\n",
            "Epoch 38/60\n",
            "1091/1091 [==============================] - 0s 98us/sample - loss: 2.8403\n",
            "Epoch 39/60\n",
            "1091/1091 [==============================] - 0s 107us/sample - loss: 2.8398\n",
            "Epoch 40/60\n",
            "1091/1091 [==============================] - 0s 97us/sample - loss: 2.8353\n",
            "Epoch 41/60\n",
            "1091/1091 [==============================] - 0s 99us/sample - loss: 2.8116\n",
            "Epoch 42/60\n",
            "1091/1091 [==============================] - 0s 93us/sample - loss: 2.8113\n",
            "Epoch 43/60\n",
            "1091/1091 [==============================] - 0s 92us/sample - loss: 2.7891\n",
            "Epoch 44/60\n",
            "1091/1091 [==============================] - 0s 92us/sample - loss: 2.8078\n",
            "Epoch 45/60\n",
            "1091/1091 [==============================] - 0s 90us/sample - loss: 2.7914\n",
            "Epoch 46/60\n",
            "1091/1091 [==============================] - 0s 92us/sample - loss: 2.7771\n",
            "Epoch 47/60\n",
            "1091/1091 [==============================] - 0s 91us/sample - loss: 2.7692\n",
            "Epoch 48/60\n",
            "1091/1091 [==============================] - 0s 91us/sample - loss: 2.7499\n",
            "Epoch 49/60\n",
            "1091/1091 [==============================] - 0s 108us/sample - loss: 2.7496\n",
            "Epoch 50/60\n",
            "1091/1091 [==============================] - 0s 94us/sample - loss: 2.7639\n",
            "Epoch 51/60\n",
            "1091/1091 [==============================] - 0s 101us/sample - loss: 2.7863\n",
            "Epoch 52/60\n",
            "1091/1091 [==============================] - 0s 97us/sample - loss: 2.7090\n",
            "Epoch 53/60\n",
            "1091/1091 [==============================] - 0s 103us/sample - loss: 2.7176\n",
            "Epoch 54/60\n",
            "1091/1091 [==============================] - 0s 94us/sample - loss: 2.6990\n",
            "Epoch 55/60\n",
            "1091/1091 [==============================] - 0s 97us/sample - loss: 2.7052\n",
            "Epoch 56/60\n",
            "1091/1091 [==============================] - 0s 90us/sample - loss: 2.7210\n",
            "Epoch 57/60\n",
            "1091/1091 [==============================] - 0s 96us/sample - loss: 2.7045\n",
            "Epoch 58/60\n",
            "1091/1091 [==============================] - 0s 120us/sample - loss: 2.6815\n",
            "Epoch 59/60\n",
            "1091/1091 [==============================] - 0s 104us/sample - loss: 2.6657\n",
            "Epoch 60/60\n",
            "1091/1091 [==============================] - 0s 93us/sample - loss: 2.6678\n",
            "Train on 1091 samples\n",
            "Epoch 1/60\n",
            "1091/1091 [==============================] - 0s 393us/sample - loss: 20.3692\n",
            "Epoch 2/60\n",
            "1091/1091 [==============================] - 0s 94us/sample - loss: 17.0423\n",
            "Epoch 3/60\n",
            "1091/1091 [==============================] - 0s 107us/sample - loss: 12.0960\n",
            "Epoch 4/60\n",
            "1091/1091 [==============================] - 0s 96us/sample - loss: 9.7471\n",
            "Epoch 5/60\n",
            "1091/1091 [==============================] - 0s 97us/sample - loss: 9.0343\n",
            "Epoch 6/60\n",
            "1091/1091 [==============================] - 0s 113us/sample - loss: 8.3553\n",
            "Epoch 7/60\n",
            "1091/1091 [==============================] - 0s 95us/sample - loss: 7.6772\n",
            "Epoch 8/60\n",
            "1091/1091 [==============================] - 0s 92us/sample - loss: 7.0391\n",
            "Epoch 9/60\n",
            "1091/1091 [==============================] - 0s 106us/sample - loss: 6.3232\n",
            "Epoch 10/60\n",
            "1091/1091 [==============================] - 0s 94us/sample - loss: 5.6171\n",
            "Epoch 11/60\n",
            "1091/1091 [==============================] - 0s 105us/sample - loss: 4.9156\n",
            "Epoch 12/60\n",
            "1091/1091 [==============================] - 0s 108us/sample - loss: 4.3587\n",
            "Epoch 13/60\n",
            "1091/1091 [==============================] - 0s 94us/sample - loss: 4.0033\n",
            "Epoch 14/60\n",
            "1091/1091 [==============================] - 0s 93us/sample - loss: 3.7816\n",
            "Epoch 15/60\n",
            "1091/1091 [==============================] - 0s 96us/sample - loss: 3.6433\n",
            "Epoch 16/60\n",
            "1091/1091 [==============================] - 0s 91us/sample - loss: 3.5463\n",
            "Epoch 17/60\n",
            "1091/1091 [==============================] - 0s 93us/sample - loss: 3.4449\n",
            "Epoch 18/60\n",
            "1091/1091 [==============================] - 0s 91us/sample - loss: 3.3950\n",
            "Epoch 19/60\n",
            "1091/1091 [==============================] - 0s 92us/sample - loss: 3.3206\n",
            "Epoch 20/60\n",
            "1091/1091 [==============================] - 0s 97us/sample - loss: 3.2795\n",
            "Epoch 21/60\n",
            "1091/1091 [==============================] - 0s 90us/sample - loss: 3.2229\n",
            "Epoch 22/60\n",
            "1091/1091 [==============================] - 0s 105us/sample - loss: 3.1788\n",
            "Epoch 23/60\n",
            "1091/1091 [==============================] - 0s 95us/sample - loss: 3.1739\n",
            "Epoch 24/60\n",
            "1091/1091 [==============================] - 0s 109us/sample - loss: 3.1239\n",
            "Epoch 25/60\n",
            "1091/1091 [==============================] - 0s 110us/sample - loss: 3.0803\n",
            "Epoch 26/60\n",
            "1091/1091 [==============================] - 0s 96us/sample - loss: 3.0499\n",
            "Epoch 27/60\n",
            "1091/1091 [==============================] - 0s 92us/sample - loss: 3.0435\n",
            "Epoch 28/60\n",
            "1091/1091 [==============================] - 0s 91us/sample - loss: 3.0281\n",
            "Epoch 29/60\n",
            "1091/1091 [==============================] - 0s 95us/sample - loss: 2.9822\n",
            "Epoch 30/60\n",
            "1091/1091 [==============================] - 0s 94us/sample - loss: 2.9801\n",
            "Epoch 31/60\n",
            "1091/1091 [==============================] - 0s 90us/sample - loss: 2.9688\n",
            "Epoch 32/60\n",
            "1091/1091 [==============================] - 0s 119us/sample - loss: 2.9472\n",
            "Epoch 33/60\n",
            "1091/1091 [==============================] - 0s 96us/sample - loss: 2.9279\n",
            "Epoch 34/60\n",
            "1091/1091 [==============================] - 0s 95us/sample - loss: 2.9080\n",
            "Epoch 35/60\n",
            "1091/1091 [==============================] - 0s 107us/sample - loss: 2.8972\n",
            "Epoch 36/60\n",
            "1091/1091 [==============================] - 0s 90us/sample - loss: 2.8986\n",
            "Epoch 37/60\n",
            "1091/1091 [==============================] - 0s 93us/sample - loss: 2.8759\n",
            "Epoch 38/60\n",
            "1091/1091 [==============================] - 0s 104us/sample - loss: 2.8593\n",
            "Epoch 39/60\n",
            "1091/1091 [==============================] - 0s 91us/sample - loss: 2.8663\n",
            "Epoch 40/60\n",
            "1091/1091 [==============================] - 0s 91us/sample - loss: 2.8532\n",
            "Epoch 41/60\n",
            "1091/1091 [==============================] - 0s 105us/sample - loss: 2.8321\n",
            "Epoch 42/60\n",
            "1091/1091 [==============================] - 0s 107us/sample - loss: 2.8076\n",
            "Epoch 43/60\n",
            "1091/1091 [==============================] - 0s 91us/sample - loss: 2.8483\n",
            "Epoch 44/60\n",
            "1091/1091 [==============================] - 0s 99us/sample - loss: 2.8278\n",
            "Epoch 45/60\n",
            "1091/1091 [==============================] - 0s 96us/sample - loss: 2.8026\n",
            "Epoch 46/60\n",
            "1091/1091 [==============================] - 0s 97us/sample - loss: 2.8270\n",
            "Epoch 47/60\n",
            "1091/1091 [==============================] - 0s 91us/sample - loss: 2.7935\n",
            "Epoch 48/60\n",
            "1091/1091 [==============================] - 0s 93us/sample - loss: 2.7809\n",
            "Epoch 49/60\n",
            "1091/1091 [==============================] - 0s 89us/sample - loss: 2.7830\n",
            "Epoch 50/60\n",
            "1091/1091 [==============================] - 0s 91us/sample - loss: 2.7556\n",
            "Epoch 51/60\n",
            "1091/1091 [==============================] - 0s 123us/sample - loss: 2.7515\n",
            "Epoch 52/60\n",
            "1091/1091 [==============================] - 0s 95us/sample - loss: 2.7282\n",
            "Epoch 53/60\n",
            "1091/1091 [==============================] - 0s 95us/sample - loss: 2.7803\n",
            "Epoch 54/60\n",
            "1091/1091 [==============================] - 0s 106us/sample - loss: 2.7136\n",
            "Epoch 55/60\n",
            "1091/1091 [==============================] - 0s 95us/sample - loss: 2.7190\n",
            "Epoch 56/60\n",
            "1091/1091 [==============================] - 0s 106us/sample - loss: 2.7127\n",
            "Epoch 57/60\n",
            "1091/1091 [==============================] - 0s 98us/sample - loss: 2.7097\n",
            "Epoch 58/60\n",
            "1091/1091 [==============================] - 0s 94us/sample - loss: 2.7070\n",
            "Epoch 59/60\n",
            "1091/1091 [==============================] - 0s 92us/sample - loss: 2.6951\n",
            "Epoch 60/60\n",
            "1091/1091 [==============================] - 0s 111us/sample - loss: 2.6816\n",
            "keras_reg validation score(rmse) : 5.3607515857677175\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIpU_LfiqNxz",
        "colab_type": "code",
        "outputId": "af42aca2-6895-4a29-ac6c-8d58c30b56fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_reg.fit(X, y_reg.values, epochs=100,\n",
        "                  validation_split=0.1,\n",
        "                  callbacks=[early_stopping_cb])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1226 samples, validate on 137 samples\n",
            "Epoch 1/100\n",
            "1226/1226 [==============================] - 1s 413us/sample - loss: 19.9516 - val_loss: 17.2662\n",
            "Epoch 2/100\n",
            "1226/1226 [==============================] - 0s 117us/sample - loss: 14.4540 - val_loss: 11.7231\n",
            "Epoch 3/100\n",
            "1226/1226 [==============================] - 0s 115us/sample - loss: 10.2448 - val_loss: 10.3893\n",
            "Epoch 4/100\n",
            "1226/1226 [==============================] - 0s 116us/sample - loss: 9.2025 - val_loss: 9.7757\n",
            "Epoch 5/100\n",
            "1226/1226 [==============================] - 0s 120us/sample - loss: 8.4859 - val_loss: 8.9997\n",
            "Epoch 6/100\n",
            "1226/1226 [==============================] - 0s 113us/sample - loss: 7.7038 - val_loss: 8.0203\n",
            "Epoch 7/100\n",
            "1226/1226 [==============================] - 0s 111us/sample - loss: 6.8803 - val_loss: 7.0562\n",
            "Epoch 8/100\n",
            "1226/1226 [==============================] - 0s 112us/sample - loss: 6.0716 - val_loss: 6.2571\n",
            "Epoch 9/100\n",
            "1226/1226 [==============================] - 0s 128us/sample - loss: 5.3375 - val_loss: 5.6061\n",
            "Epoch 10/100\n",
            "1226/1226 [==============================] - 0s 115us/sample - loss: 4.6949 - val_loss: 4.7674\n",
            "Epoch 11/100\n",
            "1226/1226 [==============================] - 0s 113us/sample - loss: 4.1584 - val_loss: 4.1875\n",
            "Epoch 12/100\n",
            "1226/1226 [==============================] - 0s 109us/sample - loss: 3.8002 - val_loss: 3.9032\n",
            "Epoch 13/100\n",
            "1226/1226 [==============================] - 0s 119us/sample - loss: 3.5962 - val_loss: 3.6523\n",
            "Epoch 14/100\n",
            "1226/1226 [==============================] - 0s 109us/sample - loss: 3.4537 - val_loss: 3.5677\n",
            "Epoch 15/100\n",
            "1226/1226 [==============================] - 0s 124us/sample - loss: 3.3454 - val_loss: 3.4848\n",
            "Epoch 16/100\n",
            "1226/1226 [==============================] - 0s 121us/sample - loss: 3.2724 - val_loss: 3.5046\n",
            "Epoch 17/100\n",
            "1226/1226 [==============================] - 0s 106us/sample - loss: 3.2167 - val_loss: 3.4968\n",
            "Epoch 18/100\n",
            "1226/1226 [==============================] - 0s 102us/sample - loss: 3.1752 - val_loss: 3.3361\n",
            "Epoch 19/100\n",
            "1226/1226 [==============================] - 0s 106us/sample - loss: 3.1286 - val_loss: 3.3376\n",
            "Epoch 20/100\n",
            "1226/1226 [==============================] - 0s 114us/sample - loss: 3.0946 - val_loss: 3.3207\n",
            "Epoch 21/100\n",
            "1226/1226 [==============================] - 0s 110us/sample - loss: 3.0581 - val_loss: 3.2991\n",
            "Epoch 22/100\n",
            "1226/1226 [==============================] - 0s 114us/sample - loss: 3.0394 - val_loss: 3.3897\n",
            "Epoch 23/100\n",
            "1226/1226 [==============================] - 0s 122us/sample - loss: 3.0303 - val_loss: 3.4441\n",
            "Epoch 24/100\n",
            "1226/1226 [==============================] - 0s 118us/sample - loss: 2.9985 - val_loss: 3.2146\n",
            "Epoch 25/100\n",
            "1226/1226 [==============================] - 0s 111us/sample - loss: 2.9714 - val_loss: 3.1965\n",
            "Epoch 26/100\n",
            "1226/1226 [==============================] - 0s 115us/sample - loss: 2.9596 - val_loss: 3.1736\n",
            "Epoch 27/100\n",
            "1226/1226 [==============================] - 0s 118us/sample - loss: 2.9552 - val_loss: 3.2024\n",
            "Epoch 28/100\n",
            "1226/1226 [==============================] - 0s 113us/sample - loss: 2.9239 - val_loss: 3.1756\n",
            "Epoch 29/100\n",
            "1226/1226 [==============================] - 0s 115us/sample - loss: 2.9107 - val_loss: 3.2720\n",
            "Epoch 30/100\n",
            "1226/1226 [==============================] - 0s 125us/sample - loss: 2.8939 - val_loss: 3.1190\n",
            "Epoch 31/100\n",
            "1226/1226 [==============================] - 0s 110us/sample - loss: 2.8830 - val_loss: 3.1537\n",
            "Epoch 32/100\n",
            "1226/1226 [==============================] - 0s 110us/sample - loss: 2.8817 - val_loss: 3.1490\n",
            "Epoch 33/100\n",
            "1226/1226 [==============================] - 0s 115us/sample - loss: 2.8629 - val_loss: 3.1223\n",
            "Epoch 34/100\n",
            "1226/1226 [==============================] - 0s 110us/sample - loss: 2.8395 - val_loss: 3.1583\n",
            "Epoch 35/100\n",
            "1226/1226 [==============================] - 0s 114us/sample - loss: 2.8366 - val_loss: 3.1632\n",
            "Epoch 36/100\n",
            "1226/1226 [==============================] - 0s 130us/sample - loss: 2.8372 - val_loss: 3.1162\n",
            "Epoch 37/100\n",
            "1226/1226 [==============================] - 0s 125us/sample - loss: 2.8274 - val_loss: 3.1129\n",
            "Epoch 38/100\n",
            "1226/1226 [==============================] - 0s 115us/sample - loss: 2.8221 - val_loss: 3.2736\n",
            "Epoch 39/100\n",
            "1226/1226 [==============================] - 0s 121us/sample - loss: 2.7965 - val_loss: 3.4066\n",
            "Epoch 40/100\n",
            "1226/1226 [==============================] - 0s 101us/sample - loss: 2.8290 - val_loss: 3.2217\n",
            "Epoch 41/100\n",
            "1226/1226 [==============================] - 0s 115us/sample - loss: 2.8010 - val_loss: 3.1271\n",
            "Epoch 42/100\n",
            "1226/1226 [==============================] - 0s 112us/sample - loss: 2.7821 - val_loss: 3.1603\n",
            "Epoch 43/100\n",
            "1226/1226 [==============================] - 0s 115us/sample - loss: 2.7697 - val_loss: 3.1504\n",
            "Epoch 44/100\n",
            "1226/1226 [==============================] - 0s 122us/sample - loss: 2.7566 - val_loss: 3.1315\n",
            "Epoch 45/100\n",
            "1226/1226 [==============================] - 0s 112us/sample - loss: 2.7536 - val_loss: 3.2193\n",
            "Epoch 46/100\n",
            "1226/1226 [==============================] - 0s 114us/sample - loss: 2.7491 - val_loss: 3.1412\n",
            "Epoch 47/100\n",
            "1226/1226 [==============================] - 0s 112us/sample - loss: 2.7349 - val_loss: 3.1128\n",
            "Epoch 48/100\n",
            "1226/1226 [==============================] - 0s 112us/sample - loss: 2.7354 - val_loss: 3.2165\n",
            "Epoch 49/100\n",
            "1226/1226 [==============================] - 0s 110us/sample - loss: 2.7389 - val_loss: 3.1380\n",
            "Epoch 50/100\n",
            "1226/1226 [==============================] - 0s 124us/sample - loss: 2.7205 - val_loss: 3.1673\n",
            "Epoch 51/100\n",
            "1226/1226 [==============================] - 0s 109us/sample - loss: 2.7087 - val_loss: 3.3319\n",
            "Epoch 52/100\n",
            "1226/1226 [==============================] - 0s 127us/sample - loss: 2.7127 - val_loss: 3.1943\n",
            "Epoch 53/100\n",
            "1226/1226 [==============================] - 0s 110us/sample - loss: 2.7030 - val_loss: 3.2563\n",
            "Epoch 54/100\n",
            "1226/1226 [==============================] - 0s 103us/sample - loss: 2.6937 - val_loss: 3.1418\n",
            "Epoch 55/100\n",
            "1226/1226 [==============================] - 0s 102us/sample - loss: 2.6826 - val_loss: 3.1454\n",
            "Epoch 56/100\n",
            "1226/1226 [==============================] - 0s 109us/sample - loss: 2.6740 - val_loss: 3.1441\n",
            "Epoch 57/100\n",
            "1226/1226 [==============================] - 0s 121us/sample - loss: 2.6715 - val_loss: 3.2036\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7faab7a51be0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 324
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "945HVZYqlzqp",
        "colab_type": "code",
        "outputId": "3f62f6cf-0ed4-468c-86a1-57dc7bb31fcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "predict_test = model_reg.predict(X)\n",
        "print('NN keras predict:\\n' ,predict_test)\n",
        "print('real y: \\n',y_reg.values)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NN keras predict:\n",
            " [[29.39446    7.2868323]\n",
            " [28.675013  12.430223 ]\n",
            " [28.01379   15.016221 ]\n",
            " ...\n",
            " [26.057144  19.790718 ]\n",
            " [29.838053  19.374912 ]\n",
            " [27.94377   13.519667 ]]\n",
            "real y: \n",
            " [[30.   10.  ]\n",
            " [30.   13.  ]\n",
            " [29.   15.33]\n",
            " ...\n",
            " [26.   27.  ]\n",
            " [23.   29.33]\n",
            " [30.   12.  ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ltm0SKyjpwwj",
        "colab_type": "text"
      },
      "source": [
        "# 중간고사 regression : randomforest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPBJWfTZpwMf",
        "colab_type": "code",
        "outputId": "05874f63-8e86-4719-fb1d-fd9375ab0380",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "param_grid = [\n",
        "    {'n_estimators': [1500],  #n_estimators : 생성할 tree개수-많을수록 좋은듯 500,1000,1500\n",
        "    'max_features': [34],    #max_features : 최대 선택할 특성의 수 34,35,36\n",
        "    'max_depth' : [15]\n",
        "     }\n",
        "  ]\n",
        "\n",
        "rf_reg = RandomForestRegressor(random_state=42)\n",
        "\n",
        "grid_search = GridSearchCV(rf_reg, param_grid, cv=5,\n",
        "                           scoring='neg_mean_squared_error',\n",
        "                           return_train_score=True)\n",
        "grid_search.fit(X,y_reg)\n",
        "\n",
        "print('best estimator : ')\n",
        "print(grid_search.best_estimator_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "best estimator : \n",
            "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=15,\n",
            "                      max_features=34, max_leaf_nodes=None,\n",
            "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                      min_samples_leaf=1, min_samples_split=2,\n",
            "                      min_weight_fraction_leaf=0.0, n_estimators=1500,\n",
            "                      n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
            "                      warm_start=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAaohKbiqwZH",
        "colab_type": "code",
        "outputId": "3f4b5c30-e474-4a40-d472-fef09d1ce20e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "final_reg = grid_search.best_estimator_\n",
        "\n",
        "final_reg.fit(X,y_reg)\n",
        "final_reg = MultiOutputRegressor(final_reg)\n",
        "final_reg.fit(X,y_reg)\n",
        "\n",
        "final_reg_predictions = final_reg.predict(X)\n",
        "final_reg_mse = mean_squared_error(y_reg, final_reg_predictions)\n",
        "final_reg_rmse = np.sqrt(final_reg_mse)\n",
        "\n",
        "scores = cross_val_score(final_reg,X,y_reg,\n",
        "                         scoring=\"neg_mean_squared_error\",cv=5)\n",
        "final_reg_scores = np.sqrt(-scores).mean()\n",
        "\n",
        "print(\"final regression model : randomforest\")\n",
        "print(\"--------------------------------------\")\n",
        "print(\"final model train loss : \", final_reg_rmse)\n",
        "print(\"final model validation loss: \",final_reg_scores)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "final regression model : randomforest\n",
            "--------------------------------------\n",
            "final model train loss :  2.0519076740841107\n",
            "final model validation loss:  5.187938017583692\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GAY38MXspcY",
        "colab_type": "text"
      },
      "source": [
        "# 2- NN classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5NFgY9Z1aST",
        "colab_type": "code",
        "outputId": "7bafcacc-5436-4bf5-8388-eb4500bcd4d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "from keras import metrics"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0W_mXBRUsxoq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model_clf(n_hidden=1, n_neurons=30, input_shape=[73]):\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
        "    for layer in range(n_hidden):\n",
        "        model.add(keras.layers.Dense(n_neurons, activation=\"selu\"))\n",
        "    model.add(keras.layers.Dense(3, activation= \"softmax\"))\n",
        "\n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\", \n",
        "                  optimizer=\"sgd\",\n",
        "                  metrics=['sparse_categorical_accuracy'])\n",
        "    return model\n",
        "\n",
        "model_clf = keras.wrappers.scikit_learn.KerasClassifier(build_fn=build_model_clf,\n",
        "                                                      epochs=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bo1VMv2MvNrT",
        "colab_type": "code",
        "outputId": "71d76284-a340-4076-a5d4-626f50f41260",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "kfold = KFold(n_splits=5, random_state=42)\n",
        "scores = cross_val_score(model_clf,X_plus,y_cls.values.T[0],\n",
        "                         scoring=\"accuracy\",\n",
        "                         cv=kfold)\n",
        "print('keras_reg validation score(accuracy) :', scores.mean())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1090 samples\n",
            "Epoch 1/100\n",
            "1090/1090 [==============================] - 0s 410us/sample - loss: 1.3076 - sparse_categorical_accuracy: 0.3872\n",
            "Epoch 2/100\n",
            "1090/1090 [==============================] - 0s 110us/sample - loss: 1.0392 - sparse_categorical_accuracy: 0.4761\n",
            "Epoch 3/100\n",
            "1090/1090 [==============================] - 0s 115us/sample - loss: 0.9286 - sparse_categorical_accuracy: 0.5495\n",
            "Epoch 4/100\n",
            "1090/1090 [==============================] - 0s 124us/sample - loss: 0.8584 - sparse_categorical_accuracy: 0.5716\n",
            "Epoch 5/100\n",
            "1090/1090 [==============================] - 0s 121us/sample - loss: 0.8078 - sparse_categorical_accuracy: 0.6028\n",
            "Epoch 6/100\n",
            "1090/1090 [==============================] - 0s 110us/sample - loss: 0.7697 - sparse_categorical_accuracy: 0.6248\n",
            "Epoch 7/100\n",
            "1090/1090 [==============================] - 0s 111us/sample - loss: 0.7373 - sparse_categorical_accuracy: 0.6422\n",
            "Epoch 8/100\n",
            "1090/1090 [==============================] - 0s 109us/sample - loss: 0.7120 - sparse_categorical_accuracy: 0.6541\n",
            "Epoch 9/100\n",
            "1090/1090 [==============================] - 0s 107us/sample - loss: 0.6905 - sparse_categorical_accuracy: 0.6743\n",
            "Epoch 10/100\n",
            "1090/1090 [==============================] - 0s 108us/sample - loss: 0.6713 - sparse_categorical_accuracy: 0.6789\n",
            "Epoch 11/100\n",
            "1090/1090 [==============================] - 0s 104us/sample - loss: 0.6542 - sparse_categorical_accuracy: 0.6890\n",
            "Epoch 12/100\n",
            "1090/1090 [==============================] - 0s 118us/sample - loss: 0.6413 - sparse_categorical_accuracy: 0.6917\n",
            "Epoch 13/100\n",
            "1090/1090 [==============================] - 0s 118us/sample - loss: 0.6288 - sparse_categorical_accuracy: 0.7009\n",
            "Epoch 14/100\n",
            "1090/1090 [==============================] - 0s 110us/sample - loss: 0.6151 - sparse_categorical_accuracy: 0.7147\n",
            "Epoch 15/100\n",
            "1090/1090 [==============================] - 0s 112us/sample - loss: 0.6043 - sparse_categorical_accuracy: 0.7202\n",
            "Epoch 16/100\n",
            "1090/1090 [==============================] - 0s 116us/sample - loss: 0.5975 - sparse_categorical_accuracy: 0.7266\n",
            "Epoch 17/100\n",
            "1090/1090 [==============================] - 0s 112us/sample - loss: 0.5885 - sparse_categorical_accuracy: 0.7294\n",
            "Epoch 18/100\n",
            "1090/1090 [==============================] - 0s 114us/sample - loss: 0.5773 - sparse_categorical_accuracy: 0.7385\n",
            "Epoch 19/100\n",
            "1090/1090 [==============================] - 0s 111us/sample - loss: 0.5703 - sparse_categorical_accuracy: 0.7376\n",
            "Epoch 20/100\n",
            "1090/1090 [==============================] - 0s 114us/sample - loss: 0.5621 - sparse_categorical_accuracy: 0.7495\n",
            "Epoch 21/100\n",
            "1090/1090 [==============================] - 0s 116us/sample - loss: 0.5563 - sparse_categorical_accuracy: 0.7550\n",
            "Epoch 22/100\n",
            "1090/1090 [==============================] - 0s 106us/sample - loss: 0.5517 - sparse_categorical_accuracy: 0.7495\n",
            "Epoch 23/100\n",
            "1090/1090 [==============================] - 0s 109us/sample - loss: 0.5433 - sparse_categorical_accuracy: 0.7505\n",
            "Epoch 24/100\n",
            "1090/1090 [==============================] - 0s 120us/sample - loss: 0.5415 - sparse_categorical_accuracy: 0.7541\n",
            "Epoch 25/100\n",
            "1090/1090 [==============================] - 0s 137us/sample - loss: 0.5360 - sparse_categorical_accuracy: 0.7578\n",
            "Epoch 26/100\n",
            "1090/1090 [==============================] - 0s 113us/sample - loss: 0.5305 - sparse_categorical_accuracy: 0.7550\n",
            "Epoch 27/100\n",
            "1090/1090 [==============================] - 0s 107us/sample - loss: 0.5276 - sparse_categorical_accuracy: 0.7578\n",
            "Epoch 28/100\n",
            "1090/1090 [==============================] - 0s 110us/sample - loss: 0.5257 - sparse_categorical_accuracy: 0.7615\n",
            "Epoch 29/100\n",
            "1090/1090 [==============================] - 0s 126us/sample - loss: 0.5207 - sparse_categorical_accuracy: 0.7596\n",
            "Epoch 30/100\n",
            "1090/1090 [==============================] - 0s 112us/sample - loss: 0.5161 - sparse_categorical_accuracy: 0.7615\n",
            "Epoch 31/100\n",
            "1090/1090 [==============================] - 0s 113us/sample - loss: 0.5143 - sparse_categorical_accuracy: 0.7697\n",
            "Epoch 32/100\n",
            "1090/1090 [==============================] - 0s 116us/sample - loss: 0.5089 - sparse_categorical_accuracy: 0.7596\n",
            "Epoch 33/100\n",
            "1090/1090 [==============================] - 0s 121us/sample - loss: 0.5072 - sparse_categorical_accuracy: 0.7606\n",
            "Epoch 34/100\n",
            "1090/1090 [==============================] - 0s 110us/sample - loss: 0.5054 - sparse_categorical_accuracy: 0.7661\n",
            "Epoch 35/100\n",
            "1090/1090 [==============================] - 0s 112us/sample - loss: 0.5021 - sparse_categorical_accuracy: 0.7716\n",
            "Epoch 36/100\n",
            "1090/1090 [==============================] - 0s 108us/sample - loss: 0.4999 - sparse_categorical_accuracy: 0.7734\n",
            "Epoch 37/100\n",
            "1090/1090 [==============================] - 0s 117us/sample - loss: 0.4974 - sparse_categorical_accuracy: 0.7642\n",
            "Epoch 38/100\n",
            "1090/1090 [==============================] - 0s 106us/sample - loss: 0.4953 - sparse_categorical_accuracy: 0.7706\n",
            "Epoch 39/100\n",
            "1090/1090 [==============================] - 0s 107us/sample - loss: 0.4933 - sparse_categorical_accuracy: 0.7789\n",
            "Epoch 40/100\n",
            "1090/1090 [==============================] - 0s 112us/sample - loss: 0.4895 - sparse_categorical_accuracy: 0.7706\n",
            "Epoch 41/100\n",
            "1090/1090 [==============================] - 0s 116us/sample - loss: 0.4879 - sparse_categorical_accuracy: 0.7725\n",
            "Epoch 42/100\n",
            "1090/1090 [==============================] - 0s 105us/sample - loss: 0.4877 - sparse_categorical_accuracy: 0.7780\n",
            "Epoch 43/100\n",
            "1090/1090 [==============================] - 0s 106us/sample - loss: 0.4854 - sparse_categorical_accuracy: 0.7734\n",
            "Epoch 44/100\n",
            "1090/1090 [==============================] - 0s 110us/sample - loss: 0.4842 - sparse_categorical_accuracy: 0.7761\n",
            "Epoch 45/100\n",
            "1090/1090 [==============================] - 0s 132us/sample - loss: 0.4827 - sparse_categorical_accuracy: 0.7807\n",
            "Epoch 46/100\n",
            "1090/1090 [==============================] - 0s 114us/sample - loss: 0.4805 - sparse_categorical_accuracy: 0.7734\n",
            "Epoch 47/100\n",
            "1090/1090 [==============================] - 0s 108us/sample - loss: 0.4791 - sparse_categorical_accuracy: 0.7706\n",
            "Epoch 48/100\n",
            "1090/1090 [==============================] - 0s 120us/sample - loss: 0.4785 - sparse_categorical_accuracy: 0.7743\n",
            "Epoch 49/100\n",
            "1090/1090 [==============================] - 0s 113us/sample - loss: 0.4769 - sparse_categorical_accuracy: 0.7817\n",
            "Epoch 50/100\n",
            "1090/1090 [==============================] - 0s 105us/sample - loss: 0.4773 - sparse_categorical_accuracy: 0.7771\n",
            "Epoch 51/100\n",
            "1090/1090 [==============================] - 0s 116us/sample - loss: 0.4744 - sparse_categorical_accuracy: 0.7706\n",
            "Epoch 52/100\n",
            "1090/1090 [==============================] - 0s 109us/sample - loss: 0.4719 - sparse_categorical_accuracy: 0.7752\n",
            "Epoch 53/100\n",
            "1090/1090 [==============================] - 0s 105us/sample - loss: 0.4706 - sparse_categorical_accuracy: 0.7734\n",
            "Epoch 54/100\n",
            "1090/1090 [==============================] - 0s 117us/sample - loss: 0.4713 - sparse_categorical_accuracy: 0.7752\n",
            "Epoch 55/100\n",
            "1090/1090 [==============================] - 0s 111us/sample - loss: 0.4691 - sparse_categorical_accuracy: 0.7826\n",
            "Epoch 56/100\n",
            "1090/1090 [==============================] - 0s 118us/sample - loss: 0.4683 - sparse_categorical_accuracy: 0.7706\n",
            "Epoch 57/100\n",
            "1090/1090 [==============================] - 0s 123us/sample - loss: 0.4676 - sparse_categorical_accuracy: 0.7761\n",
            "Epoch 58/100\n",
            "1090/1090 [==============================] - 0s 100us/sample - loss: 0.4665 - sparse_categorical_accuracy: 0.7771\n",
            "Epoch 59/100\n",
            "1090/1090 [==============================] - 0s 112us/sample - loss: 0.4652 - sparse_categorical_accuracy: 0.7807\n",
            "Epoch 60/100\n",
            "1090/1090 [==============================] - 0s 114us/sample - loss: 0.4645 - sparse_categorical_accuracy: 0.7771\n",
            "Epoch 61/100\n",
            "1090/1090 [==============================] - 0s 110us/sample - loss: 0.4643 - sparse_categorical_accuracy: 0.7798\n",
            "Epoch 62/100\n",
            "1090/1090 [==============================] - 0s 118us/sample - loss: 0.4623 - sparse_categorical_accuracy: 0.7780\n",
            "Epoch 63/100\n",
            "1090/1090 [==============================] - 0s 110us/sample - loss: 0.4618 - sparse_categorical_accuracy: 0.7826\n",
            "Epoch 64/100\n",
            "1090/1090 [==============================] - 0s 105us/sample - loss: 0.4636 - sparse_categorical_accuracy: 0.7734\n",
            "Epoch 65/100\n",
            "1090/1090 [==============================] - 0s 109us/sample - loss: 0.4613 - sparse_categorical_accuracy: 0.7844\n",
            "Epoch 66/100\n",
            "1090/1090 [==============================] - 0s 107us/sample - loss: 0.4595 - sparse_categorical_accuracy: 0.7826\n",
            "Epoch 67/100\n",
            "1090/1090 [==============================] - 0s 110us/sample - loss: 0.4588 - sparse_categorical_accuracy: 0.7853\n",
            "Epoch 68/100\n",
            "1090/1090 [==============================] - 0s 110us/sample - loss: 0.4580 - sparse_categorical_accuracy: 0.7817\n",
            "Epoch 69/100\n",
            "1090/1090 [==============================] - 0s 107us/sample - loss: 0.4563 - sparse_categorical_accuracy: 0.7771\n",
            "Epoch 70/100\n",
            "1090/1090 [==============================] - 0s 113us/sample - loss: 0.4566 - sparse_categorical_accuracy: 0.7826\n",
            "Epoch 71/100\n",
            "1090/1090 [==============================] - 0s 113us/sample - loss: 0.4562 - sparse_categorical_accuracy: 0.7927\n",
            "Epoch 72/100\n",
            "1090/1090 [==============================] - 0s 102us/sample - loss: 0.4559 - sparse_categorical_accuracy: 0.7890\n",
            "Epoch 73/100\n",
            "1090/1090 [==============================] - 0s 112us/sample - loss: 0.4544 - sparse_categorical_accuracy: 0.7917\n",
            "Epoch 74/100\n",
            "1090/1090 [==============================] - 0s 112us/sample - loss: 0.4539 - sparse_categorical_accuracy: 0.7872\n",
            "Epoch 75/100\n",
            "1090/1090 [==============================] - 0s 134us/sample - loss: 0.4534 - sparse_categorical_accuracy: 0.7890\n",
            "Epoch 76/100\n",
            "1090/1090 [==============================] - 0s 111us/sample - loss: 0.4527 - sparse_categorical_accuracy: 0.7826\n",
            "Epoch 77/100\n",
            "1090/1090 [==============================] - 0s 115us/sample - loss: 0.4600 - sparse_categorical_accuracy: 0.7734\n",
            "Epoch 78/100\n",
            "1090/1090 [==============================] - 0s 98us/sample - loss: 0.4533 - sparse_categorical_accuracy: 0.7881\n",
            "Epoch 79/100\n",
            "1090/1090 [==============================] - 0s 117us/sample - loss: 0.4517 - sparse_categorical_accuracy: 0.7844\n",
            "Epoch 80/100\n",
            "1090/1090 [==============================] - 0s 109us/sample - loss: 0.4512 - sparse_categorical_accuracy: 0.7927\n",
            "Epoch 81/100\n",
            "1090/1090 [==============================] - 0s 107us/sample - loss: 0.4494 - sparse_categorical_accuracy: 0.7872\n",
            "Epoch 82/100\n",
            "1090/1090 [==============================] - 0s 117us/sample - loss: 0.4497 - sparse_categorical_accuracy: 0.7844\n",
            "Epoch 83/100\n",
            "1090/1090 [==============================] - 0s 112us/sample - loss: 0.4497 - sparse_categorical_accuracy: 0.7890\n",
            "Epoch 84/100\n",
            "1090/1090 [==============================] - 0s 108us/sample - loss: 0.4480 - sparse_categorical_accuracy: 0.7917\n",
            "Epoch 85/100\n",
            "1090/1090 [==============================] - 0s 105us/sample - loss: 0.4490 - sparse_categorical_accuracy: 0.7917\n",
            "Epoch 86/100\n",
            "1090/1090 [==============================] - 0s 106us/sample - loss: 0.4470 - sparse_categorical_accuracy: 0.7899\n",
            "Epoch 87/100\n",
            "1090/1090 [==============================] - 0s 122us/sample - loss: 0.4459 - sparse_categorical_accuracy: 0.8009\n",
            "Epoch 88/100\n",
            "1090/1090 [==============================] - 0s 119us/sample - loss: 0.4470 - sparse_categorical_accuracy: 0.7927\n",
            "Epoch 89/100\n",
            "1090/1090 [==============================] - 0s 107us/sample - loss: 0.4476 - sparse_categorical_accuracy: 0.7899\n",
            "Epoch 90/100\n",
            "1090/1090 [==============================] - 0s 106us/sample - loss: 0.4460 - sparse_categorical_accuracy: 0.7899\n",
            "Epoch 91/100\n",
            "1090/1090 [==============================] - 0s 108us/sample - loss: 0.4495 - sparse_categorical_accuracy: 0.7936\n",
            "Epoch 92/100\n",
            "1090/1090 [==============================] - 0s 117us/sample - loss: 0.4466 - sparse_categorical_accuracy: 0.7963\n",
            "Epoch 93/100\n",
            "1090/1090 [==============================] - 0s 105us/sample - loss: 0.4441 - sparse_categorical_accuracy: 0.8028\n",
            "Epoch 94/100\n",
            "1090/1090 [==============================] - 0s 110us/sample - loss: 0.4416 - sparse_categorical_accuracy: 0.8000\n",
            "Epoch 95/100\n",
            "1090/1090 [==============================] - 0s 118us/sample - loss: 0.4435 - sparse_categorical_accuracy: 0.7936\n",
            "Epoch 96/100\n",
            "1090/1090 [==============================] - 0s 111us/sample - loss: 0.4436 - sparse_categorical_accuracy: 0.7927\n",
            "Epoch 97/100\n",
            "1090/1090 [==============================] - 0s 101us/sample - loss: 0.4418 - sparse_categorical_accuracy: 0.7963\n",
            "Epoch 98/100\n",
            "1090/1090 [==============================] - 0s 99us/sample - loss: 0.4400 - sparse_categorical_accuracy: 0.8000\n",
            "Epoch 99/100\n",
            "1090/1090 [==============================] - 0s 111us/sample - loss: 0.4404 - sparse_categorical_accuracy: 0.7982\n",
            "Epoch 100/100\n",
            "1090/1090 [==============================] - 0s 117us/sample - loss: 0.4390 - sparse_categorical_accuracy: 0.7908\n",
            "Train on 1090 samples\n",
            "Epoch 1/100\n",
            "1090/1090 [==============================] - 0s 393us/sample - loss: 1.0601 - sparse_categorical_accuracy: 0.4560\n",
            "Epoch 2/100\n",
            "1090/1090 [==============================] - 0s 103us/sample - loss: 0.9295 - sparse_categorical_accuracy: 0.5156\n",
            "Epoch 3/100\n",
            "1090/1090 [==============================] - 0s 119us/sample - loss: 0.8576 - sparse_categorical_accuracy: 0.5706\n",
            "Epoch 4/100\n",
            "1090/1090 [==============================] - 0s 122us/sample - loss: 0.7997 - sparse_categorical_accuracy: 0.5991\n",
            "Epoch 5/100\n",
            "1090/1090 [==============================] - 0s 122us/sample - loss: 0.7588 - sparse_categorical_accuracy: 0.6349\n",
            "Epoch 6/100\n",
            "1090/1090 [==============================] - 0s 116us/sample - loss: 0.7266 - sparse_categorical_accuracy: 0.6550\n",
            "Epoch 7/100\n",
            "1090/1090 [==============================] - 0s 107us/sample - loss: 0.7024 - sparse_categorical_accuracy: 0.6752\n",
            "Epoch 8/100\n",
            "1090/1090 [==============================] - 0s 119us/sample - loss: 0.6767 - sparse_categorical_accuracy: 0.6780\n",
            "Epoch 9/100\n",
            "1090/1090 [==============================] - 0s 111us/sample - loss: 0.6598 - sparse_categorical_accuracy: 0.6899\n",
            "Epoch 10/100\n",
            "1090/1090 [==============================] - 0s 115us/sample - loss: 0.6407 - sparse_categorical_accuracy: 0.7119\n",
            "Epoch 11/100\n",
            "1090/1090 [==============================] - 0s 115us/sample - loss: 0.6276 - sparse_categorical_accuracy: 0.7119\n",
            "Epoch 12/100\n",
            "1090/1090 [==============================] - 0s 118us/sample - loss: 0.6127 - sparse_categorical_accuracy: 0.7248\n",
            "Epoch 13/100\n",
            "1090/1090 [==============================] - 0s 119us/sample - loss: 0.6017 - sparse_categorical_accuracy: 0.7239\n",
            "Epoch 14/100\n",
            "1090/1090 [==============================] - 0s 123us/sample - loss: 0.5912 - sparse_categorical_accuracy: 0.7266\n",
            "Epoch 15/100\n",
            "1090/1090 [==============================] - 0s 118us/sample - loss: 0.5827 - sparse_categorical_accuracy: 0.7349\n",
            "Epoch 16/100\n",
            "1090/1090 [==============================] - 0s 118us/sample - loss: 0.5721 - sparse_categorical_accuracy: 0.7404\n",
            "Epoch 17/100\n",
            "1090/1090 [==============================] - 0s 108us/sample - loss: 0.5646 - sparse_categorical_accuracy: 0.7394\n",
            "Epoch 18/100\n",
            "1090/1090 [==============================] - 0s 112us/sample - loss: 0.5583 - sparse_categorical_accuracy: 0.7459\n",
            "Epoch 19/100\n",
            "1090/1090 [==============================] - 0s 112us/sample - loss: 0.5520 - sparse_categorical_accuracy: 0.7431\n",
            "Epoch 20/100\n",
            "1090/1090 [==============================] - 0s 105us/sample - loss: 0.5463 - sparse_categorical_accuracy: 0.7495\n",
            "Epoch 21/100\n",
            "1090/1090 [==============================] - 0s 114us/sample - loss: 0.5409 - sparse_categorical_accuracy: 0.7532\n",
            "Epoch 22/100\n",
            "1090/1090 [==============================] - 0s 109us/sample - loss: 0.5354 - sparse_categorical_accuracy: 0.7459\n",
            "Epoch 23/100\n",
            "1090/1090 [==============================] - 0s 105us/sample - loss: 0.5303 - sparse_categorical_accuracy: 0.7550\n",
            "Epoch 24/100\n",
            "1090/1090 [==============================] - 0s 118us/sample - loss: 0.5282 - sparse_categorical_accuracy: 0.7550\n",
            "Epoch 25/100\n",
            "1090/1090 [==============================] - 0s 110us/sample - loss: 0.5225 - sparse_categorical_accuracy: 0.7550\n",
            "Epoch 26/100\n",
            "1090/1090 [==============================] - 0s 111us/sample - loss: 0.5204 - sparse_categorical_accuracy: 0.7569\n",
            "Epoch 27/100\n",
            "1090/1090 [==============================] - 0s 113us/sample - loss: 0.5160 - sparse_categorical_accuracy: 0.7606\n",
            "Epoch 28/100\n",
            "1090/1090 [==============================] - 0s 119us/sample - loss: 0.5124 - sparse_categorical_accuracy: 0.7578\n",
            "Epoch 29/100\n",
            "1090/1090 [==============================] - 0s 128us/sample - loss: 0.5085 - sparse_categorical_accuracy: 0.7633\n",
            "Epoch 30/100\n",
            "1090/1090 [==============================] - 0s 124us/sample - loss: 0.5062 - sparse_categorical_accuracy: 0.7587\n",
            "Epoch 31/100\n",
            "1090/1090 [==============================] - 0s 113us/sample - loss: 0.5029 - sparse_categorical_accuracy: 0.7633\n",
            "Epoch 32/100\n",
            "1090/1090 [==============================] - 0s 122us/sample - loss: 0.5006 - sparse_categorical_accuracy: 0.7670\n",
            "Epoch 33/100\n",
            "1090/1090 [==============================] - 0s 107us/sample - loss: 0.4972 - sparse_categorical_accuracy: 0.7651\n",
            "Epoch 34/100\n",
            "1090/1090 [==============================] - 0s 109us/sample - loss: 0.4952 - sparse_categorical_accuracy: 0.7633\n",
            "Epoch 35/100\n",
            "1090/1090 [==============================] - 0s 109us/sample - loss: 0.4945 - sparse_categorical_accuracy: 0.7771\n",
            "Epoch 36/100\n",
            "1090/1090 [==============================] - 0s 126us/sample - loss: 0.4886 - sparse_categorical_accuracy: 0.7716\n",
            "Epoch 37/100\n",
            "1090/1090 [==============================] - 0s 113us/sample - loss: 0.4883 - sparse_categorical_accuracy: 0.7624\n",
            "Epoch 38/100\n",
            "1090/1090 [==============================] - 0s 112us/sample - loss: 0.4858 - sparse_categorical_accuracy: 0.7688\n",
            "Epoch 39/100\n",
            "1090/1090 [==============================] - 0s 114us/sample - loss: 0.4840 - sparse_categorical_accuracy: 0.7661\n",
            "Epoch 40/100\n",
            "1090/1090 [==============================] - 0s 120us/sample - loss: 0.4811 - sparse_categorical_accuracy: 0.7761\n",
            "Epoch 41/100\n",
            "1090/1090 [==============================] - 0s 108us/sample - loss: 0.4802 - sparse_categorical_accuracy: 0.7734\n",
            "Epoch 42/100\n",
            "1090/1090 [==============================] - 0s 110us/sample - loss: 0.4783 - sparse_categorical_accuracy: 0.7817\n",
            "Epoch 43/100\n",
            "1090/1090 [==============================] - 0s 119us/sample - loss: 0.4757 - sparse_categorical_accuracy: 0.7798\n",
            "Epoch 44/100\n",
            "1090/1090 [==============================] - 0s 116us/sample - loss: 0.4755 - sparse_categorical_accuracy: 0.7771\n",
            "Epoch 45/100\n",
            "1090/1090 [==============================] - 0s 117us/sample - loss: 0.4736 - sparse_categorical_accuracy: 0.7725\n",
            "Epoch 46/100\n",
            "1090/1090 [==============================] - 0s 112us/sample - loss: 0.4726 - sparse_categorical_accuracy: 0.7862\n",
            "Epoch 47/100\n",
            "1090/1090 [==============================] - 0s 126us/sample - loss: 0.4704 - sparse_categorical_accuracy: 0.7817\n",
            "Epoch 48/100\n",
            "1090/1090 [==============================] - 0s 123us/sample - loss: 0.4691 - sparse_categorical_accuracy: 0.7807\n",
            "Epoch 49/100\n",
            "1090/1090 [==============================] - 0s 116us/sample - loss: 0.4677 - sparse_categorical_accuracy: 0.7817\n",
            "Epoch 50/100\n",
            "1090/1090 [==============================] - 0s 106us/sample - loss: 0.4695 - sparse_categorical_accuracy: 0.7743\n",
            "Epoch 51/100\n",
            "1090/1090 [==============================] - 0s 106us/sample - loss: 0.4657 - sparse_categorical_accuracy: 0.7844\n",
            "Epoch 52/100\n",
            "1090/1090 [==============================] - 0s 107us/sample - loss: 0.4644 - sparse_categorical_accuracy: 0.7835\n",
            "Epoch 53/100\n",
            "1090/1090 [==============================] - 0s 101us/sample - loss: 0.4644 - sparse_categorical_accuracy: 0.7817\n",
            "Epoch 54/100\n",
            "1090/1090 [==============================] - 0s 100us/sample - loss: 0.4618 - sparse_categorical_accuracy: 0.7936\n",
            "Epoch 55/100\n",
            "1090/1090 [==============================] - 0s 117us/sample - loss: 0.4610 - sparse_categorical_accuracy: 0.7853\n",
            "Epoch 56/100\n",
            "1090/1090 [==============================] - 0s 105us/sample - loss: 0.4631 - sparse_categorical_accuracy: 0.7761\n",
            "Epoch 57/100\n",
            "1090/1090 [==============================] - 0s 120us/sample - loss: 0.4584 - sparse_categorical_accuracy: 0.7807\n",
            "Epoch 58/100\n",
            "1090/1090 [==============================] - 0s 107us/sample - loss: 0.4576 - sparse_categorical_accuracy: 0.7853\n",
            "Epoch 59/100\n",
            "1090/1090 [==============================] - 0s 114us/sample - loss: 0.4580 - sparse_categorical_accuracy: 0.7853\n",
            "Epoch 60/100\n",
            "1090/1090 [==============================] - 0s 108us/sample - loss: 0.4558 - sparse_categorical_accuracy: 0.7872\n",
            "Epoch 61/100\n",
            "1090/1090 [==============================] - 0s 114us/sample - loss: 0.4548 - sparse_categorical_accuracy: 0.7890\n",
            "Epoch 62/100\n",
            "1090/1090 [==============================] - 0s 104us/sample - loss: 0.4543 - sparse_categorical_accuracy: 0.7927\n",
            "Epoch 63/100\n",
            "1090/1090 [==============================] - 0s 111us/sample - loss: 0.4526 - sparse_categorical_accuracy: 0.7881\n",
            "Epoch 64/100\n",
            "1090/1090 [==============================] - 0s 106us/sample - loss: 0.4532 - sparse_categorical_accuracy: 0.7881\n",
            "Epoch 65/100\n",
            "1090/1090 [==============================] - 0s 112us/sample - loss: 0.4541 - sparse_categorical_accuracy: 0.7917\n",
            "Epoch 66/100\n",
            "1090/1090 [==============================] - 0s 101us/sample - loss: 0.4513 - sparse_categorical_accuracy: 0.7862\n",
            "Epoch 67/100\n",
            "1090/1090 [==============================] - 0s 105us/sample - loss: 0.4549 - sparse_categorical_accuracy: 0.7972\n",
            "Epoch 68/100\n",
            "1090/1090 [==============================] - 0s 109us/sample - loss: 0.4484 - sparse_categorical_accuracy: 0.7908\n",
            "Epoch 69/100\n",
            "1090/1090 [==============================] - 0s 108us/sample - loss: 0.4473 - sparse_categorical_accuracy: 0.7954\n",
            "Epoch 70/100\n",
            "1090/1090 [==============================] - 0s 101us/sample - loss: 0.4480 - sparse_categorical_accuracy: 0.7890\n",
            "Epoch 71/100\n",
            "1090/1090 [==============================] - 0s 107us/sample - loss: 0.4480 - sparse_categorical_accuracy: 0.7862\n",
            "Epoch 72/100\n",
            "1090/1090 [==============================] - 0s 99us/sample - loss: 0.4454 - sparse_categorical_accuracy: 0.7927\n",
            "Epoch 73/100\n",
            "1090/1090 [==============================] - 0s 117us/sample - loss: 0.4460 - sparse_categorical_accuracy: 0.7936\n",
            "Epoch 74/100\n",
            "1090/1090 [==============================] - 0s 118us/sample - loss: 0.4446 - sparse_categorical_accuracy: 0.7991\n",
            "Epoch 75/100\n",
            "1090/1090 [==============================] - 0s 120us/sample - loss: 0.4425 - sparse_categorical_accuracy: 0.7982\n",
            "Epoch 76/100\n",
            "1090/1090 [==============================] - 0s 107us/sample - loss: 0.4424 - sparse_categorical_accuracy: 0.7954\n",
            "Epoch 77/100\n",
            "1090/1090 [==============================] - 0s 113us/sample - loss: 0.4416 - sparse_categorical_accuracy: 0.7963\n",
            "Epoch 78/100\n",
            "1090/1090 [==============================] - 0s 108us/sample - loss: 0.4406 - sparse_categorical_accuracy: 0.7936\n",
            "Epoch 79/100\n",
            "1090/1090 [==============================] - 0s 106us/sample - loss: 0.4455 - sparse_categorical_accuracy: 0.7963\n",
            "Epoch 80/100\n",
            "1090/1090 [==============================] - 0s 100us/sample - loss: 0.4406 - sparse_categorical_accuracy: 0.7991\n",
            "Epoch 81/100\n",
            "1090/1090 [==============================] - 0s 110us/sample - loss: 0.4400 - sparse_categorical_accuracy: 0.7982\n",
            "Epoch 82/100\n",
            "1090/1090 [==============================] - 0s 126us/sample - loss: 0.4427 - sparse_categorical_accuracy: 0.7917\n",
            "Epoch 83/100\n",
            "1090/1090 [==============================] - 0s 108us/sample - loss: 0.4400 - sparse_categorical_accuracy: 0.8037\n",
            "Epoch 84/100\n",
            "1090/1090 [==============================] - 0s 105us/sample - loss: 0.4384 - sparse_categorical_accuracy: 0.8055\n",
            "Epoch 85/100\n",
            "1090/1090 [==============================] - 0s 114us/sample - loss: 0.4382 - sparse_categorical_accuracy: 0.7982\n",
            "Epoch 86/100\n",
            "1090/1090 [==============================] - 0s 101us/sample - loss: 0.4370 - sparse_categorical_accuracy: 0.8028\n",
            "Epoch 87/100\n",
            "1090/1090 [==============================] - 0s 112us/sample - loss: 0.4357 - sparse_categorical_accuracy: 0.8055\n",
            "Epoch 88/100\n",
            "1090/1090 [==============================] - 0s 123us/sample - loss: 0.4351 - sparse_categorical_accuracy: 0.8028\n",
            "Epoch 89/100\n",
            "1090/1090 [==============================] - 0s 108us/sample - loss: 0.4329 - sparse_categorical_accuracy: 0.8028\n",
            "Epoch 90/100\n",
            "1090/1090 [==============================] - 0s 132us/sample - loss: 0.4337 - sparse_categorical_accuracy: 0.8064\n",
            "Epoch 91/100\n",
            "1090/1090 [==============================] - 0s 106us/sample - loss: 0.4328 - sparse_categorical_accuracy: 0.7991\n",
            "Epoch 92/100\n",
            "1090/1090 [==============================] - 0s 126us/sample - loss: 0.4332 - sparse_categorical_accuracy: 0.8037\n",
            "Epoch 93/100\n",
            "1090/1090 [==============================] - 0s 114us/sample - loss: 0.4326 - sparse_categorical_accuracy: 0.7982\n",
            "Epoch 94/100\n",
            "1090/1090 [==============================] - 0s 107us/sample - loss: 0.4378 - sparse_categorical_accuracy: 0.8018\n",
            "Epoch 95/100\n",
            "1090/1090 [==============================] - 0s 107us/sample - loss: 0.4310 - sparse_categorical_accuracy: 0.8009\n",
            "Epoch 96/100\n",
            "1090/1090 [==============================] - 0s 101us/sample - loss: 0.4335 - sparse_categorical_accuracy: 0.8110\n",
            "Epoch 97/100\n",
            "1090/1090 [==============================] - 0s 108us/sample - loss: 0.4313 - sparse_categorical_accuracy: 0.8018\n",
            "Epoch 98/100\n",
            "1090/1090 [==============================] - 0s 107us/sample - loss: 0.4306 - sparse_categorical_accuracy: 0.8037\n",
            "Epoch 99/100\n",
            "1090/1090 [==============================] - 0s 122us/sample - loss: 0.4283 - sparse_categorical_accuracy: 0.8073\n",
            "Epoch 100/100\n",
            "1090/1090 [==============================] - 0s 113us/sample - loss: 0.4271 - sparse_categorical_accuracy: 0.8092\n",
            "Train on 1090 samples\n",
            "Epoch 1/100\n",
            "1090/1090 [==============================] - 0s 394us/sample - loss: 1.2981 - sparse_categorical_accuracy: 0.4174\n",
            "Epoch 2/100\n",
            "1090/1090 [==============================] - 0s 123us/sample - loss: 1.0428 - sparse_categorical_accuracy: 0.4817\n",
            "Epoch 3/100\n",
            "1090/1090 [==============================] - 0s 127us/sample - loss: 0.9226 - sparse_categorical_accuracy: 0.5358\n",
            "Epoch 4/100\n",
            "1090/1090 [==============================] - 0s 115us/sample - loss: 0.8494 - sparse_categorical_accuracy: 0.5615\n",
            "Epoch 5/100\n",
            "1090/1090 [==============================] - 0s 114us/sample - loss: 0.7986 - sparse_categorical_accuracy: 0.5927\n",
            "Epoch 6/100\n",
            "1090/1090 [==============================] - 0s 102us/sample - loss: 0.7686 - sparse_categorical_accuracy: 0.6119\n",
            "Epoch 7/100\n",
            "1090/1090 [==============================] - 0s 101us/sample - loss: 0.7317 - sparse_categorical_accuracy: 0.6385\n",
            "Epoch 8/100\n",
            "1090/1090 [==============================] - 0s 105us/sample - loss: 0.7119 - sparse_categorical_accuracy: 0.6587\n",
            "Epoch 9/100\n",
            "1090/1090 [==============================] - 0s 104us/sample - loss: 0.6892 - sparse_categorical_accuracy: 0.6642\n",
            "Epoch 10/100\n",
            "1090/1090 [==============================] - 0s 104us/sample - loss: 0.6718 - sparse_categorical_accuracy: 0.6752\n",
            "Epoch 11/100\n",
            "1090/1090 [==============================] - 0s 117us/sample - loss: 0.6553 - sparse_categorical_accuracy: 0.6899\n",
            "Epoch 12/100\n",
            "1090/1090 [==============================] - 0s 112us/sample - loss: 0.6427 - sparse_categorical_accuracy: 0.6927\n",
            "Epoch 13/100\n",
            "1090/1090 [==============================] - 0s 115us/sample - loss: 0.6308 - sparse_categorical_accuracy: 0.6982\n",
            "Epoch 14/100\n",
            "1090/1090 [==============================] - 0s 107us/sample - loss: 0.6221 - sparse_categorical_accuracy: 0.6972\n",
            "Epoch 15/100\n",
            "1090/1090 [==============================] - 0s 108us/sample - loss: 0.6107 - sparse_categorical_accuracy: 0.7028\n",
            "Epoch 16/100\n",
            "1090/1090 [==============================] - 0s 102us/sample - loss: 0.6014 - sparse_categorical_accuracy: 0.7156\n",
            "Epoch 17/100\n",
            "1090/1090 [==============================] - 0s 105us/sample - loss: 0.5932 - sparse_categorical_accuracy: 0.7138\n",
            "Epoch 18/100\n",
            "1090/1090 [==============================] - 0s 98us/sample - loss: 0.5873 - sparse_categorical_accuracy: 0.7220\n",
            "Epoch 19/100\n",
            "1090/1090 [==============================] - 0s 107us/sample - loss: 0.5810 - sparse_categorical_accuracy: 0.7257\n",
            "Epoch 20/100\n",
            "1090/1090 [==============================] - 0s 120us/sample - loss: 0.5747 - sparse_categorical_accuracy: 0.7275\n",
            "Epoch 21/100\n",
            "1090/1090 [==============================] - 0s 110us/sample - loss: 0.5684 - sparse_categorical_accuracy: 0.7349\n",
            "Epoch 22/100\n",
            "1090/1090 [==============================] - 0s 127us/sample - loss: 0.5636 - sparse_categorical_accuracy: 0.7358\n",
            "Epoch 23/100\n",
            "1090/1090 [==============================] - 0s 108us/sample - loss: 0.5599 - sparse_categorical_accuracy: 0.7394\n",
            "Epoch 24/100\n",
            "1090/1090 [==============================] - 0s 109us/sample - loss: 0.5550 - sparse_categorical_accuracy: 0.7431\n",
            "Epoch 25/100\n",
            "1090/1090 [==============================] - 0s 113us/sample - loss: 0.5501 - sparse_categorical_accuracy: 0.7505\n",
            "Epoch 26/100\n",
            "1090/1090 [==============================] - 0s 107us/sample - loss: 0.5451 - sparse_categorical_accuracy: 0.7486\n",
            "Epoch 27/100\n",
            "1090/1090 [==============================] - 0s 107us/sample - loss: 0.5416 - sparse_categorical_accuracy: 0.7550\n",
            "Epoch 28/100\n",
            "1090/1090 [==============================] - 0s 126us/sample - loss: 0.5395 - sparse_categorical_accuracy: 0.7486\n",
            "Epoch 29/100\n",
            "1090/1090 [==============================] - 0s 128us/sample - loss: 0.5358 - sparse_categorical_accuracy: 0.7541\n",
            "Epoch 30/100\n",
            "1090/1090 [==============================] - 0s 112us/sample - loss: 0.5434 - sparse_categorical_accuracy: 0.7505\n",
            "Epoch 31/100\n",
            "1090/1090 [==============================] - 0s 111us/sample - loss: 0.5302 - sparse_categorical_accuracy: 0.7569\n",
            "Epoch 32/100\n",
            "1090/1090 [==============================] - 0s 110us/sample - loss: 0.5272 - sparse_categorical_accuracy: 0.7606\n",
            "Epoch 33/100\n",
            "1090/1090 [==============================] - 0s 106us/sample - loss: 0.5243 - sparse_categorical_accuracy: 0.7624\n",
            "Epoch 34/100\n",
            "1090/1090 [==============================] - 0s 109us/sample - loss: 0.5217 - sparse_categorical_accuracy: 0.7642\n",
            "Epoch 35/100\n",
            "1090/1090 [==============================] - 0s 110us/sample - loss: 0.5202 - sparse_categorical_accuracy: 0.7661\n",
            "Epoch 36/100\n",
            "1090/1090 [==============================] - 0s 118us/sample - loss: 0.5170 - sparse_categorical_accuracy: 0.7615\n",
            "Epoch 37/100\n",
            "1090/1090 [==============================] - 0s 113us/sample - loss: 0.5145 - sparse_categorical_accuracy: 0.7679\n",
            "Epoch 38/100\n",
            "1090/1090 [==============================] - 0s 115us/sample - loss: 0.5157 - sparse_categorical_accuracy: 0.7734\n",
            "Epoch 39/100\n",
            "1090/1090 [==============================] - 0s 107us/sample - loss: 0.5117 - sparse_categorical_accuracy: 0.7734\n",
            "Epoch 40/100\n",
            "1090/1090 [==============================] - 0s 105us/sample - loss: 0.5085 - sparse_categorical_accuracy: 0.7734\n",
            "Epoch 41/100\n",
            "1090/1090 [==============================] - 0s 109us/sample - loss: 0.5080 - sparse_categorical_accuracy: 0.7743\n",
            "Epoch 42/100\n",
            "1090/1090 [==============================] - 0s 106us/sample - loss: 0.5063 - sparse_categorical_accuracy: 0.7706\n",
            "Epoch 43/100\n",
            "1090/1090 [==============================] - 0s 117us/sample - loss: 0.5039 - sparse_categorical_accuracy: 0.7734\n",
            "Epoch 44/100\n",
            "1090/1090 [==============================] - 0s 109us/sample - loss: 0.5025 - sparse_categorical_accuracy: 0.7771\n",
            "Epoch 45/100\n",
            "1090/1090 [==============================] - 0s 129us/sample - loss: 0.5003 - sparse_categorical_accuracy: 0.7670\n",
            "Epoch 46/100\n",
            "1090/1090 [==============================] - 0s 118us/sample - loss: 0.5001 - sparse_categorical_accuracy: 0.7725\n",
            "Epoch 47/100\n",
            "1090/1090 [==============================] - 0s 108us/sample - loss: 0.4984 - sparse_categorical_accuracy: 0.7817\n",
            "Epoch 48/100\n",
            "1090/1090 [==============================] - 0s 112us/sample - loss: 0.4958 - sparse_categorical_accuracy: 0.7743\n",
            "Epoch 49/100\n",
            "1090/1090 [==============================] - 0s 107us/sample - loss: 0.4946 - sparse_categorical_accuracy: 0.7725\n",
            "Epoch 50/100\n",
            "1090/1090 [==============================] - 0s 111us/sample - loss: 0.4939 - sparse_categorical_accuracy: 0.7780\n",
            "Epoch 51/100\n",
            "1090/1090 [==============================] - 0s 106us/sample - loss: 0.4919 - sparse_categorical_accuracy: 0.7780\n",
            "Epoch 52/100\n",
            "1090/1090 [==============================] - 0s 112us/sample - loss: 0.4913 - sparse_categorical_accuracy: 0.7743\n",
            "Epoch 53/100\n",
            "1090/1090 [==============================] - 0s 117us/sample - loss: 0.4909 - sparse_categorical_accuracy: 0.7771\n",
            "Epoch 54/100\n",
            "1090/1090 [==============================] - 0s 116us/sample - loss: 0.4908 - sparse_categorical_accuracy: 0.7752\n",
            "Epoch 55/100\n",
            "1090/1090 [==============================] - 0s 105us/sample - loss: 0.4906 - sparse_categorical_accuracy: 0.7743\n",
            "Epoch 56/100\n",
            "1090/1090 [==============================] - 0s 105us/sample - loss: 0.4877 - sparse_categorical_accuracy: 0.7789\n",
            "Epoch 57/100\n",
            "1090/1090 [==============================] - 0s 105us/sample - loss: 0.4846 - sparse_categorical_accuracy: 0.7725\n",
            "Epoch 58/100\n",
            "1090/1090 [==============================] - 0s 102us/sample - loss: 0.4843 - sparse_categorical_accuracy: 0.7780\n",
            "Epoch 59/100\n",
            "1090/1090 [==============================] - 0s 112us/sample - loss: 0.4855 - sparse_categorical_accuracy: 0.7817\n",
            "Epoch 60/100\n",
            "1090/1090 [==============================] - 0s 116us/sample - loss: 0.4860 - sparse_categorical_accuracy: 0.7872\n",
            "Epoch 61/100\n",
            "1090/1090 [==============================] - 0s 113us/sample - loss: 0.4822 - sparse_categorical_accuracy: 0.7872\n",
            "Epoch 62/100\n",
            "1090/1090 [==============================] - 0s 119us/sample - loss: 0.4806 - sparse_categorical_accuracy: 0.7853\n",
            "Epoch 63/100\n",
            "1090/1090 [==============================] - 0s 123us/sample - loss: 0.4822 - sparse_categorical_accuracy: 0.7862\n",
            "Epoch 64/100\n",
            "1090/1090 [==============================] - 0s 113us/sample - loss: 0.4814 - sparse_categorical_accuracy: 0.7780\n",
            "Epoch 65/100\n",
            "1090/1090 [==============================] - 0s 106us/sample - loss: 0.4785 - sparse_categorical_accuracy: 0.7798\n",
            "Epoch 66/100\n",
            "1090/1090 [==============================] - 0s 99us/sample - loss: 0.4841 - sparse_categorical_accuracy: 0.7780\n",
            "Epoch 67/100\n",
            "1090/1090 [==============================] - 0s 100us/sample - loss: 0.4770 - sparse_categorical_accuracy: 0.7872\n",
            "Epoch 68/100\n",
            "1090/1090 [==============================] - 0s 116us/sample - loss: 0.4760 - sparse_categorical_accuracy: 0.7872\n",
            "Epoch 69/100\n",
            "1090/1090 [==============================] - 0s 106us/sample - loss: 0.4765 - sparse_categorical_accuracy: 0.7917\n",
            "Epoch 70/100\n",
            "1090/1090 [==============================] - 0s 117us/sample - loss: 0.4743 - sparse_categorical_accuracy: 0.7862\n",
            "Epoch 71/100\n",
            "1090/1090 [==============================] - 0s 110us/sample - loss: 0.4732 - sparse_categorical_accuracy: 0.7927\n",
            "Epoch 72/100\n",
            "1090/1090 [==============================] - 0s 108us/sample - loss: 0.4757 - sparse_categorical_accuracy: 0.7826\n",
            "Epoch 73/100\n",
            "1090/1090 [==============================] - 0s 117us/sample - loss: 0.4710 - sparse_categorical_accuracy: 0.7917\n",
            "Epoch 74/100\n",
            "1090/1090 [==============================] - 0s 116us/sample - loss: 0.4718 - sparse_categorical_accuracy: 0.7881\n",
            "Epoch 75/100\n",
            "1090/1090 [==============================] - 0s 114us/sample - loss: 0.4712 - sparse_categorical_accuracy: 0.7844\n",
            "Epoch 76/100\n",
            "1090/1090 [==============================] - 0s 110us/sample - loss: 0.4697 - sparse_categorical_accuracy: 0.7899\n",
            "Epoch 77/100\n",
            "1090/1090 [==============================] - 0s 108us/sample - loss: 0.4697 - sparse_categorical_accuracy: 0.7881\n",
            "Epoch 78/100\n",
            "1090/1090 [==============================] - 0s 124us/sample - loss: 0.4687 - sparse_categorical_accuracy: 0.7908\n",
            "Epoch 79/100\n",
            "1090/1090 [==============================] - 0s 111us/sample - loss: 0.4682 - sparse_categorical_accuracy: 0.7917\n",
            "Epoch 80/100\n",
            "1090/1090 [==============================] - 0s 113us/sample - loss: 0.4670 - sparse_categorical_accuracy: 0.7890\n",
            "Epoch 81/100\n",
            "1090/1090 [==============================] - 0s 107us/sample - loss: 0.4702 - sparse_categorical_accuracy: 0.7844\n",
            "Epoch 82/100\n",
            "1090/1090 [==============================] - 0s 112us/sample - loss: 0.4684 - sparse_categorical_accuracy: 0.7881\n",
            "Epoch 83/100\n",
            "1090/1090 [==============================] - 0s 109us/sample - loss: 0.4663 - sparse_categorical_accuracy: 0.7927\n",
            "Epoch 84/100\n",
            "1090/1090 [==============================] - 0s 112us/sample - loss: 0.4647 - sparse_categorical_accuracy: 0.7899\n",
            "Epoch 85/100\n",
            "1090/1090 [==============================] - 0s 113us/sample - loss: 0.4656 - sparse_categorical_accuracy: 0.7872\n",
            "Epoch 86/100\n",
            "1090/1090 [==============================] - 0s 128us/sample - loss: 0.4655 - sparse_categorical_accuracy: 0.7917\n",
            "Epoch 87/100\n",
            "1090/1090 [==============================] - 0s 117us/sample - loss: 0.4647 - sparse_categorical_accuracy: 0.7862\n",
            "Epoch 88/100\n",
            "1090/1090 [==============================] - 0s 119us/sample - loss: 0.4635 - sparse_categorical_accuracy: 0.7927\n",
            "Epoch 89/100\n",
            "1090/1090 [==============================] - 0s 119us/sample - loss: 0.4626 - sparse_categorical_accuracy: 0.7890\n",
            "Epoch 90/100\n",
            "1090/1090 [==============================] - 0s 111us/sample - loss: 0.4614 - sparse_categorical_accuracy: 0.7899\n",
            "Epoch 91/100\n",
            "1090/1090 [==============================] - 0s 106us/sample - loss: 0.4616 - sparse_categorical_accuracy: 0.7908\n",
            "Epoch 92/100\n",
            "1090/1090 [==============================] - 0s 99us/sample - loss: 0.4605 - sparse_categorical_accuracy: 0.7908\n",
            "Epoch 93/100\n",
            "1090/1090 [==============================] - 0s 114us/sample - loss: 0.4681 - sparse_categorical_accuracy: 0.7936\n",
            "Epoch 94/100\n",
            "1090/1090 [==============================] - 0s 116us/sample - loss: 0.4613 - sparse_categorical_accuracy: 0.7917\n",
            "Epoch 95/100\n",
            "1090/1090 [==============================] - 0s 107us/sample - loss: 0.4646 - sparse_categorical_accuracy: 0.7844\n",
            "Epoch 96/100\n",
            "1090/1090 [==============================] - 0s 105us/sample - loss: 0.4587 - sparse_categorical_accuracy: 0.7936\n",
            "Epoch 97/100\n",
            "1090/1090 [==============================] - 0s 112us/sample - loss: 0.4599 - sparse_categorical_accuracy: 0.7972\n",
            "Epoch 98/100\n",
            "1090/1090 [==============================] - 0s 106us/sample - loss: 0.4594 - sparse_categorical_accuracy: 0.7927\n",
            "Epoch 99/100\n",
            "1090/1090 [==============================] - 0s 103us/sample - loss: 0.4639 - sparse_categorical_accuracy: 0.7872\n",
            "Epoch 100/100\n",
            "1090/1090 [==============================] - 0s 109us/sample - loss: 0.4641 - sparse_categorical_accuracy: 0.7835\n",
            "Train on 1091 samples\n",
            "Epoch 1/100\n",
            "1091/1091 [==============================] - 0s 403us/sample - loss: 1.2044 - sparse_categorical_accuracy: 0.4180\n",
            "Epoch 2/100\n",
            "1091/1091 [==============================] - 0s 112us/sample - loss: 1.0288 - sparse_categorical_accuracy: 0.4730\n",
            "Epoch 3/100\n",
            "1091/1091 [==============================] - 0s 118us/sample - loss: 0.9248 - sparse_categorical_accuracy: 0.5188\n",
            "Epoch 4/100\n",
            "1091/1091 [==============================] - 0s 113us/sample - loss: 0.8513 - sparse_categorical_accuracy: 0.5600\n",
            "Epoch 5/100\n",
            "1091/1091 [==============================] - 0s 120us/sample - loss: 0.8011 - sparse_categorical_accuracy: 0.5793\n",
            "Epoch 6/100\n",
            "1091/1091 [==============================] - 0s 113us/sample - loss: 0.7591 - sparse_categorical_accuracy: 0.6196\n",
            "Epoch 7/100\n",
            "1091/1091 [==============================] - 0s 116us/sample - loss: 0.7275 - sparse_categorical_accuracy: 0.6352\n",
            "Epoch 8/100\n",
            "1091/1091 [==============================] - 0s 109us/sample - loss: 0.6985 - sparse_categorical_accuracy: 0.6554\n",
            "Epoch 9/100\n",
            "1091/1091 [==============================] - 0s 105us/sample - loss: 0.6766 - sparse_categorical_accuracy: 0.6764\n",
            "Epoch 10/100\n",
            "1091/1091 [==============================] - 0s 120us/sample - loss: 0.6542 - sparse_categorical_accuracy: 0.6819\n",
            "Epoch 11/100\n",
            "1091/1091 [==============================] - 0s 110us/sample - loss: 0.6390 - sparse_categorical_accuracy: 0.6994\n",
            "Epoch 12/100\n",
            "1091/1091 [==============================] - 0s 123us/sample - loss: 0.6229 - sparse_categorical_accuracy: 0.7094\n",
            "Epoch 13/100\n",
            "1091/1091 [==============================] - 0s 103us/sample - loss: 0.6093 - sparse_categorical_accuracy: 0.7204\n",
            "Epoch 14/100\n",
            "1091/1091 [==============================] - 0s 104us/sample - loss: 0.5994 - sparse_categorical_accuracy: 0.7232\n",
            "Epoch 15/100\n",
            "1091/1091 [==============================] - 0s 116us/sample - loss: 0.5875 - sparse_categorical_accuracy: 0.7287\n",
            "Epoch 16/100\n",
            "1091/1091 [==============================] - 0s 105us/sample - loss: 0.5767 - sparse_categorical_accuracy: 0.7360\n",
            "Epoch 17/100\n",
            "1091/1091 [==============================] - 0s 110us/sample - loss: 0.5691 - sparse_categorical_accuracy: 0.7351\n",
            "Epoch 18/100\n",
            "1091/1091 [==============================] - 0s 119us/sample - loss: 0.5615 - sparse_categorical_accuracy: 0.7369\n",
            "Epoch 19/100\n",
            "1091/1091 [==============================] - 0s 119us/sample - loss: 0.5535 - sparse_categorical_accuracy: 0.7369\n",
            "Epoch 20/100\n",
            "1091/1091 [==============================] - 0s 105us/sample - loss: 0.5446 - sparse_categorical_accuracy: 0.7534\n",
            "Epoch 21/100\n",
            "1091/1091 [==============================] - 0s 106us/sample - loss: 0.5401 - sparse_categorical_accuracy: 0.7525\n",
            "Epoch 22/100\n",
            "1091/1091 [==============================] - 0s 103us/sample - loss: 0.5328 - sparse_categorical_accuracy: 0.7562\n",
            "Epoch 23/100\n",
            "1091/1091 [==============================] - 0s 98us/sample - loss: 0.5283 - sparse_categorical_accuracy: 0.7599\n",
            "Epoch 24/100\n",
            "1091/1091 [==============================] - 0s 123us/sample - loss: 0.5215 - sparse_categorical_accuracy: 0.7599\n",
            "Epoch 25/100\n",
            "1091/1091 [==============================] - 0s 105us/sample - loss: 0.5176 - sparse_categorical_accuracy: 0.7635\n",
            "Epoch 26/100\n",
            "1091/1091 [==============================] - 0s 111us/sample - loss: 0.5127 - sparse_categorical_accuracy: 0.7635\n",
            "Epoch 27/100\n",
            "1091/1091 [==============================] - 0s 109us/sample - loss: 0.5074 - sparse_categorical_accuracy: 0.7709\n",
            "Epoch 28/100\n",
            "1091/1091 [==============================] - 0s 105us/sample - loss: 0.5045 - sparse_categorical_accuracy: 0.7736\n",
            "Epoch 29/100\n",
            "1091/1091 [==============================] - 0s 106us/sample - loss: 0.5008 - sparse_categorical_accuracy: 0.7764\n",
            "Epoch 30/100\n",
            "1091/1091 [==============================] - 0s 116us/sample - loss: 0.4965 - sparse_categorical_accuracy: 0.7764\n",
            "Epoch 31/100\n",
            "1091/1091 [==============================] - 0s 107us/sample - loss: 0.4936 - sparse_categorical_accuracy: 0.7745\n",
            "Epoch 32/100\n",
            "1091/1091 [==============================] - 0s 124us/sample - loss: 0.4899 - sparse_categorical_accuracy: 0.7764\n",
            "Epoch 33/100\n",
            "1091/1091 [==============================] - 0s 102us/sample - loss: 0.4871 - sparse_categorical_accuracy: 0.7736\n",
            "Epoch 34/100\n",
            "1091/1091 [==============================] - 0s 116us/sample - loss: 0.4835 - sparse_categorical_accuracy: 0.7773\n",
            "Epoch 35/100\n",
            "1091/1091 [==============================] - 0s 106us/sample - loss: 0.4801 - sparse_categorical_accuracy: 0.7819\n",
            "Epoch 36/100\n",
            "1091/1091 [==============================] - 0s 114us/sample - loss: 0.4786 - sparse_categorical_accuracy: 0.7874\n",
            "Epoch 37/100\n",
            "1091/1091 [==============================] - 0s 108us/sample - loss: 0.4775 - sparse_categorical_accuracy: 0.7874\n",
            "Epoch 38/100\n",
            "1091/1091 [==============================] - 0s 108us/sample - loss: 0.4738 - sparse_categorical_accuracy: 0.7837\n",
            "Epoch 39/100\n",
            "1091/1091 [==============================] - 0s 109us/sample - loss: 0.4707 - sparse_categorical_accuracy: 0.7874\n",
            "Epoch 40/100\n",
            "1091/1091 [==============================] - 0s 132us/sample - loss: 0.4701 - sparse_categorical_accuracy: 0.7809\n",
            "Epoch 41/100\n",
            "1091/1091 [==============================] - 0s 106us/sample - loss: 0.4672 - sparse_categorical_accuracy: 0.7782\n",
            "Epoch 42/100\n",
            "1091/1091 [==============================] - 0s 105us/sample - loss: 0.4640 - sparse_categorical_accuracy: 0.7800\n",
            "Epoch 43/100\n",
            "1091/1091 [==============================] - 0s 104us/sample - loss: 0.4636 - sparse_categorical_accuracy: 0.7791\n",
            "Epoch 44/100\n",
            "1091/1091 [==============================] - 0s 111us/sample - loss: 0.4620 - sparse_categorical_accuracy: 0.7828\n",
            "Epoch 45/100\n",
            "1091/1091 [==============================] - 0s 105us/sample - loss: 0.4601 - sparse_categorical_accuracy: 0.7864\n",
            "Epoch 46/100\n",
            "1091/1091 [==============================] - 0s 110us/sample - loss: 0.4580 - sparse_categorical_accuracy: 0.7855\n",
            "Epoch 47/100\n",
            "1091/1091 [==============================] - 0s 106us/sample - loss: 0.4576 - sparse_categorical_accuracy: 0.7901\n",
            "Epoch 48/100\n",
            "1091/1091 [==============================] - 0s 106us/sample - loss: 0.4553 - sparse_categorical_accuracy: 0.7855\n",
            "Epoch 49/100\n",
            "1091/1091 [==============================] - 0s 143us/sample - loss: 0.4522 - sparse_categorical_accuracy: 0.7892\n",
            "Epoch 50/100\n",
            "1091/1091 [==============================] - 0s 110us/sample - loss: 0.4520 - sparse_categorical_accuracy: 0.7901\n",
            "Epoch 51/100\n",
            "1091/1091 [==============================] - 0s 106us/sample - loss: 0.4507 - sparse_categorical_accuracy: 0.7929\n",
            "Epoch 52/100\n",
            "1091/1091 [==============================] - 0s 108us/sample - loss: 0.4495 - sparse_categorical_accuracy: 0.7929\n",
            "Epoch 53/100\n",
            "1091/1091 [==============================] - 0s 115us/sample - loss: 0.4485 - sparse_categorical_accuracy: 0.7929\n",
            "Epoch 54/100\n",
            "1091/1091 [==============================] - 0s 100us/sample - loss: 0.4463 - sparse_categorical_accuracy: 0.7919\n",
            "Epoch 55/100\n",
            "1091/1091 [==============================] - 0s 105us/sample - loss: 0.4462 - sparse_categorical_accuracy: 0.7901\n",
            "Epoch 56/100\n",
            "1091/1091 [==============================] - 0s 101us/sample - loss: 0.4434 - sparse_categorical_accuracy: 0.7846\n",
            "Epoch 57/100\n",
            "1091/1091 [==============================] - 0s 117us/sample - loss: 0.4431 - sparse_categorical_accuracy: 0.7864\n",
            "Epoch 58/100\n",
            "1091/1091 [==============================] - 0s 103us/sample - loss: 0.4424 - sparse_categorical_accuracy: 0.7919\n",
            "Epoch 59/100\n",
            "1091/1091 [==============================] - 0s 108us/sample - loss: 0.4399 - sparse_categorical_accuracy: 0.7938\n",
            "Epoch 60/100\n",
            "1091/1091 [==============================] - 0s 105us/sample - loss: 0.4397 - sparse_categorical_accuracy: 0.7947\n",
            "Epoch 61/100\n",
            "1091/1091 [==============================] - 0s 112us/sample - loss: 0.4376 - sparse_categorical_accuracy: 0.7947\n",
            "Epoch 62/100\n",
            "1091/1091 [==============================] - 0s 108us/sample - loss: 0.4386 - sparse_categorical_accuracy: 0.7956\n",
            "Epoch 63/100\n",
            "1091/1091 [==============================] - 0s 110us/sample - loss: 0.4381 - sparse_categorical_accuracy: 0.7965\n",
            "Epoch 64/100\n",
            "1091/1091 [==============================] - 0s 111us/sample - loss: 0.4354 - sparse_categorical_accuracy: 0.7938\n",
            "Epoch 65/100\n",
            "1091/1091 [==============================] - 0s 107us/sample - loss: 0.4358 - sparse_categorical_accuracy: 0.7974\n",
            "Epoch 66/100\n",
            "1091/1091 [==============================] - 0s 117us/sample - loss: 0.4342 - sparse_categorical_accuracy: 0.7965\n",
            "Epoch 67/100\n",
            "1091/1091 [==============================] - 0s 104us/sample - loss: 0.4338 - sparse_categorical_accuracy: 0.7993\n",
            "Epoch 68/100\n",
            "1091/1091 [==============================] - 0s 111us/sample - loss: 0.4322 - sparse_categorical_accuracy: 0.7965\n",
            "Epoch 69/100\n",
            "1091/1091 [==============================] - 0s 101us/sample - loss: 0.4309 - sparse_categorical_accuracy: 0.7974\n",
            "Epoch 70/100\n",
            "1091/1091 [==============================] - 0s 105us/sample - loss: 0.4307 - sparse_categorical_accuracy: 0.7947\n",
            "Epoch 71/100\n",
            "1091/1091 [==============================] - 0s 110us/sample - loss: 0.4307 - sparse_categorical_accuracy: 0.8002\n",
            "Epoch 72/100\n",
            "1091/1091 [==============================] - 0s 111us/sample - loss: 0.4286 - sparse_categorical_accuracy: 0.7984\n",
            "Epoch 73/100\n",
            "1091/1091 [==============================] - 0s 108us/sample - loss: 0.4285 - sparse_categorical_accuracy: 0.7984\n",
            "Epoch 74/100\n",
            "1091/1091 [==============================] - 0s 142us/sample - loss: 0.4275 - sparse_categorical_accuracy: 0.7984\n",
            "Epoch 75/100\n",
            "1091/1091 [==============================] - 0s 112us/sample - loss: 0.4280 - sparse_categorical_accuracy: 0.7993\n",
            "Epoch 76/100\n",
            "1091/1091 [==============================] - 0s 103us/sample - loss: 0.4267 - sparse_categorical_accuracy: 0.8011\n",
            "Epoch 77/100\n",
            "1091/1091 [==============================] - 0s 105us/sample - loss: 0.4267 - sparse_categorical_accuracy: 0.8020\n",
            "Epoch 78/100\n",
            "1091/1091 [==============================] - 0s 105us/sample - loss: 0.4251 - sparse_categorical_accuracy: 0.7984\n",
            "Epoch 79/100\n",
            "1091/1091 [==============================] - 0s 114us/sample - loss: 0.4234 - sparse_categorical_accuracy: 0.8020\n",
            "Epoch 80/100\n",
            "1091/1091 [==============================] - 0s 108us/sample - loss: 0.4240 - sparse_categorical_accuracy: 0.8038\n",
            "Epoch 81/100\n",
            "1091/1091 [==============================] - 0s 111us/sample - loss: 0.4224 - sparse_categorical_accuracy: 0.8093\n",
            "Epoch 82/100\n",
            "1091/1091 [==============================] - 0s 111us/sample - loss: 0.4229 - sparse_categorical_accuracy: 0.8038\n",
            "Epoch 83/100\n",
            "1091/1091 [==============================] - 0s 119us/sample - loss: 0.4283 - sparse_categorical_accuracy: 0.7984\n",
            "Epoch 84/100\n",
            "1091/1091 [==============================] - 0s 107us/sample - loss: 0.4212 - sparse_categorical_accuracy: 0.8048\n",
            "Epoch 85/100\n",
            "1091/1091 [==============================] - 0s 115us/sample - loss: 0.4203 - sparse_categorical_accuracy: 0.8038\n",
            "Epoch 86/100\n",
            "1091/1091 [==============================] - 0s 108us/sample - loss: 0.4215 - sparse_categorical_accuracy: 0.8002\n",
            "Epoch 87/100\n",
            "1091/1091 [==============================] - 0s 114us/sample - loss: 0.4184 - sparse_categorical_accuracy: 0.8066\n",
            "Epoch 88/100\n",
            "1091/1091 [==============================] - 0s 118us/sample - loss: 0.4184 - sparse_categorical_accuracy: 0.8084\n",
            "Epoch 89/100\n",
            "1091/1091 [==============================] - 0s 114us/sample - loss: 0.4184 - sparse_categorical_accuracy: 0.8038\n",
            "Epoch 90/100\n",
            "1091/1091 [==============================] - 0s 111us/sample - loss: 0.4183 - sparse_categorical_accuracy: 0.8084\n",
            "Epoch 91/100\n",
            "1091/1091 [==============================] - 0s 116us/sample - loss: 0.4180 - sparse_categorical_accuracy: 0.8112\n",
            "Epoch 92/100\n",
            "1091/1091 [==============================] - 0s 109us/sample - loss: 0.4173 - sparse_categorical_accuracy: 0.8048\n",
            "Epoch 93/100\n",
            "1091/1091 [==============================] - 0s 98us/sample - loss: 0.4169 - sparse_categorical_accuracy: 0.8103\n",
            "Epoch 94/100\n",
            "1091/1091 [==============================] - 0s 108us/sample - loss: 0.4153 - sparse_categorical_accuracy: 0.8084\n",
            "Epoch 95/100\n",
            "1091/1091 [==============================] - 0s 104us/sample - loss: 0.4147 - sparse_categorical_accuracy: 0.8084\n",
            "Epoch 96/100\n",
            "1091/1091 [==============================] - 0s 108us/sample - loss: 0.4142 - sparse_categorical_accuracy: 0.8093\n",
            "Epoch 97/100\n",
            "1091/1091 [==============================] - 0s 113us/sample - loss: 0.4137 - sparse_categorical_accuracy: 0.8130\n",
            "Epoch 98/100\n",
            "1091/1091 [==============================] - 0s 108us/sample - loss: 0.4145 - sparse_categorical_accuracy: 0.8084\n",
            "Epoch 99/100\n",
            "1091/1091 [==============================] - 0s 113us/sample - loss: 0.4105 - sparse_categorical_accuracy: 0.8167\n",
            "Epoch 100/100\n",
            "1091/1091 [==============================] - 0s 106us/sample - loss: 0.4128 - sparse_categorical_accuracy: 0.8057\n",
            "Train on 1091 samples\n",
            "Epoch 1/100\n",
            "1091/1091 [==============================] - 0s 400us/sample - loss: 1.2548 - sparse_categorical_accuracy: 0.3630\n",
            "Epoch 2/100\n",
            "1091/1091 [==============================] - 0s 112us/sample - loss: 1.0519 - sparse_categorical_accuracy: 0.4473\n",
            "Epoch 3/100\n",
            "1091/1091 [==============================] - 0s 119us/sample - loss: 0.9458 - sparse_categorical_accuracy: 0.5078\n",
            "Epoch 4/100\n",
            "1091/1091 [==============================] - 0s 112us/sample - loss: 0.8750 - sparse_categorical_accuracy: 0.5399\n",
            "Epoch 5/100\n",
            "1091/1091 [==============================] - 0s 110us/sample - loss: 0.8275 - sparse_categorical_accuracy: 0.5784\n",
            "Epoch 6/100\n",
            "1091/1091 [==============================] - 0s 112us/sample - loss: 0.7877 - sparse_categorical_accuracy: 0.6059\n",
            "Epoch 7/100\n",
            "1091/1091 [==============================] - 0s 109us/sample - loss: 0.7544 - sparse_categorical_accuracy: 0.6269\n",
            "Epoch 8/100\n",
            "1091/1091 [==============================] - 0s 105us/sample - loss: 0.7264 - sparse_categorical_accuracy: 0.6416\n",
            "Epoch 9/100\n",
            "1091/1091 [==============================] - 0s 121us/sample - loss: 0.7028 - sparse_categorical_accuracy: 0.6554\n",
            "Epoch 10/100\n",
            "1091/1091 [==============================] - 0s 110us/sample - loss: 0.6822 - sparse_categorical_accuracy: 0.6719\n",
            "Epoch 11/100\n",
            "1091/1091 [==============================] - 0s 105us/sample - loss: 0.6634 - sparse_categorical_accuracy: 0.6865\n",
            "Epoch 12/100\n",
            "1091/1091 [==============================] - 0s 115us/sample - loss: 0.6483 - sparse_categorical_accuracy: 0.6975\n",
            "Epoch 13/100\n",
            "1091/1091 [==============================] - 0s 116us/sample - loss: 0.6343 - sparse_categorical_accuracy: 0.7104\n",
            "Epoch 14/100\n",
            "1091/1091 [==============================] - 0s 110us/sample - loss: 0.6201 - sparse_categorical_accuracy: 0.7195\n",
            "Epoch 15/100\n",
            "1091/1091 [==============================] - 0s 112us/sample - loss: 0.6103 - sparse_categorical_accuracy: 0.7259\n",
            "Epoch 16/100\n",
            "1091/1091 [==============================] - 0s 110us/sample - loss: 0.5997 - sparse_categorical_accuracy: 0.7351\n",
            "Epoch 17/100\n",
            "1091/1091 [==============================] - 0s 104us/sample - loss: 0.5909 - sparse_categorical_accuracy: 0.7369\n",
            "Epoch 18/100\n",
            "1091/1091 [==============================] - 0s 121us/sample - loss: 0.5822 - sparse_categorical_accuracy: 0.7424\n",
            "Epoch 19/100\n",
            "1091/1091 [==============================] - 0s 116us/sample - loss: 0.5761 - sparse_categorical_accuracy: 0.7397\n",
            "Epoch 20/100\n",
            "1091/1091 [==============================] - 0s 123us/sample - loss: 0.5669 - sparse_categorical_accuracy: 0.7461\n",
            "Epoch 21/100\n",
            "1091/1091 [==============================] - 0s 106us/sample - loss: 0.5612 - sparse_categorical_accuracy: 0.7479\n",
            "Epoch 22/100\n",
            "1091/1091 [==============================] - 0s 107us/sample - loss: 0.5539 - sparse_categorical_accuracy: 0.7507\n",
            "Epoch 23/100\n",
            "1091/1091 [==============================] - 0s 106us/sample - loss: 0.5489 - sparse_categorical_accuracy: 0.7498\n",
            "Epoch 24/100\n",
            "1091/1091 [==============================] - 0s 109us/sample - loss: 0.5444 - sparse_categorical_accuracy: 0.7470\n",
            "Epoch 25/100\n",
            "1091/1091 [==============================] - 0s 108us/sample - loss: 0.5386 - sparse_categorical_accuracy: 0.7599\n",
            "Epoch 26/100\n",
            "1091/1091 [==============================] - 0s 114us/sample - loss: 0.5340 - sparse_categorical_accuracy: 0.7544\n",
            "Epoch 27/100\n",
            "1091/1091 [==============================] - 0s 110us/sample - loss: 0.5311 - sparse_categorical_accuracy: 0.7589\n",
            "Epoch 28/100\n",
            "1091/1091 [==============================] - 0s 116us/sample - loss: 0.5254 - sparse_categorical_accuracy: 0.7672\n",
            "Epoch 29/100\n",
            "1091/1091 [==============================] - 0s 109us/sample - loss: 0.5228 - sparse_categorical_accuracy: 0.7663\n",
            "Epoch 30/100\n",
            "1091/1091 [==============================] - 0s 105us/sample - loss: 0.5189 - sparse_categorical_accuracy: 0.7644\n",
            "Epoch 31/100\n",
            "1091/1091 [==============================] - 0s 105us/sample - loss: 0.5147 - sparse_categorical_accuracy: 0.7635\n",
            "Epoch 32/100\n",
            "1091/1091 [==============================] - 0s 109us/sample - loss: 0.5120 - sparse_categorical_accuracy: 0.7654\n",
            "Epoch 33/100\n",
            "1091/1091 [==============================] - 0s 109us/sample - loss: 0.5088 - sparse_categorical_accuracy: 0.7690\n",
            "Epoch 34/100\n",
            "1091/1091 [==============================] - 0s 129us/sample - loss: 0.5066 - sparse_categorical_accuracy: 0.7672\n",
            "Epoch 35/100\n",
            "1091/1091 [==============================] - 0s 116us/sample - loss: 0.5023 - sparse_categorical_accuracy: 0.7718\n",
            "Epoch 36/100\n",
            "1091/1091 [==============================] - 0s 105us/sample - loss: 0.5010 - sparse_categorical_accuracy: 0.7699\n",
            "Epoch 37/100\n",
            "1091/1091 [==============================] - 0s 115us/sample - loss: 0.4978 - sparse_categorical_accuracy: 0.7690\n",
            "Epoch 38/100\n",
            "1091/1091 [==============================] - 0s 108us/sample - loss: 0.4964 - sparse_categorical_accuracy: 0.7681\n",
            "Epoch 39/100\n",
            "1091/1091 [==============================] - 0s 107us/sample - loss: 0.4951 - sparse_categorical_accuracy: 0.7718\n",
            "Epoch 40/100\n",
            "1091/1091 [==============================] - 0s 100us/sample - loss: 0.4919 - sparse_categorical_accuracy: 0.7690\n",
            "Epoch 41/100\n",
            "1091/1091 [==============================] - 0s 105us/sample - loss: 0.4897 - sparse_categorical_accuracy: 0.7681\n",
            "Epoch 42/100\n",
            "1091/1091 [==============================] - 0s 102us/sample - loss: 0.4880 - sparse_categorical_accuracy: 0.7727\n",
            "Epoch 43/100\n",
            "1091/1091 [==============================] - 0s 106us/sample - loss: 0.4855 - sparse_categorical_accuracy: 0.7727\n",
            "Epoch 44/100\n",
            "1091/1091 [==============================] - 0s 114us/sample - loss: 0.4865 - sparse_categorical_accuracy: 0.7718\n",
            "Epoch 45/100\n",
            "1091/1091 [==============================] - 0s 125us/sample - loss: 0.4822 - sparse_categorical_accuracy: 0.7773\n",
            "Epoch 46/100\n",
            "1091/1091 [==============================] - 0s 110us/sample - loss: 0.4796 - sparse_categorical_accuracy: 0.7809\n",
            "Epoch 47/100\n",
            "1091/1091 [==============================] - 0s 109us/sample - loss: 0.4815 - sparse_categorical_accuracy: 0.7819\n",
            "Epoch 48/100\n",
            "1091/1091 [==============================] - 0s 100us/sample - loss: 0.4777 - sparse_categorical_accuracy: 0.7773\n",
            "Epoch 49/100\n",
            "1091/1091 [==============================] - 0s 111us/sample - loss: 0.4758 - sparse_categorical_accuracy: 0.7846\n",
            "Epoch 50/100\n",
            "1091/1091 [==============================] - 0s 100us/sample - loss: 0.4746 - sparse_categorical_accuracy: 0.7938\n",
            "Epoch 51/100\n",
            "1091/1091 [==============================] - 0s 106us/sample - loss: 0.4729 - sparse_categorical_accuracy: 0.7819\n",
            "Epoch 52/100\n",
            "1091/1091 [==============================] - 0s 101us/sample - loss: 0.4701 - sparse_categorical_accuracy: 0.7874\n",
            "Epoch 53/100\n",
            "1091/1091 [==============================] - 0s 105us/sample - loss: 0.4712 - sparse_categorical_accuracy: 0.7782\n",
            "Epoch 54/100\n",
            "1091/1091 [==============================] - 0s 118us/sample - loss: 0.4692 - sparse_categorical_accuracy: 0.7874\n",
            "Epoch 55/100\n",
            "1091/1091 [==============================] - 0s 108us/sample - loss: 0.4701 - sparse_categorical_accuracy: 0.7846\n",
            "Epoch 56/100\n",
            "1091/1091 [==============================] - 0s 106us/sample - loss: 0.4664 - sparse_categorical_accuracy: 0.7864\n",
            "Epoch 57/100\n",
            "1091/1091 [==============================] - 0s 114us/sample - loss: 0.4666 - sparse_categorical_accuracy: 0.7901\n",
            "Epoch 58/100\n",
            "1091/1091 [==============================] - 0s 114us/sample - loss: 0.4642 - sparse_categorical_accuracy: 0.7956\n",
            "Epoch 59/100\n",
            "1091/1091 [==============================] - 0s 103us/sample - loss: 0.4636 - sparse_categorical_accuracy: 0.7892\n",
            "Epoch 60/100\n",
            "1091/1091 [==============================] - 0s 111us/sample - loss: 0.4619 - sparse_categorical_accuracy: 0.7974\n",
            "Epoch 61/100\n",
            "1091/1091 [==============================] - 0s 109us/sample - loss: 0.4610 - sparse_categorical_accuracy: 0.7974\n",
            "Epoch 62/100\n",
            "1091/1091 [==============================] - 0s 119us/sample - loss: 0.4618 - sparse_categorical_accuracy: 0.7984\n",
            "Epoch 63/100\n",
            "1091/1091 [==============================] - 0s 115us/sample - loss: 0.4589 - sparse_categorical_accuracy: 0.7938\n",
            "Epoch 64/100\n",
            "1091/1091 [==============================] - 0s 119us/sample - loss: 0.4579 - sparse_categorical_accuracy: 0.7919\n",
            "Epoch 65/100\n",
            "1091/1091 [==============================] - 0s 115us/sample - loss: 0.4582 - sparse_categorical_accuracy: 0.7864\n",
            "Epoch 66/100\n",
            "1091/1091 [==============================] - 0s 109us/sample - loss: 0.4575 - sparse_categorical_accuracy: 0.7947\n",
            "Epoch 67/100\n",
            "1091/1091 [==============================] - 0s 113us/sample - loss: 0.4552 - sparse_categorical_accuracy: 0.7910\n",
            "Epoch 68/100\n",
            "1091/1091 [==============================] - 0s 104us/sample - loss: 0.4551 - sparse_categorical_accuracy: 0.7947\n",
            "Epoch 69/100\n",
            "1091/1091 [==============================] - 0s 108us/sample - loss: 0.4568 - sparse_categorical_accuracy: 0.7910\n",
            "Epoch 70/100\n",
            "1091/1091 [==============================] - 0s 109us/sample - loss: 0.4541 - sparse_categorical_accuracy: 0.7974\n",
            "Epoch 71/100\n",
            "1091/1091 [==============================] - 0s 114us/sample - loss: 0.4537 - sparse_categorical_accuracy: 0.7965\n",
            "Epoch 72/100\n",
            "1091/1091 [==============================] - 0s 106us/sample - loss: 0.4519 - sparse_categorical_accuracy: 0.7947\n",
            "Epoch 73/100\n",
            "1091/1091 [==============================] - 0s 107us/sample - loss: 0.4503 - sparse_categorical_accuracy: 0.7974\n",
            "Epoch 74/100\n",
            "1091/1091 [==============================] - 0s 121us/sample - loss: 0.4500 - sparse_categorical_accuracy: 0.7993\n",
            "Epoch 75/100\n",
            "1091/1091 [==============================] - 0s 103us/sample - loss: 0.4511 - sparse_categorical_accuracy: 0.7947\n",
            "Epoch 76/100\n",
            "1091/1091 [==============================] - 0s 107us/sample - loss: 0.4495 - sparse_categorical_accuracy: 0.7993\n",
            "Epoch 77/100\n",
            "1091/1091 [==============================] - 0s 116us/sample - loss: 0.4483 - sparse_categorical_accuracy: 0.7910\n",
            "Epoch 78/100\n",
            "1091/1091 [==============================] - 0s 116us/sample - loss: 0.4473 - sparse_categorical_accuracy: 0.7938\n",
            "Epoch 79/100\n",
            "1091/1091 [==============================] - 0s 124us/sample - loss: 0.4468 - sparse_categorical_accuracy: 0.7956\n",
            "Epoch 80/100\n",
            "1091/1091 [==============================] - 0s 105us/sample - loss: 0.4468 - sparse_categorical_accuracy: 0.7919\n",
            "Epoch 81/100\n",
            "1091/1091 [==============================] - 0s 106us/sample - loss: 0.4458 - sparse_categorical_accuracy: 0.8029\n",
            "Epoch 82/100\n",
            "1091/1091 [==============================] - 0s 106us/sample - loss: 0.4450 - sparse_categorical_accuracy: 0.7947\n",
            "Epoch 83/100\n",
            "1091/1091 [==============================] - 0s 99us/sample - loss: 0.4441 - sparse_categorical_accuracy: 0.7984\n",
            "Epoch 84/100\n",
            "1091/1091 [==============================] - 0s 109us/sample - loss: 0.4438 - sparse_categorical_accuracy: 0.8011\n",
            "Epoch 85/100\n",
            "1091/1091 [==============================] - 0s 101us/sample - loss: 0.4419 - sparse_categorical_accuracy: 0.8020\n",
            "Epoch 86/100\n",
            "1091/1091 [==============================] - 0s 98us/sample - loss: 0.4415 - sparse_categorical_accuracy: 0.8057\n",
            "Epoch 87/100\n",
            "1091/1091 [==============================] - 0s 105us/sample - loss: 0.4397 - sparse_categorical_accuracy: 0.8029\n",
            "Epoch 88/100\n",
            "1091/1091 [==============================] - 0s 131us/sample - loss: 0.4400 - sparse_categorical_accuracy: 0.7984\n",
            "Epoch 89/100\n",
            "1091/1091 [==============================] - 0s 107us/sample - loss: 0.4393 - sparse_categorical_accuracy: 0.8020\n",
            "Epoch 90/100\n",
            "1091/1091 [==============================] - 0s 110us/sample - loss: 0.4387 - sparse_categorical_accuracy: 0.8075\n",
            "Epoch 91/100\n",
            "1091/1091 [==============================] - 0s 104us/sample - loss: 0.4375 - sparse_categorical_accuracy: 0.8011\n",
            "Epoch 92/100\n",
            "1091/1091 [==============================] - 0s 105us/sample - loss: 0.4375 - sparse_categorical_accuracy: 0.7974\n",
            "Epoch 93/100\n",
            "1091/1091 [==============================] - 0s 108us/sample - loss: 0.4377 - sparse_categorical_accuracy: 0.7965\n",
            "Epoch 94/100\n",
            "1091/1091 [==============================] - 0s 115us/sample - loss: 0.4369 - sparse_categorical_accuracy: 0.8011\n",
            "Epoch 95/100\n",
            "1091/1091 [==============================] - 0s 105us/sample - loss: 0.4373 - sparse_categorical_accuracy: 0.8057\n",
            "Epoch 96/100\n",
            "1091/1091 [==============================] - 0s 116us/sample - loss: 0.4352 - sparse_categorical_accuracy: 0.8048\n",
            "Epoch 97/100\n",
            "1091/1091 [==============================] - 0s 108us/sample - loss: 0.4358 - sparse_categorical_accuracy: 0.8084\n",
            "Epoch 98/100\n",
            "1091/1091 [==============================] - 0s 107us/sample - loss: 0.4333 - sparse_categorical_accuracy: 0.8066\n",
            "Epoch 99/100\n",
            "1091/1091 [==============================] - 0s 111us/sample - loss: 0.4345 - sparse_categorical_accuracy: 0.8093\n",
            "Epoch 100/100\n",
            "1091/1091 [==============================] - 0s 101us/sample - loss: 0.4338 - sparse_categorical_accuracy: 0.8121\n",
            "keras_reg validation score(accuracy) : 0.7160822021116139\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqvQlzL-43-S",
        "colab_type": "code",
        "outputId": "442b0efa-052e-4bf5-bea9-e12f536cc9fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from scipy.stats import reciprocal\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "param_distribs = {\n",
        "    \"n_hidden\": [0, 1, 2, 3,4,5],\n",
        "    \"n_neurons\": np.arange(1, 100)\n",
        "}\n",
        "\n",
        "rnd_search_clf = RandomizedSearchCV(model_clf, param_distribs, n_iter=10,\n",
        "                                   cv=kfold, scoring='accuracy',\n",
        "                                   verbose=2)\n",
        "rnd_search_clf.fit(X_plus, y_cls.values.T[0], epochs=100,\n",
        "                  validation_split=0.1,\n",
        "                  callbacks=[early_stopping_cb])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "[CV] n_neurons=86, n_hidden=5 ........................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 981 samples, validate on 109 samples\n",
            "Epoch 1/100\n",
            "981/981 [==============================] - 1s 917us/sample - loss: 0.8994 - sparse_categorical_accuracy: 0.5566 - val_loss: 0.7624 - val_sparse_categorical_accuracy: 0.6055\n",
            "Epoch 2/100\n",
            "981/981 [==============================] - 0s 182us/sample - loss: 0.6996 - sparse_categorical_accuracy: 0.6585 - val_loss: 0.7094 - val_sparse_categorical_accuracy: 0.6422\n",
            "Epoch 3/100\n",
            "981/981 [==============================] - 0s 184us/sample - loss: 0.6125 - sparse_categorical_accuracy: 0.7207 - val_loss: 0.6488 - val_sparse_categorical_accuracy: 0.6606\n",
            "Epoch 4/100\n",
            "981/981 [==============================] - 0s 165us/sample - loss: 0.5756 - sparse_categorical_accuracy: 0.7350 - val_loss: 0.6136 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 5/100\n",
            "981/981 [==============================] - 0s 167us/sample - loss: 0.5400 - sparse_categorical_accuracy: 0.7554 - val_loss: 0.6758 - val_sparse_categorical_accuracy: 0.6514\n",
            "Epoch 6/100\n",
            "981/981 [==============================] - 0s 161us/sample - loss: 0.5185 - sparse_categorical_accuracy: 0.7655 - val_loss: 0.6195 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 7/100\n",
            "981/981 [==============================] - 0s 185us/sample - loss: 0.4922 - sparse_categorical_accuracy: 0.7941 - val_loss: 0.6055 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 8/100\n",
            "981/981 [==============================] - 0s 172us/sample - loss: 0.4765 - sparse_categorical_accuracy: 0.7808 - val_loss: 0.6396 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 9/100\n",
            "981/981 [==============================] - 0s 161us/sample - loss: 0.4598 - sparse_categorical_accuracy: 0.7920 - val_loss: 0.6493 - val_sparse_categorical_accuracy: 0.6697\n",
            "Epoch 10/100\n",
            "981/981 [==============================] - 0s 165us/sample - loss: 0.4511 - sparse_categorical_accuracy: 0.8073 - val_loss: 0.5994 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 11/100\n",
            "981/981 [==============================] - 0s 175us/sample - loss: 0.4358 - sparse_categorical_accuracy: 0.8012 - val_loss: 0.6018 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 12/100\n",
            "981/981 [==============================] - 0s 163us/sample - loss: 0.4259 - sparse_categorical_accuracy: 0.8043 - val_loss: 0.6410 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 13/100\n",
            "981/981 [==============================] - 0s 184us/sample - loss: 0.4209 - sparse_categorical_accuracy: 0.8124 - val_loss: 0.6160 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 14/100\n",
            "981/981 [==============================] - 0s 167us/sample - loss: 0.4084 - sparse_categorical_accuracy: 0.8267 - val_loss: 0.6949 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 15/100\n",
            "981/981 [==============================] - 0s 156us/sample - loss: 0.3988 - sparse_categorical_accuracy: 0.8328 - val_loss: 0.6889 - val_sparse_categorical_accuracy: 0.6697\n",
            "Epoch 16/100\n",
            "981/981 [==============================] - 0s 183us/sample - loss: 0.3985 - sparse_categorical_accuracy: 0.8349 - val_loss: 0.6399 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 17/100\n",
            "981/981 [==============================] - 0s 161us/sample - loss: 0.3792 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.6413 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 18/100\n",
            "981/981 [==============================] - 0s 160us/sample - loss: 0.3781 - sparse_categorical_accuracy: 0.8400 - val_loss: 0.6441 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 19/100\n",
            "981/981 [==============================] - 0s 156us/sample - loss: 0.3555 - sparse_categorical_accuracy: 0.8512 - val_loss: 0.7172 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 20/100\n",
            "981/981 [==============================] - 0s 182us/sample - loss: 0.3409 - sparse_categorical_accuracy: 0.8614 - val_loss: 0.6900 - val_sparse_categorical_accuracy: 0.7064\n",
            "[CV] ......................... n_neurons=86, n_hidden=5, total=   4.5s\n",
            "[CV] n_neurons=86, n_hidden=5 ........................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.5s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 981 samples, validate on 109 samples\n",
            "Epoch 1/100\n",
            "981/981 [==============================] - 1s 929us/sample - loss: 1.0192 - sparse_categorical_accuracy: 0.5005 - val_loss: 0.7652 - val_sparse_categorical_accuracy: 0.6422\n",
            "Epoch 2/100\n",
            "981/981 [==============================] - 0s 160us/sample - loss: 0.7449 - sparse_categorical_accuracy: 0.6198 - val_loss: 0.6749 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 3/100\n",
            "981/981 [==============================] - 0s 155us/sample - loss: 0.6562 - sparse_categorical_accuracy: 0.6779 - val_loss: 0.6582 - val_sparse_categorical_accuracy: 0.6697\n",
            "Epoch 4/100\n",
            "981/981 [==============================] - 0s 161us/sample - loss: 0.6007 - sparse_categorical_accuracy: 0.7044 - val_loss: 0.6310 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 5/100\n",
            "981/981 [==============================] - 0s 166us/sample - loss: 0.5579 - sparse_categorical_accuracy: 0.7421 - val_loss: 0.5834 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 6/100\n",
            "981/981 [==============================] - 0s 173us/sample - loss: 0.5306 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.5912 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 7/100\n",
            "981/981 [==============================] - 0s 162us/sample - loss: 0.5060 - sparse_categorical_accuracy: 0.7737 - val_loss: 0.6501 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 8/100\n",
            "981/981 [==============================] - 0s 167us/sample - loss: 0.4910 - sparse_categorical_accuracy: 0.7706 - val_loss: 0.5870 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 9/100\n",
            "981/981 [==============================] - 0s 163us/sample - loss: 0.4666 - sparse_categorical_accuracy: 0.7920 - val_loss: 0.5676 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 10/100\n",
            "981/981 [==============================] - 0s 154us/sample - loss: 0.4547 - sparse_categorical_accuracy: 0.8022 - val_loss: 0.5734 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 11/100\n",
            "981/981 [==============================] - 0s 161us/sample - loss: 0.4456 - sparse_categorical_accuracy: 0.8043 - val_loss: 0.5821 - val_sparse_categorical_accuracy: 0.7523\n",
            "Epoch 12/100\n",
            "981/981 [==============================] - 0s 171us/sample - loss: 0.4346 - sparse_categorical_accuracy: 0.8216 - val_loss: 0.5755 - val_sparse_categorical_accuracy: 0.7523\n",
            "Epoch 13/100\n",
            "981/981 [==============================] - 0s 160us/sample - loss: 0.4219 - sparse_categorical_accuracy: 0.8236 - val_loss: 0.5798 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 14/100\n",
            "981/981 [==============================] - 0s 182us/sample - loss: 0.4130 - sparse_categorical_accuracy: 0.8226 - val_loss: 0.5688 - val_sparse_categorical_accuracy: 0.7615\n",
            "Epoch 15/100\n",
            "981/981 [==============================] - 0s 157us/sample - loss: 0.4020 - sparse_categorical_accuracy: 0.8338 - val_loss: 0.5910 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 16/100\n",
            "981/981 [==============================] - 0s 150us/sample - loss: 0.3912 - sparse_categorical_accuracy: 0.8369 - val_loss: 0.5720 - val_sparse_categorical_accuracy: 0.7523\n",
            "Epoch 17/100\n",
            "981/981 [==============================] - 0s 164us/sample - loss: 0.3836 - sparse_categorical_accuracy: 0.8420 - val_loss: 0.5580 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 18/100\n",
            "981/981 [==============================] - 0s 162us/sample - loss: 0.3749 - sparse_categorical_accuracy: 0.8379 - val_loss: 0.5762 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 19/100\n",
            "981/981 [==============================] - 0s 158us/sample - loss: 0.3648 - sparse_categorical_accuracy: 0.8542 - val_loss: 0.5956 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 20/100\n",
            "981/981 [==============================] - 0s 154us/sample - loss: 0.3567 - sparse_categorical_accuracy: 0.8614 - val_loss: 0.5620 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 21/100\n",
            "981/981 [==============================] - 0s 173us/sample - loss: 0.3440 - sparse_categorical_accuracy: 0.8726 - val_loss: 0.5724 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 22/100\n",
            "981/981 [==============================] - 0s 151us/sample - loss: 0.3327 - sparse_categorical_accuracy: 0.8644 - val_loss: 0.5796 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 23/100\n",
            "981/981 [==============================] - 0s 165us/sample - loss: 0.3436 - sparse_categorical_accuracy: 0.8614 - val_loss: 0.6468 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 24/100\n",
            "981/981 [==============================] - 0s 157us/sample - loss: 0.3356 - sparse_categorical_accuracy: 0.8705 - val_loss: 0.5882 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 25/100\n",
            "981/981 [==============================] - 0s 159us/sample - loss: 0.3221 - sparse_categorical_accuracy: 0.8675 - val_loss: 0.5821 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 26/100\n",
            "981/981 [==============================] - 0s 154us/sample - loss: 0.3180 - sparse_categorical_accuracy: 0.8705 - val_loss: 0.5868 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 27/100\n",
            "981/981 [==============================] - 0s 159us/sample - loss: 0.3117 - sparse_categorical_accuracy: 0.8736 - val_loss: 0.6225 - val_sparse_categorical_accuracy: 0.7064\n",
            "[CV] ......................... n_neurons=86, n_hidden=5, total=   5.4s\n",
            "[CV] n_neurons=86, n_hidden=5 ........................................\n",
            "Train on 981 samples, validate on 109 samples\n",
            "Epoch 1/100\n",
            "981/981 [==============================] - 1s 950us/sample - loss: 0.9507 - sparse_categorical_accuracy: 0.5189 - val_loss: 0.8560 - val_sparse_categorical_accuracy: 0.5596\n",
            "Epoch 2/100\n",
            "981/981 [==============================] - 0s 166us/sample - loss: 0.7468 - sparse_categorical_accuracy: 0.6310 - val_loss: 0.7436 - val_sparse_categorical_accuracy: 0.6422\n",
            "Epoch 3/100\n",
            "981/981 [==============================] - 0s 155us/sample - loss: 0.6653 - sparse_categorical_accuracy: 0.6942 - val_loss: 0.6799 - val_sparse_categorical_accuracy: 0.6330\n",
            "Epoch 4/100\n",
            "981/981 [==============================] - 0s 176us/sample - loss: 0.6210 - sparse_categorical_accuracy: 0.7095 - val_loss: 0.6484 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 5/100\n",
            "981/981 [==============================] - 0s 161us/sample - loss: 0.5854 - sparse_categorical_accuracy: 0.7207 - val_loss: 0.6282 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 6/100\n",
            "981/981 [==============================] - 0s 176us/sample - loss: 0.5579 - sparse_categorical_accuracy: 0.7462 - val_loss: 0.6173 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 7/100\n",
            "981/981 [==============================] - 0s 161us/sample - loss: 0.5401 - sparse_categorical_accuracy: 0.7554 - val_loss: 0.6083 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 8/100\n",
            "981/981 [==============================] - 0s 156us/sample - loss: 0.5172 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.5966 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 9/100\n",
            "981/981 [==============================] - 0s 163us/sample - loss: 0.5003 - sparse_categorical_accuracy: 0.7757 - val_loss: 0.5766 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 10/100\n",
            "981/981 [==============================] - 0s 171us/sample - loss: 0.4883 - sparse_categorical_accuracy: 0.7829 - val_loss: 0.6144 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 11/100\n",
            "981/981 [==============================] - 0s 151us/sample - loss: 0.4759 - sparse_categorical_accuracy: 0.7859 - val_loss: 0.5966 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 12/100\n",
            "981/981 [==============================] - 0s 160us/sample - loss: 0.4631 - sparse_categorical_accuracy: 0.8053 - val_loss: 0.5830 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 13/100\n",
            "981/981 [==============================] - 0s 171us/sample - loss: 0.4557 - sparse_categorical_accuracy: 0.7839 - val_loss: 0.5863 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 14/100\n",
            "981/981 [==============================] - 0s 155us/sample - loss: 0.4471 - sparse_categorical_accuracy: 0.7961 - val_loss: 0.5824 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 15/100\n",
            "981/981 [==============================] - 0s 156us/sample - loss: 0.4417 - sparse_categorical_accuracy: 0.8002 - val_loss: 0.5814 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 16/100\n",
            "981/981 [==============================] - 0s 166us/sample - loss: 0.4282 - sparse_categorical_accuracy: 0.8124 - val_loss: 0.6222 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 17/100\n",
            "981/981 [==============================] - 0s 157us/sample - loss: 0.4161 - sparse_categorical_accuracy: 0.8155 - val_loss: 0.6167 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 18/100\n",
            "981/981 [==============================] - 0s 153us/sample - loss: 0.4113 - sparse_categorical_accuracy: 0.8216 - val_loss: 0.5955 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 19/100\n",
            "981/981 [==============================] - 0s 188us/sample - loss: 0.4075 - sparse_categorical_accuracy: 0.8277 - val_loss: 0.5874 - val_sparse_categorical_accuracy: 0.6972\n",
            "[CV] ......................... n_neurons=86, n_hidden=5, total=   4.2s\n",
            "[CV] n_neurons=86, n_hidden=5 ........................................\n",
            "Train on 981 samples, validate on 110 samples\n",
            "Epoch 1/100\n",
            "981/981 [==============================] - 1s 920us/sample - loss: 0.9499 - sparse_categorical_accuracy: 0.5311 - val_loss: 0.7238 - val_sparse_categorical_accuracy: 0.6273\n",
            "Epoch 2/100\n",
            "981/981 [==============================] - 0s 166us/sample - loss: 0.7015 - sparse_categorical_accuracy: 0.6279 - val_loss: 0.6555 - val_sparse_categorical_accuracy: 0.6455\n",
            "Epoch 3/100\n",
            "981/981 [==============================] - 0s 164us/sample - loss: 0.6159 - sparse_categorical_accuracy: 0.6962 - val_loss: 0.6548 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 4/100\n",
            "981/981 [==============================] - 0s 160us/sample - loss: 0.5734 - sparse_categorical_accuracy: 0.7197 - val_loss: 0.5857 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 5/100\n",
            "981/981 [==============================] - 0s 158us/sample - loss: 0.5309 - sparse_categorical_accuracy: 0.7472 - val_loss: 0.5801 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 6/100\n",
            "981/981 [==============================] - 0s 155us/sample - loss: 0.5079 - sparse_categorical_accuracy: 0.7513 - val_loss: 0.6303 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 7/100\n",
            "981/981 [==============================] - 0s 168us/sample - loss: 0.4958 - sparse_categorical_accuracy: 0.7676 - val_loss: 0.5769 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 8/100\n",
            "981/981 [==============================] - 0s 166us/sample - loss: 0.4693 - sparse_categorical_accuracy: 0.7849 - val_loss: 0.5944 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 9/100\n",
            "981/981 [==============================] - 0s 163us/sample - loss: 0.4581 - sparse_categorical_accuracy: 0.7900 - val_loss: 0.5704 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 10/100\n",
            "981/981 [==============================] - 0s 159us/sample - loss: 0.4463 - sparse_categorical_accuracy: 0.7982 - val_loss: 0.5675 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 11/100\n",
            "981/981 [==============================] - 0s 173us/sample - loss: 0.4279 - sparse_categorical_accuracy: 0.8186 - val_loss: 0.5621 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 12/100\n",
            "981/981 [==============================] - 0s 165us/sample - loss: 0.4186 - sparse_categorical_accuracy: 0.8165 - val_loss: 0.5580 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 13/100\n",
            "981/981 [==============================] - 0s 157us/sample - loss: 0.4057 - sparse_categorical_accuracy: 0.8206 - val_loss: 0.5710 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 14/100\n",
            "981/981 [==============================] - 0s 167us/sample - loss: 0.3901 - sparse_categorical_accuracy: 0.8318 - val_loss: 0.5445 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 15/100\n",
            "981/981 [==============================] - 0s 158us/sample - loss: 0.3912 - sparse_categorical_accuracy: 0.8359 - val_loss: 0.5777 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 16/100\n",
            "981/981 [==============================] - 0s 169us/sample - loss: 0.3769 - sparse_categorical_accuracy: 0.8420 - val_loss: 0.5334 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 17/100\n",
            "981/981 [==============================] - 0s 161us/sample - loss: 0.3687 - sparse_categorical_accuracy: 0.8440 - val_loss: 0.5457 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 18/100\n",
            "981/981 [==============================] - 0s 166us/sample - loss: 0.3639 - sparse_categorical_accuracy: 0.8400 - val_loss: 0.5685 - val_sparse_categorical_accuracy: 0.7636\n",
            "Epoch 19/100\n",
            "981/981 [==============================] - 0s 161us/sample - loss: 0.3619 - sparse_categorical_accuracy: 0.8542 - val_loss: 0.5448 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 20/100\n",
            "981/981 [==============================] - 0s 167us/sample - loss: 0.3462 - sparse_categorical_accuracy: 0.8522 - val_loss: 0.5620 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 21/100\n",
            "981/981 [==============================] - 0s 170us/sample - loss: 0.3364 - sparse_categorical_accuracy: 0.8695 - val_loss: 0.5513 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 22/100\n",
            "981/981 [==============================] - 0s 167us/sample - loss: 0.3309 - sparse_categorical_accuracy: 0.8573 - val_loss: 0.5720 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 23/100\n",
            "981/981 [==============================] - 0s 157us/sample - loss: 0.3241 - sparse_categorical_accuracy: 0.8695 - val_loss: 0.5557 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 24/100\n",
            "981/981 [==============================] - 0s 154us/sample - loss: 0.3153 - sparse_categorical_accuracy: 0.8705 - val_loss: 0.5747 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 25/100\n",
            "981/981 [==============================] - 0s 158us/sample - loss: 0.3040 - sparse_categorical_accuracy: 0.8787 - val_loss: 0.5577 - val_sparse_categorical_accuracy: 0.7636\n",
            "Epoch 26/100\n",
            "981/981 [==============================] - 0s 161us/sample - loss: 0.3016 - sparse_categorical_accuracy: 0.8797 - val_loss: 0.5659 - val_sparse_categorical_accuracy: 0.7182\n",
            "[CV] ......................... n_neurons=86, n_hidden=5, total=   5.3s\n",
            "[CV] n_neurons=86, n_hidden=5 ........................................\n",
            "Train on 981 samples, validate on 110 samples\n",
            "Epoch 1/100\n",
            "981/981 [==============================] - 1s 898us/sample - loss: 0.9008 - sparse_categorical_accuracy: 0.5474 - val_loss: 0.8046 - val_sparse_categorical_accuracy: 0.5545\n",
            "Epoch 2/100\n",
            "981/981 [==============================] - 0s 168us/sample - loss: 0.6725 - sparse_categorical_accuracy: 0.6799 - val_loss: 0.7332 - val_sparse_categorical_accuracy: 0.6000\n",
            "Epoch 3/100\n",
            "981/981 [==============================] - 0s 158us/sample - loss: 0.6055 - sparse_categorical_accuracy: 0.7238 - val_loss: 0.6797 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 4/100\n",
            "981/981 [==============================] - 0s 163us/sample - loss: 0.5610 - sparse_categorical_accuracy: 0.7574 - val_loss: 0.6622 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 5/100\n",
            "981/981 [==============================] - 0s 155us/sample - loss: 0.5366 - sparse_categorical_accuracy: 0.7401 - val_loss: 0.6311 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 6/100\n",
            "981/981 [==============================] - 0s 149us/sample - loss: 0.5138 - sparse_categorical_accuracy: 0.7635 - val_loss: 0.6556 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 7/100\n",
            "981/981 [==============================] - 0s 163us/sample - loss: 0.4962 - sparse_categorical_accuracy: 0.7717 - val_loss: 0.6611 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 8/100\n",
            "981/981 [==============================] - 0s 157us/sample - loss: 0.4780 - sparse_categorical_accuracy: 0.7737 - val_loss: 0.6739 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 9/100\n",
            "981/981 [==============================] - 0s 169us/sample - loss: 0.4612 - sparse_categorical_accuracy: 0.8053 - val_loss: 0.6520 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 10/100\n",
            "981/981 [==============================] - 0s 162us/sample - loss: 0.4493 - sparse_categorical_accuracy: 0.7920 - val_loss: 0.6875 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 11/100\n",
            "981/981 [==============================] - 0s 163us/sample - loss: 0.4420 - sparse_categorical_accuracy: 0.8033 - val_loss: 0.6308 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 12/100\n",
            "981/981 [==============================] - 0s 150us/sample - loss: 0.4273 - sparse_categorical_accuracy: 0.8084 - val_loss: 0.6582 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 13/100\n",
            "981/981 [==============================] - 0s 161us/sample - loss: 0.4207 - sparse_categorical_accuracy: 0.8114 - val_loss: 0.6659 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 14/100\n",
            "981/981 [==============================] - 0s 176us/sample - loss: 0.4052 - sparse_categorical_accuracy: 0.8124 - val_loss: 0.6501 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 15/100\n",
            "981/981 [==============================] - 0s 166us/sample - loss: 0.3988 - sparse_categorical_accuracy: 0.8135 - val_loss: 0.6856 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 16/100\n",
            "981/981 [==============================] - 0s 155us/sample - loss: 0.3896 - sparse_categorical_accuracy: 0.8267 - val_loss: 0.6469 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 17/100\n",
            "981/981 [==============================] - 0s 154us/sample - loss: 0.3758 - sparse_categorical_accuracy: 0.8328 - val_loss: 0.6516 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 18/100\n",
            "981/981 [==============================] - 0s 167us/sample - loss: 0.3720 - sparse_categorical_accuracy: 0.8349 - val_loss: 0.6967 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 19/100\n",
            "981/981 [==============================] - 0s 156us/sample - loss: 0.3752 - sparse_categorical_accuracy: 0.8287 - val_loss: 0.6431 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 20/100\n",
            "981/981 [==============================] - 0s 161us/sample - loss: 0.3576 - sparse_categorical_accuracy: 0.8461 - val_loss: 0.6701 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 21/100\n",
            "981/981 [==============================] - 0s 173us/sample - loss: 0.3487 - sparse_categorical_accuracy: 0.8552 - val_loss: 0.7965 - val_sparse_categorical_accuracy: 0.6182\n",
            "[CV] ......................... n_neurons=86, n_hidden=5, total=   4.5s\n",
            "[CV] n_neurons=26, n_hidden=0 ........................................\n",
            "Train on 981 samples, validate on 109 samples\n",
            "Epoch 1/100\n",
            "981/981 [==============================] - 0s 455us/sample - loss: 1.2713 - sparse_categorical_accuracy: 0.3812 - val_loss: 1.2585 - val_sparse_categorical_accuracy: 0.3853\n",
            "Epoch 2/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 1.1687 - sparse_categorical_accuracy: 0.4128 - val_loss: 1.1632 - val_sparse_categorical_accuracy: 0.4312\n",
            "Epoch 3/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 1.0942 - sparse_categorical_accuracy: 0.4414 - val_loss: 1.0880 - val_sparse_categorical_accuracy: 0.4771\n",
            "Epoch 4/100\n",
            "981/981 [==============================] - 0s 134us/sample - loss: 1.0346 - sparse_categorical_accuracy: 0.4689 - val_loss: 1.0297 - val_sparse_categorical_accuracy: 0.4954\n",
            "Epoch 5/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.9880 - sparse_categorical_accuracy: 0.4822 - val_loss: 0.9841 - val_sparse_categorical_accuracy: 0.4954\n",
            "Epoch 6/100\n",
            "981/981 [==============================] - 0s 113us/sample - loss: 0.9487 - sparse_categorical_accuracy: 0.4995 - val_loss: 0.9458 - val_sparse_categorical_accuracy: 0.5138\n",
            "Epoch 7/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.9157 - sparse_categorical_accuracy: 0.5240 - val_loss: 0.9160 - val_sparse_categorical_accuracy: 0.5138\n",
            "Epoch 8/100\n",
            "981/981 [==============================] - 0s 110us/sample - loss: 0.8885 - sparse_categorical_accuracy: 0.5464 - val_loss: 0.8899 - val_sparse_categorical_accuracy: 0.5321\n",
            "Epoch 9/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.8646 - sparse_categorical_accuracy: 0.5678 - val_loss: 0.8669 - val_sparse_categorical_accuracy: 0.5596\n",
            "Epoch 10/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.8434 - sparse_categorical_accuracy: 0.5902 - val_loss: 0.8472 - val_sparse_categorical_accuracy: 0.5872\n",
            "Epoch 11/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.8254 - sparse_categorical_accuracy: 0.5943 - val_loss: 0.8314 - val_sparse_categorical_accuracy: 0.5963\n",
            "Epoch 12/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.8085 - sparse_categorical_accuracy: 0.6086 - val_loss: 0.8159 - val_sparse_categorical_accuracy: 0.5963\n",
            "Epoch 13/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.7934 - sparse_categorical_accuracy: 0.6188 - val_loss: 0.8017 - val_sparse_categorical_accuracy: 0.5963\n",
            "Epoch 14/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.7794 - sparse_categorical_accuracy: 0.6300 - val_loss: 0.7890 - val_sparse_categorical_accuracy: 0.6239\n",
            "Epoch 15/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.7663 - sparse_categorical_accuracy: 0.6228 - val_loss: 0.7790 - val_sparse_categorical_accuracy: 0.6239\n",
            "Epoch 16/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.7554 - sparse_categorical_accuracy: 0.6432 - val_loss: 0.7680 - val_sparse_categorical_accuracy: 0.6239\n",
            "Epoch 17/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.7445 - sparse_categorical_accuracy: 0.6534 - val_loss: 0.7586 - val_sparse_categorical_accuracy: 0.6422\n",
            "Epoch 18/100\n",
            "981/981 [==============================] - 0s 113us/sample - loss: 0.7354 - sparse_categorical_accuracy: 0.6534 - val_loss: 0.7506 - val_sparse_categorical_accuracy: 0.6606\n",
            "Epoch 19/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.7255 - sparse_categorical_accuracy: 0.6626 - val_loss: 0.7430 - val_sparse_categorical_accuracy: 0.6606\n",
            "Epoch 20/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.7169 - sparse_categorical_accuracy: 0.6656 - val_loss: 0.7361 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 21/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.7091 - sparse_categorical_accuracy: 0.6687 - val_loss: 0.7281 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 22/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.7012 - sparse_categorical_accuracy: 0.6758 - val_loss: 0.7216 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 23/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.6938 - sparse_categorical_accuracy: 0.6799 - val_loss: 0.7163 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 24/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.6870 - sparse_categorical_accuracy: 0.6840 - val_loss: 0.7098 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 25/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.6810 - sparse_categorical_accuracy: 0.6891 - val_loss: 0.7047 - val_sparse_categorical_accuracy: 0.6697\n",
            "Epoch 26/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.6746 - sparse_categorical_accuracy: 0.6972 - val_loss: 0.7002 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 27/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.6694 - sparse_categorical_accuracy: 0.6942 - val_loss: 0.6941 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 28/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.6637 - sparse_categorical_accuracy: 0.7003 - val_loss: 0.6897 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 29/100\n",
            "981/981 [==============================] - 0s 149us/sample - loss: 0.6587 - sparse_categorical_accuracy: 0.7044 - val_loss: 0.6859 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 30/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.6538 - sparse_categorical_accuracy: 0.7034 - val_loss: 0.6826 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 31/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.6482 - sparse_categorical_accuracy: 0.7085 - val_loss: 0.6773 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 32/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.6441 - sparse_categorical_accuracy: 0.7095 - val_loss: 0.6741 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 33/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.6400 - sparse_categorical_accuracy: 0.7085 - val_loss: 0.6705 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 34/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.6355 - sparse_categorical_accuracy: 0.7156 - val_loss: 0.6678 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 35/100\n",
            "981/981 [==============================] - 0s 113us/sample - loss: 0.6316 - sparse_categorical_accuracy: 0.7095 - val_loss: 0.6652 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 36/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.6282 - sparse_categorical_accuracy: 0.7207 - val_loss: 0.6615 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 37/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.6239 - sparse_categorical_accuracy: 0.7166 - val_loss: 0.6583 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 38/100\n",
            "981/981 [==============================] - 0s 137us/sample - loss: 0.6206 - sparse_categorical_accuracy: 0.7278 - val_loss: 0.6550 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 39/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.6172 - sparse_categorical_accuracy: 0.7268 - val_loss: 0.6526 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 40/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.6140 - sparse_categorical_accuracy: 0.7319 - val_loss: 0.6497 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 41/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.6108 - sparse_categorical_accuracy: 0.7268 - val_loss: 0.6479 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 42/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.6079 - sparse_categorical_accuracy: 0.7350 - val_loss: 0.6450 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 43/100\n",
            "981/981 [==============================] - 0s 113us/sample - loss: 0.6051 - sparse_categorical_accuracy: 0.7350 - val_loss: 0.6430 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 44/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.6019 - sparse_categorical_accuracy: 0.7380 - val_loss: 0.6405 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 45/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5992 - sparse_categorical_accuracy: 0.7401 - val_loss: 0.6389 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 46/100\n",
            "981/981 [==============================] - 0s 135us/sample - loss: 0.5967 - sparse_categorical_accuracy: 0.7390 - val_loss: 0.6368 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 47/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.5940 - sparse_categorical_accuracy: 0.7411 - val_loss: 0.6342 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 48/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.5917 - sparse_categorical_accuracy: 0.7462 - val_loss: 0.6326 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 49/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.5895 - sparse_categorical_accuracy: 0.7462 - val_loss: 0.6306 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 50/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5871 - sparse_categorical_accuracy: 0.7503 - val_loss: 0.6294 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 51/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.5850 - sparse_categorical_accuracy: 0.7431 - val_loss: 0.6279 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 52/100\n",
            "981/981 [==============================] - 0s 135us/sample - loss: 0.5828 - sparse_categorical_accuracy: 0.7472 - val_loss: 0.6265 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 53/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.5803 - sparse_categorical_accuracy: 0.7543 - val_loss: 0.6267 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 54/100\n",
            "981/981 [==============================] - 0s 146us/sample - loss: 0.5787 - sparse_categorical_accuracy: 0.7472 - val_loss: 0.6228 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 55/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.5765 - sparse_categorical_accuracy: 0.7594 - val_loss: 0.6221 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 56/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.5747 - sparse_categorical_accuracy: 0.7543 - val_loss: 0.6203 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 57/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.5725 - sparse_categorical_accuracy: 0.7574 - val_loss: 0.6194 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 58/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.5709 - sparse_categorical_accuracy: 0.7513 - val_loss: 0.6172 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 59/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5692 - sparse_categorical_accuracy: 0.7574 - val_loss: 0.6154 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 60/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.5678 - sparse_categorical_accuracy: 0.7564 - val_loss: 0.6142 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 61/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.5658 - sparse_categorical_accuracy: 0.7574 - val_loss: 0.6143 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 62/100\n",
            "981/981 [==============================] - 0s 112us/sample - loss: 0.5643 - sparse_categorical_accuracy: 0.7554 - val_loss: 0.6125 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 63/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.5625 - sparse_categorical_accuracy: 0.7543 - val_loss: 0.6103 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 64/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.5614 - sparse_categorical_accuracy: 0.7604 - val_loss: 0.6093 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 65/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.5593 - sparse_categorical_accuracy: 0.7554 - val_loss: 0.6092 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 66/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.5582 - sparse_categorical_accuracy: 0.7604 - val_loss: 0.6082 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 67/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5564 - sparse_categorical_accuracy: 0.7594 - val_loss: 0.6069 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 68/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.5552 - sparse_categorical_accuracy: 0.7655 - val_loss: 0.6050 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 69/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.5539 - sparse_categorical_accuracy: 0.7554 - val_loss: 0.6042 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 70/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5523 - sparse_categorical_accuracy: 0.7564 - val_loss: 0.6029 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 71/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.5510 - sparse_categorical_accuracy: 0.7584 - val_loss: 0.6025 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 72/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.5497 - sparse_categorical_accuracy: 0.7594 - val_loss: 0.6016 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 73/100\n",
            "981/981 [==============================] - 0s 113us/sample - loss: 0.5484 - sparse_categorical_accuracy: 0.7594 - val_loss: 0.6020 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 74/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.5475 - sparse_categorical_accuracy: 0.7604 - val_loss: 0.6009 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 75/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.5462 - sparse_categorical_accuracy: 0.7635 - val_loss: 0.5989 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 76/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5449 - sparse_categorical_accuracy: 0.7594 - val_loss: 0.5983 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 77/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.5440 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.5977 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 78/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5429 - sparse_categorical_accuracy: 0.7615 - val_loss: 0.5972 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 79/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.5416 - sparse_categorical_accuracy: 0.7645 - val_loss: 0.5961 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 80/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5407 - sparse_categorical_accuracy: 0.7615 - val_loss: 0.5950 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 81/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5398 - sparse_categorical_accuracy: 0.7666 - val_loss: 0.5945 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 82/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5387 - sparse_categorical_accuracy: 0.7666 - val_loss: 0.5946 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 83/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5375 - sparse_categorical_accuracy: 0.7635 - val_loss: 0.5941 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 84/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.5365 - sparse_categorical_accuracy: 0.7635 - val_loss: 0.5926 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 85/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.5354 - sparse_categorical_accuracy: 0.7635 - val_loss: 0.5929 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 86/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.5348 - sparse_categorical_accuracy: 0.7635 - val_loss: 0.5920 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 87/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.5339 - sparse_categorical_accuracy: 0.7666 - val_loss: 0.5910 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 88/100\n",
            "981/981 [==============================] - 0s 159us/sample - loss: 0.5331 - sparse_categorical_accuracy: 0.7645 - val_loss: 0.5914 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 89/100\n",
            "981/981 [==============================] - 0s 137us/sample - loss: 0.5318 - sparse_categorical_accuracy: 0.7594 - val_loss: 0.5890 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 90/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5315 - sparse_categorical_accuracy: 0.7686 - val_loss: 0.5892 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 91/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.5303 - sparse_categorical_accuracy: 0.7676 - val_loss: 0.5890 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 92/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.5295 - sparse_categorical_accuracy: 0.7666 - val_loss: 0.5887 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 93/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.5285 - sparse_categorical_accuracy: 0.7635 - val_loss: 0.5879 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 94/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.5278 - sparse_categorical_accuracy: 0.7706 - val_loss: 0.5872 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 95/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.5270 - sparse_categorical_accuracy: 0.7615 - val_loss: 0.5864 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 96/100\n",
            "981/981 [==============================] - 0s 139us/sample - loss: 0.5264 - sparse_categorical_accuracy: 0.7655 - val_loss: 0.5870 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 97/100\n",
            "981/981 [==============================] - 0s 139us/sample - loss: 0.5255 - sparse_categorical_accuracy: 0.7666 - val_loss: 0.5858 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 98/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.5248 - sparse_categorical_accuracy: 0.7635 - val_loss: 0.5848 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 99/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.5237 - sparse_categorical_accuracy: 0.7696 - val_loss: 0.5850 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 100/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.5232 - sparse_categorical_accuracy: 0.7666 - val_loss: 0.5836 - val_sparse_categorical_accuracy: 0.7339\n",
            "[CV] ......................... n_neurons=26, n_hidden=0, total=  12.8s\n",
            "[CV] n_neurons=26, n_hidden=0 ........................................\n",
            "Train on 981 samples, validate on 109 samples\n",
            "Epoch 1/100\n",
            "981/981 [==============================] - 0s 440us/sample - loss: 1.1928 - sparse_categorical_accuracy: 0.3721 - val_loss: 0.9975 - val_sparse_categorical_accuracy: 0.4679\n",
            "Epoch 2/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 1.0663 - sparse_categorical_accuracy: 0.4302 - val_loss: 0.9464 - val_sparse_categorical_accuracy: 0.5596\n",
            "Epoch 3/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 1.0025 - sparse_categorical_accuracy: 0.4822 - val_loss: 0.9022 - val_sparse_categorical_accuracy: 0.5872\n",
            "Epoch 4/100\n",
            "981/981 [==============================] - 0s 134us/sample - loss: 0.9544 - sparse_categorical_accuracy: 0.5056 - val_loss: 0.8661 - val_sparse_categorical_accuracy: 0.6147\n",
            "Epoch 5/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.9164 - sparse_categorical_accuracy: 0.5382 - val_loss: 0.8360 - val_sparse_categorical_accuracy: 0.6330\n",
            "Epoch 6/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.8849 - sparse_categorical_accuracy: 0.5545 - val_loss: 0.8157 - val_sparse_categorical_accuracy: 0.6422\n",
            "Epoch 7/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.8585 - sparse_categorical_accuracy: 0.5708 - val_loss: 0.7943 - val_sparse_categorical_accuracy: 0.6514\n",
            "Epoch 8/100\n",
            "981/981 [==============================] - 0s 135us/sample - loss: 0.8357 - sparse_categorical_accuracy: 0.5892 - val_loss: 0.7768 - val_sparse_categorical_accuracy: 0.6422\n",
            "Epoch 9/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.8153 - sparse_categorical_accuracy: 0.6045 - val_loss: 0.7613 - val_sparse_categorical_accuracy: 0.6606\n",
            "Epoch 10/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.7977 - sparse_categorical_accuracy: 0.6157 - val_loss: 0.7447 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 11/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.7818 - sparse_categorical_accuracy: 0.6310 - val_loss: 0.7334 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 12/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.7679 - sparse_categorical_accuracy: 0.6391 - val_loss: 0.7221 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 13/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.7543 - sparse_categorical_accuracy: 0.6381 - val_loss: 0.7152 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 14/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.7430 - sparse_categorical_accuracy: 0.6524 - val_loss: 0.7045 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 15/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.7315 - sparse_categorical_accuracy: 0.6697 - val_loss: 0.6969 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 16/100\n",
            "981/981 [==============================] - 0s 110us/sample - loss: 0.7212 - sparse_categorical_accuracy: 0.6667 - val_loss: 0.6927 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 17/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.7118 - sparse_categorical_accuracy: 0.6769 - val_loss: 0.6827 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 18/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.7030 - sparse_categorical_accuracy: 0.6871 - val_loss: 0.6758 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 19/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.6945 - sparse_categorical_accuracy: 0.6881 - val_loss: 0.6695 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 20/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.6868 - sparse_categorical_accuracy: 0.6983 - val_loss: 0.6627 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 21/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.6796 - sparse_categorical_accuracy: 0.6993 - val_loss: 0.6569 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 22/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.6730 - sparse_categorical_accuracy: 0.7003 - val_loss: 0.6516 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 23/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.6664 - sparse_categorical_accuracy: 0.6993 - val_loss: 0.6517 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 24/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.6603 - sparse_categorical_accuracy: 0.7064 - val_loss: 0.6433 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 25/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.6550 - sparse_categorical_accuracy: 0.7125 - val_loss: 0.6416 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 26/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.6491 - sparse_categorical_accuracy: 0.7156 - val_loss: 0.6377 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 27/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.6437 - sparse_categorical_accuracy: 0.7187 - val_loss: 0.6324 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 28/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.6388 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.6314 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 29/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.6343 - sparse_categorical_accuracy: 0.7207 - val_loss: 0.6291 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 30/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.6296 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.6237 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 31/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.6254 - sparse_categorical_accuracy: 0.7197 - val_loss: 0.6246 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 32/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.6208 - sparse_categorical_accuracy: 0.7227 - val_loss: 0.6198 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 33/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.6172 - sparse_categorical_accuracy: 0.7268 - val_loss: 0.6157 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 34/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.6135 - sparse_categorical_accuracy: 0.7278 - val_loss: 0.6123 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 35/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.6104 - sparse_categorical_accuracy: 0.7309 - val_loss: 0.6103 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 36/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.6063 - sparse_categorical_accuracy: 0.7401 - val_loss: 0.6090 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 37/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.6030 - sparse_categorical_accuracy: 0.7411 - val_loss: 0.6083 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 38/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.5996 - sparse_categorical_accuracy: 0.7421 - val_loss: 0.6062 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 39/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.5971 - sparse_categorical_accuracy: 0.7370 - val_loss: 0.6027 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 40/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.5938 - sparse_categorical_accuracy: 0.7411 - val_loss: 0.6017 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 41/100\n",
            "981/981 [==============================] - 0s 113us/sample - loss: 0.5912 - sparse_categorical_accuracy: 0.7462 - val_loss: 0.6002 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 42/100\n",
            "981/981 [==============================] - 0s 137us/sample - loss: 0.5882 - sparse_categorical_accuracy: 0.7441 - val_loss: 0.5988 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 43/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5858 - sparse_categorical_accuracy: 0.7462 - val_loss: 0.5987 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 44/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.5830 - sparse_categorical_accuracy: 0.7452 - val_loss: 0.5940 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 45/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.5807 - sparse_categorical_accuracy: 0.7513 - val_loss: 0.5924 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 46/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5782 - sparse_categorical_accuracy: 0.7503 - val_loss: 0.5910 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 47/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.5761 - sparse_categorical_accuracy: 0.7503 - val_loss: 0.5874 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 48/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.5738 - sparse_categorical_accuracy: 0.7472 - val_loss: 0.5878 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 49/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.5714 - sparse_categorical_accuracy: 0.7533 - val_loss: 0.5861 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 50/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.5692 - sparse_categorical_accuracy: 0.7503 - val_loss: 0.5842 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 51/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.5673 - sparse_categorical_accuracy: 0.7492 - val_loss: 0.5872 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 52/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.5654 - sparse_categorical_accuracy: 0.7543 - val_loss: 0.5836 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 53/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5634 - sparse_categorical_accuracy: 0.7584 - val_loss: 0.5793 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 54/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.5614 - sparse_categorical_accuracy: 0.7513 - val_loss: 0.5796 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 55/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.5597 - sparse_categorical_accuracy: 0.7564 - val_loss: 0.5790 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 56/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.5580 - sparse_categorical_accuracy: 0.7554 - val_loss: 0.5795 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 57/100\n",
            "981/981 [==============================] - 0s 111us/sample - loss: 0.5561 - sparse_categorical_accuracy: 0.7543 - val_loss: 0.5787 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 58/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.5545 - sparse_categorical_accuracy: 0.7574 - val_loss: 0.5778 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 59/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.5533 - sparse_categorical_accuracy: 0.7584 - val_loss: 0.5745 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 60/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5512 - sparse_categorical_accuracy: 0.7564 - val_loss: 0.5755 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 61/100\n",
            "981/981 [==============================] - 0s 112us/sample - loss: 0.5498 - sparse_categorical_accuracy: 0.7594 - val_loss: 0.5734 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 62/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5483 - sparse_categorical_accuracy: 0.7574 - val_loss: 0.5704 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 63/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.5471 - sparse_categorical_accuracy: 0.7604 - val_loss: 0.5700 - val_sparse_categorical_accuracy: 0.7523\n",
            "Epoch 64/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.5457 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.5697 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 65/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.5442 - sparse_categorical_accuracy: 0.7615 - val_loss: 0.5703 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 66/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.5428 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.5657 - val_sparse_categorical_accuracy: 0.7615\n",
            "Epoch 67/100\n",
            "981/981 [==============================] - 0s 142us/sample - loss: 0.5414 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.5678 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 68/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.5404 - sparse_categorical_accuracy: 0.7615 - val_loss: 0.5658 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 69/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.5389 - sparse_categorical_accuracy: 0.7604 - val_loss: 0.5635 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 70/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.5381 - sparse_categorical_accuracy: 0.7635 - val_loss: 0.5646 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 71/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.5364 - sparse_categorical_accuracy: 0.7655 - val_loss: 0.5627 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 72/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5353 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.5609 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 73/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5345 - sparse_categorical_accuracy: 0.7676 - val_loss: 0.5635 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 74/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5331 - sparse_categorical_accuracy: 0.7706 - val_loss: 0.5598 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 75/100\n",
            "981/981 [==============================] - 0s 136us/sample - loss: 0.5322 - sparse_categorical_accuracy: 0.7635 - val_loss: 0.5609 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 76/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5312 - sparse_categorical_accuracy: 0.7676 - val_loss: 0.5620 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 77/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.5300 - sparse_categorical_accuracy: 0.7706 - val_loss: 0.5592 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 78/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.5289 - sparse_categorical_accuracy: 0.7676 - val_loss: 0.5585 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 79/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.5279 - sparse_categorical_accuracy: 0.7717 - val_loss: 0.5587 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 80/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.5270 - sparse_categorical_accuracy: 0.7706 - val_loss: 0.5566 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 81/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.5264 - sparse_categorical_accuracy: 0.7696 - val_loss: 0.5571 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 82/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.5255 - sparse_categorical_accuracy: 0.7706 - val_loss: 0.5579 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 83/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.5243 - sparse_categorical_accuracy: 0.7696 - val_loss: 0.5571 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 84/100\n",
            "981/981 [==============================] - 0s 139us/sample - loss: 0.5232 - sparse_categorical_accuracy: 0.7717 - val_loss: 0.5537 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 85/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.5225 - sparse_categorical_accuracy: 0.7686 - val_loss: 0.5555 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 86/100\n",
            "981/981 [==============================] - 0s 113us/sample - loss: 0.5218 - sparse_categorical_accuracy: 0.7706 - val_loss: 0.5561 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 87/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5208 - sparse_categorical_accuracy: 0.7727 - val_loss: 0.5526 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 88/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.5202 - sparse_categorical_accuracy: 0.7737 - val_loss: 0.5533 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 89/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5189 - sparse_categorical_accuracy: 0.7727 - val_loss: 0.5514 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 90/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5188 - sparse_categorical_accuracy: 0.7747 - val_loss: 0.5519 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 91/100\n",
            "981/981 [==============================] - 0s 112us/sample - loss: 0.5173 - sparse_categorical_accuracy: 0.7727 - val_loss: 0.5527 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 92/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.5166 - sparse_categorical_accuracy: 0.7737 - val_loss: 0.5530 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 93/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.5159 - sparse_categorical_accuracy: 0.7717 - val_loss: 0.5512 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 94/100\n",
            "981/981 [==============================] - 0s 113us/sample - loss: 0.5151 - sparse_categorical_accuracy: 0.7768 - val_loss: 0.5536 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 95/100\n",
            "981/981 [==============================] - 0s 111us/sample - loss: 0.5145 - sparse_categorical_accuracy: 0.7747 - val_loss: 0.5516 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 96/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.5136 - sparse_categorical_accuracy: 0.7747 - val_loss: 0.5492 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 97/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.5132 - sparse_categorical_accuracy: 0.7757 - val_loss: 0.5478 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 98/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.5126 - sparse_categorical_accuracy: 0.7737 - val_loss: 0.5473 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 99/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.5117 - sparse_categorical_accuracy: 0.7747 - val_loss: 0.5482 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 100/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5111 - sparse_categorical_accuracy: 0.7757 - val_loss: 0.5497 - val_sparse_categorical_accuracy: 0.7248\n",
            "[CV] ......................... n_neurons=26, n_hidden=0, total=  12.7s\n",
            "[CV] n_neurons=26, n_hidden=0 ........................................\n",
            "Train on 981 samples, validate on 109 samples\n",
            "Epoch 1/100\n",
            "981/981 [==============================] - 0s 438us/sample - loss: 1.4138 - sparse_categorical_accuracy: 0.2752 - val_loss: 1.1848 - val_sparse_categorical_accuracy: 0.3670\n",
            "Epoch 2/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 1.1881 - sparse_categorical_accuracy: 0.3415 - val_loss: 1.0894 - val_sparse_categorical_accuracy: 0.4312\n",
            "Epoch 3/100\n",
            "981/981 [==============================] - 0s 113us/sample - loss: 1.1041 - sparse_categorical_accuracy: 0.3792 - val_loss: 1.0192 - val_sparse_categorical_accuracy: 0.4679\n",
            "Epoch 4/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 1.0413 - sparse_categorical_accuracy: 0.4220 - val_loss: 0.9632 - val_sparse_categorical_accuracy: 0.5046\n",
            "Epoch 5/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.9924 - sparse_categorical_accuracy: 0.4536 - val_loss: 0.9219 - val_sparse_categorical_accuracy: 0.5413\n",
            "Epoch 6/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.9523 - sparse_categorical_accuracy: 0.4873 - val_loss: 0.8785 - val_sparse_categorical_accuracy: 0.5780\n",
            "Epoch 7/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.9191 - sparse_categorical_accuracy: 0.5046 - val_loss: 0.8495 - val_sparse_categorical_accuracy: 0.5963\n",
            "Epoch 8/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.8918 - sparse_categorical_accuracy: 0.5301 - val_loss: 0.8232 - val_sparse_categorical_accuracy: 0.6239\n",
            "Epoch 9/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.8671 - sparse_categorical_accuracy: 0.5627 - val_loss: 0.8002 - val_sparse_categorical_accuracy: 0.6330\n",
            "Epoch 10/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.8466 - sparse_categorical_accuracy: 0.5729 - val_loss: 0.7795 - val_sparse_categorical_accuracy: 0.6422\n",
            "Epoch 11/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.8283 - sparse_categorical_accuracy: 0.5831 - val_loss: 0.7615 - val_sparse_categorical_accuracy: 0.6606\n",
            "Epoch 12/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.8106 - sparse_categorical_accuracy: 0.5963 - val_loss: 0.7464 - val_sparse_categorical_accuracy: 0.6697\n",
            "Epoch 13/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.7960 - sparse_categorical_accuracy: 0.6075 - val_loss: 0.7325 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 14/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.7825 - sparse_categorical_accuracy: 0.6208 - val_loss: 0.7197 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 15/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.7703 - sparse_categorical_accuracy: 0.6320 - val_loss: 0.7091 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 16/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.7581 - sparse_categorical_accuracy: 0.6391 - val_loss: 0.6979 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 17/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.7476 - sparse_categorical_accuracy: 0.6483 - val_loss: 0.6892 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 18/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.7375 - sparse_categorical_accuracy: 0.6555 - val_loss: 0.6828 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 19/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.7285 - sparse_categorical_accuracy: 0.6636 - val_loss: 0.6739 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 20/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.7200 - sparse_categorical_accuracy: 0.6697 - val_loss: 0.6681 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 21/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.7122 - sparse_categorical_accuracy: 0.6738 - val_loss: 0.6573 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 22/100\n",
            "981/981 [==============================] - 0s 141us/sample - loss: 0.7049 - sparse_categorical_accuracy: 0.6769 - val_loss: 0.6520 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 23/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.6983 - sparse_categorical_accuracy: 0.6789 - val_loss: 0.6474 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 24/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.6911 - sparse_categorical_accuracy: 0.6809 - val_loss: 0.6407 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 25/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.6845 - sparse_categorical_accuracy: 0.6891 - val_loss: 0.6358 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 26/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.6789 - sparse_categorical_accuracy: 0.6972 - val_loss: 0.6310 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 27/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.6732 - sparse_categorical_accuracy: 0.6993 - val_loss: 0.6257 - val_sparse_categorical_accuracy: 0.7523\n",
            "Epoch 28/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.6679 - sparse_categorical_accuracy: 0.7034 - val_loss: 0.6226 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 29/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.6631 - sparse_categorical_accuracy: 0.7034 - val_loss: 0.6196 - val_sparse_categorical_accuracy: 0.7523\n",
            "Epoch 30/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.6589 - sparse_categorical_accuracy: 0.7064 - val_loss: 0.6147 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 31/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.6539 - sparse_categorical_accuracy: 0.7095 - val_loss: 0.6106 - val_sparse_categorical_accuracy: 0.7523\n",
            "Epoch 32/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.6490 - sparse_categorical_accuracy: 0.7125 - val_loss: 0.6080 - val_sparse_categorical_accuracy: 0.7523\n",
            "Epoch 33/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.6447 - sparse_categorical_accuracy: 0.7125 - val_loss: 0.6071 - val_sparse_categorical_accuracy: 0.7523\n",
            "Epoch 34/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.6416 - sparse_categorical_accuracy: 0.7197 - val_loss: 0.6022 - val_sparse_categorical_accuracy: 0.7523\n",
            "Epoch 35/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.6375 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.5982 - val_sparse_categorical_accuracy: 0.7615\n",
            "Epoch 36/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.6333 - sparse_categorical_accuracy: 0.7136 - val_loss: 0.5995 - val_sparse_categorical_accuracy: 0.7523\n",
            "Epoch 37/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.6301 - sparse_categorical_accuracy: 0.7146 - val_loss: 0.5930 - val_sparse_categorical_accuracy: 0.7706\n",
            "Epoch 38/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.6274 - sparse_categorical_accuracy: 0.7238 - val_loss: 0.5904 - val_sparse_categorical_accuracy: 0.7706\n",
            "Epoch 39/100\n",
            "981/981 [==============================] - 0s 155us/sample - loss: 0.6238 - sparse_categorical_accuracy: 0.7217 - val_loss: 0.5881 - val_sparse_categorical_accuracy: 0.7706\n",
            "Epoch 40/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.6206 - sparse_categorical_accuracy: 0.7258 - val_loss: 0.5856 - val_sparse_categorical_accuracy: 0.7798\n",
            "Epoch 41/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.6171 - sparse_categorical_accuracy: 0.7319 - val_loss: 0.5857 - val_sparse_categorical_accuracy: 0.7706\n",
            "Epoch 42/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.6147 - sparse_categorical_accuracy: 0.7268 - val_loss: 0.5820 - val_sparse_categorical_accuracy: 0.7798\n",
            "Epoch 43/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.6116 - sparse_categorical_accuracy: 0.7309 - val_loss: 0.5785 - val_sparse_categorical_accuracy: 0.7890\n",
            "Epoch 44/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.6095 - sparse_categorical_accuracy: 0.7329 - val_loss: 0.5771 - val_sparse_categorical_accuracy: 0.7890\n",
            "Epoch 45/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.6067 - sparse_categorical_accuracy: 0.7350 - val_loss: 0.5754 - val_sparse_categorical_accuracy: 0.7890\n",
            "Epoch 46/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.6040 - sparse_categorical_accuracy: 0.7370 - val_loss: 0.5749 - val_sparse_categorical_accuracy: 0.7798\n",
            "Epoch 47/100\n",
            "981/981 [==============================] - 0s 144us/sample - loss: 0.6017 - sparse_categorical_accuracy: 0.7421 - val_loss: 0.5733 - val_sparse_categorical_accuracy: 0.7798\n",
            "Epoch 48/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.5996 - sparse_categorical_accuracy: 0.7319 - val_loss: 0.5704 - val_sparse_categorical_accuracy: 0.7798\n",
            "Epoch 49/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.5970 - sparse_categorical_accuracy: 0.7360 - val_loss: 0.5697 - val_sparse_categorical_accuracy: 0.7706\n",
            "Epoch 50/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.5947 - sparse_categorical_accuracy: 0.7411 - val_loss: 0.5688 - val_sparse_categorical_accuracy: 0.7706\n",
            "Epoch 51/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.5931 - sparse_categorical_accuracy: 0.7370 - val_loss: 0.5678 - val_sparse_categorical_accuracy: 0.7706\n",
            "Epoch 52/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5906 - sparse_categorical_accuracy: 0.7350 - val_loss: 0.5646 - val_sparse_categorical_accuracy: 0.7798\n",
            "Epoch 53/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.5887 - sparse_categorical_accuracy: 0.7390 - val_loss: 0.5635 - val_sparse_categorical_accuracy: 0.7798\n",
            "Epoch 54/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.5867 - sparse_categorical_accuracy: 0.7339 - val_loss: 0.5620 - val_sparse_categorical_accuracy: 0.7890\n",
            "Epoch 55/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.5848 - sparse_categorical_accuracy: 0.7380 - val_loss: 0.5617 - val_sparse_categorical_accuracy: 0.7706\n",
            "Epoch 56/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.5835 - sparse_categorical_accuracy: 0.7401 - val_loss: 0.5602 - val_sparse_categorical_accuracy: 0.7706\n",
            "Epoch 57/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.5819 - sparse_categorical_accuracy: 0.7329 - val_loss: 0.5587 - val_sparse_categorical_accuracy: 0.7706\n",
            "Epoch 58/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.5799 - sparse_categorical_accuracy: 0.7401 - val_loss: 0.5583 - val_sparse_categorical_accuracy: 0.7706\n",
            "Epoch 59/100\n",
            "981/981 [==============================] - 0s 113us/sample - loss: 0.5784 - sparse_categorical_accuracy: 0.7421 - val_loss: 0.5578 - val_sparse_categorical_accuracy: 0.7706\n",
            "Epoch 60/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.5768 - sparse_categorical_accuracy: 0.7390 - val_loss: 0.5561 - val_sparse_categorical_accuracy: 0.7615\n",
            "Epoch 61/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.5753 - sparse_categorical_accuracy: 0.7441 - val_loss: 0.5547 - val_sparse_categorical_accuracy: 0.7615\n",
            "Epoch 62/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5736 - sparse_categorical_accuracy: 0.7452 - val_loss: 0.5536 - val_sparse_categorical_accuracy: 0.7615\n",
            "Epoch 63/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.5721 - sparse_categorical_accuracy: 0.7492 - val_loss: 0.5526 - val_sparse_categorical_accuracy: 0.7615\n",
            "Epoch 64/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.5706 - sparse_categorical_accuracy: 0.7482 - val_loss: 0.5520 - val_sparse_categorical_accuracy: 0.7615\n",
            "Epoch 65/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.5692 - sparse_categorical_accuracy: 0.7462 - val_loss: 0.5542 - val_sparse_categorical_accuracy: 0.7523\n",
            "Epoch 66/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.5681 - sparse_categorical_accuracy: 0.7431 - val_loss: 0.5512 - val_sparse_categorical_accuracy: 0.7615\n",
            "Epoch 67/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5666 - sparse_categorical_accuracy: 0.7503 - val_loss: 0.5495 - val_sparse_categorical_accuracy: 0.7615\n",
            "Epoch 68/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.5654 - sparse_categorical_accuracy: 0.7462 - val_loss: 0.5481 - val_sparse_categorical_accuracy: 0.7706\n",
            "Epoch 69/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.5637 - sparse_categorical_accuracy: 0.7513 - val_loss: 0.5496 - val_sparse_categorical_accuracy: 0.7615\n",
            "Epoch 70/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5626 - sparse_categorical_accuracy: 0.7543 - val_loss: 0.5465 - val_sparse_categorical_accuracy: 0.7615\n",
            "Epoch 71/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5614 - sparse_categorical_accuracy: 0.7554 - val_loss: 0.5448 - val_sparse_categorical_accuracy: 0.7798\n",
            "Epoch 72/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.5603 - sparse_categorical_accuracy: 0.7554 - val_loss: 0.5461 - val_sparse_categorical_accuracy: 0.7615\n",
            "Epoch 73/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.5589 - sparse_categorical_accuracy: 0.7615 - val_loss: 0.5463 - val_sparse_categorical_accuracy: 0.7615\n",
            "Epoch 74/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5583 - sparse_categorical_accuracy: 0.7492 - val_loss: 0.5439 - val_sparse_categorical_accuracy: 0.7615\n",
            "Epoch 75/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.5569 - sparse_categorical_accuracy: 0.7533 - val_loss: 0.5430 - val_sparse_categorical_accuracy: 0.7706\n",
            "Epoch 76/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.5557 - sparse_categorical_accuracy: 0.7584 - val_loss: 0.5431 - val_sparse_categorical_accuracy: 0.7615\n",
            "Epoch 77/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.5549 - sparse_categorical_accuracy: 0.7574 - val_loss: 0.5416 - val_sparse_categorical_accuracy: 0.7615\n",
            "Epoch 78/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5539 - sparse_categorical_accuracy: 0.7554 - val_loss: 0.5412 - val_sparse_categorical_accuracy: 0.7615\n",
            "Epoch 79/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.5532 - sparse_categorical_accuracy: 0.7543 - val_loss: 0.5415 - val_sparse_categorical_accuracy: 0.7615\n",
            "Epoch 80/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.5522 - sparse_categorical_accuracy: 0.7543 - val_loss: 0.5403 - val_sparse_categorical_accuracy: 0.7615\n",
            "Epoch 81/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.5508 - sparse_categorical_accuracy: 0.7615 - val_loss: 0.5411 - val_sparse_categorical_accuracy: 0.7615\n",
            "Epoch 82/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.5506 - sparse_categorical_accuracy: 0.7594 - val_loss: 0.5399 - val_sparse_categorical_accuracy: 0.7615\n",
            "Epoch 83/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.5491 - sparse_categorical_accuracy: 0.7554 - val_loss: 0.5392 - val_sparse_categorical_accuracy: 0.7523\n",
            "Epoch 84/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5482 - sparse_categorical_accuracy: 0.7574 - val_loss: 0.5392 - val_sparse_categorical_accuracy: 0.7615\n",
            "Epoch 85/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.5472 - sparse_categorical_accuracy: 0.7584 - val_loss: 0.5372 - val_sparse_categorical_accuracy: 0.7615\n",
            "Epoch 86/100\n",
            "981/981 [==============================] - 0s 113us/sample - loss: 0.5467 - sparse_categorical_accuracy: 0.7594 - val_loss: 0.5387 - val_sparse_categorical_accuracy: 0.7523\n",
            "Epoch 87/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.5456 - sparse_categorical_accuracy: 0.7615 - val_loss: 0.5364 - val_sparse_categorical_accuracy: 0.7615\n",
            "Epoch 88/100\n",
            "981/981 [==============================] - 0s 113us/sample - loss: 0.5449 - sparse_categorical_accuracy: 0.7594 - val_loss: 0.5373 - val_sparse_categorical_accuracy: 0.7523\n",
            "Epoch 89/100\n",
            "981/981 [==============================] - 0s 143us/sample - loss: 0.5443 - sparse_categorical_accuracy: 0.7594 - val_loss: 0.5357 - val_sparse_categorical_accuracy: 0.7615\n",
            "Epoch 90/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.5435 - sparse_categorical_accuracy: 0.7594 - val_loss: 0.5360 - val_sparse_categorical_accuracy: 0.7523\n",
            "Epoch 91/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.5425 - sparse_categorical_accuracy: 0.7584 - val_loss: 0.5351 - val_sparse_categorical_accuracy: 0.7523\n",
            "Epoch 92/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.5421 - sparse_categorical_accuracy: 0.7584 - val_loss: 0.5343 - val_sparse_categorical_accuracy: 0.7706\n",
            "Epoch 93/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.5412 - sparse_categorical_accuracy: 0.7543 - val_loss: 0.5342 - val_sparse_categorical_accuracy: 0.7706\n",
            "Epoch 94/100\n",
            "981/981 [==============================] - 0s 113us/sample - loss: 0.5404 - sparse_categorical_accuracy: 0.7645 - val_loss: 0.5348 - val_sparse_categorical_accuracy: 0.7523\n",
            "Epoch 95/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5400 - sparse_categorical_accuracy: 0.7574 - val_loss: 0.5340 - val_sparse_categorical_accuracy: 0.7523\n",
            "Epoch 96/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.5389 - sparse_categorical_accuracy: 0.7584 - val_loss: 0.5333 - val_sparse_categorical_accuracy: 0.7706\n",
            "Epoch 97/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.5382 - sparse_categorical_accuracy: 0.7645 - val_loss: 0.5341 - val_sparse_categorical_accuracy: 0.7523\n",
            "Epoch 98/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.5376 - sparse_categorical_accuracy: 0.7594 - val_loss: 0.5335 - val_sparse_categorical_accuracy: 0.7523\n",
            "Epoch 99/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5371 - sparse_categorical_accuracy: 0.7635 - val_loss: 0.5323 - val_sparse_categorical_accuracy: 0.7523\n",
            "Epoch 100/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5362 - sparse_categorical_accuracy: 0.7615 - val_loss: 0.5322 - val_sparse_categorical_accuracy: 0.7523\n",
            "[CV] ......................... n_neurons=26, n_hidden=0, total=  12.7s\n",
            "[CV] n_neurons=26, n_hidden=0 ........................................\n",
            "Train on 981 samples, validate on 110 samples\n",
            "Epoch 1/100\n",
            "981/981 [==============================] - 0s 452us/sample - loss: 1.3680 - sparse_categorical_accuracy: 0.3231 - val_loss: 1.2924 - val_sparse_categorical_accuracy: 0.3273\n",
            "Epoch 2/100\n",
            "981/981 [==============================] - 0s 138us/sample - loss: 1.1930 - sparse_categorical_accuracy: 0.3935 - val_loss: 1.2026 - val_sparse_categorical_accuracy: 0.4000\n",
            "Epoch 3/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 1.1142 - sparse_categorical_accuracy: 0.4230 - val_loss: 1.1231 - val_sparse_categorical_accuracy: 0.4182\n",
            "Epoch 4/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 1.0542 - sparse_categorical_accuracy: 0.4546 - val_loss: 1.0619 - val_sparse_categorical_accuracy: 0.4818\n",
            "Epoch 5/100\n",
            "981/981 [==============================] - 0s 139us/sample - loss: 1.0039 - sparse_categorical_accuracy: 0.4852 - val_loss: 1.0086 - val_sparse_categorical_accuracy: 0.4909\n",
            "Epoch 6/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.9618 - sparse_categorical_accuracy: 0.5076 - val_loss: 0.9613 - val_sparse_categorical_accuracy: 0.5000\n",
            "Epoch 7/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.9266 - sparse_categorical_accuracy: 0.5219 - val_loss: 0.9283 - val_sparse_categorical_accuracy: 0.5455\n",
            "Epoch 8/100\n",
            "981/981 [==============================] - 0s 134us/sample - loss: 0.8972 - sparse_categorical_accuracy: 0.5372 - val_loss: 0.8999 - val_sparse_categorical_accuracy: 0.5455\n",
            "Epoch 9/100\n",
            "981/981 [==============================] - 0s 139us/sample - loss: 0.8709 - sparse_categorical_accuracy: 0.5657 - val_loss: 0.8677 - val_sparse_categorical_accuracy: 0.5636\n",
            "Epoch 10/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.8479 - sparse_categorical_accuracy: 0.5841 - val_loss: 0.8431 - val_sparse_categorical_accuracy: 0.5545\n",
            "Epoch 11/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.8288 - sparse_categorical_accuracy: 0.5973 - val_loss: 0.8257 - val_sparse_categorical_accuracy: 0.6091\n",
            "Epoch 12/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.8093 - sparse_categorical_accuracy: 0.6106 - val_loss: 0.8113 - val_sparse_categorical_accuracy: 0.6182\n",
            "Epoch 13/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.7937 - sparse_categorical_accuracy: 0.6330 - val_loss: 0.7932 - val_sparse_categorical_accuracy: 0.6273\n",
            "Epoch 14/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.7795 - sparse_categorical_accuracy: 0.6310 - val_loss: 0.7781 - val_sparse_categorical_accuracy: 0.6364\n",
            "Epoch 15/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.7653 - sparse_categorical_accuracy: 0.6442 - val_loss: 0.7649 - val_sparse_categorical_accuracy: 0.6091\n",
            "Epoch 16/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.7532 - sparse_categorical_accuracy: 0.6606 - val_loss: 0.7523 - val_sparse_categorical_accuracy: 0.6455\n",
            "Epoch 17/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.7421 - sparse_categorical_accuracy: 0.6606 - val_loss: 0.7441 - val_sparse_categorical_accuracy: 0.6455\n",
            "Epoch 18/100\n",
            "981/981 [==============================] - 0s 135us/sample - loss: 0.7320 - sparse_categorical_accuracy: 0.6667 - val_loss: 0.7360 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 19/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.7223 - sparse_categorical_accuracy: 0.6779 - val_loss: 0.7243 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 20/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.7130 - sparse_categorical_accuracy: 0.6738 - val_loss: 0.7150 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 21/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.7052 - sparse_categorical_accuracy: 0.6799 - val_loss: 0.7111 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 22/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.6972 - sparse_categorical_accuracy: 0.6840 - val_loss: 0.7043 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 23/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.6892 - sparse_categorical_accuracy: 0.6952 - val_loss: 0.6995 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 24/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.6828 - sparse_categorical_accuracy: 0.6962 - val_loss: 0.6914 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 25/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.6758 - sparse_categorical_accuracy: 0.7034 - val_loss: 0.6810 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 26/100\n",
            "981/981 [==============================] - 0s 148us/sample - loss: 0.6695 - sparse_categorical_accuracy: 0.6952 - val_loss: 0.6762 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 27/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.6639 - sparse_categorical_accuracy: 0.7044 - val_loss: 0.6707 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 28/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.6577 - sparse_categorical_accuracy: 0.7003 - val_loss: 0.6704 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 29/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.6530 - sparse_categorical_accuracy: 0.7105 - val_loss: 0.6662 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 30/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.6480 - sparse_categorical_accuracy: 0.7146 - val_loss: 0.6581 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 31/100\n",
            "981/981 [==============================] - 0s 135us/sample - loss: 0.6431 - sparse_categorical_accuracy: 0.7156 - val_loss: 0.6545 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 32/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.6386 - sparse_categorical_accuracy: 0.7217 - val_loss: 0.6513 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 33/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.6342 - sparse_categorical_accuracy: 0.7248 - val_loss: 0.6452 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 34/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.6301 - sparse_categorical_accuracy: 0.7217 - val_loss: 0.6407 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 35/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.6258 - sparse_categorical_accuracy: 0.7258 - val_loss: 0.6390 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 36/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.6221 - sparse_categorical_accuracy: 0.7227 - val_loss: 0.6382 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 37/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.6184 - sparse_categorical_accuracy: 0.7329 - val_loss: 0.6318 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 38/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.6144 - sparse_categorical_accuracy: 0.7258 - val_loss: 0.6311 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 39/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.6113 - sparse_categorical_accuracy: 0.7309 - val_loss: 0.6258 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 40/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.6078 - sparse_categorical_accuracy: 0.7309 - val_loss: 0.6238 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 41/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.6047 - sparse_categorical_accuracy: 0.7288 - val_loss: 0.6219 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 42/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.6018 - sparse_categorical_accuracy: 0.7309 - val_loss: 0.6192 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 43/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.5989 - sparse_categorical_accuracy: 0.7329 - val_loss: 0.6148 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 44/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.5955 - sparse_categorical_accuracy: 0.7380 - val_loss: 0.6117 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 45/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5929 - sparse_categorical_accuracy: 0.7309 - val_loss: 0.6113 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 46/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5905 - sparse_categorical_accuracy: 0.7329 - val_loss: 0.6075 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 47/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5877 - sparse_categorical_accuracy: 0.7390 - val_loss: 0.6059 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 48/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.5853 - sparse_categorical_accuracy: 0.7350 - val_loss: 0.6060 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 49/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5826 - sparse_categorical_accuracy: 0.7401 - val_loss: 0.6017 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 50/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.5807 - sparse_categorical_accuracy: 0.7390 - val_loss: 0.5994 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 51/100\n",
            "981/981 [==============================] - 0s 137us/sample - loss: 0.5781 - sparse_categorical_accuracy: 0.7401 - val_loss: 0.5987 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 52/100\n",
            "981/981 [==============================] - 0s 136us/sample - loss: 0.5755 - sparse_categorical_accuracy: 0.7441 - val_loss: 0.5954 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 53/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.5738 - sparse_categorical_accuracy: 0.7441 - val_loss: 0.5951 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 54/100\n",
            "981/981 [==============================] - 0s 112us/sample - loss: 0.5716 - sparse_categorical_accuracy: 0.7411 - val_loss: 0.5930 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 55/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.5699 - sparse_categorical_accuracy: 0.7462 - val_loss: 0.5921 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 56/100\n",
            "981/981 [==============================] - 0s 113us/sample - loss: 0.5676 - sparse_categorical_accuracy: 0.7421 - val_loss: 0.5889 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 57/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.5657 - sparse_categorical_accuracy: 0.7462 - val_loss: 0.5886 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 58/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5640 - sparse_categorical_accuracy: 0.7472 - val_loss: 0.5873 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 59/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.5619 - sparse_categorical_accuracy: 0.7503 - val_loss: 0.5848 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 60/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.5600 - sparse_categorical_accuracy: 0.7503 - val_loss: 0.5847 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 61/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.5586 - sparse_categorical_accuracy: 0.7554 - val_loss: 0.5829 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 62/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.5570 - sparse_categorical_accuracy: 0.7492 - val_loss: 0.5825 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 63/100\n",
            "981/981 [==============================] - 0s 110us/sample - loss: 0.5541 - sparse_categorical_accuracy: 0.7615 - val_loss: 0.5784 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 64/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.5536 - sparse_categorical_accuracy: 0.7533 - val_loss: 0.5793 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 65/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.5522 - sparse_categorical_accuracy: 0.7584 - val_loss: 0.5780 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 66/100\n",
            "981/981 [==============================] - 0s 113us/sample - loss: 0.5505 - sparse_categorical_accuracy: 0.7584 - val_loss: 0.5787 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 67/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.5489 - sparse_categorical_accuracy: 0.7523 - val_loss: 0.5750 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 68/100\n",
            "981/981 [==============================] - 0s 147us/sample - loss: 0.5476 - sparse_categorical_accuracy: 0.7554 - val_loss: 0.5756 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 69/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.5465 - sparse_categorical_accuracy: 0.7533 - val_loss: 0.5738 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 70/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.5448 - sparse_categorical_accuracy: 0.7554 - val_loss: 0.5729 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 71/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.5434 - sparse_categorical_accuracy: 0.7604 - val_loss: 0.5721 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 72/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.5421 - sparse_categorical_accuracy: 0.7604 - val_loss: 0.5715 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 73/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.5406 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.5704 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 74/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5394 - sparse_categorical_accuracy: 0.7574 - val_loss: 0.5678 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 75/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.5380 - sparse_categorical_accuracy: 0.7574 - val_loss: 0.5689 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 76/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.5370 - sparse_categorical_accuracy: 0.7584 - val_loss: 0.5653 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 77/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.5356 - sparse_categorical_accuracy: 0.7584 - val_loss: 0.5658 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 78/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.5347 - sparse_categorical_accuracy: 0.7594 - val_loss: 0.5641 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 79/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5332 - sparse_categorical_accuracy: 0.7584 - val_loss: 0.5624 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 80/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.5322 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.5627 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 81/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.5310 - sparse_categorical_accuracy: 0.7635 - val_loss: 0.5624 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 82/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.5303 - sparse_categorical_accuracy: 0.7696 - val_loss: 0.5611 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 83/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.5292 - sparse_categorical_accuracy: 0.7655 - val_loss: 0.5598 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 84/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.5280 - sparse_categorical_accuracy: 0.7676 - val_loss: 0.5605 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 85/100\n",
            "981/981 [==============================] - 0s 144us/sample - loss: 0.5270 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.5587 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 86/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.5262 - sparse_categorical_accuracy: 0.7686 - val_loss: 0.5579 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 87/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.5250 - sparse_categorical_accuracy: 0.7676 - val_loss: 0.5577 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 88/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.5240 - sparse_categorical_accuracy: 0.7615 - val_loss: 0.5553 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 89/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5233 - sparse_categorical_accuracy: 0.7655 - val_loss: 0.5555 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 90/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5224 - sparse_categorical_accuracy: 0.7666 - val_loss: 0.5562 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 91/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.5213 - sparse_categorical_accuracy: 0.7696 - val_loss: 0.5553 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 92/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5205 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.5543 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 93/100\n",
            "981/981 [==============================] - 0s 141us/sample - loss: 0.5195 - sparse_categorical_accuracy: 0.7635 - val_loss: 0.5526 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 94/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.5185 - sparse_categorical_accuracy: 0.7686 - val_loss: 0.5540 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 95/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.5181 - sparse_categorical_accuracy: 0.7676 - val_loss: 0.5528 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 96/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.5172 - sparse_categorical_accuracy: 0.7686 - val_loss: 0.5530 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 97/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5165 - sparse_categorical_accuracy: 0.7686 - val_loss: 0.5525 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 98/100\n",
            "981/981 [==============================] - 0s 112us/sample - loss: 0.5157 - sparse_categorical_accuracy: 0.7686 - val_loss: 0.5505 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 99/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.5144 - sparse_categorical_accuracy: 0.7676 - val_loss: 0.5496 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 100/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.5138 - sparse_categorical_accuracy: 0.7686 - val_loss: 0.5501 - val_sparse_categorical_accuracy: 0.7273\n",
            "[CV] ......................... n_neurons=26, n_hidden=0, total=  12.8s\n",
            "[CV] n_neurons=26, n_hidden=0 ........................................\n",
            "Train on 981 samples, validate on 110 samples\n",
            "Epoch 1/100\n",
            "981/981 [==============================] - 2s 2ms/sample - loss: 1.2623 - sparse_categorical_accuracy: 0.3558 - val_loss: 1.1629 - val_sparse_categorical_accuracy: 0.4455\n",
            "Epoch 2/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 1.1560 - sparse_categorical_accuracy: 0.3751 - val_loss: 1.0990 - val_sparse_categorical_accuracy: 0.4727\n",
            "Epoch 3/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 1.0859 - sparse_categorical_accuracy: 0.4027 - val_loss: 1.0454 - val_sparse_categorical_accuracy: 0.5000\n",
            "Epoch 4/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 1.0321 - sparse_categorical_accuracy: 0.4332 - val_loss: 1.0029 - val_sparse_categorical_accuracy: 0.5182\n",
            "Epoch 5/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.9891 - sparse_categorical_accuracy: 0.4546 - val_loss: 0.9668 - val_sparse_categorical_accuracy: 0.5727\n",
            "Epoch 6/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.9526 - sparse_categorical_accuracy: 0.4750 - val_loss: 0.9364 - val_sparse_categorical_accuracy: 0.6000\n",
            "Epoch 7/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.9220 - sparse_categorical_accuracy: 0.5066 - val_loss: 0.9099 - val_sparse_categorical_accuracy: 0.6091\n",
            "Epoch 8/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.8953 - sparse_categorical_accuracy: 0.5291 - val_loss: 0.8888 - val_sparse_categorical_accuracy: 0.6182\n",
            "Epoch 9/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.8715 - sparse_categorical_accuracy: 0.5423 - val_loss: 0.8695 - val_sparse_categorical_accuracy: 0.6000\n",
            "Epoch 10/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.8505 - sparse_categorical_accuracy: 0.5688 - val_loss: 0.8501 - val_sparse_categorical_accuracy: 0.6091\n",
            "Epoch 11/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.8314 - sparse_categorical_accuracy: 0.5872 - val_loss: 0.8338 - val_sparse_categorical_accuracy: 0.6091\n",
            "Epoch 12/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.8146 - sparse_categorical_accuracy: 0.6035 - val_loss: 0.8197 - val_sparse_categorical_accuracy: 0.6182\n",
            "Epoch 13/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.7987 - sparse_categorical_accuracy: 0.6096 - val_loss: 0.8083 - val_sparse_categorical_accuracy: 0.6182\n",
            "Epoch 14/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.7851 - sparse_categorical_accuracy: 0.6290 - val_loss: 0.7946 - val_sparse_categorical_accuracy: 0.6273\n",
            "Epoch 15/100\n",
            "981/981 [==============================] - 0s 150us/sample - loss: 0.7720 - sparse_categorical_accuracy: 0.6371 - val_loss: 0.7838 - val_sparse_categorical_accuracy: 0.6273\n",
            "Epoch 16/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.7598 - sparse_categorical_accuracy: 0.6381 - val_loss: 0.7731 - val_sparse_categorical_accuracy: 0.6273\n",
            "Epoch 17/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.7490 - sparse_categorical_accuracy: 0.6493 - val_loss: 0.7649 - val_sparse_categorical_accuracy: 0.6273\n",
            "Epoch 18/100\n",
            "981/981 [==============================] - 0s 134us/sample - loss: 0.7389 - sparse_categorical_accuracy: 0.6575 - val_loss: 0.7554 - val_sparse_categorical_accuracy: 0.6273\n",
            "Epoch 19/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.7286 - sparse_categorical_accuracy: 0.6606 - val_loss: 0.7470 - val_sparse_categorical_accuracy: 0.6273\n",
            "Epoch 20/100\n",
            "981/981 [==============================] - 0s 141us/sample - loss: 0.7205 - sparse_categorical_accuracy: 0.6677 - val_loss: 0.7387 - val_sparse_categorical_accuracy: 0.6273\n",
            "Epoch 21/100\n",
            "981/981 [==============================] - 0s 134us/sample - loss: 0.7116 - sparse_categorical_accuracy: 0.6687 - val_loss: 0.7322 - val_sparse_categorical_accuracy: 0.6455\n",
            "Epoch 22/100\n",
            "981/981 [==============================] - 0s 162us/sample - loss: 0.7036 - sparse_categorical_accuracy: 0.6738 - val_loss: 0.7267 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 23/100\n",
            "981/981 [==============================] - 0s 141us/sample - loss: 0.6965 - sparse_categorical_accuracy: 0.6758 - val_loss: 0.7192 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 24/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.6895 - sparse_categorical_accuracy: 0.6779 - val_loss: 0.7119 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 25/100\n",
            "981/981 [==============================] - 0s 146us/sample - loss: 0.6827 - sparse_categorical_accuracy: 0.6799 - val_loss: 0.7068 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 26/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.6760 - sparse_categorical_accuracy: 0.6830 - val_loss: 0.6983 - val_sparse_categorical_accuracy: 0.6455\n",
            "Epoch 27/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.6707 - sparse_categorical_accuracy: 0.6901 - val_loss: 0.6951 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 28/100\n",
            "981/981 [==============================] - 0s 142us/sample - loss: 0.6645 - sparse_categorical_accuracy: 0.6952 - val_loss: 0.6931 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 29/100\n",
            "981/981 [==============================] - 0s 153us/sample - loss: 0.6592 - sparse_categorical_accuracy: 0.6881 - val_loss: 0.6852 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 30/100\n",
            "981/981 [==============================] - 0s 146us/sample - loss: 0.6538 - sparse_categorical_accuracy: 0.6983 - val_loss: 0.6803 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 31/100\n",
            "981/981 [==============================] - 0s 147us/sample - loss: 0.6491 - sparse_categorical_accuracy: 0.7034 - val_loss: 0.6759 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 32/100\n",
            "981/981 [==============================] - 0s 136us/sample - loss: 0.6444 - sparse_categorical_accuracy: 0.7044 - val_loss: 0.6723 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 33/100\n",
            "981/981 [==============================] - 0s 135us/sample - loss: 0.6401 - sparse_categorical_accuracy: 0.7125 - val_loss: 0.6700 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 34/100\n",
            "981/981 [==============================] - 0s 135us/sample - loss: 0.6361 - sparse_categorical_accuracy: 0.7125 - val_loss: 0.6671 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 35/100\n",
            "981/981 [==============================] - 0s 143us/sample - loss: 0.6311 - sparse_categorical_accuracy: 0.7166 - val_loss: 0.6600 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 36/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.6278 - sparse_categorical_accuracy: 0.7146 - val_loss: 0.6567 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 37/100\n",
            "981/981 [==============================] - 0s 148us/sample - loss: 0.6241 - sparse_categorical_accuracy: 0.7166 - val_loss: 0.6543 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 38/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.6205 - sparse_categorical_accuracy: 0.7278 - val_loss: 0.6519 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 39/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.6165 - sparse_categorical_accuracy: 0.7238 - val_loss: 0.6505 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 40/100\n",
            "981/981 [==============================] - 0s 134us/sample - loss: 0.6136 - sparse_categorical_accuracy: 0.7299 - val_loss: 0.6478 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 41/100\n",
            "981/981 [==============================] - 0s 148us/sample - loss: 0.6108 - sparse_categorical_accuracy: 0.7299 - val_loss: 0.6448 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 42/100\n",
            "981/981 [==============================] - 0s 135us/sample - loss: 0.6071 - sparse_categorical_accuracy: 0.7319 - val_loss: 0.6404 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 43/100\n",
            "981/981 [==============================] - 0s 147us/sample - loss: 0.6043 - sparse_categorical_accuracy: 0.7258 - val_loss: 0.6378 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 44/100\n",
            "981/981 [==============================] - 0s 149us/sample - loss: 0.6014 - sparse_categorical_accuracy: 0.7421 - val_loss: 0.6365 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 45/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.5985 - sparse_categorical_accuracy: 0.7339 - val_loss: 0.6332 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 46/100\n",
            "981/981 [==============================] - 0s 135us/sample - loss: 0.5958 - sparse_categorical_accuracy: 0.7401 - val_loss: 0.6296 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 47/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.5931 - sparse_categorical_accuracy: 0.7401 - val_loss: 0.6282 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 48/100\n",
            "981/981 [==============================] - 0s 154us/sample - loss: 0.5907 - sparse_categorical_accuracy: 0.7360 - val_loss: 0.6266 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 49/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.5883 - sparse_categorical_accuracy: 0.7360 - val_loss: 0.6240 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 50/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.5861 - sparse_categorical_accuracy: 0.7360 - val_loss: 0.6221 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 51/100\n",
            "981/981 [==============================] - 0s 113us/sample - loss: 0.5837 - sparse_categorical_accuracy: 0.7380 - val_loss: 0.6199 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 52/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.5815 - sparse_categorical_accuracy: 0.7380 - val_loss: 0.6165 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 53/100\n",
            "981/981 [==============================] - 0s 113us/sample - loss: 0.5790 - sparse_categorical_accuracy: 0.7390 - val_loss: 0.6184 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 54/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.5776 - sparse_categorical_accuracy: 0.7401 - val_loss: 0.6153 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 55/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5750 - sparse_categorical_accuracy: 0.7431 - val_loss: 0.6129 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 56/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.5731 - sparse_categorical_accuracy: 0.7421 - val_loss: 0.6112 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 57/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.5714 - sparse_categorical_accuracy: 0.7452 - val_loss: 0.6100 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 58/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5693 - sparse_categorical_accuracy: 0.7482 - val_loss: 0.6096 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 59/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.5677 - sparse_categorical_accuracy: 0.7452 - val_loss: 0.6066 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 60/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.5655 - sparse_categorical_accuracy: 0.7503 - val_loss: 0.6075 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 61/100\n",
            "981/981 [==============================] - 0s 141us/sample - loss: 0.5639 - sparse_categorical_accuracy: 0.7452 - val_loss: 0.6029 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 62/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.5625 - sparse_categorical_accuracy: 0.7492 - val_loss: 0.6017 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 63/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.5609 - sparse_categorical_accuracy: 0.7492 - val_loss: 0.6012 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 64/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.5590 - sparse_categorical_accuracy: 0.7523 - val_loss: 0.6004 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 65/100\n",
            "981/981 [==============================] - 0s 146us/sample - loss: 0.5575 - sparse_categorical_accuracy: 0.7513 - val_loss: 0.6009 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 66/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.5563 - sparse_categorical_accuracy: 0.7533 - val_loss: 0.6003 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 67/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5549 - sparse_categorical_accuracy: 0.7523 - val_loss: 0.5997 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 68/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5531 - sparse_categorical_accuracy: 0.7513 - val_loss: 0.5985 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 69/100\n",
            "981/981 [==============================] - 0s 136us/sample - loss: 0.5518 - sparse_categorical_accuracy: 0.7523 - val_loss: 0.5951 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 70/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.5506 - sparse_categorical_accuracy: 0.7503 - val_loss: 0.5949 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 71/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.5491 - sparse_categorical_accuracy: 0.7503 - val_loss: 0.5934 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 72/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.5476 - sparse_categorical_accuracy: 0.7543 - val_loss: 0.5925 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 73/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5463 - sparse_categorical_accuracy: 0.7554 - val_loss: 0.5907 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 74/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.5454 - sparse_categorical_accuracy: 0.7523 - val_loss: 0.5896 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 75/100\n",
            "981/981 [==============================] - 0s 135us/sample - loss: 0.5441 - sparse_categorical_accuracy: 0.7543 - val_loss: 0.5892 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 76/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5427 - sparse_categorical_accuracy: 0.7513 - val_loss: 0.5870 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 77/100\n",
            "981/981 [==============================] - 0s 146us/sample - loss: 0.5414 - sparse_categorical_accuracy: 0.7523 - val_loss: 0.5881 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 78/100\n",
            "981/981 [==============================] - 0s 141us/sample - loss: 0.5402 - sparse_categorical_accuracy: 0.7533 - val_loss: 0.5874 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 79/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.5396 - sparse_categorical_accuracy: 0.7543 - val_loss: 0.5872 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 80/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.5380 - sparse_categorical_accuracy: 0.7574 - val_loss: 0.5847 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 81/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5370 - sparse_categorical_accuracy: 0.7533 - val_loss: 0.5842 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 82/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5362 - sparse_categorical_accuracy: 0.7543 - val_loss: 0.5833 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 83/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5351 - sparse_categorical_accuracy: 0.7564 - val_loss: 0.5826 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 84/100\n",
            "981/981 [==============================] - 0s 112us/sample - loss: 0.5341 - sparse_categorical_accuracy: 0.7554 - val_loss: 0.5847 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 85/100\n",
            "981/981 [==============================] - 0s 143us/sample - loss: 0.5333 - sparse_categorical_accuracy: 0.7594 - val_loss: 0.5835 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 86/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5320 - sparse_categorical_accuracy: 0.7594 - val_loss: 0.5817 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 87/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.5310 - sparse_categorical_accuracy: 0.7523 - val_loss: 0.5804 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 88/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.5299 - sparse_categorical_accuracy: 0.7533 - val_loss: 0.5793 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 89/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.5296 - sparse_categorical_accuracy: 0.7574 - val_loss: 0.5803 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 90/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.5285 - sparse_categorical_accuracy: 0.7554 - val_loss: 0.5814 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 91/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.5274 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.5792 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 92/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.5267 - sparse_categorical_accuracy: 0.7564 - val_loss: 0.5799 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 93/100\n",
            "981/981 [==============================] - 0s 139us/sample - loss: 0.5258 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.5789 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 94/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5248 - sparse_categorical_accuracy: 0.7686 - val_loss: 0.5799 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 95/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.5241 - sparse_categorical_accuracy: 0.7655 - val_loss: 0.5770 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 96/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5232 - sparse_categorical_accuracy: 0.7655 - val_loss: 0.5757 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 97/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.5224 - sparse_categorical_accuracy: 0.7635 - val_loss: 0.5767 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 98/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5216 - sparse_categorical_accuracy: 0.7645 - val_loss: 0.5770 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 99/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.5210 - sparse_categorical_accuracy: 0.7676 - val_loss: 0.5766 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 100/100\n",
            "981/981 [==============================] - 0s 137us/sample - loss: 0.5201 - sparse_categorical_accuracy: 0.7717 - val_loss: 0.5746 - val_sparse_categorical_accuracy: 0.7455\n",
            "[CV] ......................... n_neurons=26, n_hidden=0, total=  15.4s\n",
            "[CV] n_neurons=14, n_hidden=5 ........................................\n",
            "Train on 981 samples, validate on 109 samples\n",
            "Epoch 1/100\n",
            "981/981 [==============================] - 1s 948us/sample - loss: 1.0682 - sparse_categorical_accuracy: 0.4169 - val_loss: 0.9071 - val_sparse_categorical_accuracy: 0.5321\n",
            "Epoch 2/100\n",
            "981/981 [==============================] - 0s 158us/sample - loss: 0.9399 - sparse_categorical_accuracy: 0.4852 - val_loss: 0.8444 - val_sparse_categorical_accuracy: 0.5963\n",
            "Epoch 3/100\n",
            "981/981 [==============================] - 0s 158us/sample - loss: 0.8872 - sparse_categorical_accuracy: 0.5270 - val_loss: 0.8110 - val_sparse_categorical_accuracy: 0.5963\n",
            "Epoch 4/100\n",
            "981/981 [==============================] - 0s 165us/sample - loss: 0.8405 - sparse_categorical_accuracy: 0.5617 - val_loss: 0.7805 - val_sparse_categorical_accuracy: 0.6330\n",
            "Epoch 5/100\n",
            "981/981 [==============================] - 0s 184us/sample - loss: 0.8034 - sparse_categorical_accuracy: 0.5851 - val_loss: 0.7541 - val_sparse_categorical_accuracy: 0.6514\n",
            "Epoch 6/100\n",
            "981/981 [==============================] - 0s 170us/sample - loss: 0.7697 - sparse_categorical_accuracy: 0.6055 - val_loss: 0.7409 - val_sparse_categorical_accuracy: 0.6697\n",
            "Epoch 7/100\n",
            "981/981 [==============================] - 0s 178us/sample - loss: 0.7388 - sparse_categorical_accuracy: 0.6249 - val_loss: 0.7172 - val_sparse_categorical_accuracy: 0.6606\n",
            "Epoch 8/100\n",
            "981/981 [==============================] - 0s 174us/sample - loss: 0.7115 - sparse_categorical_accuracy: 0.6412 - val_loss: 0.6997 - val_sparse_categorical_accuracy: 0.6514\n",
            "Epoch 9/100\n",
            "981/981 [==============================] - 0s 166us/sample - loss: 0.6891 - sparse_categorical_accuracy: 0.6636 - val_loss: 0.6870 - val_sparse_categorical_accuracy: 0.6606\n",
            "Epoch 10/100\n",
            "981/981 [==============================] - 0s 163us/sample - loss: 0.6669 - sparse_categorical_accuracy: 0.6656 - val_loss: 0.7003 - val_sparse_categorical_accuracy: 0.6697\n",
            "Epoch 11/100\n",
            "981/981 [==============================] - 0s 164us/sample - loss: 0.6550 - sparse_categorical_accuracy: 0.6799 - val_loss: 0.6659 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 12/100\n",
            "981/981 [==============================] - 0s 191us/sample - loss: 0.6388 - sparse_categorical_accuracy: 0.6932 - val_loss: 0.6525 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 13/100\n",
            "981/981 [==============================] - 0s 177us/sample - loss: 0.6268 - sparse_categorical_accuracy: 0.6901 - val_loss: 0.6311 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 14/100\n",
            "981/981 [==============================] - 0s 157us/sample - loss: 0.6155 - sparse_categorical_accuracy: 0.6891 - val_loss: 0.6234 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 15/100\n",
            "981/981 [==============================] - 0s 158us/sample - loss: 0.6059 - sparse_categorical_accuracy: 0.7034 - val_loss: 0.6165 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 16/100\n",
            "981/981 [==============================] - 0s 166us/sample - loss: 0.5942 - sparse_categorical_accuracy: 0.7044 - val_loss: 0.6061 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 17/100\n",
            "981/981 [==============================] - 0s 160us/sample - loss: 0.5849 - sparse_categorical_accuracy: 0.7074 - val_loss: 0.5985 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 18/100\n",
            "981/981 [==============================] - 0s 163us/sample - loss: 0.5761 - sparse_categorical_accuracy: 0.7187 - val_loss: 0.5969 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 19/100\n",
            "981/981 [==============================] - 0s 156us/sample - loss: 0.5684 - sparse_categorical_accuracy: 0.7136 - val_loss: 0.6018 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 20/100\n",
            "981/981 [==============================] - 0s 179us/sample - loss: 0.5604 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.5918 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 21/100\n",
            "981/981 [==============================] - 0s 154us/sample - loss: 0.5537 - sparse_categorical_accuracy: 0.7462 - val_loss: 0.6042 - val_sparse_categorical_accuracy: 0.7523\n",
            "Epoch 22/100\n",
            "981/981 [==============================] - 0s 170us/sample - loss: 0.5455 - sparse_categorical_accuracy: 0.7380 - val_loss: 0.5848 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 23/100\n",
            "981/981 [==============================] - 0s 160us/sample - loss: 0.5387 - sparse_categorical_accuracy: 0.7441 - val_loss: 0.5807 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 24/100\n",
            "981/981 [==============================] - 0s 163us/sample - loss: 0.5350 - sparse_categorical_accuracy: 0.7441 - val_loss: 0.5943 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 25/100\n",
            "981/981 [==============================] - 0s 186us/sample - loss: 0.5305 - sparse_categorical_accuracy: 0.7431 - val_loss: 0.5912 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 26/100\n",
            "981/981 [==============================] - 0s 167us/sample - loss: 0.5234 - sparse_categorical_accuracy: 0.7543 - val_loss: 0.5912 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 27/100\n",
            "981/981 [==============================] - 0s 157us/sample - loss: 0.5188 - sparse_categorical_accuracy: 0.7564 - val_loss: 0.5773 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 28/100\n",
            "981/981 [==============================] - 0s 154us/sample - loss: 0.5151 - sparse_categorical_accuracy: 0.7574 - val_loss: 0.5799 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 29/100\n",
            "981/981 [==============================] - 0s 172us/sample - loss: 0.5093 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.5872 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 30/100\n",
            "981/981 [==============================] - 0s 162us/sample - loss: 0.5054 - sparse_categorical_accuracy: 0.7717 - val_loss: 0.5826 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 31/100\n",
            "981/981 [==============================] - 0s 161us/sample - loss: 0.5017 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.5751 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 32/100\n",
            "981/981 [==============================] - 0s 175us/sample - loss: 0.4950 - sparse_categorical_accuracy: 0.7645 - val_loss: 0.5865 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 33/100\n",
            "981/981 [==============================] - 0s 149us/sample - loss: 0.4940 - sparse_categorical_accuracy: 0.7717 - val_loss: 0.5953 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 34/100\n",
            "981/981 [==============================] - 0s 155us/sample - loss: 0.4910 - sparse_categorical_accuracy: 0.7727 - val_loss: 0.5862 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 35/100\n",
            "981/981 [==============================] - 0s 178us/sample - loss: 0.4813 - sparse_categorical_accuracy: 0.7757 - val_loss: 0.5841 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 36/100\n",
            "981/981 [==============================] - 0s 175us/sample - loss: 0.4817 - sparse_categorical_accuracy: 0.7737 - val_loss: 0.5816 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 37/100\n",
            "981/981 [==============================] - 0s 157us/sample - loss: 0.4730 - sparse_categorical_accuracy: 0.7768 - val_loss: 0.6036 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 38/100\n",
            "981/981 [==============================] - 0s 188us/sample - loss: 0.4760 - sparse_categorical_accuracy: 0.7757 - val_loss: 0.5806 - val_sparse_categorical_accuracy: 0.7615\n",
            "Epoch 39/100\n",
            "981/981 [==============================] - 0s 174us/sample - loss: 0.4702 - sparse_categorical_accuracy: 0.7747 - val_loss: 0.5828 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 40/100\n",
            "981/981 [==============================] - 0s 168us/sample - loss: 0.4670 - sparse_categorical_accuracy: 0.7737 - val_loss: 0.5838 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 41/100\n",
            "981/981 [==============================] - 0s 159us/sample - loss: 0.4626 - sparse_categorical_accuracy: 0.7849 - val_loss: 0.5869 - val_sparse_categorical_accuracy: 0.7339\n",
            "[CV] ......................... n_neurons=14, n_hidden=5, total=   7.9s\n",
            "[CV] n_neurons=14, n_hidden=5 ........................................\n",
            "Train on 981 samples, validate on 109 samples\n",
            "Epoch 1/100\n",
            "981/981 [==============================] - 1s 905us/sample - loss: 1.0457 - sparse_categorical_accuracy: 0.4536 - val_loss: 0.9811 - val_sparse_categorical_accuracy: 0.5046\n",
            "Epoch 2/100\n",
            "981/981 [==============================] - 0s 161us/sample - loss: 0.9234 - sparse_categorical_accuracy: 0.5382 - val_loss: 0.9230 - val_sparse_categorical_accuracy: 0.5321\n",
            "Epoch 3/100\n",
            "981/981 [==============================] - 0s 166us/sample - loss: 0.8677 - sparse_categorical_accuracy: 0.5545 - val_loss: 0.8812 - val_sparse_categorical_accuracy: 0.5321\n",
            "Epoch 4/100\n",
            "981/981 [==============================] - 0s 160us/sample - loss: 0.8239 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.8446 - val_sparse_categorical_accuracy: 0.5688\n",
            "Epoch 5/100\n",
            "981/981 [==============================] - 0s 165us/sample - loss: 0.7864 - sparse_categorical_accuracy: 0.6126 - val_loss: 0.8217 - val_sparse_categorical_accuracy: 0.5413\n",
            "Epoch 6/100\n",
            "981/981 [==============================] - 0s 169us/sample - loss: 0.7500 - sparse_categorical_accuracy: 0.6310 - val_loss: 0.7969 - val_sparse_categorical_accuracy: 0.6147\n",
            "Epoch 7/100\n",
            "981/981 [==============================] - 0s 159us/sample - loss: 0.7177 - sparse_categorical_accuracy: 0.6453 - val_loss: 0.7654 - val_sparse_categorical_accuracy: 0.6514\n",
            "Epoch 8/100\n",
            "981/981 [==============================] - 0s 168us/sample - loss: 0.6905 - sparse_categorical_accuracy: 0.6555 - val_loss: 0.7358 - val_sparse_categorical_accuracy: 0.6514\n",
            "Epoch 9/100\n",
            "981/981 [==============================] - 0s 160us/sample - loss: 0.6662 - sparse_categorical_accuracy: 0.6748 - val_loss: 0.7041 - val_sparse_categorical_accuracy: 0.6239\n",
            "Epoch 10/100\n",
            "981/981 [==============================] - 0s 187us/sample - loss: 0.6454 - sparse_categorical_accuracy: 0.6860 - val_loss: 0.6776 - val_sparse_categorical_accuracy: 0.6422\n",
            "Epoch 11/100\n",
            "981/981 [==============================] - 0s 164us/sample - loss: 0.6236 - sparse_categorical_accuracy: 0.6993 - val_loss: 0.6639 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 12/100\n",
            "981/981 [==============================] - 0s 161us/sample - loss: 0.6058 - sparse_categorical_accuracy: 0.7064 - val_loss: 0.6399 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 13/100\n",
            "981/981 [==============================] - 0s 164us/sample - loss: 0.5927 - sparse_categorical_accuracy: 0.7136 - val_loss: 0.6178 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 14/100\n",
            "981/981 [==============================] - 0s 160us/sample - loss: 0.5809 - sparse_categorical_accuracy: 0.7227 - val_loss: 0.5948 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 15/100\n",
            "981/981 [==============================] - 0s 162us/sample - loss: 0.5669 - sparse_categorical_accuracy: 0.7350 - val_loss: 0.5791 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 16/100\n",
            "981/981 [==============================] - 0s 195us/sample - loss: 0.5591 - sparse_categorical_accuracy: 0.7258 - val_loss: 0.5799 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 17/100\n",
            "981/981 [==============================] - 0s 172us/sample - loss: 0.5486 - sparse_categorical_accuracy: 0.7441 - val_loss: 0.5707 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 18/100\n",
            "981/981 [==============================] - 0s 158us/sample - loss: 0.5382 - sparse_categorical_accuracy: 0.7360 - val_loss: 0.5573 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 19/100\n",
            "981/981 [==============================] - 0s 160us/sample - loss: 0.5310 - sparse_categorical_accuracy: 0.7482 - val_loss: 0.5496 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 20/100\n",
            "981/981 [==============================] - 0s 158us/sample - loss: 0.5253 - sparse_categorical_accuracy: 0.7482 - val_loss: 0.5475 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 21/100\n",
            "981/981 [==============================] - 0s 153us/sample - loss: 0.5166 - sparse_categorical_accuracy: 0.7574 - val_loss: 0.5428 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 22/100\n",
            "981/981 [==============================] - 0s 167us/sample - loss: 0.5100 - sparse_categorical_accuracy: 0.7666 - val_loss: 0.5319 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 23/100\n",
            "981/981 [==============================] - 0s 175us/sample - loss: 0.5045 - sparse_categorical_accuracy: 0.7666 - val_loss: 0.5279 - val_sparse_categorical_accuracy: 0.7706\n",
            "Epoch 24/100\n",
            "981/981 [==============================] - 0s 160us/sample - loss: 0.4987 - sparse_categorical_accuracy: 0.7686 - val_loss: 0.5274 - val_sparse_categorical_accuracy: 0.7523\n",
            "Epoch 25/100\n",
            "981/981 [==============================] - 0s 159us/sample - loss: 0.4931 - sparse_categorical_accuracy: 0.7747 - val_loss: 0.5144 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 26/100\n",
            "981/981 [==============================] - 0s 158us/sample - loss: 0.4889 - sparse_categorical_accuracy: 0.7747 - val_loss: 0.5068 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 27/100\n",
            "981/981 [==============================] - 0s 153us/sample - loss: 0.4811 - sparse_categorical_accuracy: 0.7798 - val_loss: 0.5091 - val_sparse_categorical_accuracy: 0.7706\n",
            "Epoch 28/100\n",
            "981/981 [==============================] - 0s 175us/sample - loss: 0.4758 - sparse_categorical_accuracy: 0.7880 - val_loss: 0.5051 - val_sparse_categorical_accuracy: 0.7523\n",
            "Epoch 29/100\n",
            "981/981 [==============================] - 0s 171us/sample - loss: 0.4746 - sparse_categorical_accuracy: 0.7829 - val_loss: 0.4902 - val_sparse_categorical_accuracy: 0.7798\n",
            "Epoch 30/100\n",
            "981/981 [==============================] - 0s 160us/sample - loss: 0.4677 - sparse_categorical_accuracy: 0.7971 - val_loss: 0.4902 - val_sparse_categorical_accuracy: 0.7798\n",
            "Epoch 31/100\n",
            "981/981 [==============================] - 0s 159us/sample - loss: 0.4646 - sparse_categorical_accuracy: 0.7931 - val_loss: 0.4894 - val_sparse_categorical_accuracy: 0.7706\n",
            "Epoch 32/100\n",
            "981/981 [==============================] - 0s 151us/sample - loss: 0.4600 - sparse_categorical_accuracy: 0.7982 - val_loss: 0.5016 - val_sparse_categorical_accuracy: 0.7615\n",
            "Epoch 33/100\n",
            "981/981 [==============================] - 0s 158us/sample - loss: 0.4549 - sparse_categorical_accuracy: 0.8033 - val_loss: 0.4837 - val_sparse_categorical_accuracy: 0.7798\n",
            "Epoch 34/100\n",
            "981/981 [==============================] - 0s 155us/sample - loss: 0.4499 - sparse_categorical_accuracy: 0.8033 - val_loss: 0.4861 - val_sparse_categorical_accuracy: 0.7706\n",
            "Epoch 35/100\n",
            "981/981 [==============================] - 0s 164us/sample - loss: 0.4446 - sparse_categorical_accuracy: 0.8033 - val_loss: 0.4931 - val_sparse_categorical_accuracy: 0.7615\n",
            "Epoch 36/100\n",
            "981/981 [==============================] - 0s 165us/sample - loss: 0.4410 - sparse_categorical_accuracy: 0.8063 - val_loss: 0.4695 - val_sparse_categorical_accuracy: 0.7890\n",
            "Epoch 37/100\n",
            "981/981 [==============================] - 0s 154us/sample - loss: 0.4396 - sparse_categorical_accuracy: 0.8145 - val_loss: 0.4742 - val_sparse_categorical_accuracy: 0.7615\n",
            "Epoch 38/100\n",
            "981/981 [==============================] - 0s 153us/sample - loss: 0.4352 - sparse_categorical_accuracy: 0.8165 - val_loss: 0.4922 - val_sparse_categorical_accuracy: 0.7615\n",
            "Epoch 39/100\n",
            "981/981 [==============================] - 0s 158us/sample - loss: 0.4283 - sparse_categorical_accuracy: 0.8196 - val_loss: 0.4746 - val_sparse_categorical_accuracy: 0.7706\n",
            "Epoch 40/100\n",
            "981/981 [==============================] - 0s 159us/sample - loss: 0.4293 - sparse_categorical_accuracy: 0.8135 - val_loss: 0.4736 - val_sparse_categorical_accuracy: 0.8165\n",
            "Epoch 41/100\n",
            "981/981 [==============================] - 0s 181us/sample - loss: 0.4260 - sparse_categorical_accuracy: 0.8135 - val_loss: 0.4865 - val_sparse_categorical_accuracy: 0.7798\n",
            "Epoch 42/100\n",
            "981/981 [==============================] - 0s 171us/sample - loss: 0.4221 - sparse_categorical_accuracy: 0.8216 - val_loss: 0.4828 - val_sparse_categorical_accuracy: 0.7890\n",
            "Epoch 43/100\n",
            "981/981 [==============================] - 0s 151us/sample - loss: 0.4173 - sparse_categorical_accuracy: 0.8186 - val_loss: 0.4850 - val_sparse_categorical_accuracy: 0.7706\n",
            "Epoch 44/100\n",
            "981/981 [==============================] - 0s 153us/sample - loss: 0.4124 - sparse_categorical_accuracy: 0.8236 - val_loss: 0.4705 - val_sparse_categorical_accuracy: 0.7982\n",
            "Epoch 45/100\n",
            "981/981 [==============================] - 0s 154us/sample - loss: 0.4075 - sparse_categorical_accuracy: 0.8267 - val_loss: 0.4865 - val_sparse_categorical_accuracy: 0.7615\n",
            "Epoch 46/100\n",
            "981/981 [==============================] - 0s 160us/sample - loss: 0.4074 - sparse_categorical_accuracy: 0.8247 - val_loss: 0.4658 - val_sparse_categorical_accuracy: 0.7798\n",
            "Epoch 47/100\n",
            "981/981 [==============================] - 0s 148us/sample - loss: 0.4011 - sparse_categorical_accuracy: 0.8298 - val_loss: 0.4667 - val_sparse_categorical_accuracy: 0.8073\n",
            "Epoch 48/100\n",
            "981/981 [==============================] - 0s 186us/sample - loss: 0.4006 - sparse_categorical_accuracy: 0.8308 - val_loss: 0.4619 - val_sparse_categorical_accuracy: 0.8073\n",
            "Epoch 49/100\n",
            "981/981 [==============================] - 0s 169us/sample - loss: 0.3972 - sparse_categorical_accuracy: 0.8277 - val_loss: 0.4944 - val_sparse_categorical_accuracy: 0.7706\n",
            "Epoch 50/100\n",
            "981/981 [==============================] - 0s 158us/sample - loss: 0.3952 - sparse_categorical_accuracy: 0.8379 - val_loss: 0.4786 - val_sparse_categorical_accuracy: 0.7706\n",
            "Epoch 51/100\n",
            "981/981 [==============================] - 0s 152us/sample - loss: 0.3899 - sparse_categorical_accuracy: 0.8379 - val_loss: 0.4703 - val_sparse_categorical_accuracy: 0.7890\n",
            "Epoch 52/100\n",
            "981/981 [==============================] - 0s 159us/sample - loss: 0.3845 - sparse_categorical_accuracy: 0.8338 - val_loss: 0.5040 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 53/100\n",
            "981/981 [==============================] - 0s 155us/sample - loss: 0.3843 - sparse_categorical_accuracy: 0.8389 - val_loss: 0.4683 - val_sparse_categorical_accuracy: 0.8165\n",
            "Epoch 54/100\n",
            "981/981 [==============================] - 0s 167us/sample - loss: 0.3798 - sparse_categorical_accuracy: 0.8400 - val_loss: 0.4629 - val_sparse_categorical_accuracy: 0.8073\n",
            "Epoch 55/100\n",
            "981/981 [==============================] - 0s 184us/sample - loss: 0.3747 - sparse_categorical_accuracy: 0.8481 - val_loss: 0.4712 - val_sparse_categorical_accuracy: 0.7798\n",
            "Epoch 56/100\n",
            "981/981 [==============================] - 0s 155us/sample - loss: 0.3736 - sparse_categorical_accuracy: 0.8502 - val_loss: 0.4764 - val_sparse_categorical_accuracy: 0.7982\n",
            "Epoch 57/100\n",
            "981/981 [==============================] - 0s 153us/sample - loss: 0.3724 - sparse_categorical_accuracy: 0.8420 - val_loss: 0.4663 - val_sparse_categorical_accuracy: 0.7982\n",
            "Epoch 58/100\n",
            "981/981 [==============================] - 0s 155us/sample - loss: 0.3673 - sparse_categorical_accuracy: 0.8491 - val_loss: 0.4799 - val_sparse_categorical_accuracy: 0.7798\n",
            "[CV] ......................... n_neurons=14, n_hidden=5, total=  10.5s\n",
            "[CV] n_neurons=14, n_hidden=5 ........................................\n",
            "Train on 981 samples, validate on 109 samples\n",
            "Epoch 1/100\n",
            "981/981 [==============================] - 1s 901us/sample - loss: 1.0830 - sparse_categorical_accuracy: 0.4424 - val_loss: 0.9902 - val_sparse_categorical_accuracy: 0.5138\n",
            "Epoch 2/100\n",
            "981/981 [==============================] - 0s 180us/sample - loss: 0.9397 - sparse_categorical_accuracy: 0.5127 - val_loss: 0.9296 - val_sparse_categorical_accuracy: 0.5596\n",
            "Epoch 3/100\n",
            "981/981 [==============================] - 0s 167us/sample - loss: 0.8835 - sparse_categorical_accuracy: 0.5596 - val_loss: 0.8845 - val_sparse_categorical_accuracy: 0.5321\n",
            "Epoch 4/100\n",
            "981/981 [==============================] - 0s 171us/sample - loss: 0.8395 - sparse_categorical_accuracy: 0.5861 - val_loss: 0.8385 - val_sparse_categorical_accuracy: 0.5688\n",
            "Epoch 5/100\n",
            "981/981 [==============================] - 0s 154us/sample - loss: 0.8007 - sparse_categorical_accuracy: 0.6177 - val_loss: 0.8104 - val_sparse_categorical_accuracy: 0.5780\n",
            "Epoch 6/100\n",
            "981/981 [==============================] - 0s 156us/sample - loss: 0.7683 - sparse_categorical_accuracy: 0.6228 - val_loss: 0.7787 - val_sparse_categorical_accuracy: 0.6330\n",
            "Epoch 7/100\n",
            "981/981 [==============================] - 0s 171us/sample - loss: 0.7366 - sparse_categorical_accuracy: 0.6463 - val_loss: 0.7521 - val_sparse_categorical_accuracy: 0.6514\n",
            "Epoch 8/100\n",
            "981/981 [==============================] - 0s 180us/sample - loss: 0.7098 - sparse_categorical_accuracy: 0.6514 - val_loss: 0.7259 - val_sparse_categorical_accuracy: 0.6422\n",
            "Epoch 9/100\n",
            "981/981 [==============================] - 0s 157us/sample - loss: 0.6852 - sparse_categorical_accuracy: 0.6585 - val_loss: 0.7105 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 10/100\n",
            "981/981 [==============================] - 0s 168us/sample - loss: 0.6652 - sparse_categorical_accuracy: 0.6656 - val_loss: 0.6908 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 11/100\n",
            "981/981 [==============================] - 0s 165us/sample - loss: 0.6470 - sparse_categorical_accuracy: 0.6820 - val_loss: 0.6781 - val_sparse_categorical_accuracy: 0.6697\n",
            "Epoch 12/100\n",
            "981/981 [==============================] - 0s 161us/sample - loss: 0.6312 - sparse_categorical_accuracy: 0.6972 - val_loss: 0.6708 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 13/100\n",
            "981/981 [==============================] - 0s 166us/sample - loss: 0.6158 - sparse_categorical_accuracy: 0.6901 - val_loss: 0.6555 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 14/100\n",
            "981/981 [==============================] - 0s 162us/sample - loss: 0.6022 - sparse_categorical_accuracy: 0.7013 - val_loss: 0.6454 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 15/100\n",
            "981/981 [==============================] - 0s 161us/sample - loss: 0.5911 - sparse_categorical_accuracy: 0.7166 - val_loss: 0.6404 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 16/100\n",
            "981/981 [==============================] - 0s 158us/sample - loss: 0.5799 - sparse_categorical_accuracy: 0.7115 - val_loss: 0.6345 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 17/100\n",
            "981/981 [==============================] - 0s 174us/sample - loss: 0.5689 - sparse_categorical_accuracy: 0.7207 - val_loss: 0.6239 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 18/100\n",
            "981/981 [==============================] - 0s 174us/sample - loss: 0.5600 - sparse_categorical_accuracy: 0.7268 - val_loss: 0.6123 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 19/100\n",
            "981/981 [==============================] - 0s 167us/sample - loss: 0.5517 - sparse_categorical_accuracy: 0.7329 - val_loss: 0.6164 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 20/100\n",
            "981/981 [==============================] - 0s 169us/sample - loss: 0.5461 - sparse_categorical_accuracy: 0.7360 - val_loss: 0.6118 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 21/100\n",
            "981/981 [==============================] - 0s 170us/sample - loss: 0.5403 - sparse_categorical_accuracy: 0.7472 - val_loss: 0.6021 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 22/100\n",
            "981/981 [==============================] - 0s 155us/sample - loss: 0.5338 - sparse_categorical_accuracy: 0.7513 - val_loss: 0.5987 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 23/100\n",
            "981/981 [==============================] - 0s 158us/sample - loss: 0.5258 - sparse_categorical_accuracy: 0.7472 - val_loss: 0.6007 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 24/100\n",
            "981/981 [==============================] - 0s 158us/sample - loss: 0.5218 - sparse_categorical_accuracy: 0.7543 - val_loss: 0.6066 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 25/100\n",
            "981/981 [==============================] - 0s 181us/sample - loss: 0.5180 - sparse_categorical_accuracy: 0.7594 - val_loss: 0.5897 - val_sparse_categorical_accuracy: 0.7523\n",
            "Epoch 26/100\n",
            "981/981 [==============================] - 0s 157us/sample - loss: 0.5135 - sparse_categorical_accuracy: 0.7564 - val_loss: 0.5893 - val_sparse_categorical_accuracy: 0.7523\n",
            "Epoch 27/100\n",
            "981/981 [==============================] - 0s 168us/sample - loss: 0.5054 - sparse_categorical_accuracy: 0.7615 - val_loss: 0.5863 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 28/100\n",
            "981/981 [==============================] - 0s 158us/sample - loss: 0.5019 - sparse_categorical_accuracy: 0.7594 - val_loss: 0.5909 - val_sparse_categorical_accuracy: 0.7523\n",
            "Epoch 29/100\n",
            "981/981 [==============================] - 0s 162us/sample - loss: 0.4998 - sparse_categorical_accuracy: 0.7747 - val_loss: 0.5866 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 30/100\n",
            "981/981 [==============================] - 0s 181us/sample - loss: 0.4922 - sparse_categorical_accuracy: 0.7655 - val_loss: 0.5806 - val_sparse_categorical_accuracy: 0.7615\n",
            "Epoch 31/100\n",
            "981/981 [==============================] - 0s 160us/sample - loss: 0.4910 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.5984 - val_sparse_categorical_accuracy: 0.7615\n",
            "Epoch 32/100\n",
            "981/981 [==============================] - 0s 160us/sample - loss: 0.4862 - sparse_categorical_accuracy: 0.7696 - val_loss: 0.5919 - val_sparse_categorical_accuracy: 0.7523\n",
            "Epoch 33/100\n",
            "981/981 [==============================] - 0s 178us/sample - loss: 0.4815 - sparse_categorical_accuracy: 0.7706 - val_loss: 0.5866 - val_sparse_categorical_accuracy: 0.7523\n",
            "Epoch 34/100\n",
            "981/981 [==============================] - 0s 158us/sample - loss: 0.4777 - sparse_categorical_accuracy: 0.7839 - val_loss: 0.5978 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 35/100\n",
            "981/981 [==============================] - 0s 160us/sample - loss: 0.4761 - sparse_categorical_accuracy: 0.7727 - val_loss: 0.5948 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 36/100\n",
            "981/981 [==============================] - 0s 151us/sample - loss: 0.4735 - sparse_categorical_accuracy: 0.7717 - val_loss: 0.5959 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 37/100\n",
            "981/981 [==============================] - 0s 155us/sample - loss: 0.4701 - sparse_categorical_accuracy: 0.7768 - val_loss: 0.5951 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 38/100\n",
            "981/981 [==============================] - 0s 172us/sample - loss: 0.4637 - sparse_categorical_accuracy: 0.7768 - val_loss: 0.5991 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 39/100\n",
            "981/981 [==============================] - 0s 158us/sample - loss: 0.4620 - sparse_categorical_accuracy: 0.7788 - val_loss: 0.5844 - val_sparse_categorical_accuracy: 0.7615\n",
            "Epoch 40/100\n",
            "981/981 [==============================] - 0s 176us/sample - loss: 0.4561 - sparse_categorical_accuracy: 0.7819 - val_loss: 0.6015 - val_sparse_categorical_accuracy: 0.7339\n",
            "[CV] ......................... n_neurons=14, n_hidden=5, total=   7.7s\n",
            "[CV] n_neurons=14, n_hidden=5 ........................................\n",
            "Train on 981 samples, validate on 110 samples\n",
            "Epoch 1/100\n",
            "981/981 [==============================] - 1s 934us/sample - loss: 1.2383 - sparse_categorical_accuracy: 0.4628 - val_loss: 0.9727 - val_sparse_categorical_accuracy: 0.5364\n",
            "Epoch 2/100\n",
            "981/981 [==============================] - 0s 163us/sample - loss: 0.9305 - sparse_categorical_accuracy: 0.5250 - val_loss: 0.8685 - val_sparse_categorical_accuracy: 0.5455\n",
            "Epoch 3/100\n",
            "981/981 [==============================] - 0s 176us/sample - loss: 0.8486 - sparse_categorical_accuracy: 0.5607 - val_loss: 0.8068 - val_sparse_categorical_accuracy: 0.6091\n",
            "Epoch 4/100\n",
            "981/981 [==============================] - 0s 158us/sample - loss: 0.7938 - sparse_categorical_accuracy: 0.6004 - val_loss: 0.7573 - val_sparse_categorical_accuracy: 0.6364\n",
            "Epoch 5/100\n",
            "981/981 [==============================] - 0s 173us/sample - loss: 0.7517 - sparse_categorical_accuracy: 0.6208 - val_loss: 0.7270 - val_sparse_categorical_accuracy: 0.6273\n",
            "Epoch 6/100\n",
            "981/981 [==============================] - 0s 158us/sample - loss: 0.7204 - sparse_categorical_accuracy: 0.6371 - val_loss: 0.7077 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 7/100\n",
            "981/981 [==============================] - 0s 156us/sample - loss: 0.6944 - sparse_categorical_accuracy: 0.6524 - val_loss: 0.6941 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 8/100\n",
            "981/981 [==============================] - 0s 166us/sample - loss: 0.6714 - sparse_categorical_accuracy: 0.6697 - val_loss: 0.6853 - val_sparse_categorical_accuracy: 0.6455\n",
            "Epoch 9/100\n",
            "981/981 [==============================] - 0s 186us/sample - loss: 0.6528 - sparse_categorical_accuracy: 0.6830 - val_loss: 0.6687 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 10/100\n",
            "981/981 [==============================] - 0s 169us/sample - loss: 0.6383 - sparse_categorical_accuracy: 0.6809 - val_loss: 0.6478 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 11/100\n",
            "981/981 [==============================] - 0s 167us/sample - loss: 0.6246 - sparse_categorical_accuracy: 0.6942 - val_loss: 0.6533 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 12/100\n",
            "981/981 [==============================] - 0s 157us/sample - loss: 0.6121 - sparse_categorical_accuracy: 0.7125 - val_loss: 0.6415 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 13/100\n",
            "981/981 [==============================] - 0s 159us/sample - loss: 0.6004 - sparse_categorical_accuracy: 0.7115 - val_loss: 0.6379 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 14/100\n",
            "981/981 [==============================] - 0s 155us/sample - loss: 0.5896 - sparse_categorical_accuracy: 0.7197 - val_loss: 0.6262 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 15/100\n",
            "981/981 [==============================] - 0s 166us/sample - loss: 0.5810 - sparse_categorical_accuracy: 0.7227 - val_loss: 0.6346 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 16/100\n",
            "981/981 [==============================] - 0s 169us/sample - loss: 0.5718 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.6220 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 17/100\n",
            "981/981 [==============================] - 0s 155us/sample - loss: 0.5652 - sparse_categorical_accuracy: 0.7248 - val_loss: 0.6120 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 18/100\n",
            "981/981 [==============================] - 0s 167us/sample - loss: 0.5555 - sparse_categorical_accuracy: 0.7299 - val_loss: 0.6006 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 19/100\n",
            "981/981 [==============================] - 0s 164us/sample - loss: 0.5481 - sparse_categorical_accuracy: 0.7319 - val_loss: 0.6152 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 20/100\n",
            "981/981 [==============================] - 0s 156us/sample - loss: 0.5405 - sparse_categorical_accuracy: 0.7350 - val_loss: 0.6027 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 21/100\n",
            "981/981 [==============================] - 0s 162us/sample - loss: 0.5356 - sparse_categorical_accuracy: 0.7452 - val_loss: 0.6043 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 22/100\n",
            "981/981 [==============================] - 0s 168us/sample - loss: 0.5237 - sparse_categorical_accuracy: 0.7503 - val_loss: 0.5944 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 23/100\n",
            "981/981 [==============================] - 0s 166us/sample - loss: 0.5225 - sparse_categorical_accuracy: 0.7482 - val_loss: 0.5754 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 24/100\n",
            "981/981 [==============================] - 0s 163us/sample - loss: 0.5155 - sparse_categorical_accuracy: 0.7543 - val_loss: 0.6030 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 25/100\n",
            "981/981 [==============================] - 0s 149us/sample - loss: 0.5091 - sparse_categorical_accuracy: 0.7676 - val_loss: 0.5908 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 26/100\n",
            "981/981 [==============================] - 0s 150us/sample - loss: 0.5044 - sparse_categorical_accuracy: 0.7584 - val_loss: 0.6024 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 27/100\n",
            "981/981 [==============================] - 0s 149us/sample - loss: 0.5000 - sparse_categorical_accuracy: 0.7676 - val_loss: 0.6073 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 28/100\n",
            "981/981 [==============================] - 0s 166us/sample - loss: 0.4935 - sparse_categorical_accuracy: 0.7666 - val_loss: 0.6044 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 29/100\n",
            "981/981 [==============================] - 0s 175us/sample - loss: 0.4911 - sparse_categorical_accuracy: 0.7686 - val_loss: 0.5812 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 30/100\n",
            "981/981 [==============================] - 0s 163us/sample - loss: 0.4848 - sparse_categorical_accuracy: 0.7757 - val_loss: 0.6097 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 31/100\n",
            "981/981 [==============================] - 0s 170us/sample - loss: 0.4792 - sparse_categorical_accuracy: 0.7859 - val_loss: 0.5818 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 32/100\n",
            "981/981 [==============================] - 0s 156us/sample - loss: 0.4737 - sparse_categorical_accuracy: 0.7778 - val_loss: 0.5839 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 33/100\n",
            "981/981 [==============================] - 0s 165us/sample - loss: 0.4727 - sparse_categorical_accuracy: 0.7839 - val_loss: 0.5828 - val_sparse_categorical_accuracy: 0.7000\n",
            "[CV] ......................... n_neurons=14, n_hidden=5, total=   6.5s\n",
            "[CV] n_neurons=14, n_hidden=5 ........................................\n",
            "Train on 981 samples, validate on 110 samples\n",
            "Epoch 1/100\n",
            "981/981 [==============================] - 1s 956us/sample - loss: 1.1242 - sparse_categorical_accuracy: 0.4383 - val_loss: 0.9733 - val_sparse_categorical_accuracy: 0.5091\n",
            "Epoch 2/100\n",
            "981/981 [==============================] - 0s 161us/sample - loss: 0.9218 - sparse_categorical_accuracy: 0.5148 - val_loss: 0.8798 - val_sparse_categorical_accuracy: 0.5455\n",
            "Epoch 3/100\n",
            "981/981 [==============================] - 0s 172us/sample - loss: 0.8510 - sparse_categorical_accuracy: 0.5627 - val_loss: 0.8298 - val_sparse_categorical_accuracy: 0.5364\n",
            "Epoch 4/100\n",
            "981/981 [==============================] - 0s 163us/sample - loss: 0.8070 - sparse_categorical_accuracy: 0.5800 - val_loss: 0.7955 - val_sparse_categorical_accuracy: 0.5909\n",
            "Epoch 5/100\n",
            "981/981 [==============================] - 0s 155us/sample - loss: 0.7705 - sparse_categorical_accuracy: 0.6075 - val_loss: 0.7726 - val_sparse_categorical_accuracy: 0.6273\n",
            "Epoch 6/100\n",
            "981/981 [==============================] - 0s 174us/sample - loss: 0.7396 - sparse_categorical_accuracy: 0.6279 - val_loss: 0.7451 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 7/100\n",
            "981/981 [==============================] - 0s 171us/sample - loss: 0.7105 - sparse_categorical_accuracy: 0.6463 - val_loss: 0.7324 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 8/100\n",
            "981/981 [==============================] - 0s 173us/sample - loss: 0.6864 - sparse_categorical_accuracy: 0.6544 - val_loss: 0.7181 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 9/100\n",
            "981/981 [==============================] - 0s 167us/sample - loss: 0.6606 - sparse_categorical_accuracy: 0.6769 - val_loss: 0.6949 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 10/100\n",
            "981/981 [==============================] - 0s 167us/sample - loss: 0.6389 - sparse_categorical_accuracy: 0.6932 - val_loss: 0.6927 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 11/100\n",
            "981/981 [==============================] - 0s 155us/sample - loss: 0.6259 - sparse_categorical_accuracy: 0.6942 - val_loss: 0.6852 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 12/100\n",
            "981/981 [==============================] - 0s 161us/sample - loss: 0.6114 - sparse_categorical_accuracy: 0.7054 - val_loss: 0.6770 - val_sparse_categorical_accuracy: 0.6455\n",
            "Epoch 13/100\n",
            "981/981 [==============================] - 0s 186us/sample - loss: 0.5961 - sparse_categorical_accuracy: 0.7034 - val_loss: 0.6743 - val_sparse_categorical_accuracy: 0.6455\n",
            "Epoch 14/100\n",
            "981/981 [==============================] - 0s 169us/sample - loss: 0.5831 - sparse_categorical_accuracy: 0.7095 - val_loss: 0.6658 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 15/100\n",
            "981/981 [==============================] - 0s 156us/sample - loss: 0.5734 - sparse_categorical_accuracy: 0.7217 - val_loss: 0.6664 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 16/100\n",
            "981/981 [==============================] - 0s 194us/sample - loss: 0.5632 - sparse_categorical_accuracy: 0.7258 - val_loss: 0.6668 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 17/100\n",
            "981/981 [==============================] - 0s 161us/sample - loss: 0.5560 - sparse_categorical_accuracy: 0.7278 - val_loss: 0.6629 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 18/100\n",
            "981/981 [==============================] - 0s 149us/sample - loss: 0.5480 - sparse_categorical_accuracy: 0.7339 - val_loss: 0.6637 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 19/100\n",
            "981/981 [==============================] - 0s 164us/sample - loss: 0.5394 - sparse_categorical_accuracy: 0.7329 - val_loss: 0.6609 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 20/100\n",
            "981/981 [==============================] - 0s 161us/sample - loss: 0.5324 - sparse_categorical_accuracy: 0.7513 - val_loss: 0.6611 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 21/100\n",
            "981/981 [==============================] - 0s 158us/sample - loss: 0.5326 - sparse_categorical_accuracy: 0.7462 - val_loss: 0.6492 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 22/100\n",
            "981/981 [==============================] - 0s 194us/sample - loss: 0.5258 - sparse_categorical_accuracy: 0.7411 - val_loss: 0.6476 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 23/100\n",
            "981/981 [==============================] - 0s 178us/sample - loss: 0.5207 - sparse_categorical_accuracy: 0.7492 - val_loss: 0.6695 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 24/100\n",
            "981/981 [==============================] - 0s 157us/sample - loss: 0.5107 - sparse_categorical_accuracy: 0.7554 - val_loss: 0.6628 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 25/100\n",
            "981/981 [==============================] - 0s 161us/sample - loss: 0.5094 - sparse_categorical_accuracy: 0.7503 - val_loss: 0.6363 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 26/100\n",
            "981/981 [==============================] - 0s 158us/sample - loss: 0.5052 - sparse_categorical_accuracy: 0.7472 - val_loss: 0.6459 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 27/100\n",
            "981/981 [==============================] - 0s 154us/sample - loss: 0.4982 - sparse_categorical_accuracy: 0.7655 - val_loss: 0.6569 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 28/100\n",
            "981/981 [==============================] - 0s 174us/sample - loss: 0.4960 - sparse_categorical_accuracy: 0.7604 - val_loss: 0.6560 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 29/100\n",
            "981/981 [==============================] - 0s 155us/sample - loss: 0.4942 - sparse_categorical_accuracy: 0.7635 - val_loss: 0.6458 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 30/100\n",
            "981/981 [==============================] - 0s 157us/sample - loss: 0.4836 - sparse_categorical_accuracy: 0.7696 - val_loss: 0.6436 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 31/100\n",
            "981/981 [==============================] - 0s 159us/sample - loss: 0.4850 - sparse_categorical_accuracy: 0.7696 - val_loss: 0.6388 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 32/100\n",
            "981/981 [==============================] - 0s 181us/sample - loss: 0.4806 - sparse_categorical_accuracy: 0.7717 - val_loss: 0.6399 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 33/100\n",
            "981/981 [==============================] - 0s 178us/sample - loss: 0.4792 - sparse_categorical_accuracy: 0.7808 - val_loss: 0.6360 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 34/100\n",
            "981/981 [==============================] - 0s 175us/sample - loss: 0.4734 - sparse_categorical_accuracy: 0.7768 - val_loss: 0.6403 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 35/100\n",
            "981/981 [==============================] - 0s 178us/sample - loss: 0.4665 - sparse_categorical_accuracy: 0.7849 - val_loss: 0.6347 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 36/100\n",
            "981/981 [==============================] - 0s 168us/sample - loss: 0.4639 - sparse_categorical_accuracy: 0.7717 - val_loss: 0.6536 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 37/100\n",
            "981/981 [==============================] - 0s 163us/sample - loss: 0.4638 - sparse_categorical_accuracy: 0.7819 - val_loss: 0.6625 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 38/100\n",
            "981/981 [==============================] - 0s 162us/sample - loss: 0.4610 - sparse_categorical_accuracy: 0.7920 - val_loss: 0.6614 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 39/100\n",
            "981/981 [==============================] - 0s 159us/sample - loss: 0.4562 - sparse_categorical_accuracy: 0.7819 - val_loss: 0.6417 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 40/100\n",
            "981/981 [==============================] - 0s 170us/sample - loss: 0.4513 - sparse_categorical_accuracy: 0.7808 - val_loss: 0.6644 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 41/100\n",
            "981/981 [==============================] - 0s 155us/sample - loss: 0.4471 - sparse_categorical_accuracy: 0.7870 - val_loss: 0.6445 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 42/100\n",
            "981/981 [==============================] - 0s 176us/sample - loss: 0.4474 - sparse_categorical_accuracy: 0.7941 - val_loss: 0.6575 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 43/100\n",
            "981/981 [==============================] - 0s 170us/sample - loss: 0.4432 - sparse_categorical_accuracy: 0.7920 - val_loss: 0.6547 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 44/100\n",
            "981/981 [==============================] - 0s 158us/sample - loss: 0.4365 - sparse_categorical_accuracy: 0.8012 - val_loss: 0.6658 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 45/100\n",
            "981/981 [==============================] - 0s 170us/sample - loss: 0.4377 - sparse_categorical_accuracy: 0.7961 - val_loss: 0.6507 - val_sparse_categorical_accuracy: 0.7000\n",
            "[CV] ......................... n_neurons=14, n_hidden=5, total=   8.6s\n",
            "[CV] n_neurons=45, n_hidden=2 ........................................\n",
            "Train on 981 samples, validate on 109 samples\n",
            "Epoch 1/100\n",
            "981/981 [==============================] - 1s 664us/sample - loss: 1.1595 - sparse_categorical_accuracy: 0.4108 - val_loss: 0.9607 - val_sparse_categorical_accuracy: 0.4954\n",
            "Epoch 2/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.9492 - sparse_categorical_accuracy: 0.4862 - val_loss: 0.8402 - val_sparse_categorical_accuracy: 0.5872\n",
            "Epoch 3/100\n",
            "981/981 [==============================] - 0s 148us/sample - loss: 0.8473 - sparse_categorical_accuracy: 0.5311 - val_loss: 0.7672 - val_sparse_categorical_accuracy: 0.6147\n",
            "Epoch 4/100\n",
            "981/981 [==============================] - 0s 136us/sample - loss: 0.7773 - sparse_categorical_accuracy: 0.6004 - val_loss: 0.7245 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 5/100\n",
            "981/981 [==============================] - 0s 135us/sample - loss: 0.7286 - sparse_categorical_accuracy: 0.6340 - val_loss: 0.6929 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 6/100\n",
            "981/981 [==============================] - 0s 142us/sample - loss: 0.6925 - sparse_categorical_accuracy: 0.6606 - val_loss: 0.6737 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 7/100\n",
            "981/981 [==============================] - 0s 143us/sample - loss: 0.6632 - sparse_categorical_accuracy: 0.6820 - val_loss: 0.6603 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 8/100\n",
            "981/981 [==============================] - 0s 144us/sample - loss: 0.6388 - sparse_categorical_accuracy: 0.6983 - val_loss: 0.6450 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 9/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.6180 - sparse_categorical_accuracy: 0.7095 - val_loss: 0.6304 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 10/100\n",
            "981/981 [==============================] - 0s 162us/sample - loss: 0.6005 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.6222 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 11/100\n",
            "981/981 [==============================] - 0s 145us/sample - loss: 0.5853 - sparse_categorical_accuracy: 0.7248 - val_loss: 0.6091 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 12/100\n",
            "981/981 [==============================] - 0s 135us/sample - loss: 0.5728 - sparse_categorical_accuracy: 0.7360 - val_loss: 0.6078 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 13/100\n",
            "981/981 [==============================] - 0s 147us/sample - loss: 0.5608 - sparse_categorical_accuracy: 0.7390 - val_loss: 0.5998 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 14/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.5501 - sparse_categorical_accuracy: 0.7431 - val_loss: 0.5886 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 15/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.5385 - sparse_categorical_accuracy: 0.7513 - val_loss: 0.5972 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 16/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.5315 - sparse_categorical_accuracy: 0.7503 - val_loss: 0.5833 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 17/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.5217 - sparse_categorical_accuracy: 0.7523 - val_loss: 0.6012 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 18/100\n",
            "981/981 [==============================] - 0s 164us/sample - loss: 0.5206 - sparse_categorical_accuracy: 0.7513 - val_loss: 0.5860 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 19/100\n",
            "981/981 [==============================] - 0s 140us/sample - loss: 0.5119 - sparse_categorical_accuracy: 0.7696 - val_loss: 0.5791 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 20/100\n",
            "981/981 [==============================] - 0s 137us/sample - loss: 0.5052 - sparse_categorical_accuracy: 0.7727 - val_loss: 0.5777 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 21/100\n",
            "981/981 [==============================] - 0s 139us/sample - loss: 0.5010 - sparse_categorical_accuracy: 0.7696 - val_loss: 0.5755 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 22/100\n",
            "981/981 [==============================] - 0s 142us/sample - loss: 0.4960 - sparse_categorical_accuracy: 0.7696 - val_loss: 0.5724 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 23/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.4888 - sparse_categorical_accuracy: 0.7788 - val_loss: 0.5678 - val_sparse_categorical_accuracy: 0.7523\n",
            "Epoch 24/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.4881 - sparse_categorical_accuracy: 0.7747 - val_loss: 0.5649 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 25/100\n",
            "981/981 [==============================] - 0s 140us/sample - loss: 0.4831 - sparse_categorical_accuracy: 0.7778 - val_loss: 0.5665 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 26/100\n",
            "981/981 [==============================] - 0s 143us/sample - loss: 0.4772 - sparse_categorical_accuracy: 0.7819 - val_loss: 0.5816 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 27/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.4741 - sparse_categorical_accuracy: 0.7839 - val_loss: 0.5680 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 28/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.4705 - sparse_categorical_accuracy: 0.7910 - val_loss: 0.5608 - val_sparse_categorical_accuracy: 0.7706\n",
            "Epoch 29/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.4701 - sparse_categorical_accuracy: 0.7890 - val_loss: 0.5579 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 30/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.4648 - sparse_categorical_accuracy: 0.7880 - val_loss: 0.5657 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 31/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.4619 - sparse_categorical_accuracy: 0.7941 - val_loss: 0.5642 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 32/100\n",
            "981/981 [==============================] - 0s 151us/sample - loss: 0.4593 - sparse_categorical_accuracy: 0.8033 - val_loss: 0.5614 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 33/100\n",
            "981/981 [==============================] - 0s 153us/sample - loss: 0.4581 - sparse_categorical_accuracy: 0.7839 - val_loss: 0.5621 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 34/100\n",
            "981/981 [==============================] - 0s 138us/sample - loss: 0.4534 - sparse_categorical_accuracy: 0.7910 - val_loss: 0.5595 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 35/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.4537 - sparse_categorical_accuracy: 0.7951 - val_loss: 0.5676 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 36/100\n",
            "981/981 [==============================] - 0s 141us/sample - loss: 0.4490 - sparse_categorical_accuracy: 0.8033 - val_loss: 0.5687 - val_sparse_categorical_accuracy: 0.7615\n",
            "Epoch 37/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.4481 - sparse_categorical_accuracy: 0.8053 - val_loss: 0.5659 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 38/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.4453 - sparse_categorical_accuracy: 0.8033 - val_loss: 0.5653 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 39/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.4454 - sparse_categorical_accuracy: 0.8033 - val_loss: 0.5643 - val_sparse_categorical_accuracy: 0.7339\n",
            "[CV] ......................... n_neurons=45, n_hidden=2, total=   6.1s\n",
            "[CV] n_neurons=45, n_hidden=2 ........................................\n",
            "Train on 981 samples, validate on 109 samples\n",
            "Epoch 1/100\n",
            "981/981 [==============================] - 1s 632us/sample - loss: 1.1063 - sparse_categorical_accuracy: 0.4557 - val_loss: 0.9858 - val_sparse_categorical_accuracy: 0.5321\n",
            "Epoch 2/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.9195 - sparse_categorical_accuracy: 0.5219 - val_loss: 0.8959 - val_sparse_categorical_accuracy: 0.6055\n",
            "Epoch 3/100\n",
            "981/981 [==============================] - 0s 140us/sample - loss: 0.8348 - sparse_categorical_accuracy: 0.5739 - val_loss: 0.8189 - val_sparse_categorical_accuracy: 0.6055\n",
            "Epoch 4/100\n",
            "981/981 [==============================] - 0s 160us/sample - loss: 0.7803 - sparse_categorical_accuracy: 0.6045 - val_loss: 0.7857 - val_sparse_categorical_accuracy: 0.6055\n",
            "Epoch 5/100\n",
            "981/981 [==============================] - 0s 141us/sample - loss: 0.7378 - sparse_categorical_accuracy: 0.6279 - val_loss: 0.7546 - val_sparse_categorical_accuracy: 0.6239\n",
            "Epoch 6/100\n",
            "981/981 [==============================] - 0s 139us/sample - loss: 0.7062 - sparse_categorical_accuracy: 0.6585 - val_loss: 0.7310 - val_sparse_categorical_accuracy: 0.6239\n",
            "Epoch 7/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.6783 - sparse_categorical_accuracy: 0.6718 - val_loss: 0.7063 - val_sparse_categorical_accuracy: 0.6514\n",
            "Epoch 8/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.6529 - sparse_categorical_accuracy: 0.6891 - val_loss: 0.6929 - val_sparse_categorical_accuracy: 0.6606\n",
            "Epoch 9/100\n",
            "981/981 [==============================] - 0s 134us/sample - loss: 0.6337 - sparse_categorical_accuracy: 0.7054 - val_loss: 0.6704 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 10/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.6149 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.6553 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 11/100\n",
            "981/981 [==============================] - 0s 175us/sample - loss: 0.5987 - sparse_categorical_accuracy: 0.7136 - val_loss: 0.6429 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 12/100\n",
            "981/981 [==============================] - 0s 148us/sample - loss: 0.5853 - sparse_categorical_accuracy: 0.7288 - val_loss: 0.6347 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 13/100\n",
            "981/981 [==============================] - 0s 143us/sample - loss: 0.5732 - sparse_categorical_accuracy: 0.7401 - val_loss: 0.6228 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 14/100\n",
            "981/981 [==============================] - 0s 146us/sample - loss: 0.5616 - sparse_categorical_accuracy: 0.7452 - val_loss: 0.6093 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 15/100\n",
            "981/981 [==============================] - 0s 137us/sample - loss: 0.5505 - sparse_categorical_accuracy: 0.7472 - val_loss: 0.6027 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 16/100\n",
            "981/981 [==============================] - 0s 143us/sample - loss: 0.5410 - sparse_categorical_accuracy: 0.7533 - val_loss: 0.6000 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 17/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.5333 - sparse_categorical_accuracy: 0.7604 - val_loss: 0.5833 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 18/100\n",
            "981/981 [==============================] - 0s 145us/sample - loss: 0.5244 - sparse_categorical_accuracy: 0.7717 - val_loss: 0.5826 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 19/100\n",
            "981/981 [==============================] - 0s 137us/sample - loss: 0.5197 - sparse_categorical_accuracy: 0.7564 - val_loss: 0.5740 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 20/100\n",
            "981/981 [==============================] - 0s 157us/sample - loss: 0.5109 - sparse_categorical_accuracy: 0.7676 - val_loss: 0.5711 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 21/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.5071 - sparse_categorical_accuracy: 0.7788 - val_loss: 0.5645 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 22/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.4998 - sparse_categorical_accuracy: 0.7757 - val_loss: 0.5647 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 23/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.4955 - sparse_categorical_accuracy: 0.7706 - val_loss: 0.5617 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 24/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.4897 - sparse_categorical_accuracy: 0.7778 - val_loss: 0.5543 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 25/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.4860 - sparse_categorical_accuracy: 0.7747 - val_loss: 0.5496 - val_sparse_categorical_accuracy: 0.7523\n",
            "Epoch 26/100\n",
            "981/981 [==============================] - 0s 144us/sample - loss: 0.4833 - sparse_categorical_accuracy: 0.7808 - val_loss: 0.5467 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 27/100\n",
            "981/981 [==============================] - 0s 145us/sample - loss: 0.4757 - sparse_categorical_accuracy: 0.7829 - val_loss: 0.5430 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 28/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.4736 - sparse_categorical_accuracy: 0.7890 - val_loss: 0.5424 - val_sparse_categorical_accuracy: 0.7523\n",
            "Epoch 29/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.4708 - sparse_categorical_accuracy: 0.7839 - val_loss: 0.5444 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 30/100\n",
            "981/981 [==============================] - 0s 141us/sample - loss: 0.4678 - sparse_categorical_accuracy: 0.7859 - val_loss: 0.5377 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 31/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.4629 - sparse_categorical_accuracy: 0.7992 - val_loss: 0.5471 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 32/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.4623 - sparse_categorical_accuracy: 0.7900 - val_loss: 0.5433 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 33/100\n",
            "981/981 [==============================] - 0s 145us/sample - loss: 0.4609 - sparse_categorical_accuracy: 0.7920 - val_loss: 0.5393 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 34/100\n",
            "981/981 [==============================] - 0s 140us/sample - loss: 0.4552 - sparse_categorical_accuracy: 0.7931 - val_loss: 0.5408 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 35/100\n",
            "981/981 [==============================] - 0s 150us/sample - loss: 0.4531 - sparse_categorical_accuracy: 0.7931 - val_loss: 0.5352 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 36/100\n",
            "981/981 [==============================] - 0s 135us/sample - loss: 0.4502 - sparse_categorical_accuracy: 0.7992 - val_loss: 0.5404 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 37/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.4491 - sparse_categorical_accuracy: 0.8012 - val_loss: 0.5381 - val_sparse_categorical_accuracy: 0.7523\n",
            "Epoch 38/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.4461 - sparse_categorical_accuracy: 0.8022 - val_loss: 0.5377 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 39/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.4445 - sparse_categorical_accuracy: 0.8033 - val_loss: 0.5379 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 40/100\n",
            "981/981 [==============================] - 0s 150us/sample - loss: 0.4414 - sparse_categorical_accuracy: 0.8043 - val_loss: 0.5355 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 41/100\n",
            "981/981 [==============================] - 0s 160us/sample - loss: 0.4392 - sparse_categorical_accuracy: 0.8043 - val_loss: 0.5306 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 42/100\n",
            "981/981 [==============================] - 0s 145us/sample - loss: 0.4371 - sparse_categorical_accuracy: 0.8135 - val_loss: 0.5388 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 43/100\n",
            "981/981 [==============================] - 0s 149us/sample - loss: 0.4367 - sparse_categorical_accuracy: 0.8012 - val_loss: 0.5351 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 44/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.4346 - sparse_categorical_accuracy: 0.8135 - val_loss: 0.5371 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 45/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.4307 - sparse_categorical_accuracy: 0.8175 - val_loss: 0.5408 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 46/100\n",
            "981/981 [==============================] - 0s 151us/sample - loss: 0.4311 - sparse_categorical_accuracy: 0.8135 - val_loss: 0.5378 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 47/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.4291 - sparse_categorical_accuracy: 0.8104 - val_loss: 0.5364 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 48/100\n",
            "981/981 [==============================] - 0s 149us/sample - loss: 0.4265 - sparse_categorical_accuracy: 0.8165 - val_loss: 0.5455 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 49/100\n",
            "981/981 [==============================] - 0s 147us/sample - loss: 0.4261 - sparse_categorical_accuracy: 0.8155 - val_loss: 0.5367 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 50/100\n",
            "981/981 [==============================] - 0s 138us/sample - loss: 0.4238 - sparse_categorical_accuracy: 0.8135 - val_loss: 0.5358 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 51/100\n",
            "981/981 [==============================] - 0s 153us/sample - loss: 0.4220 - sparse_categorical_accuracy: 0.8165 - val_loss: 0.5403 - val_sparse_categorical_accuracy: 0.7248\n",
            "[CV] ......................... n_neurons=45, n_hidden=2, total=   7.9s\n",
            "[CV] n_neurons=45, n_hidden=2 ........................................\n",
            "Train on 981 samples, validate on 109 samples\n",
            "Epoch 1/100\n",
            "981/981 [==============================] - 1s 654us/sample - loss: 1.2578 - sparse_categorical_accuracy: 0.3884 - val_loss: 1.1156 - val_sparse_categorical_accuracy: 0.4312\n",
            "Epoch 2/100\n",
            "981/981 [==============================] - 0s 150us/sample - loss: 0.9759 - sparse_categorical_accuracy: 0.4964 - val_loss: 0.9487 - val_sparse_categorical_accuracy: 0.4954\n",
            "Epoch 3/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.8583 - sparse_categorical_accuracy: 0.5719 - val_loss: 0.8548 - val_sparse_categorical_accuracy: 0.5780\n",
            "Epoch 4/100\n",
            "981/981 [==============================] - 0s 134us/sample - loss: 0.7956 - sparse_categorical_accuracy: 0.6218 - val_loss: 0.7985 - val_sparse_categorical_accuracy: 0.5963\n",
            "Epoch 5/100\n",
            "981/981 [==============================] - 0s 134us/sample - loss: 0.7503 - sparse_categorical_accuracy: 0.6442 - val_loss: 0.7535 - val_sparse_categorical_accuracy: 0.6514\n",
            "Epoch 6/100\n",
            "981/981 [==============================] - 0s 147us/sample - loss: 0.7142 - sparse_categorical_accuracy: 0.6616 - val_loss: 0.7197 - val_sparse_categorical_accuracy: 0.6697\n",
            "Epoch 7/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.6878 - sparse_categorical_accuracy: 0.6809 - val_loss: 0.6898 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 8/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.6629 - sparse_categorical_accuracy: 0.6983 - val_loss: 0.6694 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 9/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.6430 - sparse_categorical_accuracy: 0.7125 - val_loss: 0.6612 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 10/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.6261 - sparse_categorical_accuracy: 0.7156 - val_loss: 0.6414 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 11/100\n",
            "981/981 [==============================] - 0s 136us/sample - loss: 0.6120 - sparse_categorical_accuracy: 0.7197 - val_loss: 0.6258 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 12/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.5987 - sparse_categorical_accuracy: 0.7299 - val_loss: 0.6143 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 13/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.5887 - sparse_categorical_accuracy: 0.7380 - val_loss: 0.6074 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 14/100\n",
            "981/981 [==============================] - 0s 155us/sample - loss: 0.5768 - sparse_categorical_accuracy: 0.7472 - val_loss: 0.5995 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 15/100\n",
            "981/981 [==============================] - 0s 135us/sample - loss: 0.5668 - sparse_categorical_accuracy: 0.7523 - val_loss: 0.5888 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 16/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.5594 - sparse_categorical_accuracy: 0.7492 - val_loss: 0.5804 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 17/100\n",
            "981/981 [==============================] - 0s 144us/sample - loss: 0.5528 - sparse_categorical_accuracy: 0.7574 - val_loss: 0.5757 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 18/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.5457 - sparse_categorical_accuracy: 0.7533 - val_loss: 0.5730 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 19/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.5368 - sparse_categorical_accuracy: 0.7655 - val_loss: 0.5649 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 20/100\n",
            "981/981 [==============================] - 0s 152us/sample - loss: 0.5333 - sparse_categorical_accuracy: 0.7635 - val_loss: 0.5613 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 21/100\n",
            "981/981 [==============================] - 0s 154us/sample - loss: 0.5265 - sparse_categorical_accuracy: 0.7717 - val_loss: 0.5559 - val_sparse_categorical_accuracy: 0.7523\n",
            "Epoch 22/100\n",
            "981/981 [==============================] - 0s 145us/sample - loss: 0.5209 - sparse_categorical_accuracy: 0.7686 - val_loss: 0.5585 - val_sparse_categorical_accuracy: 0.7523\n",
            "Epoch 23/100\n",
            "981/981 [==============================] - 0s 143us/sample - loss: 0.5179 - sparse_categorical_accuracy: 0.7686 - val_loss: 0.5505 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 24/100\n",
            "981/981 [==============================] - 0s 136us/sample - loss: 0.5117 - sparse_categorical_accuracy: 0.7666 - val_loss: 0.5450 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 25/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.5074 - sparse_categorical_accuracy: 0.7757 - val_loss: 0.5531 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 26/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.5039 - sparse_categorical_accuracy: 0.7798 - val_loss: 0.5416 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 27/100\n",
            "981/981 [==============================] - 0s 145us/sample - loss: 0.5018 - sparse_categorical_accuracy: 0.7798 - val_loss: 0.5416 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 28/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.4975 - sparse_categorical_accuracy: 0.7839 - val_loss: 0.5416 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 29/100\n",
            "981/981 [==============================] - 0s 152us/sample - loss: 0.4936 - sparse_categorical_accuracy: 0.7829 - val_loss: 0.5421 - val_sparse_categorical_accuracy: 0.7523\n",
            "Epoch 30/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.4903 - sparse_categorical_accuracy: 0.7859 - val_loss: 0.5409 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 31/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.4889 - sparse_categorical_accuracy: 0.7747 - val_loss: 0.5375 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 32/100\n",
            "981/981 [==============================] - 0s 167us/sample - loss: 0.4853 - sparse_categorical_accuracy: 0.7849 - val_loss: 0.5372 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 33/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.4813 - sparse_categorical_accuracy: 0.7890 - val_loss: 0.5303 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 34/100\n",
            "981/981 [==============================] - 0s 139us/sample - loss: 0.4808 - sparse_categorical_accuracy: 0.7829 - val_loss: 0.5296 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 35/100\n",
            "981/981 [==============================] - 0s 141us/sample - loss: 0.4771 - sparse_categorical_accuracy: 0.7951 - val_loss: 0.5312 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 36/100\n",
            "981/981 [==============================] - 0s 160us/sample - loss: 0.4734 - sparse_categorical_accuracy: 0.7992 - val_loss: 0.5301 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 37/100\n",
            "981/981 [==============================] - 0s 139us/sample - loss: 0.4709 - sparse_categorical_accuracy: 0.7941 - val_loss: 0.5399 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 38/100\n",
            "981/981 [==============================] - 0s 158us/sample - loss: 0.4706 - sparse_categorical_accuracy: 0.7819 - val_loss: 0.5291 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 39/100\n",
            "981/981 [==============================] - 0s 141us/sample - loss: 0.4688 - sparse_categorical_accuracy: 0.7931 - val_loss: 0.5412 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 40/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.4681 - sparse_categorical_accuracy: 0.7941 - val_loss: 0.5300 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 41/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.4640 - sparse_categorical_accuracy: 0.7870 - val_loss: 0.5342 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 42/100\n",
            "981/981 [==============================] - 0s 151us/sample - loss: 0.4620 - sparse_categorical_accuracy: 0.7910 - val_loss: 0.5292 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 43/100\n",
            "981/981 [==============================] - 0s 166us/sample - loss: 0.4599 - sparse_categorical_accuracy: 0.7982 - val_loss: 0.5316 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 44/100\n",
            "981/981 [==============================] - 0s 137us/sample - loss: 0.4590 - sparse_categorical_accuracy: 0.7961 - val_loss: 0.5411 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 45/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.4579 - sparse_categorical_accuracy: 0.8053 - val_loss: 0.5396 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 46/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.4554 - sparse_categorical_accuracy: 0.7951 - val_loss: 0.5368 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 47/100\n",
            "981/981 [==============================] - 0s 140us/sample - loss: 0.4526 - sparse_categorical_accuracy: 0.7951 - val_loss: 0.5365 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 48/100\n",
            "981/981 [==============================] - 0s 139us/sample - loss: 0.4518 - sparse_categorical_accuracy: 0.8043 - val_loss: 0.5365 - val_sparse_categorical_accuracy: 0.7339\n",
            "[CV] ......................... n_neurons=45, n_hidden=2, total=   7.4s\n",
            "[CV] n_neurons=45, n_hidden=2 ........................................\n",
            "Train on 981 samples, validate on 110 samples\n",
            "Epoch 1/100\n",
            "981/981 [==============================] - 1s 647us/sample - loss: 1.2279 - sparse_categorical_accuracy: 0.4016 - val_loss: 0.9841 - val_sparse_categorical_accuracy: 0.5364\n",
            "Epoch 2/100\n",
            "981/981 [==============================] - 0s 151us/sample - loss: 0.9514 - sparse_categorical_accuracy: 0.5260 - val_loss: 0.8842 - val_sparse_categorical_accuracy: 0.6000\n",
            "Epoch 3/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.8399 - sparse_categorical_accuracy: 0.5719 - val_loss: 0.8274 - val_sparse_categorical_accuracy: 0.5909\n",
            "Epoch 4/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.7744 - sparse_categorical_accuracy: 0.6157 - val_loss: 0.7861 - val_sparse_categorical_accuracy: 0.6273\n",
            "Epoch 5/100\n",
            "981/981 [==============================] - 0s 140us/sample - loss: 0.7264 - sparse_categorical_accuracy: 0.6432 - val_loss: 0.7652 - val_sparse_categorical_accuracy: 0.6273\n",
            "Epoch 6/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.6972 - sparse_categorical_accuracy: 0.6544 - val_loss: 0.7331 - val_sparse_categorical_accuracy: 0.6273\n",
            "Epoch 7/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.6679 - sparse_categorical_accuracy: 0.6830 - val_loss: 0.7369 - val_sparse_categorical_accuracy: 0.6364\n",
            "Epoch 8/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.6473 - sparse_categorical_accuracy: 0.6850 - val_loss: 0.7063 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 9/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.6255 - sparse_categorical_accuracy: 0.7115 - val_loss: 0.6709 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 10/100\n",
            "981/981 [==============================] - 0s 142us/sample - loss: 0.6084 - sparse_categorical_accuracy: 0.7238 - val_loss: 0.6582 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 11/100\n",
            "981/981 [==============================] - 0s 151us/sample - loss: 0.5939 - sparse_categorical_accuracy: 0.7339 - val_loss: 0.6428 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 12/100\n",
            "981/981 [==============================] - 0s 152us/sample - loss: 0.5792 - sparse_categorical_accuracy: 0.7339 - val_loss: 0.6301 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 13/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.5690 - sparse_categorical_accuracy: 0.7492 - val_loss: 0.6229 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 14/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.5582 - sparse_categorical_accuracy: 0.7421 - val_loss: 0.6246 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 15/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.5453 - sparse_categorical_accuracy: 0.7492 - val_loss: 0.6178 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 16/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.5373 - sparse_categorical_accuracy: 0.7543 - val_loss: 0.6098 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 17/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.5299 - sparse_categorical_accuracy: 0.7615 - val_loss: 0.5943 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 18/100\n",
            "981/981 [==============================] - 0s 152us/sample - loss: 0.5213 - sparse_categorical_accuracy: 0.7635 - val_loss: 0.5904 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 19/100\n",
            "981/981 [==============================] - 0s 140us/sample - loss: 0.5142 - sparse_categorical_accuracy: 0.7635 - val_loss: 0.5814 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 20/100\n",
            "981/981 [==============================] - 0s 152us/sample - loss: 0.5053 - sparse_categorical_accuracy: 0.7666 - val_loss: 0.5704 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 21/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.5010 - sparse_categorical_accuracy: 0.7666 - val_loss: 0.5644 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 22/100\n",
            "981/981 [==============================] - 0s 147us/sample - loss: 0.4937 - sparse_categorical_accuracy: 0.7757 - val_loss: 0.5594 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 23/100\n",
            "981/981 [==============================] - 0s 140us/sample - loss: 0.4883 - sparse_categorical_accuracy: 0.7859 - val_loss: 0.5649 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 24/100\n",
            "981/981 [==============================] - 0s 134us/sample - loss: 0.4819 - sparse_categorical_accuracy: 0.7870 - val_loss: 0.5653 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 25/100\n",
            "981/981 [==============================] - 0s 134us/sample - loss: 0.4783 - sparse_categorical_accuracy: 0.7839 - val_loss: 0.5582 - val_sparse_categorical_accuracy: 0.7636\n",
            "Epoch 26/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.4732 - sparse_categorical_accuracy: 0.7920 - val_loss: 0.5507 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 27/100\n",
            "981/981 [==============================] - 0s 157us/sample - loss: 0.4690 - sparse_categorical_accuracy: 0.7900 - val_loss: 0.5513 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 28/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.4642 - sparse_categorical_accuracy: 0.7910 - val_loss: 0.5443 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 29/100\n",
            "981/981 [==============================] - 0s 151us/sample - loss: 0.4597 - sparse_categorical_accuracy: 0.7971 - val_loss: 0.5420 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 30/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.4569 - sparse_categorical_accuracy: 0.8022 - val_loss: 0.5364 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 31/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.4539 - sparse_categorical_accuracy: 0.7951 - val_loss: 0.5384 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 32/100\n",
            "981/981 [==============================] - 0s 136us/sample - loss: 0.4511 - sparse_categorical_accuracy: 0.7992 - val_loss: 0.5357 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 33/100\n",
            "981/981 [==============================] - 0s 146us/sample - loss: 0.4461 - sparse_categorical_accuracy: 0.7941 - val_loss: 0.5364 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 34/100\n",
            "981/981 [==============================] - 0s 142us/sample - loss: 0.4430 - sparse_categorical_accuracy: 0.8012 - val_loss: 0.5341 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 35/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.4389 - sparse_categorical_accuracy: 0.7992 - val_loss: 0.5340 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 36/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.4370 - sparse_categorical_accuracy: 0.8043 - val_loss: 0.5326 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 37/100\n",
            "981/981 [==============================] - 0s 135us/sample - loss: 0.4349 - sparse_categorical_accuracy: 0.8084 - val_loss: 0.5324 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 38/100\n",
            "981/981 [==============================] - 0s 143us/sample - loss: 0.4312 - sparse_categorical_accuracy: 0.8053 - val_loss: 0.5295 - val_sparse_categorical_accuracy: 0.7636\n",
            "Epoch 39/100\n",
            "981/981 [==============================] - 0s 134us/sample - loss: 0.4290 - sparse_categorical_accuracy: 0.8043 - val_loss: 0.5348 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 40/100\n",
            "981/981 [==============================] - 0s 151us/sample - loss: 0.4289 - sparse_categorical_accuracy: 0.8114 - val_loss: 0.5320 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 41/100\n",
            "981/981 [==============================] - 0s 146us/sample - loss: 0.4256 - sparse_categorical_accuracy: 0.8145 - val_loss: 0.5356 - val_sparse_categorical_accuracy: 0.7636\n",
            "Epoch 42/100\n",
            "981/981 [==============================] - 0s 148us/sample - loss: 0.4211 - sparse_categorical_accuracy: 0.8186 - val_loss: 0.5351 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 43/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.4231 - sparse_categorical_accuracy: 0.8073 - val_loss: 0.5274 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 44/100\n",
            "981/981 [==============================] - 0s 145us/sample - loss: 0.4177 - sparse_categorical_accuracy: 0.8135 - val_loss: 0.5283 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 45/100\n",
            "981/981 [==============================] - 0s 135us/sample - loss: 0.4152 - sparse_categorical_accuracy: 0.8033 - val_loss: 0.5329 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 46/100\n",
            "981/981 [==============================] - 0s 149us/sample - loss: 0.4154 - sparse_categorical_accuracy: 0.8135 - val_loss: 0.5270 - val_sparse_categorical_accuracy: 0.7636\n",
            "Epoch 47/100\n",
            "981/981 [==============================] - 0s 145us/sample - loss: 0.4120 - sparse_categorical_accuracy: 0.8084 - val_loss: 0.5365 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 48/100\n",
            "981/981 [==============================] - 0s 145us/sample - loss: 0.4102 - sparse_categorical_accuracy: 0.8114 - val_loss: 0.5342 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 49/100\n",
            "981/981 [==============================] - 0s 140us/sample - loss: 0.4092 - sparse_categorical_accuracy: 0.8165 - val_loss: 0.5426 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 50/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.4069 - sparse_categorical_accuracy: 0.8145 - val_loss: 0.5355 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 51/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.4049 - sparse_categorical_accuracy: 0.8186 - val_loss: 0.5303 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 52/100\n",
            "981/981 [==============================] - 0s 143us/sample - loss: 0.4009 - sparse_categorical_accuracy: 0.8298 - val_loss: 0.5284 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 53/100\n",
            "981/981 [==============================] - 0s 161us/sample - loss: 0.4032 - sparse_categorical_accuracy: 0.8104 - val_loss: 0.5308 - val_sparse_categorical_accuracy: 0.7636\n",
            "Epoch 54/100\n",
            "981/981 [==============================] - 0s 173us/sample - loss: 0.4006 - sparse_categorical_accuracy: 0.8124 - val_loss: 0.5389 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 55/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.3987 - sparse_categorical_accuracy: 0.8226 - val_loss: 0.5337 - val_sparse_categorical_accuracy: 0.7636\n",
            "Epoch 56/100\n",
            "981/981 [==============================] - 0s 143us/sample - loss: 0.3947 - sparse_categorical_accuracy: 0.8196 - val_loss: 0.5342 - val_sparse_categorical_accuracy: 0.7364\n",
            "[CV] ......................... n_neurons=45, n_hidden=2, total=   8.5s\n",
            "[CV] n_neurons=45, n_hidden=2 ........................................\n",
            "Train on 981 samples, validate on 110 samples\n",
            "Epoch 1/100\n",
            "981/981 [==============================] - 1s 647us/sample - loss: 1.1906 - sparse_categorical_accuracy: 0.4067 - val_loss: 1.0258 - val_sparse_categorical_accuracy: 0.4273\n",
            "Epoch 2/100\n",
            "981/981 [==============================] - 0s 159us/sample - loss: 0.9511 - sparse_categorical_accuracy: 0.4995 - val_loss: 0.8965 - val_sparse_categorical_accuracy: 0.5000\n",
            "Epoch 3/100\n",
            "981/981 [==============================] - 0s 134us/sample - loss: 0.8565 - sparse_categorical_accuracy: 0.5627 - val_loss: 0.8266 - val_sparse_categorical_accuracy: 0.5545\n",
            "Epoch 4/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.7948 - sparse_categorical_accuracy: 0.6086 - val_loss: 0.7862 - val_sparse_categorical_accuracy: 0.6182\n",
            "Epoch 5/100\n",
            "981/981 [==============================] - 0s 151us/sample - loss: 0.7507 - sparse_categorical_accuracy: 0.6351 - val_loss: 0.7497 - val_sparse_categorical_accuracy: 0.5909\n",
            "Epoch 6/100\n",
            "981/981 [==============================] - 0s 135us/sample - loss: 0.7151 - sparse_categorical_accuracy: 0.6544 - val_loss: 0.7225 - val_sparse_categorical_accuracy: 0.5818\n",
            "Epoch 7/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.6860 - sparse_categorical_accuracy: 0.6769 - val_loss: 0.6997 - val_sparse_categorical_accuracy: 0.6273\n",
            "Epoch 8/100\n",
            "981/981 [==============================] - 0s 148us/sample - loss: 0.6607 - sparse_categorical_accuracy: 0.6993 - val_loss: 0.6787 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 9/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.6394 - sparse_categorical_accuracy: 0.7023 - val_loss: 0.6606 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 10/100\n",
            "981/981 [==============================] - 0s 147us/sample - loss: 0.6205 - sparse_categorical_accuracy: 0.7136 - val_loss: 0.6541 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 11/100\n",
            "981/981 [==============================] - 0s 140us/sample - loss: 0.6047 - sparse_categorical_accuracy: 0.7054 - val_loss: 0.6382 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 12/100\n",
            "981/981 [==============================] - 0s 134us/sample - loss: 0.5923 - sparse_categorical_accuracy: 0.7258 - val_loss: 0.6294 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 13/100\n",
            "981/981 [==============================] - 0s 146us/sample - loss: 0.5777 - sparse_categorical_accuracy: 0.7248 - val_loss: 0.6184 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 14/100\n",
            "981/981 [==============================] - 0s 135us/sample - loss: 0.5686 - sparse_categorical_accuracy: 0.7217 - val_loss: 0.6102 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 15/100\n",
            "981/981 [==============================] - 0s 147us/sample - loss: 0.5575 - sparse_categorical_accuracy: 0.7390 - val_loss: 0.6051 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 16/100\n",
            "981/981 [==============================] - 0s 141us/sample - loss: 0.5488 - sparse_categorical_accuracy: 0.7360 - val_loss: 0.6023 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 17/100\n",
            "981/981 [==============================] - 0s 148us/sample - loss: 0.5415 - sparse_categorical_accuracy: 0.7503 - val_loss: 0.5937 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 18/100\n",
            "981/981 [==============================] - 0s 139us/sample - loss: 0.5334 - sparse_categorical_accuracy: 0.7564 - val_loss: 0.6012 - val_sparse_categorical_accuracy: 0.7636\n",
            "Epoch 19/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.5282 - sparse_categorical_accuracy: 0.7533 - val_loss: 0.5925 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 20/100\n",
            "981/981 [==============================] - 0s 149us/sample - loss: 0.5202 - sparse_categorical_accuracy: 0.7533 - val_loss: 0.5852 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 21/100\n",
            "981/981 [==============================] - 0s 143us/sample - loss: 0.5157 - sparse_categorical_accuracy: 0.7574 - val_loss: 0.5817 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 22/100\n",
            "981/981 [==============================] - 0s 144us/sample - loss: 0.5106 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.5770 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 23/100\n",
            "981/981 [==============================] - 0s 150us/sample - loss: 0.5035 - sparse_categorical_accuracy: 0.7696 - val_loss: 0.5849 - val_sparse_categorical_accuracy: 0.7636\n",
            "Epoch 24/100\n",
            "981/981 [==============================] - 0s 154us/sample - loss: 0.5010 - sparse_categorical_accuracy: 0.7676 - val_loss: 0.5721 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 25/100\n",
            "981/981 [==============================] - 0s 160us/sample - loss: 0.4959 - sparse_categorical_accuracy: 0.7717 - val_loss: 0.5719 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 26/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.4924 - sparse_categorical_accuracy: 0.7747 - val_loss: 0.5728 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 27/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.4890 - sparse_categorical_accuracy: 0.7757 - val_loss: 0.5751 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 28/100\n",
            "981/981 [==============================] - 0s 152us/sample - loss: 0.4855 - sparse_categorical_accuracy: 0.7727 - val_loss: 0.5696 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 29/100\n",
            "981/981 [==============================] - 0s 142us/sample - loss: 0.4817 - sparse_categorical_accuracy: 0.7778 - val_loss: 0.5679 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 30/100\n",
            "981/981 [==============================] - 0s 146us/sample - loss: 0.4787 - sparse_categorical_accuracy: 0.7717 - val_loss: 0.5676 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 31/100\n",
            "981/981 [==============================] - 0s 150us/sample - loss: 0.4747 - sparse_categorical_accuracy: 0.7788 - val_loss: 0.5684 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 32/100\n",
            "981/981 [==============================] - 0s 145us/sample - loss: 0.4734 - sparse_categorical_accuracy: 0.7808 - val_loss: 0.5712 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 33/100\n",
            "981/981 [==============================] - 0s 137us/sample - loss: 0.4697 - sparse_categorical_accuracy: 0.7819 - val_loss: 0.5672 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 34/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.4657 - sparse_categorical_accuracy: 0.7839 - val_loss: 0.5687 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 35/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.4636 - sparse_categorical_accuracy: 0.7971 - val_loss: 0.5674 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 36/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.4598 - sparse_categorical_accuracy: 0.7910 - val_loss: 0.5729 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 37/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.4593 - sparse_categorical_accuracy: 0.7880 - val_loss: 0.5758 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 38/100\n",
            "981/981 [==============================] - 0s 148us/sample - loss: 0.4568 - sparse_categorical_accuracy: 0.7910 - val_loss: 0.5649 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 39/100\n",
            "981/981 [==============================] - 0s 154us/sample - loss: 0.4554 - sparse_categorical_accuracy: 0.7880 - val_loss: 0.5655 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 40/100\n",
            "981/981 [==============================] - 0s 145us/sample - loss: 0.4529 - sparse_categorical_accuracy: 0.7849 - val_loss: 0.5700 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 41/100\n",
            "981/981 [==============================] - 0s 148us/sample - loss: 0.4502 - sparse_categorical_accuracy: 0.7931 - val_loss: 0.5742 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 42/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.4484 - sparse_categorical_accuracy: 0.8002 - val_loss: 0.5650 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 43/100\n",
            "981/981 [==============================] - 0s 146us/sample - loss: 0.4450 - sparse_categorical_accuracy: 0.7910 - val_loss: 0.5661 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 44/100\n",
            "981/981 [==============================] - 0s 148us/sample - loss: 0.4424 - sparse_categorical_accuracy: 0.7941 - val_loss: 0.5801 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 45/100\n",
            "981/981 [==============================] - 0s 143us/sample - loss: 0.4424 - sparse_categorical_accuracy: 0.7951 - val_loss: 0.5666 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 46/100\n",
            "981/981 [==============================] - 0s 145us/sample - loss: 0.4413 - sparse_categorical_accuracy: 0.7920 - val_loss: 0.5699 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 47/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.4385 - sparse_categorical_accuracy: 0.7982 - val_loss: 0.5676 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 48/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.4358 - sparse_categorical_accuracy: 0.8002 - val_loss: 0.5681 - val_sparse_categorical_accuracy: 0.7273\n",
            "[CV] ......................... n_neurons=45, n_hidden=2, total=   7.5s\n",
            "[CV] n_neurons=38, n_hidden=5 ........................................\n",
            "Train on 981 samples, validate on 109 samples\n",
            "Epoch 1/100\n",
            "981/981 [==============================] - 1s 924us/sample - loss: 1.0462 - sparse_categorical_accuracy: 0.4638 - val_loss: 0.8361 - val_sparse_categorical_accuracy: 0.6147\n",
            "Epoch 2/100\n",
            "981/981 [==============================] - 0s 165us/sample - loss: 0.8425 - sparse_categorical_accuracy: 0.5800 - val_loss: 0.7794 - val_sparse_categorical_accuracy: 0.6697\n",
            "Epoch 3/100\n",
            "981/981 [==============================] - 0s 164us/sample - loss: 0.7635 - sparse_categorical_accuracy: 0.6269 - val_loss: 0.7390 - val_sparse_categorical_accuracy: 0.6514\n",
            "Epoch 4/100\n",
            "981/981 [==============================] - 0s 156us/sample - loss: 0.7096 - sparse_categorical_accuracy: 0.6544 - val_loss: 0.7083 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 5/100\n",
            "981/981 [==============================] - 0s 174us/sample - loss: 0.6671 - sparse_categorical_accuracy: 0.6758 - val_loss: 0.6891 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 6/100\n",
            "981/981 [==============================] - 0s 157us/sample - loss: 0.6339 - sparse_categorical_accuracy: 0.6962 - val_loss: 0.6723 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 7/100\n",
            "981/981 [==============================] - 0s 153us/sample - loss: 0.6017 - sparse_categorical_accuracy: 0.6962 - val_loss: 0.6501 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 8/100\n",
            "981/981 [==============================] - 0s 152us/sample - loss: 0.5718 - sparse_categorical_accuracy: 0.7268 - val_loss: 0.6516 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 9/100\n",
            "981/981 [==============================] - 0s 160us/sample - loss: 0.5536 - sparse_categorical_accuracy: 0.7268 - val_loss: 0.6257 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 10/100\n",
            "981/981 [==============================] - 0s 158us/sample - loss: 0.5265 - sparse_categorical_accuracy: 0.7533 - val_loss: 0.6220 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 11/100\n",
            "981/981 [==============================] - 0s 179us/sample - loss: 0.5135 - sparse_categorical_accuracy: 0.7615 - val_loss: 0.6289 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 12/100\n",
            "981/981 [==============================] - 0s 163us/sample - loss: 0.4989 - sparse_categorical_accuracy: 0.7778 - val_loss: 0.6343 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 13/100\n",
            "981/981 [==============================] - 0s 186us/sample - loss: 0.4913 - sparse_categorical_accuracy: 0.7768 - val_loss: 0.6167 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 14/100\n",
            "981/981 [==============================] - 0s 179us/sample - loss: 0.4738 - sparse_categorical_accuracy: 0.7849 - val_loss: 0.6352 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 15/100\n",
            "981/981 [==============================] - 0s 157us/sample - loss: 0.4616 - sparse_categorical_accuracy: 0.7910 - val_loss: 0.6224 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 16/100\n",
            "981/981 [==============================] - 0s 158us/sample - loss: 0.4593 - sparse_categorical_accuracy: 0.8022 - val_loss: 0.6296 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 17/100\n",
            "981/981 [==============================] - 0s 175us/sample - loss: 0.4462 - sparse_categorical_accuracy: 0.7971 - val_loss: 0.6405 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 18/100\n",
            "981/981 [==============================] - 0s 158us/sample - loss: 0.4338 - sparse_categorical_accuracy: 0.8063 - val_loss: 0.6297 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 19/100\n",
            "981/981 [==============================] - 0s 151us/sample - loss: 0.4262 - sparse_categorical_accuracy: 0.8104 - val_loss: 0.6298 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 20/100\n",
            "981/981 [==============================] - 0s 172us/sample - loss: 0.4227 - sparse_categorical_accuracy: 0.8186 - val_loss: 0.6356 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 21/100\n",
            "981/981 [==============================] - 0s 157us/sample - loss: 0.4125 - sparse_categorical_accuracy: 0.8216 - val_loss: 0.6677 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 22/100\n",
            "981/981 [==============================] - 0s 150us/sample - loss: 0.4072 - sparse_categorical_accuracy: 0.8216 - val_loss: 0.6361 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 23/100\n",
            "981/981 [==============================] - 0s 156us/sample - loss: 0.3977 - sparse_categorical_accuracy: 0.8287 - val_loss: 0.6493 - val_sparse_categorical_accuracy: 0.7339\n",
            "[CV] ......................... n_neurons=38, n_hidden=5, total=   4.8s\n",
            "[CV] n_neurons=38, n_hidden=5 ........................................\n",
            "Train on 981 samples, validate on 109 samples\n",
            "Epoch 1/100\n",
            "981/981 [==============================] - 1s 933us/sample - loss: 1.0513 - sparse_categorical_accuracy: 0.4903 - val_loss: 0.9701 - val_sparse_categorical_accuracy: 0.4954\n",
            "Epoch 2/100\n",
            "981/981 [==============================] - 0s 159us/sample - loss: 0.8750 - sparse_categorical_accuracy: 0.5749 - val_loss: 0.7866 - val_sparse_categorical_accuracy: 0.5688\n",
            "Epoch 3/100\n",
            "981/981 [==============================] - 0s 150us/sample - loss: 0.7884 - sparse_categorical_accuracy: 0.6004 - val_loss: 0.7887 - val_sparse_categorical_accuracy: 0.5780\n",
            "Epoch 4/100\n",
            "981/981 [==============================] - 0s 168us/sample - loss: 0.7260 - sparse_categorical_accuracy: 0.6340 - val_loss: 0.7301 - val_sparse_categorical_accuracy: 0.6055\n",
            "Epoch 5/100\n",
            "981/981 [==============================] - 0s 150us/sample - loss: 0.6769 - sparse_categorical_accuracy: 0.6687 - val_loss: 0.6792 - val_sparse_categorical_accuracy: 0.6422\n",
            "Epoch 6/100\n",
            "981/981 [==============================] - 0s 173us/sample - loss: 0.6431 - sparse_categorical_accuracy: 0.6993 - val_loss: 0.6457 - val_sparse_categorical_accuracy: 0.6697\n",
            "Epoch 7/100\n",
            "981/981 [==============================] - 0s 174us/sample - loss: 0.6113 - sparse_categorical_accuracy: 0.7074 - val_loss: 0.6281 - val_sparse_categorical_accuracy: 0.6514\n",
            "Epoch 8/100\n",
            "981/981 [==============================] - 0s 180us/sample - loss: 0.5813 - sparse_categorical_accuracy: 0.7268 - val_loss: 0.6234 - val_sparse_categorical_accuracy: 0.6514\n",
            "Epoch 9/100\n",
            "981/981 [==============================] - 0s 167us/sample - loss: 0.5655 - sparse_categorical_accuracy: 0.7390 - val_loss: 0.6171 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 10/100\n",
            "981/981 [==============================] - 0s 159us/sample - loss: 0.5483 - sparse_categorical_accuracy: 0.7543 - val_loss: 0.6117 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 11/100\n",
            "981/981 [==============================] - 0s 156us/sample - loss: 0.5316 - sparse_categorical_accuracy: 0.7594 - val_loss: 0.5862 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 12/100\n",
            "981/981 [==============================] - 0s 158us/sample - loss: 0.5184 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.5804 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 13/100\n",
            "981/981 [==============================] - 0s 174us/sample - loss: 0.5004 - sparse_categorical_accuracy: 0.7788 - val_loss: 0.5994 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 14/100\n",
            "981/981 [==============================] - 0s 171us/sample - loss: 0.4941 - sparse_categorical_accuracy: 0.7788 - val_loss: 0.5638 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 15/100\n",
            "981/981 [==============================] - 0s 184us/sample - loss: 0.4807 - sparse_categorical_accuracy: 0.7839 - val_loss: 0.5658 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 16/100\n",
            "981/981 [==============================] - 0s 157us/sample - loss: 0.4718 - sparse_categorical_accuracy: 0.7982 - val_loss: 0.5662 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 17/100\n",
            "981/981 [==============================] - 0s 171us/sample - loss: 0.4553 - sparse_categorical_accuracy: 0.8002 - val_loss: 0.5684 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 18/100\n",
            "981/981 [==============================] - 0s 158us/sample - loss: 0.4527 - sparse_categorical_accuracy: 0.7920 - val_loss: 0.6209 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 19/100\n",
            "981/981 [==============================] - 0s 178us/sample - loss: 0.4430 - sparse_categorical_accuracy: 0.8186 - val_loss: 0.5613 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 20/100\n",
            "981/981 [==============================] - 0s 157us/sample - loss: 0.4349 - sparse_categorical_accuracy: 0.8114 - val_loss: 0.5887 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 21/100\n",
            "981/981 [==============================] - 0s 163us/sample - loss: 0.4256 - sparse_categorical_accuracy: 0.8206 - val_loss: 0.6013 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 22/100\n",
            "981/981 [==============================] - 0s 150us/sample - loss: 0.4193 - sparse_categorical_accuracy: 0.8206 - val_loss: 0.5771 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 23/100\n",
            "981/981 [==============================] - 0s 156us/sample - loss: 0.4198 - sparse_categorical_accuracy: 0.8175 - val_loss: 0.5836 - val_sparse_categorical_accuracy: 0.7523\n",
            "Epoch 24/100\n",
            "981/981 [==============================] - 0s 155us/sample - loss: 0.4081 - sparse_categorical_accuracy: 0.8338 - val_loss: 0.5741 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 25/100\n",
            "981/981 [==============================] - 0s 177us/sample - loss: 0.4025 - sparse_categorical_accuracy: 0.8379 - val_loss: 0.5932 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 26/100\n",
            "981/981 [==============================] - 0s 165us/sample - loss: 0.3991 - sparse_categorical_accuracy: 0.8318 - val_loss: 0.5961 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 27/100\n",
            "981/981 [==============================] - 0s 160us/sample - loss: 0.3810 - sparse_categorical_accuracy: 0.8410 - val_loss: 0.5885 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 28/100\n",
            "981/981 [==============================] - 0s 158us/sample - loss: 0.3806 - sparse_categorical_accuracy: 0.8400 - val_loss: 0.5847 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 29/100\n",
            "981/981 [==============================] - 0s 167us/sample - loss: 0.3742 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.5913 - val_sparse_categorical_accuracy: 0.7156\n",
            "[CV] ......................... n_neurons=38, n_hidden=5, total=   5.8s\n",
            "[CV] n_neurons=38, n_hidden=5 ........................................\n",
            "Train on 981 samples, validate on 109 samples\n",
            "Epoch 1/100\n",
            "981/981 [==============================] - 1s 898us/sample - loss: 1.0925 - sparse_categorical_accuracy: 0.4210 - val_loss: 0.9541 - val_sparse_categorical_accuracy: 0.4954\n",
            "Epoch 2/100\n",
            "981/981 [==============================] - 0s 186us/sample - loss: 0.8907 - sparse_categorical_accuracy: 0.5423 - val_loss: 0.8599 - val_sparse_categorical_accuracy: 0.5780\n",
            "Epoch 3/100\n",
            "981/981 [==============================] - 0s 170us/sample - loss: 0.8103 - sparse_categorical_accuracy: 0.5821 - val_loss: 0.7980 - val_sparse_categorical_accuracy: 0.6330\n",
            "Epoch 4/100\n",
            "981/981 [==============================] - 0s 162us/sample - loss: 0.7576 - sparse_categorical_accuracy: 0.5984 - val_loss: 0.7548 - val_sparse_categorical_accuracy: 0.6606\n",
            "Epoch 5/100\n",
            "981/981 [==============================] - 0s 169us/sample - loss: 0.7130 - sparse_categorical_accuracy: 0.6290 - val_loss: 0.7203 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 6/100\n",
            "981/981 [==============================] - 0s 160us/sample - loss: 0.6804 - sparse_categorical_accuracy: 0.6534 - val_loss: 0.6966 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 7/100\n",
            "981/981 [==============================] - 0s 157us/sample - loss: 0.6510 - sparse_categorical_accuracy: 0.6656 - val_loss: 0.6647 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 8/100\n",
            "981/981 [==============================] - 0s 164us/sample - loss: 0.6233 - sparse_categorical_accuracy: 0.6840 - val_loss: 0.6661 - val_sparse_categorical_accuracy: 0.6697\n",
            "Epoch 9/100\n",
            "981/981 [==============================] - 0s 173us/sample - loss: 0.6051 - sparse_categorical_accuracy: 0.7034 - val_loss: 0.6512 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 10/100\n",
            "981/981 [==============================] - 0s 177us/sample - loss: 0.5838 - sparse_categorical_accuracy: 0.7187 - val_loss: 0.6211 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 11/100\n",
            "981/981 [==============================] - 0s 188us/sample - loss: 0.5685 - sparse_categorical_accuracy: 0.7197 - val_loss: 0.6017 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 12/100\n",
            "981/981 [==============================] - 0s 165us/sample - loss: 0.5515 - sparse_categorical_accuracy: 0.7380 - val_loss: 0.5933 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 13/100\n",
            "981/981 [==============================] - 0s 151us/sample - loss: 0.5335 - sparse_categorical_accuracy: 0.7401 - val_loss: 0.6040 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 14/100\n",
            "981/981 [==============================] - 0s 178us/sample - loss: 0.5290 - sparse_categorical_accuracy: 0.7645 - val_loss: 0.5803 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 15/100\n",
            "981/981 [==============================] - 0s 157us/sample - loss: 0.5173 - sparse_categorical_accuracy: 0.7523 - val_loss: 0.5958 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 16/100\n",
            "981/981 [==============================] - 0s 155us/sample - loss: 0.5020 - sparse_categorical_accuracy: 0.7676 - val_loss: 0.5863 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 17/100\n",
            "981/981 [==============================] - 0s 160us/sample - loss: 0.4925 - sparse_categorical_accuracy: 0.7757 - val_loss: 0.5787 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 18/100\n",
            "981/981 [==============================] - 0s 159us/sample - loss: 0.4872 - sparse_categorical_accuracy: 0.7686 - val_loss: 0.5669 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 19/100\n",
            "981/981 [==============================] - 0s 159us/sample - loss: 0.4821 - sparse_categorical_accuracy: 0.7859 - val_loss: 0.5642 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 20/100\n",
            "981/981 [==============================] - 0s 160us/sample - loss: 0.4730 - sparse_categorical_accuracy: 0.7839 - val_loss: 0.5750 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 21/100\n",
            "981/981 [==============================] - 0s 180us/sample - loss: 0.4646 - sparse_categorical_accuracy: 0.7920 - val_loss: 0.5803 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 22/100\n",
            "981/981 [==============================] - 0s 177us/sample - loss: 0.4543 - sparse_categorical_accuracy: 0.8012 - val_loss: 0.5694 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 23/100\n",
            "981/981 [==============================] - 0s 167us/sample - loss: 0.4477 - sparse_categorical_accuracy: 0.8124 - val_loss: 0.5941 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 24/100\n",
            "981/981 [==============================] - 0s 160us/sample - loss: 0.4416 - sparse_categorical_accuracy: 0.8033 - val_loss: 0.5830 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 25/100\n",
            "981/981 [==============================] - 0s 158us/sample - loss: 0.4337 - sparse_categorical_accuracy: 0.8226 - val_loss: 0.5861 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 26/100\n",
            "981/981 [==============================] - 0s 169us/sample - loss: 0.4276 - sparse_categorical_accuracy: 0.8226 - val_loss: 0.5853 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 27/100\n",
            "981/981 [==============================] - 0s 181us/sample - loss: 0.4218 - sparse_categorical_accuracy: 0.8114 - val_loss: 0.5870 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 28/100\n",
            "981/981 [==============================] - 0s 152us/sample - loss: 0.4143 - sparse_categorical_accuracy: 0.8226 - val_loss: 0.6009 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 29/100\n",
            "981/981 [==============================] - 0s 157us/sample - loss: 0.4128 - sparse_categorical_accuracy: 0.8196 - val_loss: 0.5874 - val_sparse_categorical_accuracy: 0.7064\n",
            "[CV] ......................... n_neurons=38, n_hidden=5, total=   5.9s\n",
            "[CV] n_neurons=38, n_hidden=5 ........................................\n",
            "Train on 981 samples, validate on 110 samples\n",
            "Epoch 1/100\n",
            "981/981 [==============================] - 1s 920us/sample - loss: 1.0527 - sparse_categorical_accuracy: 0.4577 - val_loss: 0.9297 - val_sparse_categorical_accuracy: 0.5364\n",
            "Epoch 2/100\n",
            "981/981 [==============================] - 0s 162us/sample - loss: 0.8128 - sparse_categorical_accuracy: 0.5841 - val_loss: 0.8181 - val_sparse_categorical_accuracy: 0.5818\n",
            "Epoch 3/100\n",
            "981/981 [==============================] - 0s 163us/sample - loss: 0.7137 - sparse_categorical_accuracy: 0.6402 - val_loss: 0.7465 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 4/100\n",
            "981/981 [==============================] - 0s 172us/sample - loss: 0.6479 - sparse_categorical_accuracy: 0.6748 - val_loss: 0.7014 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 5/100\n",
            "981/981 [==============================] - 0s 152us/sample - loss: 0.6030 - sparse_categorical_accuracy: 0.7217 - val_loss: 0.6887 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 6/100\n",
            "981/981 [==============================] - 0s 154us/sample - loss: 0.5671 - sparse_categorical_accuracy: 0.7421 - val_loss: 0.6674 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 7/100\n",
            "981/981 [==============================] - 0s 184us/sample - loss: 0.5464 - sparse_categorical_accuracy: 0.7513 - val_loss: 0.6508 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 8/100\n",
            "981/981 [==============================] - 0s 173us/sample - loss: 0.5218 - sparse_categorical_accuracy: 0.7584 - val_loss: 0.6381 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 9/100\n",
            "981/981 [==============================] - 0s 157us/sample - loss: 0.5057 - sparse_categorical_accuracy: 0.7798 - val_loss: 0.6375 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 10/100\n",
            "981/981 [==============================] - 0s 186us/sample - loss: 0.4899 - sparse_categorical_accuracy: 0.7849 - val_loss: 0.6256 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 11/100\n",
            "981/981 [==============================] - 0s 172us/sample - loss: 0.4734 - sparse_categorical_accuracy: 0.7961 - val_loss: 0.6207 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 12/100\n",
            "981/981 [==============================] - 0s 173us/sample - loss: 0.4586 - sparse_categorical_accuracy: 0.7941 - val_loss: 0.6196 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 13/100\n",
            "981/981 [==============================] - 0s 163us/sample - loss: 0.4475 - sparse_categorical_accuracy: 0.8124 - val_loss: 0.6115 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 14/100\n",
            "981/981 [==============================] - 0s 168us/sample - loss: 0.4400 - sparse_categorical_accuracy: 0.8073 - val_loss: 0.6057 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 15/100\n",
            "981/981 [==============================] - 0s 157us/sample - loss: 0.4320 - sparse_categorical_accuracy: 0.8175 - val_loss: 0.6098 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 16/100\n",
            "981/981 [==============================] - 0s 184us/sample - loss: 0.4210 - sparse_categorical_accuracy: 0.8267 - val_loss: 0.6043 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 17/100\n",
            "981/981 [==============================] - 0s 154us/sample - loss: 0.4171 - sparse_categorical_accuracy: 0.8267 - val_loss: 0.6042 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 18/100\n",
            "981/981 [==============================] - 0s 154us/sample - loss: 0.4090 - sparse_categorical_accuracy: 0.8216 - val_loss: 0.6025 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 19/100\n",
            "981/981 [==============================] - 0s 154us/sample - loss: 0.3956 - sparse_categorical_accuracy: 0.8359 - val_loss: 0.6228 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 20/100\n",
            "981/981 [==============================] - 0s 157us/sample - loss: 0.3911 - sparse_categorical_accuracy: 0.8420 - val_loss: 0.6292 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 21/100\n",
            "981/981 [==============================] - 0s 159us/sample - loss: 0.3863 - sparse_categorical_accuracy: 0.8369 - val_loss: 0.6103 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 22/100\n",
            "981/981 [==============================] - 0s 169us/sample - loss: 0.3814 - sparse_categorical_accuracy: 0.8451 - val_loss: 0.6244 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 23/100\n",
            "981/981 [==============================] - 0s 168us/sample - loss: 0.3721 - sparse_categorical_accuracy: 0.8451 - val_loss: 0.6186 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 24/100\n",
            "981/981 [==============================] - 0s 151us/sample - loss: 0.3652 - sparse_categorical_accuracy: 0.8440 - val_loss: 0.6229 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 25/100\n",
            "981/981 [==============================] - 0s 172us/sample - loss: 0.3588 - sparse_categorical_accuracy: 0.8552 - val_loss: 0.6070 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 26/100\n",
            "981/981 [==============================] - 0s 161us/sample - loss: 0.3553 - sparse_categorical_accuracy: 0.8532 - val_loss: 0.6203 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 27/100\n",
            "981/981 [==============================] - 0s 166us/sample - loss: 0.3488 - sparse_categorical_accuracy: 0.8542 - val_loss: 0.6309 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 28/100\n",
            "981/981 [==============================] - 0s 184us/sample - loss: 0.3391 - sparse_categorical_accuracy: 0.8614 - val_loss: 0.6473 - val_sparse_categorical_accuracy: 0.7182\n",
            "[CV] ......................... n_neurons=38, n_hidden=5, total=   5.7s\n",
            "[CV] n_neurons=38, n_hidden=5 ........................................\n",
            "Train on 981 samples, validate on 110 samples\n",
            "Epoch 1/100\n",
            "981/981 [==============================] - 1s 924us/sample - loss: 1.0286 - sparse_categorical_accuracy: 0.4750 - val_loss: 0.9226 - val_sparse_categorical_accuracy: 0.4818\n",
            "Epoch 2/100\n",
            "981/981 [==============================] - 0s 156us/sample - loss: 0.8461 - sparse_categorical_accuracy: 0.5698 - val_loss: 0.8027 - val_sparse_categorical_accuracy: 0.6091\n",
            "Epoch 3/100\n",
            "981/981 [==============================] - 0s 158us/sample - loss: 0.7694 - sparse_categorical_accuracy: 0.6218 - val_loss: 0.7811 - val_sparse_categorical_accuracy: 0.6000\n",
            "Epoch 4/100\n",
            "981/981 [==============================] - 0s 162us/sample - loss: 0.7168 - sparse_categorical_accuracy: 0.6575 - val_loss: 0.7146 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 5/100\n",
            "981/981 [==============================] - 0s 161us/sample - loss: 0.6666 - sparse_categorical_accuracy: 0.6707 - val_loss: 0.6779 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 6/100\n",
            "981/981 [==============================] - 0s 156us/sample - loss: 0.6304 - sparse_categorical_accuracy: 0.7003 - val_loss: 0.6613 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 7/100\n",
            "981/981 [==============================] - 0s 165us/sample - loss: 0.6043 - sparse_categorical_accuracy: 0.7146 - val_loss: 0.6391 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 8/100\n",
            "981/981 [==============================] - 0s 168us/sample - loss: 0.5733 - sparse_categorical_accuracy: 0.7258 - val_loss: 0.6235 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 9/100\n",
            "981/981 [==============================] - 0s 154us/sample - loss: 0.5519 - sparse_categorical_accuracy: 0.7350 - val_loss: 0.6318 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 10/100\n",
            "981/981 [==============================] - 0s 163us/sample - loss: 0.5370 - sparse_categorical_accuracy: 0.7401 - val_loss: 0.6190 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 11/100\n",
            "981/981 [==============================] - 0s 164us/sample - loss: 0.5195 - sparse_categorical_accuracy: 0.7513 - val_loss: 0.6178 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 12/100\n",
            "981/981 [==============================] - 0s 160us/sample - loss: 0.5054 - sparse_categorical_accuracy: 0.7666 - val_loss: 0.6422 - val_sparse_categorical_accuracy: 0.6364\n",
            "Epoch 13/100\n",
            "981/981 [==============================] - 0s 174us/sample - loss: 0.4941 - sparse_categorical_accuracy: 0.7655 - val_loss: 0.5939 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 14/100\n",
            "981/981 [==============================] - 0s 165us/sample - loss: 0.4844 - sparse_categorical_accuracy: 0.7594 - val_loss: 0.5958 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 15/100\n",
            "981/981 [==============================] - 0s 155us/sample - loss: 0.4761 - sparse_categorical_accuracy: 0.7798 - val_loss: 0.6033 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 16/100\n",
            "981/981 [==============================] - 0s 151us/sample - loss: 0.4634 - sparse_categorical_accuracy: 0.7859 - val_loss: 0.6051 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 17/100\n",
            "981/981 [==============================] - 0s 158us/sample - loss: 0.4627 - sparse_categorical_accuracy: 0.7788 - val_loss: 0.6043 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 18/100\n",
            "981/981 [==============================] - 0s 166us/sample - loss: 0.4458 - sparse_categorical_accuracy: 0.7900 - val_loss: 0.5992 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 19/100\n",
            "981/981 [==============================] - 0s 160us/sample - loss: 0.4450 - sparse_categorical_accuracy: 0.7819 - val_loss: 0.5865 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 20/100\n",
            "981/981 [==============================] - 0s 169us/sample - loss: 0.4315 - sparse_categorical_accuracy: 0.8022 - val_loss: 0.6026 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 21/100\n",
            "981/981 [==============================] - 0s 160us/sample - loss: 0.4276 - sparse_categorical_accuracy: 0.7951 - val_loss: 0.6073 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 22/100\n",
            "981/981 [==============================] - 0s 160us/sample - loss: 0.4183 - sparse_categorical_accuracy: 0.8063 - val_loss: 0.6400 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 23/100\n",
            "981/981 [==============================] - 0s 165us/sample - loss: 0.4137 - sparse_categorical_accuracy: 0.8053 - val_loss: 0.6061 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 24/100\n",
            "981/981 [==============================] - 0s 173us/sample - loss: 0.4085 - sparse_categorical_accuracy: 0.8186 - val_loss: 0.6189 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 25/100\n",
            "981/981 [==============================] - 0s 148us/sample - loss: 0.4006 - sparse_categorical_accuracy: 0.8165 - val_loss: 0.6172 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 26/100\n",
            "981/981 [==============================] - 0s 171us/sample - loss: 0.3997 - sparse_categorical_accuracy: 0.8114 - val_loss: 0.6663 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 27/100\n",
            "981/981 [==============================] - 0s 150us/sample - loss: 0.3917 - sparse_categorical_accuracy: 0.8114 - val_loss: 0.6126 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 28/100\n",
            "981/981 [==============================] - 0s 142us/sample - loss: 0.3861 - sparse_categorical_accuracy: 0.8257 - val_loss: 0.6261 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 29/100\n",
            "981/981 [==============================] - 0s 154us/sample - loss: 0.3777 - sparse_categorical_accuracy: 0.8318 - val_loss: 0.6793 - val_sparse_categorical_accuracy: 0.6636\n",
            "[CV] ......................... n_neurons=38, n_hidden=5, total=   5.7s\n",
            "[CV] n_neurons=10, n_hidden=0 ........................................\n",
            "Train on 981 samples, validate on 109 samples\n",
            "Epoch 1/100\n",
            "981/981 [==============================] - 0s 452us/sample - loss: 1.2190 - sparse_categorical_accuracy: 0.3456 - val_loss: 1.1750 - val_sparse_categorical_accuracy: 0.4128\n",
            "Epoch 2/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 1.1258 - sparse_categorical_accuracy: 0.4057 - val_loss: 1.1038 - val_sparse_categorical_accuracy: 0.4037\n",
            "Epoch 3/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 1.0667 - sparse_categorical_accuracy: 0.4322 - val_loss: 1.0586 - val_sparse_categorical_accuracy: 0.4495\n",
            "Epoch 4/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 1.0192 - sparse_categorical_accuracy: 0.4577 - val_loss: 1.0089 - val_sparse_categorical_accuracy: 0.4404\n",
            "Epoch 5/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.9781 - sparse_categorical_accuracy: 0.4852 - val_loss: 0.9733 - val_sparse_categorical_accuracy: 0.4404\n",
            "Epoch 6/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.9443 - sparse_categorical_accuracy: 0.5066 - val_loss: 0.9404 - val_sparse_categorical_accuracy: 0.4495\n",
            "Epoch 7/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.9138 - sparse_categorical_accuracy: 0.5229 - val_loss: 0.9159 - val_sparse_categorical_accuracy: 0.4679\n",
            "Epoch 8/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.8882 - sparse_categorical_accuracy: 0.5341 - val_loss: 0.8907 - val_sparse_categorical_accuracy: 0.5138\n",
            "Epoch 9/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.8649 - sparse_categorical_accuracy: 0.5545 - val_loss: 0.8679 - val_sparse_categorical_accuracy: 0.5413\n",
            "Epoch 10/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.8437 - sparse_categorical_accuracy: 0.5678 - val_loss: 0.8538 - val_sparse_categorical_accuracy: 0.5505\n",
            "Epoch 11/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.8260 - sparse_categorical_accuracy: 0.5810 - val_loss: 0.8351 - val_sparse_categorical_accuracy: 0.5321\n",
            "Epoch 12/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.8088 - sparse_categorical_accuracy: 0.5943 - val_loss: 0.8190 - val_sparse_categorical_accuracy: 0.5413\n",
            "Epoch 13/100\n",
            "981/981 [==============================] - 0s 135us/sample - loss: 0.7943 - sparse_categorical_accuracy: 0.6004 - val_loss: 0.8062 - val_sparse_categorical_accuracy: 0.5505\n",
            "Epoch 14/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.7797 - sparse_categorical_accuracy: 0.6218 - val_loss: 0.7984 - val_sparse_categorical_accuracy: 0.5872\n",
            "Epoch 15/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.7674 - sparse_categorical_accuracy: 0.6218 - val_loss: 0.7832 - val_sparse_categorical_accuracy: 0.5688\n",
            "Epoch 16/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.7553 - sparse_categorical_accuracy: 0.6290 - val_loss: 0.7742 - val_sparse_categorical_accuracy: 0.5780\n",
            "Epoch 17/100\n",
            "981/981 [==============================] - 0s 137us/sample - loss: 0.7445 - sparse_categorical_accuracy: 0.6432 - val_loss: 0.7650 - val_sparse_categorical_accuracy: 0.5872\n",
            "Epoch 18/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.7349 - sparse_categorical_accuracy: 0.6534 - val_loss: 0.7570 - val_sparse_categorical_accuracy: 0.5963\n",
            "Epoch 19/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.7246 - sparse_categorical_accuracy: 0.6595 - val_loss: 0.7495 - val_sparse_categorical_accuracy: 0.6147\n",
            "Epoch 20/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.7161 - sparse_categorical_accuracy: 0.6677 - val_loss: 0.7418 - val_sparse_categorical_accuracy: 0.6239\n",
            "Epoch 21/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.7079 - sparse_categorical_accuracy: 0.6707 - val_loss: 0.7366 - val_sparse_categorical_accuracy: 0.6147\n",
            "Epoch 22/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.7005 - sparse_categorical_accuracy: 0.6779 - val_loss: 0.7290 - val_sparse_categorical_accuracy: 0.6239\n",
            "Epoch 23/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.6925 - sparse_categorical_accuracy: 0.6769 - val_loss: 0.7245 - val_sparse_categorical_accuracy: 0.6330\n",
            "Epoch 24/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.6858 - sparse_categorical_accuracy: 0.6850 - val_loss: 0.7179 - val_sparse_categorical_accuracy: 0.6330\n",
            "Epoch 25/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.6792 - sparse_categorical_accuracy: 0.6871 - val_loss: 0.7131 - val_sparse_categorical_accuracy: 0.6514\n",
            "Epoch 26/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.6732 - sparse_categorical_accuracy: 0.6932 - val_loss: 0.7070 - val_sparse_categorical_accuracy: 0.6606\n",
            "Epoch 27/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.6667 - sparse_categorical_accuracy: 0.6922 - val_loss: 0.7043 - val_sparse_categorical_accuracy: 0.6422\n",
            "Epoch 28/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.6615 - sparse_categorical_accuracy: 0.6922 - val_loss: 0.6990 - val_sparse_categorical_accuracy: 0.6514\n",
            "Epoch 29/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.6559 - sparse_categorical_accuracy: 0.6993 - val_loss: 0.6941 - val_sparse_categorical_accuracy: 0.6697\n",
            "Epoch 30/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.6510 - sparse_categorical_accuracy: 0.6983 - val_loss: 0.6901 - val_sparse_categorical_accuracy: 0.6697\n",
            "Epoch 31/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.6461 - sparse_categorical_accuracy: 0.7064 - val_loss: 0.6869 - val_sparse_categorical_accuracy: 0.6697\n",
            "Epoch 32/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.6416 - sparse_categorical_accuracy: 0.7115 - val_loss: 0.6843 - val_sparse_categorical_accuracy: 0.6606\n",
            "Epoch 33/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.6374 - sparse_categorical_accuracy: 0.7146 - val_loss: 0.6800 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 34/100\n",
            "981/981 [==============================] - 0s 142us/sample - loss: 0.6328 - sparse_categorical_accuracy: 0.7197 - val_loss: 0.6769 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 35/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.6289 - sparse_categorical_accuracy: 0.7248 - val_loss: 0.6750 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 36/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.6252 - sparse_categorical_accuracy: 0.7258 - val_loss: 0.6709 - val_sparse_categorical_accuracy: 0.6697\n",
            "Epoch 37/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.6217 - sparse_categorical_accuracy: 0.7227 - val_loss: 0.6686 - val_sparse_categorical_accuracy: 0.6697\n",
            "Epoch 38/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.6178 - sparse_categorical_accuracy: 0.7309 - val_loss: 0.6660 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 39/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.6143 - sparse_categorical_accuracy: 0.7288 - val_loss: 0.6639 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 40/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.6109 - sparse_categorical_accuracy: 0.7339 - val_loss: 0.6620 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 41/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.6081 - sparse_categorical_accuracy: 0.7370 - val_loss: 0.6591 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 42/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.6047 - sparse_categorical_accuracy: 0.7350 - val_loss: 0.6572 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 43/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.6022 - sparse_categorical_accuracy: 0.7350 - val_loss: 0.6544 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 44/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5992 - sparse_categorical_accuracy: 0.7370 - val_loss: 0.6525 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 45/100\n",
            "981/981 [==============================] - 0s 112us/sample - loss: 0.5963 - sparse_categorical_accuracy: 0.7421 - val_loss: 0.6502 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 46/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.5938 - sparse_categorical_accuracy: 0.7462 - val_loss: 0.6481 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 47/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5910 - sparse_categorical_accuracy: 0.7543 - val_loss: 0.6469 - val_sparse_categorical_accuracy: 0.6697\n",
            "Epoch 48/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.5889 - sparse_categorical_accuracy: 0.7462 - val_loss: 0.6445 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 49/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.5856 - sparse_categorical_accuracy: 0.7452 - val_loss: 0.6443 - val_sparse_categorical_accuracy: 0.6697\n",
            "Epoch 50/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.5840 - sparse_categorical_accuracy: 0.7523 - val_loss: 0.6420 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 51/100\n",
            "981/981 [==============================] - 0s 144us/sample - loss: 0.5817 - sparse_categorical_accuracy: 0.7543 - val_loss: 0.6407 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 52/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5796 - sparse_categorical_accuracy: 0.7574 - val_loss: 0.6394 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 53/100\n",
            "981/981 [==============================] - 0s 151us/sample - loss: 0.5775 - sparse_categorical_accuracy: 0.7533 - val_loss: 0.6373 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 54/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.5752 - sparse_categorical_accuracy: 0.7564 - val_loss: 0.6363 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 55/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.5733 - sparse_categorical_accuracy: 0.7564 - val_loss: 0.6356 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 56/100\n",
            "981/981 [==============================] - 0s 113us/sample - loss: 0.5716 - sparse_categorical_accuracy: 0.7513 - val_loss: 0.6336 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 57/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.5696 - sparse_categorical_accuracy: 0.7584 - val_loss: 0.6322 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 58/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.5677 - sparse_categorical_accuracy: 0.7604 - val_loss: 0.6307 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 59/100\n",
            "981/981 [==============================] - 0s 139us/sample - loss: 0.5658 - sparse_categorical_accuracy: 0.7533 - val_loss: 0.6296 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 60/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.5644 - sparse_categorical_accuracy: 0.7615 - val_loss: 0.6284 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 61/100\n",
            "981/981 [==============================] - 0s 113us/sample - loss: 0.5629 - sparse_categorical_accuracy: 0.7594 - val_loss: 0.6272 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 62/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.5613 - sparse_categorical_accuracy: 0.7635 - val_loss: 0.6262 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 63/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.5596 - sparse_categorical_accuracy: 0.7564 - val_loss: 0.6248 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 64/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.5581 - sparse_categorical_accuracy: 0.7604 - val_loss: 0.6234 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 65/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.5564 - sparse_categorical_accuracy: 0.7635 - val_loss: 0.6224 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 66/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.5549 - sparse_categorical_accuracy: 0.7615 - val_loss: 0.6213 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 67/100\n",
            "981/981 [==============================] - 0s 140us/sample - loss: 0.5537 - sparse_categorical_accuracy: 0.7615 - val_loss: 0.6204 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 68/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.5524 - sparse_categorical_accuracy: 0.7604 - val_loss: 0.6196 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 69/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.5510 - sparse_categorical_accuracy: 0.7604 - val_loss: 0.6191 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 70/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.5494 - sparse_categorical_accuracy: 0.7604 - val_loss: 0.6182 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 71/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.5483 - sparse_categorical_accuracy: 0.7635 - val_loss: 0.6173 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 72/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.5474 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.6164 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 73/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5463 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.6145 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 74/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.5449 - sparse_categorical_accuracy: 0.7635 - val_loss: 0.6139 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 75/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.5438 - sparse_categorical_accuracy: 0.7655 - val_loss: 0.6132 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 76/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.5425 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.6127 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 77/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.5412 - sparse_categorical_accuracy: 0.7696 - val_loss: 0.6122 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 78/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5403 - sparse_categorical_accuracy: 0.7655 - val_loss: 0.6114 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 79/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.5393 - sparse_categorical_accuracy: 0.7645 - val_loss: 0.6106 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 80/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.5382 - sparse_categorical_accuracy: 0.7615 - val_loss: 0.6098 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 81/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.5370 - sparse_categorical_accuracy: 0.7676 - val_loss: 0.6094 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 82/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.5359 - sparse_categorical_accuracy: 0.7696 - val_loss: 0.6087 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 83/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.5347 - sparse_categorical_accuracy: 0.7655 - val_loss: 0.6082 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 84/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.5341 - sparse_categorical_accuracy: 0.7645 - val_loss: 0.6076 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 85/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.5335 - sparse_categorical_accuracy: 0.7666 - val_loss: 0.6066 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 86/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.5321 - sparse_categorical_accuracy: 0.7645 - val_loss: 0.6066 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 87/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.5316 - sparse_categorical_accuracy: 0.7676 - val_loss: 0.6063 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 88/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.5304 - sparse_categorical_accuracy: 0.7686 - val_loss: 0.6054 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 89/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.5297 - sparse_categorical_accuracy: 0.7645 - val_loss: 0.6047 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 90/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.5287 - sparse_categorical_accuracy: 0.7696 - val_loss: 0.6040 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 91/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.5282 - sparse_categorical_accuracy: 0.7666 - val_loss: 0.6032 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 92/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.5273 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.6029 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 93/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.5268 - sparse_categorical_accuracy: 0.7615 - val_loss: 0.6022 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 94/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.5253 - sparse_categorical_accuracy: 0.7635 - val_loss: 0.6018 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 95/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.5249 - sparse_categorical_accuracy: 0.7604 - val_loss: 0.6009 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 96/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5239 - sparse_categorical_accuracy: 0.7676 - val_loss: 0.6008 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 97/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.5234 - sparse_categorical_accuracy: 0.7645 - val_loss: 0.6005 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 98/100\n",
            "981/981 [==============================] - 0s 111us/sample - loss: 0.5226 - sparse_categorical_accuracy: 0.7666 - val_loss: 0.6003 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 99/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.5221 - sparse_categorical_accuracy: 0.7686 - val_loss: 0.5999 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 100/100\n",
            "981/981 [==============================] - 0s 113us/sample - loss: 0.5212 - sparse_categorical_accuracy: 0.7635 - val_loss: 0.6000 - val_sparse_categorical_accuracy: 0.7156\n",
            "[CV] ......................... n_neurons=10, n_hidden=0, total=  12.7s\n",
            "[CV] n_neurons=10, n_hidden=0 ........................................\n",
            "Train on 981 samples, validate on 109 samples\n",
            "Epoch 1/100\n",
            "981/981 [==============================] - 0s 445us/sample - loss: 1.1249 - sparse_categorical_accuracy: 0.4190 - val_loss: 1.0841 - val_sparse_categorical_accuracy: 0.4495\n",
            "Epoch 2/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.9982 - sparse_categorical_accuracy: 0.4791 - val_loss: 1.0319 - val_sparse_categorical_accuracy: 0.4954\n",
            "Epoch 3/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.9529 - sparse_categorical_accuracy: 0.5148 - val_loss: 0.9946 - val_sparse_categorical_accuracy: 0.5229\n",
            "Epoch 4/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.9174 - sparse_categorical_accuracy: 0.5443 - val_loss: 0.9603 - val_sparse_categorical_accuracy: 0.5413\n",
            "Epoch 5/100\n",
            "981/981 [==============================] - 0s 143us/sample - loss: 0.8867 - sparse_categorical_accuracy: 0.5596 - val_loss: 0.9290 - val_sparse_categorical_accuracy: 0.5321\n",
            "Epoch 6/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.8604 - sparse_categorical_accuracy: 0.5708 - val_loss: 0.8973 - val_sparse_categorical_accuracy: 0.5505\n",
            "Epoch 7/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.8383 - sparse_categorical_accuracy: 0.5861 - val_loss: 0.8757 - val_sparse_categorical_accuracy: 0.5688\n",
            "Epoch 8/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.8181 - sparse_categorical_accuracy: 0.5994 - val_loss: 0.8509 - val_sparse_categorical_accuracy: 0.5688\n",
            "Epoch 9/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.7998 - sparse_categorical_accuracy: 0.6075 - val_loss: 0.8336 - val_sparse_categorical_accuracy: 0.5688\n",
            "Epoch 10/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.7831 - sparse_categorical_accuracy: 0.6116 - val_loss: 0.8194 - val_sparse_categorical_accuracy: 0.5780\n",
            "Epoch 11/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.7689 - sparse_categorical_accuracy: 0.6249 - val_loss: 0.7992 - val_sparse_categorical_accuracy: 0.6055\n",
            "Epoch 12/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.7554 - sparse_categorical_accuracy: 0.6269 - val_loss: 0.7839 - val_sparse_categorical_accuracy: 0.5963\n",
            "Epoch 13/100\n",
            "981/981 [==============================] - 0s 111us/sample - loss: 0.7431 - sparse_categorical_accuracy: 0.6412 - val_loss: 0.7773 - val_sparse_categorical_accuracy: 0.6147\n",
            "Epoch 14/100\n",
            "981/981 [==============================] - 0s 134us/sample - loss: 0.7313 - sparse_categorical_accuracy: 0.6371 - val_loss: 0.7605 - val_sparse_categorical_accuracy: 0.6055\n",
            "Epoch 15/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.7219 - sparse_categorical_accuracy: 0.6463 - val_loss: 0.7561 - val_sparse_categorical_accuracy: 0.6422\n",
            "Epoch 16/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.7124 - sparse_categorical_accuracy: 0.6524 - val_loss: 0.7482 - val_sparse_categorical_accuracy: 0.6422\n",
            "Epoch 17/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.7034 - sparse_categorical_accuracy: 0.6595 - val_loss: 0.7366 - val_sparse_categorical_accuracy: 0.6514\n",
            "Epoch 18/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.6952 - sparse_categorical_accuracy: 0.6667 - val_loss: 0.7333 - val_sparse_categorical_accuracy: 0.6422\n",
            "Epoch 19/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.6881 - sparse_categorical_accuracy: 0.6687 - val_loss: 0.7220 - val_sparse_categorical_accuracy: 0.6514\n",
            "Epoch 20/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.6804 - sparse_categorical_accuracy: 0.6707 - val_loss: 0.7193 - val_sparse_categorical_accuracy: 0.6422\n",
            "Epoch 21/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.6742 - sparse_categorical_accuracy: 0.6830 - val_loss: 0.7120 - val_sparse_categorical_accuracy: 0.6514\n",
            "Epoch 22/100\n",
            "981/981 [==============================] - 0s 136us/sample - loss: 0.6679 - sparse_categorical_accuracy: 0.6860 - val_loss: 0.7041 - val_sparse_categorical_accuracy: 0.6697\n",
            "Epoch 23/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.6620 - sparse_categorical_accuracy: 0.6922 - val_loss: 0.6978 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 24/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.6562 - sparse_categorical_accuracy: 0.6942 - val_loss: 0.6930 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 25/100\n",
            "981/981 [==============================] - 0s 112us/sample - loss: 0.6506 - sparse_categorical_accuracy: 0.6972 - val_loss: 0.6894 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 26/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.6459 - sparse_categorical_accuracy: 0.6972 - val_loss: 0.6824 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 27/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.6408 - sparse_categorical_accuracy: 0.7074 - val_loss: 0.6794 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 28/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.6364 - sparse_categorical_accuracy: 0.7054 - val_loss: 0.6731 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 29/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.6322 - sparse_categorical_accuracy: 0.7105 - val_loss: 0.6697 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 30/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.6275 - sparse_categorical_accuracy: 0.7095 - val_loss: 0.6685 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 31/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.6233 - sparse_categorical_accuracy: 0.7187 - val_loss: 0.6631 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 32/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.6202 - sparse_categorical_accuracy: 0.7227 - val_loss: 0.6616 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 33/100\n",
            "981/981 [==============================] - 0s 140us/sample - loss: 0.6168 - sparse_categorical_accuracy: 0.7166 - val_loss: 0.6535 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 34/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.6127 - sparse_categorical_accuracy: 0.7288 - val_loss: 0.6505 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 35/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.6096 - sparse_categorical_accuracy: 0.7248 - val_loss: 0.6474 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 36/100\n",
            "981/981 [==============================] - 0s 111us/sample - loss: 0.6061 - sparse_categorical_accuracy: 0.7319 - val_loss: 0.6460 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 37/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.6030 - sparse_categorical_accuracy: 0.7268 - val_loss: 0.6417 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 38/100\n",
            "981/981 [==============================] - 0s 112us/sample - loss: 0.5999 - sparse_categorical_accuracy: 0.7299 - val_loss: 0.6402 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 39/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.5970 - sparse_categorical_accuracy: 0.7299 - val_loss: 0.6367 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 40/100\n",
            "981/981 [==============================] - 0s 113us/sample - loss: 0.5945 - sparse_categorical_accuracy: 0.7319 - val_loss: 0.6367 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 41/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.5915 - sparse_categorical_accuracy: 0.7339 - val_loss: 0.6335 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 42/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.5889 - sparse_categorical_accuracy: 0.7401 - val_loss: 0.6320 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 43/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5863 - sparse_categorical_accuracy: 0.7390 - val_loss: 0.6286 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 44/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5840 - sparse_categorical_accuracy: 0.7380 - val_loss: 0.6250 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 45/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.5816 - sparse_categorical_accuracy: 0.7421 - val_loss: 0.6257 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 46/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.5793 - sparse_categorical_accuracy: 0.7319 - val_loss: 0.6237 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 47/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5772 - sparse_categorical_accuracy: 0.7421 - val_loss: 0.6230 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 48/100\n",
            "981/981 [==============================] - 0s 143us/sample - loss: 0.5750 - sparse_categorical_accuracy: 0.7421 - val_loss: 0.6187 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 49/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5729 - sparse_categorical_accuracy: 0.7411 - val_loss: 0.6161 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 50/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.5711 - sparse_categorical_accuracy: 0.7441 - val_loss: 0.6164 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 51/100\n",
            "981/981 [==============================] - 0s 113us/sample - loss: 0.5689 - sparse_categorical_accuracy: 0.7452 - val_loss: 0.6164 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 52/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.5669 - sparse_categorical_accuracy: 0.7482 - val_loss: 0.6162 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 53/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.5649 - sparse_categorical_accuracy: 0.7441 - val_loss: 0.6083 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 54/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5641 - sparse_categorical_accuracy: 0.7513 - val_loss: 0.6088 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 55/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.5616 - sparse_categorical_accuracy: 0.7533 - val_loss: 0.6079 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 56/100\n",
            "981/981 [==============================] - 0s 139us/sample - loss: 0.5600 - sparse_categorical_accuracy: 0.7492 - val_loss: 0.6078 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 57/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5584 - sparse_categorical_accuracy: 0.7513 - val_loss: 0.6077 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 58/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5567 - sparse_categorical_accuracy: 0.7574 - val_loss: 0.6079 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 59/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.5557 - sparse_categorical_accuracy: 0.7482 - val_loss: 0.6042 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 60/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.5535 - sparse_categorical_accuracy: 0.7492 - val_loss: 0.5995 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 61/100\n",
            "981/981 [==============================] - 0s 111us/sample - loss: 0.5524 - sparse_categorical_accuracy: 0.7564 - val_loss: 0.5986 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 62/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.5509 - sparse_categorical_accuracy: 0.7615 - val_loss: 0.6010 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 63/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.5493 - sparse_categorical_accuracy: 0.7543 - val_loss: 0.5986 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 64/100\n",
            "981/981 [==============================] - 0s 135us/sample - loss: 0.5478 - sparse_categorical_accuracy: 0.7543 - val_loss: 0.5957 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 65/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.5467 - sparse_categorical_accuracy: 0.7554 - val_loss: 0.5959 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 66/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.5451 - sparse_categorical_accuracy: 0.7635 - val_loss: 0.5937 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 67/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.5436 - sparse_categorical_accuracy: 0.7635 - val_loss: 0.5961 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 68/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.5430 - sparse_categorical_accuracy: 0.7543 - val_loss: 0.5916 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 69/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.5413 - sparse_categorical_accuracy: 0.7564 - val_loss: 0.5894 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 70/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.5404 - sparse_categorical_accuracy: 0.7584 - val_loss: 0.5888 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 71/100\n",
            "981/981 [==============================] - 0s 136us/sample - loss: 0.5388 - sparse_categorical_accuracy: 0.7584 - val_loss: 0.5886 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 72/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.5382 - sparse_categorical_accuracy: 0.7604 - val_loss: 0.5873 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 73/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.5369 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.5850 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 74/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.5358 - sparse_categorical_accuracy: 0.7594 - val_loss: 0.5836 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 75/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.5346 - sparse_categorical_accuracy: 0.7645 - val_loss: 0.5852 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 76/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.5337 - sparse_categorical_accuracy: 0.7615 - val_loss: 0.5850 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 77/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.5328 - sparse_categorical_accuracy: 0.7594 - val_loss: 0.5851 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 78/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.5318 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.5827 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 79/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.5303 - sparse_categorical_accuracy: 0.7645 - val_loss: 0.5844 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 80/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5297 - sparse_categorical_accuracy: 0.7604 - val_loss: 0.5809 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 81/100\n",
            "981/981 [==============================] - 0s 134us/sample - loss: 0.5282 - sparse_categorical_accuracy: 0.7696 - val_loss: 0.5849 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 82/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.5276 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.5772 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 83/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.5271 - sparse_categorical_accuracy: 0.7655 - val_loss: 0.5768 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 84/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.5259 - sparse_categorical_accuracy: 0.7686 - val_loss: 0.5765 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 85/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.5246 - sparse_categorical_accuracy: 0.7655 - val_loss: 0.5734 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 86/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.5245 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.5741 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 87/100\n",
            "981/981 [==============================] - 0s 113us/sample - loss: 0.5233 - sparse_categorical_accuracy: 0.7666 - val_loss: 0.5736 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 88/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.5226 - sparse_categorical_accuracy: 0.7645 - val_loss: 0.5778 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 89/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.5217 - sparse_categorical_accuracy: 0.7655 - val_loss: 0.5746 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 90/100\n",
            "981/981 [==============================] - 0s 151us/sample - loss: 0.5208 - sparse_categorical_accuracy: 0.7645 - val_loss: 0.5749 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 91/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.5201 - sparse_categorical_accuracy: 0.7645 - val_loss: 0.5739 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 92/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.5192 - sparse_categorical_accuracy: 0.7696 - val_loss: 0.5717 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 93/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.5185 - sparse_categorical_accuracy: 0.7645 - val_loss: 0.5717 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 94/100\n",
            "981/981 [==============================] - 0s 156us/sample - loss: 0.5177 - sparse_categorical_accuracy: 0.7696 - val_loss: 0.5712 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 95/100\n",
            "981/981 [==============================] - 0s 134us/sample - loss: 0.5169 - sparse_categorical_accuracy: 0.7666 - val_loss: 0.5687 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 96/100\n",
            "981/981 [==============================] - 0s 151us/sample - loss: 0.5160 - sparse_categorical_accuracy: 0.7757 - val_loss: 0.5703 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 97/100\n",
            "981/981 [==============================] - 0s 163us/sample - loss: 0.5154 - sparse_categorical_accuracy: 0.7696 - val_loss: 0.5683 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 98/100\n",
            "981/981 [==============================] - 0s 151us/sample - loss: 0.5149 - sparse_categorical_accuracy: 0.7676 - val_loss: 0.5672 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 99/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.5146 - sparse_categorical_accuracy: 0.7717 - val_loss: 0.5661 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 100/100\n",
            "981/981 [==============================] - 0s 136us/sample - loss: 0.5133 - sparse_categorical_accuracy: 0.7706 - val_loss: 0.5648 - val_sparse_categorical_accuracy: 0.7064\n",
            "[CV] ......................... n_neurons=10, n_hidden=0, total=  12.9s\n",
            "[CV] n_neurons=10, n_hidden=0 ........................................\n",
            "Train on 981 samples, validate on 109 samples\n",
            "Epoch 1/100\n",
            "981/981 [==============================] - 0s 478us/sample - loss: 1.2259 - sparse_categorical_accuracy: 0.3547 - val_loss: 1.1700 - val_sparse_categorical_accuracy: 0.4312\n",
            "Epoch 2/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 1.1326 - sparse_categorical_accuracy: 0.3853 - val_loss: 1.0895 - val_sparse_categorical_accuracy: 0.4954\n",
            "Epoch 3/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 1.0665 - sparse_categorical_accuracy: 0.4230 - val_loss: 1.0308 - val_sparse_categorical_accuracy: 0.5138\n",
            "Epoch 4/100\n",
            "981/981 [==============================] - 0s 148us/sample - loss: 1.0155 - sparse_categorical_accuracy: 0.4465 - val_loss: 0.9758 - val_sparse_categorical_accuracy: 0.5321\n",
            "Epoch 5/100\n",
            "981/981 [==============================] - 0s 149us/sample - loss: 0.9727 - sparse_categorical_accuracy: 0.4822 - val_loss: 0.9312 - val_sparse_categorical_accuracy: 0.5780\n",
            "Epoch 6/100\n",
            "981/981 [==============================] - 0s 143us/sample - loss: 0.9362 - sparse_categorical_accuracy: 0.5046 - val_loss: 0.8942 - val_sparse_categorical_accuracy: 0.6055\n",
            "Epoch 7/100\n",
            "981/981 [==============================] - 0s 143us/sample - loss: 0.9066 - sparse_categorical_accuracy: 0.5331 - val_loss: 0.8650 - val_sparse_categorical_accuracy: 0.6239\n",
            "Epoch 8/100\n",
            "981/981 [==============================] - 0s 145us/sample - loss: 0.8798 - sparse_categorical_accuracy: 0.5525 - val_loss: 0.8384 - val_sparse_categorical_accuracy: 0.6239\n",
            "Epoch 9/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.8564 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.8161 - val_sparse_categorical_accuracy: 0.6514\n",
            "Epoch 10/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.8367 - sparse_categorical_accuracy: 0.5861 - val_loss: 0.7951 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 11/100\n",
            "981/981 [==============================] - 0s 137us/sample - loss: 0.8184 - sparse_categorical_accuracy: 0.5963 - val_loss: 0.7765 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 12/100\n",
            "981/981 [==============================] - 0s 156us/sample - loss: 0.8028 - sparse_categorical_accuracy: 0.6147 - val_loss: 0.7603 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 13/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.7878 - sparse_categorical_accuracy: 0.6249 - val_loss: 0.7472 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 14/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.7744 - sparse_categorical_accuracy: 0.6340 - val_loss: 0.7339 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 15/100\n",
            "981/981 [==============================] - 0s 147us/sample - loss: 0.7623 - sparse_categorical_accuracy: 0.6483 - val_loss: 0.7241 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 16/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.7511 - sparse_categorical_accuracy: 0.6504 - val_loss: 0.7127 - val_sparse_categorical_accuracy: 0.6697\n",
            "Epoch 17/100\n",
            "981/981 [==============================] - 0s 137us/sample - loss: 0.7407 - sparse_categorical_accuracy: 0.6606 - val_loss: 0.7036 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 18/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.7312 - sparse_categorical_accuracy: 0.6636 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 19/100\n",
            "981/981 [==============================] - 0s 150us/sample - loss: 0.7225 - sparse_categorical_accuracy: 0.6677 - val_loss: 0.6876 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 20/100\n",
            "981/981 [==============================] - 0s 145us/sample - loss: 0.7137 - sparse_categorical_accuracy: 0.6728 - val_loss: 0.6800 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 21/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.7066 - sparse_categorical_accuracy: 0.6769 - val_loss: 0.6749 - val_sparse_categorical_accuracy: 0.6697\n",
            "Epoch 22/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.6990 - sparse_categorical_accuracy: 0.6718 - val_loss: 0.6686 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 23/100\n",
            "981/981 [==============================] - 0s 145us/sample - loss: 0.6922 - sparse_categorical_accuracy: 0.6850 - val_loss: 0.6612 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 24/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.6859 - sparse_categorical_accuracy: 0.6830 - val_loss: 0.6567 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 25/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.6794 - sparse_categorical_accuracy: 0.6830 - val_loss: 0.6524 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 26/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.6736 - sparse_categorical_accuracy: 0.6860 - val_loss: 0.6487 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 27/100\n",
            "981/981 [==============================] - 0s 144us/sample - loss: 0.6683 - sparse_categorical_accuracy: 0.6871 - val_loss: 0.6421 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 28/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.6635 - sparse_categorical_accuracy: 0.6911 - val_loss: 0.6366 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 29/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.6588 - sparse_categorical_accuracy: 0.6922 - val_loss: 0.6345 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 30/100\n",
            "981/981 [==============================] - 0s 134us/sample - loss: 0.6541 - sparse_categorical_accuracy: 0.6962 - val_loss: 0.6305 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 31/100\n",
            "981/981 [==============================] - 0s 145us/sample - loss: 0.6496 - sparse_categorical_accuracy: 0.6983 - val_loss: 0.6266 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 32/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.6451 - sparse_categorical_accuracy: 0.7023 - val_loss: 0.6220 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 33/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.6414 - sparse_categorical_accuracy: 0.7013 - val_loss: 0.6204 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 34/100\n",
            "981/981 [==============================] - 0s 144us/sample - loss: 0.6379 - sparse_categorical_accuracy: 0.7034 - val_loss: 0.6160 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 35/100\n",
            "981/981 [==============================] - 0s 138us/sample - loss: 0.6333 - sparse_categorical_accuracy: 0.7013 - val_loss: 0.6157 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 36/100\n",
            "981/981 [==============================] - 0s 134us/sample - loss: 0.6304 - sparse_categorical_accuracy: 0.7105 - val_loss: 0.6114 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 37/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.6270 - sparse_categorical_accuracy: 0.7115 - val_loss: 0.6083 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 38/100\n",
            "981/981 [==============================] - 0s 149us/sample - loss: 0.6241 - sparse_categorical_accuracy: 0.7146 - val_loss: 0.6063 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 39/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.6210 - sparse_categorical_accuracy: 0.7146 - val_loss: 0.6032 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 40/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.6176 - sparse_categorical_accuracy: 0.7146 - val_loss: 0.6014 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 41/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.6149 - sparse_categorical_accuracy: 0.7217 - val_loss: 0.5991 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 42/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.6124 - sparse_categorical_accuracy: 0.7207 - val_loss: 0.5978 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 43/100\n",
            "981/981 [==============================] - 0s 135us/sample - loss: 0.6092 - sparse_categorical_accuracy: 0.7197 - val_loss: 0.5955 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 44/100\n",
            "981/981 [==============================] - 0s 144us/sample - loss: 0.6064 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.5944 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 45/100\n",
            "981/981 [==============================] - 0s 149us/sample - loss: 0.6043 - sparse_categorical_accuracy: 0.7227 - val_loss: 0.5924 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 46/100\n",
            "981/981 [==============================] - 0s 147us/sample - loss: 0.6017 - sparse_categorical_accuracy: 0.7238 - val_loss: 0.5907 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 47/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.5996 - sparse_categorical_accuracy: 0.7238 - val_loss: 0.5891 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 48/100\n",
            "981/981 [==============================] - 0s 134us/sample - loss: 0.5974 - sparse_categorical_accuracy: 0.7238 - val_loss: 0.5864 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 49/100\n",
            "981/981 [==============================] - 0s 134us/sample - loss: 0.5952 - sparse_categorical_accuracy: 0.7299 - val_loss: 0.5851 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 50/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.5933 - sparse_categorical_accuracy: 0.7299 - val_loss: 0.5844 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 51/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.5911 - sparse_categorical_accuracy: 0.7288 - val_loss: 0.5833 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 52/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.5892 - sparse_categorical_accuracy: 0.7329 - val_loss: 0.5811 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 53/100\n",
            "981/981 [==============================] - 0s 136us/sample - loss: 0.5873 - sparse_categorical_accuracy: 0.7299 - val_loss: 0.5797 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 54/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.5859 - sparse_categorical_accuracy: 0.7329 - val_loss: 0.5790 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 55/100\n",
            "981/981 [==============================] - 0s 143us/sample - loss: 0.5834 - sparse_categorical_accuracy: 0.7288 - val_loss: 0.5790 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 56/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.5809 - sparse_categorical_accuracy: 0.7329 - val_loss: 0.5757 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 57/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.5804 - sparse_categorical_accuracy: 0.7319 - val_loss: 0.5753 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 58/100\n",
            "981/981 [==============================] - 0s 137us/sample - loss: 0.5782 - sparse_categorical_accuracy: 0.7319 - val_loss: 0.5759 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 59/100\n",
            "981/981 [==============================] - 0s 143us/sample - loss: 0.5772 - sparse_categorical_accuracy: 0.7339 - val_loss: 0.5751 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 60/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.5757 - sparse_categorical_accuracy: 0.7329 - val_loss: 0.5746 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 61/100\n",
            "981/981 [==============================] - 0s 143us/sample - loss: 0.5740 - sparse_categorical_accuracy: 0.7329 - val_loss: 0.5723 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 62/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5721 - sparse_categorical_accuracy: 0.7329 - val_loss: 0.5703 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 63/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5713 - sparse_categorical_accuracy: 0.7319 - val_loss: 0.5696 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 64/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.5698 - sparse_categorical_accuracy: 0.7319 - val_loss: 0.5690 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 65/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5681 - sparse_categorical_accuracy: 0.7370 - val_loss: 0.5670 - val_sparse_categorical_accuracy: 0.7523\n",
            "Epoch 66/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.5669 - sparse_categorical_accuracy: 0.7339 - val_loss: 0.5669 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 67/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.5657 - sparse_categorical_accuracy: 0.7350 - val_loss: 0.5658 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 68/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.5644 - sparse_categorical_accuracy: 0.7360 - val_loss: 0.5648 - val_sparse_categorical_accuracy: 0.7523\n",
            "Epoch 69/100\n",
            "981/981 [==============================] - 0s 134us/sample - loss: 0.5633 - sparse_categorical_accuracy: 0.7370 - val_loss: 0.5643 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 70/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.5620 - sparse_categorical_accuracy: 0.7421 - val_loss: 0.5627 - val_sparse_categorical_accuracy: 0.7523\n",
            "Epoch 71/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.5608 - sparse_categorical_accuracy: 0.7390 - val_loss: 0.5631 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 72/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5597 - sparse_categorical_accuracy: 0.7431 - val_loss: 0.5625 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 73/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.5588 - sparse_categorical_accuracy: 0.7390 - val_loss: 0.5618 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 74/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.5578 - sparse_categorical_accuracy: 0.7401 - val_loss: 0.5615 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 75/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.5564 - sparse_categorical_accuracy: 0.7431 - val_loss: 0.5614 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 76/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.5555 - sparse_categorical_accuracy: 0.7401 - val_loss: 0.5591 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 77/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5543 - sparse_categorical_accuracy: 0.7370 - val_loss: 0.5598 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 78/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.5530 - sparse_categorical_accuracy: 0.7401 - val_loss: 0.5612 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 79/100\n",
            "981/981 [==============================] - 0s 112us/sample - loss: 0.5529 - sparse_categorical_accuracy: 0.7462 - val_loss: 0.5589 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 80/100\n",
            "981/981 [==============================] - 0s 111us/sample - loss: 0.5515 - sparse_categorical_accuracy: 0.7452 - val_loss: 0.5566 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 81/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.5509 - sparse_categorical_accuracy: 0.7431 - val_loss: 0.5566 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 82/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.5501 - sparse_categorical_accuracy: 0.7452 - val_loss: 0.5557 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 83/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5487 - sparse_categorical_accuracy: 0.7482 - val_loss: 0.5549 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 84/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.5483 - sparse_categorical_accuracy: 0.7482 - val_loss: 0.5557 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 85/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.5471 - sparse_categorical_accuracy: 0.7503 - val_loss: 0.5546 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 86/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.5463 - sparse_categorical_accuracy: 0.7482 - val_loss: 0.5546 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 87/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.5455 - sparse_categorical_accuracy: 0.7482 - val_loss: 0.5531 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 88/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.5449 - sparse_categorical_accuracy: 0.7503 - val_loss: 0.5532 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 89/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.5441 - sparse_categorical_accuracy: 0.7482 - val_loss: 0.5525 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 90/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.5430 - sparse_categorical_accuracy: 0.7523 - val_loss: 0.5534 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 91/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.5426 - sparse_categorical_accuracy: 0.7482 - val_loss: 0.5514 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 92/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.5416 - sparse_categorical_accuracy: 0.7472 - val_loss: 0.5509 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 93/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.5411 - sparse_categorical_accuracy: 0.7492 - val_loss: 0.5500 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 94/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.5404 - sparse_categorical_accuracy: 0.7543 - val_loss: 0.5495 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 95/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.5397 - sparse_categorical_accuracy: 0.7503 - val_loss: 0.5491 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 96/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5389 - sparse_categorical_accuracy: 0.7452 - val_loss: 0.5480 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 97/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.5384 - sparse_categorical_accuracy: 0.7503 - val_loss: 0.5474 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 98/100\n",
            "981/981 [==============================] - 0s 142us/sample - loss: 0.5379 - sparse_categorical_accuracy: 0.7543 - val_loss: 0.5477 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 99/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.5367 - sparse_categorical_accuracy: 0.7543 - val_loss: 0.5501 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 100/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.5365 - sparse_categorical_accuracy: 0.7513 - val_loss: 0.5469 - val_sparse_categorical_accuracy: 0.7064\n",
            "[CV] ......................... n_neurons=10, n_hidden=0, total=  13.6s\n",
            "[CV] n_neurons=10, n_hidden=0 ........................................\n",
            "Train on 981 samples, validate on 110 samples\n",
            "Epoch 1/100\n",
            "981/981 [==============================] - 0s 447us/sample - loss: 1.2066 - sparse_categorical_accuracy: 0.4037 - val_loss: 1.2064 - val_sparse_categorical_accuracy: 0.3636\n",
            "Epoch 2/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 1.1159 - sparse_categorical_accuracy: 0.4261 - val_loss: 1.1283 - val_sparse_categorical_accuracy: 0.3818\n",
            "Epoch 3/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 1.0528 - sparse_categorical_accuracy: 0.4475 - val_loss: 1.0695 - val_sparse_categorical_accuracy: 0.4182\n",
            "Epoch 4/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 1.0045 - sparse_categorical_accuracy: 0.4832 - val_loss: 1.0184 - val_sparse_categorical_accuracy: 0.4455\n",
            "Epoch 5/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.9631 - sparse_categorical_accuracy: 0.5158 - val_loss: 0.9760 - val_sparse_categorical_accuracy: 0.5000\n",
            "Epoch 6/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.9294 - sparse_categorical_accuracy: 0.5260 - val_loss: 0.9451 - val_sparse_categorical_accuracy: 0.4909\n",
            "Epoch 7/100\n",
            "981/981 [==============================] - 0s 134us/sample - loss: 0.9003 - sparse_categorical_accuracy: 0.5413 - val_loss: 0.9156 - val_sparse_categorical_accuracy: 0.5455\n",
            "Epoch 8/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.8748 - sparse_categorical_accuracy: 0.5668 - val_loss: 0.8902 - val_sparse_categorical_accuracy: 0.5545\n",
            "Epoch 9/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.8528 - sparse_categorical_accuracy: 0.5780 - val_loss: 0.8708 - val_sparse_categorical_accuracy: 0.5545\n",
            "Epoch 10/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.8340 - sparse_categorical_accuracy: 0.5892 - val_loss: 0.8460 - val_sparse_categorical_accuracy: 0.5545\n",
            "Epoch 11/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.8162 - sparse_categorical_accuracy: 0.5953 - val_loss: 0.8266 - val_sparse_categorical_accuracy: 0.5818\n",
            "Epoch 12/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.8002 - sparse_categorical_accuracy: 0.6024 - val_loss: 0.8096 - val_sparse_categorical_accuracy: 0.6000\n",
            "Epoch 13/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.7858 - sparse_categorical_accuracy: 0.6137 - val_loss: 0.7995 - val_sparse_categorical_accuracy: 0.6273\n",
            "Epoch 14/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.7729 - sparse_categorical_accuracy: 0.6269 - val_loss: 0.7882 - val_sparse_categorical_accuracy: 0.6455\n",
            "Epoch 15/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.7604 - sparse_categorical_accuracy: 0.6412 - val_loss: 0.7724 - val_sparse_categorical_accuracy: 0.6364\n",
            "Epoch 16/100\n",
            "981/981 [==============================] - 0s 111us/sample - loss: 0.7491 - sparse_categorical_accuracy: 0.6453 - val_loss: 0.7624 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 17/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.7389 - sparse_categorical_accuracy: 0.6534 - val_loss: 0.7523 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 18/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.7295 - sparse_categorical_accuracy: 0.6534 - val_loss: 0.7435 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 19/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.7201 - sparse_categorical_accuracy: 0.6595 - val_loss: 0.7365 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 20/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.7113 - sparse_categorical_accuracy: 0.6667 - val_loss: 0.7262 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 21/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.7032 - sparse_categorical_accuracy: 0.6769 - val_loss: 0.7189 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 22/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.6956 - sparse_categorical_accuracy: 0.6789 - val_loss: 0.7096 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 23/100\n",
            "981/981 [==============================] - 0s 144us/sample - loss: 0.6883 - sparse_categorical_accuracy: 0.6820 - val_loss: 0.7055 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 24/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.6819 - sparse_categorical_accuracy: 0.6850 - val_loss: 0.6978 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 25/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.6754 - sparse_categorical_accuracy: 0.6922 - val_loss: 0.6912 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 26/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.6703 - sparse_categorical_accuracy: 0.6901 - val_loss: 0.6876 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 27/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.6638 - sparse_categorical_accuracy: 0.6932 - val_loss: 0.6821 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 28/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.6578 - sparse_categorical_accuracy: 0.7003 - val_loss: 0.6765 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 29/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.6528 - sparse_categorical_accuracy: 0.7054 - val_loss: 0.6718 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 30/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.6484 - sparse_categorical_accuracy: 0.7085 - val_loss: 0.6677 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 31/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.6429 - sparse_categorical_accuracy: 0.7095 - val_loss: 0.6625 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 32/100\n",
            "981/981 [==============================] - 0s 141us/sample - loss: 0.6386 - sparse_categorical_accuracy: 0.7115 - val_loss: 0.6594 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 33/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.6341 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.6547 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 34/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.6300 - sparse_categorical_accuracy: 0.7197 - val_loss: 0.6519 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 35/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.6263 - sparse_categorical_accuracy: 0.7115 - val_loss: 0.6476 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 36/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.6221 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.6451 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 37/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.6184 - sparse_categorical_accuracy: 0.7197 - val_loss: 0.6419 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 38/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.6149 - sparse_categorical_accuracy: 0.7278 - val_loss: 0.6387 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 39/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.6117 - sparse_categorical_accuracy: 0.7248 - val_loss: 0.6337 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 40/100\n",
            "981/981 [==============================] - 0s 141us/sample - loss: 0.6083 - sparse_categorical_accuracy: 0.7248 - val_loss: 0.6319 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 41/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.6050 - sparse_categorical_accuracy: 0.7278 - val_loss: 0.6288 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 42/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.6019 - sparse_categorical_accuracy: 0.7278 - val_loss: 0.6268 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 43/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5989 - sparse_categorical_accuracy: 0.7299 - val_loss: 0.6244 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 44/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5959 - sparse_categorical_accuracy: 0.7319 - val_loss: 0.6198 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 45/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5938 - sparse_categorical_accuracy: 0.7350 - val_loss: 0.6181 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 46/100\n",
            "981/981 [==============================] - 0s 136us/sample - loss: 0.5908 - sparse_categorical_accuracy: 0.7411 - val_loss: 0.6154 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 47/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.5880 - sparse_categorical_accuracy: 0.7411 - val_loss: 0.6121 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 48/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.5858 - sparse_categorical_accuracy: 0.7360 - val_loss: 0.6105 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 49/100\n",
            "981/981 [==============================] - 0s 135us/sample - loss: 0.5834 - sparse_categorical_accuracy: 0.7411 - val_loss: 0.6089 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 50/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.5808 - sparse_categorical_accuracy: 0.7421 - val_loss: 0.6085 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 51/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.5787 - sparse_categorical_accuracy: 0.7401 - val_loss: 0.6044 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 52/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5766 - sparse_categorical_accuracy: 0.7411 - val_loss: 0.6032 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 53/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.5745 - sparse_categorical_accuracy: 0.7421 - val_loss: 0.6027 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 54/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.5721 - sparse_categorical_accuracy: 0.7431 - val_loss: 0.6010 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 55/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.5705 - sparse_categorical_accuracy: 0.7472 - val_loss: 0.5975 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 56/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5683 - sparse_categorical_accuracy: 0.7472 - val_loss: 0.5963 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 57/100\n",
            "981/981 [==============================] - 0s 147us/sample - loss: 0.5664 - sparse_categorical_accuracy: 0.7513 - val_loss: 0.5941 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 58/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.5647 - sparse_categorical_accuracy: 0.7503 - val_loss: 0.5926 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 59/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5628 - sparse_categorical_accuracy: 0.7462 - val_loss: 0.5908 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 60/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5609 - sparse_categorical_accuracy: 0.7523 - val_loss: 0.5891 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 61/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.5594 - sparse_categorical_accuracy: 0.7482 - val_loss: 0.5875 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 62/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.5577 - sparse_categorical_accuracy: 0.7543 - val_loss: 0.5873 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 63/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.5564 - sparse_categorical_accuracy: 0.7513 - val_loss: 0.5867 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 64/100\n",
            "981/981 [==============================] - 0s 138us/sample - loss: 0.5545 - sparse_categorical_accuracy: 0.7604 - val_loss: 0.5837 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 65/100\n",
            "981/981 [==============================] - 0s 138us/sample - loss: 0.5527 - sparse_categorical_accuracy: 0.7564 - val_loss: 0.5839 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 66/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5510 - sparse_categorical_accuracy: 0.7635 - val_loss: 0.5802 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 67/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.5503 - sparse_categorical_accuracy: 0.7574 - val_loss: 0.5794 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 68/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.5482 - sparse_categorical_accuracy: 0.7554 - val_loss: 0.5795 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 69/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.5469 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.5772 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 70/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.5454 - sparse_categorical_accuracy: 0.7615 - val_loss: 0.5766 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 71/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5443 - sparse_categorical_accuracy: 0.7604 - val_loss: 0.5752 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 72/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.5433 - sparse_categorical_accuracy: 0.7594 - val_loss: 0.5740 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 73/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.5417 - sparse_categorical_accuracy: 0.7615 - val_loss: 0.5716 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 74/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.5408 - sparse_categorical_accuracy: 0.7554 - val_loss: 0.5706 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 75/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.5394 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.5702 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 76/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5383 - sparse_categorical_accuracy: 0.7594 - val_loss: 0.5695 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 77/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.5369 - sparse_categorical_accuracy: 0.7635 - val_loss: 0.5691 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 78/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5359 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.5673 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 79/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.5345 - sparse_categorical_accuracy: 0.7604 - val_loss: 0.5667 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 80/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.5332 - sparse_categorical_accuracy: 0.7645 - val_loss: 0.5680 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 81/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.5324 - sparse_categorical_accuracy: 0.7676 - val_loss: 0.5649 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 82/100\n",
            "981/981 [==============================] - 0s 154us/sample - loss: 0.5317 - sparse_categorical_accuracy: 0.7635 - val_loss: 0.5644 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 83/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.5303 - sparse_categorical_accuracy: 0.7727 - val_loss: 0.5630 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 84/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5292 - sparse_categorical_accuracy: 0.7615 - val_loss: 0.5619 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 85/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5282 - sparse_categorical_accuracy: 0.7666 - val_loss: 0.5615 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 86/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5272 - sparse_categorical_accuracy: 0.7706 - val_loss: 0.5614 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 87/100\n",
            "981/981 [==============================] - 0s 113us/sample - loss: 0.5263 - sparse_categorical_accuracy: 0.7706 - val_loss: 0.5598 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 88/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5256 - sparse_categorical_accuracy: 0.7696 - val_loss: 0.5598 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 89/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5248 - sparse_categorical_accuracy: 0.7645 - val_loss: 0.5589 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 90/100\n",
            "981/981 [==============================] - 0s 152us/sample - loss: 0.5234 - sparse_categorical_accuracy: 0.7676 - val_loss: 0.5572 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 91/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.5225 - sparse_categorical_accuracy: 0.7727 - val_loss: 0.5563 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 92/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.5221 - sparse_categorical_accuracy: 0.7676 - val_loss: 0.5556 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 93/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.5209 - sparse_categorical_accuracy: 0.7676 - val_loss: 0.5547 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 94/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.5202 - sparse_categorical_accuracy: 0.7706 - val_loss: 0.5542 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 95/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5191 - sparse_categorical_accuracy: 0.7686 - val_loss: 0.5537 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 96/100\n",
            "981/981 [==============================] - 0s 113us/sample - loss: 0.5186 - sparse_categorical_accuracy: 0.7717 - val_loss: 0.5522 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 97/100\n",
            "981/981 [==============================] - 0s 113us/sample - loss: 0.5180 - sparse_categorical_accuracy: 0.7727 - val_loss: 0.5514 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 98/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.5167 - sparse_categorical_accuracy: 0.7706 - val_loss: 0.5508 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 99/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.5162 - sparse_categorical_accuracy: 0.7747 - val_loss: 0.5513 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 100/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.5156 - sparse_categorical_accuracy: 0.7727 - val_loss: 0.5505 - val_sparse_categorical_accuracy: 0.7273\n",
            "[CV] ......................... n_neurons=10, n_hidden=0, total=  12.8s\n",
            "[CV] n_neurons=10, n_hidden=0 ........................................\n",
            "Train on 981 samples, validate on 110 samples\n",
            "Epoch 1/100\n",
            "981/981 [==============================] - 2s 3ms/sample - loss: 1.2432 - sparse_categorical_accuracy: 0.3242 - val_loss: 1.1331 - val_sparse_categorical_accuracy: 0.4273\n",
            "Epoch 2/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 1.1290 - sparse_categorical_accuracy: 0.3782 - val_loss: 1.0624 - val_sparse_categorical_accuracy: 0.4727\n",
            "Epoch 3/100\n",
            "981/981 [==============================] - 0s 136us/sample - loss: 1.0679 - sparse_categorical_accuracy: 0.4200 - val_loss: 1.0127 - val_sparse_categorical_accuracy: 0.4636\n",
            "Epoch 4/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 1.0198 - sparse_categorical_accuracy: 0.4485 - val_loss: 0.9730 - val_sparse_categorical_accuracy: 0.5000\n",
            "Epoch 5/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.9785 - sparse_categorical_accuracy: 0.4791 - val_loss: 0.9393 - val_sparse_categorical_accuracy: 0.5000\n",
            "Epoch 6/100\n",
            "981/981 [==============================] - 0s 113us/sample - loss: 0.9436 - sparse_categorical_accuracy: 0.5015 - val_loss: 0.9113 - val_sparse_categorical_accuracy: 0.5182\n",
            "Epoch 7/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.9129 - sparse_categorical_accuracy: 0.5229 - val_loss: 0.8879 - val_sparse_categorical_accuracy: 0.5273\n",
            "Epoch 8/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.8866 - sparse_categorical_accuracy: 0.5331 - val_loss: 0.8673 - val_sparse_categorical_accuracy: 0.5364\n",
            "Epoch 9/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.8630 - sparse_categorical_accuracy: 0.5586 - val_loss: 0.8489 - val_sparse_categorical_accuracy: 0.5455\n",
            "Epoch 10/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.8432 - sparse_categorical_accuracy: 0.5688 - val_loss: 0.8326 - val_sparse_categorical_accuracy: 0.5455\n",
            "Epoch 11/100\n",
            "981/981 [==============================] - 0s 134us/sample - loss: 0.8237 - sparse_categorical_accuracy: 0.5790 - val_loss: 0.8163 - val_sparse_categorical_accuracy: 0.5727\n",
            "Epoch 12/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.8072 - sparse_categorical_accuracy: 0.5994 - val_loss: 0.8040 - val_sparse_categorical_accuracy: 0.5818\n",
            "Epoch 13/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.7918 - sparse_categorical_accuracy: 0.6106 - val_loss: 0.7932 - val_sparse_categorical_accuracy: 0.5909\n",
            "Epoch 14/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.7783 - sparse_categorical_accuracy: 0.6147 - val_loss: 0.7822 - val_sparse_categorical_accuracy: 0.5909\n",
            "Epoch 15/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.7651 - sparse_categorical_accuracy: 0.6290 - val_loss: 0.7697 - val_sparse_categorical_accuracy: 0.6000\n",
            "Epoch 16/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.7536 - sparse_categorical_accuracy: 0.6320 - val_loss: 0.7604 - val_sparse_categorical_accuracy: 0.6091\n",
            "Epoch 17/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.7419 - sparse_categorical_accuracy: 0.6483 - val_loss: 0.7549 - val_sparse_categorical_accuracy: 0.6000\n",
            "Epoch 18/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.7322 - sparse_categorical_accuracy: 0.6483 - val_loss: 0.7436 - val_sparse_categorical_accuracy: 0.6273\n",
            "Epoch 19/100\n",
            "981/981 [==============================] - 0s 113us/sample - loss: 0.7233 - sparse_categorical_accuracy: 0.6595 - val_loss: 0.7354 - val_sparse_categorical_accuracy: 0.6273\n",
            "Epoch 20/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.7148 - sparse_categorical_accuracy: 0.6707 - val_loss: 0.7288 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 21/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.7067 - sparse_categorical_accuracy: 0.6758 - val_loss: 0.7225 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 22/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.6987 - sparse_categorical_accuracy: 0.6820 - val_loss: 0.7169 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 23/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.6913 - sparse_categorical_accuracy: 0.6850 - val_loss: 0.7101 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 24/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.6845 - sparse_categorical_accuracy: 0.6962 - val_loss: 0.7040 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 25/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.6780 - sparse_categorical_accuracy: 0.7034 - val_loss: 0.6986 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 26/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.6718 - sparse_categorical_accuracy: 0.7054 - val_loss: 0.6943 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 27/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.6662 - sparse_categorical_accuracy: 0.7064 - val_loss: 0.6894 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 28/100\n",
            "981/981 [==============================] - 0s 141us/sample - loss: 0.6603 - sparse_categorical_accuracy: 0.7044 - val_loss: 0.6866 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 29/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.6553 - sparse_categorical_accuracy: 0.7054 - val_loss: 0.6818 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 30/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.6500 - sparse_categorical_accuracy: 0.7085 - val_loss: 0.6780 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 31/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.6456 - sparse_categorical_accuracy: 0.7156 - val_loss: 0.6744 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 32/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.6413 - sparse_categorical_accuracy: 0.7146 - val_loss: 0.6691 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 33/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.6364 - sparse_categorical_accuracy: 0.7156 - val_loss: 0.6658 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 34/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.6324 - sparse_categorical_accuracy: 0.7207 - val_loss: 0.6641 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 35/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.6286 - sparse_categorical_accuracy: 0.7136 - val_loss: 0.6591 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 36/100\n",
            "981/981 [==============================] - 0s 113us/sample - loss: 0.6244 - sparse_categorical_accuracy: 0.7187 - val_loss: 0.6560 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 37/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.6209 - sparse_categorical_accuracy: 0.7268 - val_loss: 0.6528 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 38/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.6173 - sparse_categorical_accuracy: 0.7268 - val_loss: 0.6521 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 39/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.6140 - sparse_categorical_accuracy: 0.7299 - val_loss: 0.6480 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 40/100\n",
            "981/981 [==============================] - 0s 138us/sample - loss: 0.6103 - sparse_categorical_accuracy: 0.7380 - val_loss: 0.6474 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 41/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.6082 - sparse_categorical_accuracy: 0.7268 - val_loss: 0.6443 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 42/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.6047 - sparse_categorical_accuracy: 0.7268 - val_loss: 0.6406 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 43/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.6013 - sparse_categorical_accuracy: 0.7319 - val_loss: 0.6400 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 44/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.5988 - sparse_categorical_accuracy: 0.7309 - val_loss: 0.6341 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 45/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.5967 - sparse_categorical_accuracy: 0.7339 - val_loss: 0.6321 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 46/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5940 - sparse_categorical_accuracy: 0.7380 - val_loss: 0.6306 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 47/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.5908 - sparse_categorical_accuracy: 0.7339 - val_loss: 0.6285 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 48/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5888 - sparse_categorical_accuracy: 0.7339 - val_loss: 0.6260 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 49/100\n",
            "981/981 [==============================] - 0s 142us/sample - loss: 0.5861 - sparse_categorical_accuracy: 0.7380 - val_loss: 0.6242 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 50/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.5838 - sparse_categorical_accuracy: 0.7431 - val_loss: 0.6241 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 51/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.5816 - sparse_categorical_accuracy: 0.7390 - val_loss: 0.6233 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 52/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.5798 - sparse_categorical_accuracy: 0.7370 - val_loss: 0.6200 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 53/100\n",
            "981/981 [==============================] - 0s 142us/sample - loss: 0.5771 - sparse_categorical_accuracy: 0.7401 - val_loss: 0.6169 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 54/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.5752 - sparse_categorical_accuracy: 0.7452 - val_loss: 0.6155 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 55/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.5732 - sparse_categorical_accuracy: 0.7472 - val_loss: 0.6157 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 56/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.5706 - sparse_categorical_accuracy: 0.7441 - val_loss: 0.6111 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 57/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.5696 - sparse_categorical_accuracy: 0.7482 - val_loss: 0.6109 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 58/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.5676 - sparse_categorical_accuracy: 0.7472 - val_loss: 0.6113 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 59/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.5658 - sparse_categorical_accuracy: 0.7411 - val_loss: 0.6097 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 60/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5643 - sparse_categorical_accuracy: 0.7482 - val_loss: 0.6092 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 61/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.5623 - sparse_categorical_accuracy: 0.7431 - val_loss: 0.6069 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 62/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.5608 - sparse_categorical_accuracy: 0.7452 - val_loss: 0.6067 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 63/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.5591 - sparse_categorical_accuracy: 0.7513 - val_loss: 0.6065 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 64/100\n",
            "981/981 [==============================] - 0s 113us/sample - loss: 0.5574 - sparse_categorical_accuracy: 0.7513 - val_loss: 0.6066 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 65/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5563 - sparse_categorical_accuracy: 0.7492 - val_loss: 0.6035 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 66/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.5545 - sparse_categorical_accuracy: 0.7472 - val_loss: 0.6013 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 67/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.5533 - sparse_categorical_accuracy: 0.7523 - val_loss: 0.6007 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 68/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.5520 - sparse_categorical_accuracy: 0.7513 - val_loss: 0.6004 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 69/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.5503 - sparse_categorical_accuracy: 0.7574 - val_loss: 0.6004 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 70/100\n",
            "981/981 [==============================] - 0s 138us/sample - loss: 0.5492 - sparse_categorical_accuracy: 0.7554 - val_loss: 0.5972 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 71/100\n",
            "981/981 [==============================] - 0s 140us/sample - loss: 0.5480 - sparse_categorical_accuracy: 0.7523 - val_loss: 0.5976 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 72/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.5465 - sparse_categorical_accuracy: 0.7554 - val_loss: 0.5962 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 73/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.5452 - sparse_categorical_accuracy: 0.7533 - val_loss: 0.5953 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 74/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5443 - sparse_categorical_accuracy: 0.7523 - val_loss: 0.5945 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 75/100\n",
            "981/981 [==============================] - 0s 111us/sample - loss: 0.5429 - sparse_categorical_accuracy: 0.7533 - val_loss: 0.5937 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 76/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5415 - sparse_categorical_accuracy: 0.7523 - val_loss: 0.5919 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 77/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5403 - sparse_categorical_accuracy: 0.7513 - val_loss: 0.5910 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 78/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5395 - sparse_categorical_accuracy: 0.7554 - val_loss: 0.5919 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 79/100\n",
            "981/981 [==============================] - 0s 143us/sample - loss: 0.5381 - sparse_categorical_accuracy: 0.7594 - val_loss: 0.5904 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 80/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.5374 - sparse_categorical_accuracy: 0.7564 - val_loss: 0.5889 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 81/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.5364 - sparse_categorical_accuracy: 0.7574 - val_loss: 0.5903 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 82/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.5347 - sparse_categorical_accuracy: 0.7554 - val_loss: 0.5884 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 83/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.5340 - sparse_categorical_accuracy: 0.7543 - val_loss: 0.5868 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 84/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5332 - sparse_categorical_accuracy: 0.7574 - val_loss: 0.5870 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 85/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.5319 - sparse_categorical_accuracy: 0.7655 - val_loss: 0.5878 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 86/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.5312 - sparse_categorical_accuracy: 0.7584 - val_loss: 0.5864 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 87/100\n",
            "981/981 [==============================] - 0s 137us/sample - loss: 0.5301 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.5862 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 88/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5292 - sparse_categorical_accuracy: 0.7594 - val_loss: 0.5844 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 89/100\n",
            "981/981 [==============================] - 0s 110us/sample - loss: 0.5286 - sparse_categorical_accuracy: 0.7584 - val_loss: 0.5846 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 90/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.5277 - sparse_categorical_accuracy: 0.7574 - val_loss: 0.5842 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 91/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5266 - sparse_categorical_accuracy: 0.7584 - val_loss: 0.5847 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 92/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5257 - sparse_categorical_accuracy: 0.7594 - val_loss: 0.5846 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 93/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.5248 - sparse_categorical_accuracy: 0.7615 - val_loss: 0.5824 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 94/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5244 - sparse_categorical_accuracy: 0.7574 - val_loss: 0.5824 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 95/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.5235 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.5811 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 96/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5228 - sparse_categorical_accuracy: 0.7635 - val_loss: 0.5814 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 97/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5219 - sparse_categorical_accuracy: 0.7655 - val_loss: 0.5822 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 98/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.5213 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.5810 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 99/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.5204 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.5802 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 100/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5194 - sparse_categorical_accuracy: 0.7666 - val_loss: 0.5811 - val_sparse_categorical_accuracy: 0.7182\n",
            "[CV] ......................... n_neurons=10, n_hidden=0, total=  14.7s\n",
            "[CV] n_neurons=23, n_hidden=1 ........................................\n",
            "Train on 981 samples, validate on 109 samples\n",
            "Epoch 1/100\n",
            "981/981 [==============================] - 1s 549us/sample - loss: 1.1158 - sparse_categorical_accuracy: 0.4108 - val_loss: 1.0549 - val_sparse_categorical_accuracy: 0.4404\n",
            "Epoch 2/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.9690 - sparse_categorical_accuracy: 0.4709 - val_loss: 0.9479 - val_sparse_categorical_accuracy: 0.4954\n",
            "Epoch 3/100\n",
            "981/981 [==============================] - 0s 140us/sample - loss: 0.8918 - sparse_categorical_accuracy: 0.5291 - val_loss: 0.8835 - val_sparse_categorical_accuracy: 0.5505\n",
            "Epoch 4/100\n",
            "981/981 [==============================] - 0s 141us/sample - loss: 0.8379 - sparse_categorical_accuracy: 0.5505 - val_loss: 0.8373 - val_sparse_categorical_accuracy: 0.5596\n",
            "Epoch 5/100\n",
            "981/981 [==============================] - 0s 140us/sample - loss: 0.7979 - sparse_categorical_accuracy: 0.5912 - val_loss: 0.7980 - val_sparse_categorical_accuracy: 0.5688\n",
            "Epoch 6/100\n",
            "981/981 [==============================] - 0s 148us/sample - loss: 0.7647 - sparse_categorical_accuracy: 0.6147 - val_loss: 0.7743 - val_sparse_categorical_accuracy: 0.5872\n",
            "Epoch 7/100\n",
            "981/981 [==============================] - 0s 142us/sample - loss: 0.7378 - sparse_categorical_accuracy: 0.6402 - val_loss: 0.7461 - val_sparse_categorical_accuracy: 0.5963\n",
            "Epoch 8/100\n",
            "981/981 [==============================] - 0s 140us/sample - loss: 0.7160 - sparse_categorical_accuracy: 0.6565 - val_loss: 0.7245 - val_sparse_categorical_accuracy: 0.6239\n",
            "Epoch 9/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.6958 - sparse_categorical_accuracy: 0.6738 - val_loss: 0.7079 - val_sparse_categorical_accuracy: 0.6422\n",
            "Epoch 10/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.6784 - sparse_categorical_accuracy: 0.6993 - val_loss: 0.6925 - val_sparse_categorical_accuracy: 0.6514\n",
            "Epoch 11/100\n",
            "981/981 [==============================] - 0s 136us/sample - loss: 0.6644 - sparse_categorical_accuracy: 0.7013 - val_loss: 0.6791 - val_sparse_categorical_accuracy: 0.6697\n",
            "Epoch 12/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.6519 - sparse_categorical_accuracy: 0.7034 - val_loss: 0.6684 - val_sparse_categorical_accuracy: 0.6606\n",
            "Epoch 13/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.6386 - sparse_categorical_accuracy: 0.7197 - val_loss: 0.6586 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 14/100\n",
            "981/981 [==============================] - 0s 134us/sample - loss: 0.6288 - sparse_categorical_accuracy: 0.7166 - val_loss: 0.6502 - val_sparse_categorical_accuracy: 0.6697\n",
            "Epoch 15/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.6183 - sparse_categorical_accuracy: 0.7268 - val_loss: 0.6366 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 16/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.6096 - sparse_categorical_accuracy: 0.7268 - val_loss: 0.6312 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 17/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.6013 - sparse_categorical_accuracy: 0.7258 - val_loss: 0.6257 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 18/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.5936 - sparse_categorical_accuracy: 0.7309 - val_loss: 0.6209 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 19/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.5872 - sparse_categorical_accuracy: 0.7299 - val_loss: 0.6192 - val_sparse_categorical_accuracy: 0.6697\n",
            "Epoch 20/100\n",
            "981/981 [==============================] - 0s 135us/sample - loss: 0.5805 - sparse_categorical_accuracy: 0.7329 - val_loss: 0.6094 - val_sparse_categorical_accuracy: 0.6606\n",
            "Epoch 21/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.5743 - sparse_categorical_accuracy: 0.7360 - val_loss: 0.6023 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 22/100\n",
            "981/981 [==============================] - 0s 143us/sample - loss: 0.5676 - sparse_categorical_accuracy: 0.7390 - val_loss: 0.5966 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 23/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.5625 - sparse_categorical_accuracy: 0.7390 - val_loss: 0.5962 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 24/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.5580 - sparse_categorical_accuracy: 0.7492 - val_loss: 0.5938 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 25/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.5529 - sparse_categorical_accuracy: 0.7482 - val_loss: 0.5865 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 26/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.5486 - sparse_categorical_accuracy: 0.7503 - val_loss: 0.5844 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 27/100\n",
            "981/981 [==============================] - 0s 134us/sample - loss: 0.5439 - sparse_categorical_accuracy: 0.7523 - val_loss: 0.5838 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 28/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.5397 - sparse_categorical_accuracy: 0.7574 - val_loss: 0.5778 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 29/100\n",
            "981/981 [==============================] - 0s 159us/sample - loss: 0.5368 - sparse_categorical_accuracy: 0.7533 - val_loss: 0.5791 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 30/100\n",
            "981/981 [==============================] - 0s 138us/sample - loss: 0.5334 - sparse_categorical_accuracy: 0.7645 - val_loss: 0.5772 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 31/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.5294 - sparse_categorical_accuracy: 0.7564 - val_loss: 0.5716 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 32/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.5262 - sparse_categorical_accuracy: 0.7645 - val_loss: 0.5665 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 33/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.5238 - sparse_categorical_accuracy: 0.7584 - val_loss: 0.5684 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 34/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.5193 - sparse_categorical_accuracy: 0.7676 - val_loss: 0.5618 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 35/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.5177 - sparse_categorical_accuracy: 0.7645 - val_loss: 0.5640 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 36/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.5144 - sparse_categorical_accuracy: 0.7584 - val_loss: 0.5671 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 37/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.5118 - sparse_categorical_accuracy: 0.7676 - val_loss: 0.5629 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 38/100\n",
            "981/981 [==============================] - 0s 143us/sample - loss: 0.5084 - sparse_categorical_accuracy: 0.7727 - val_loss: 0.5585 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 39/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.5063 - sparse_categorical_accuracy: 0.7737 - val_loss: 0.5635 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 40/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.5039 - sparse_categorical_accuracy: 0.7747 - val_loss: 0.5654 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 41/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.5016 - sparse_categorical_accuracy: 0.7798 - val_loss: 0.5599 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 42/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.4993 - sparse_categorical_accuracy: 0.7788 - val_loss: 0.5598 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 43/100\n",
            "981/981 [==============================] - 0s 145us/sample - loss: 0.4967 - sparse_categorical_accuracy: 0.7757 - val_loss: 0.5570 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 44/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.4948 - sparse_categorical_accuracy: 0.7737 - val_loss: 0.5589 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 45/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.4930 - sparse_categorical_accuracy: 0.7778 - val_loss: 0.5573 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 46/100\n",
            "981/981 [==============================] - 0s 151us/sample - loss: 0.4918 - sparse_categorical_accuracy: 0.7788 - val_loss: 0.5554 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 47/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.4895 - sparse_categorical_accuracy: 0.7798 - val_loss: 0.5542 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 48/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.4881 - sparse_categorical_accuracy: 0.7737 - val_loss: 0.5548 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 49/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.4859 - sparse_categorical_accuracy: 0.7839 - val_loss: 0.5533 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 50/100\n",
            "981/981 [==============================] - 0s 141us/sample - loss: 0.4840 - sparse_categorical_accuracy: 0.7757 - val_loss: 0.5518 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 51/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.4823 - sparse_categorical_accuracy: 0.7717 - val_loss: 0.5546 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 52/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.4817 - sparse_categorical_accuracy: 0.7829 - val_loss: 0.5545 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 53/100\n",
            "981/981 [==============================] - 0s 158us/sample - loss: 0.4804 - sparse_categorical_accuracy: 0.7788 - val_loss: 0.5515 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 54/100\n",
            "981/981 [==============================] - 0s 134us/sample - loss: 0.4788 - sparse_categorical_accuracy: 0.7798 - val_loss: 0.5520 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 55/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.4774 - sparse_categorical_accuracy: 0.7839 - val_loss: 0.5549 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 56/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.4761 - sparse_categorical_accuracy: 0.7890 - val_loss: 0.5573 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 57/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.4749 - sparse_categorical_accuracy: 0.7880 - val_loss: 0.5540 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 58/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.4735 - sparse_categorical_accuracy: 0.7839 - val_loss: 0.5544 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 59/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.4723 - sparse_categorical_accuracy: 0.7880 - val_loss: 0.5595 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 60/100\n",
            "981/981 [==============================] - 0s 141us/sample - loss: 0.4709 - sparse_categorical_accuracy: 0.7910 - val_loss: 0.5550 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 61/100\n",
            "981/981 [==============================] - 0s 144us/sample - loss: 0.4705 - sparse_categorical_accuracy: 0.7839 - val_loss: 0.5551 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 62/100\n",
            "981/981 [==============================] - 0s 143us/sample - loss: 0.4693 - sparse_categorical_accuracy: 0.7880 - val_loss: 0.5570 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 63/100\n",
            "981/981 [==============================] - 0s 135us/sample - loss: 0.4689 - sparse_categorical_accuracy: 0.7931 - val_loss: 0.5613 - val_sparse_categorical_accuracy: 0.7156\n",
            "[CV] ......................... n_neurons=23, n_hidden=1, total=   9.0s\n",
            "[CV] n_neurons=23, n_hidden=1 ........................................\n",
            "Train on 981 samples, validate on 109 samples\n",
            "Epoch 1/100\n",
            "981/981 [==============================] - 1s 534us/sample - loss: 1.2335 - sparse_categorical_accuracy: 0.3792 - val_loss: 1.1444 - val_sparse_categorical_accuracy: 0.4037\n",
            "Epoch 2/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 1.0632 - sparse_categorical_accuracy: 0.4312 - val_loss: 1.0464 - val_sparse_categorical_accuracy: 0.4495\n",
            "Epoch 3/100\n",
            "981/981 [==============================] - 0s 134us/sample - loss: 0.9757 - sparse_categorical_accuracy: 0.4862 - val_loss: 0.9633 - val_sparse_categorical_accuracy: 0.4862\n",
            "Epoch 4/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.9132 - sparse_categorical_accuracy: 0.5189 - val_loss: 0.9106 - val_sparse_categorical_accuracy: 0.4954\n",
            "Epoch 5/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.8642 - sparse_categorical_accuracy: 0.5617 - val_loss: 0.8700 - val_sparse_categorical_accuracy: 0.5229\n",
            "Epoch 6/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.8266 - sparse_categorical_accuracy: 0.5841 - val_loss: 0.8343 - val_sparse_categorical_accuracy: 0.5505\n",
            "Epoch 7/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.7948 - sparse_categorical_accuracy: 0.5963 - val_loss: 0.8077 - val_sparse_categorical_accuracy: 0.5688\n",
            "Epoch 8/100\n",
            "981/981 [==============================] - 0s 134us/sample - loss: 0.7655 - sparse_categorical_accuracy: 0.6167 - val_loss: 0.7910 - val_sparse_categorical_accuracy: 0.5872\n",
            "Epoch 9/100\n",
            "981/981 [==============================] - 0s 143us/sample - loss: 0.7424 - sparse_categorical_accuracy: 0.6218 - val_loss: 0.7700 - val_sparse_categorical_accuracy: 0.5963\n",
            "Epoch 10/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.7212 - sparse_categorical_accuracy: 0.6361 - val_loss: 0.7490 - val_sparse_categorical_accuracy: 0.6147\n",
            "Epoch 11/100\n",
            "981/981 [==============================] - 0s 144us/sample - loss: 0.7021 - sparse_categorical_accuracy: 0.6585 - val_loss: 0.7417 - val_sparse_categorical_accuracy: 0.6147\n",
            "Epoch 12/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.6880 - sparse_categorical_accuracy: 0.6677 - val_loss: 0.7203 - val_sparse_categorical_accuracy: 0.6239\n",
            "Epoch 13/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.6706 - sparse_categorical_accuracy: 0.6789 - val_loss: 0.7038 - val_sparse_categorical_accuracy: 0.6422\n",
            "Epoch 14/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.6581 - sparse_categorical_accuracy: 0.6820 - val_loss: 0.6942 - val_sparse_categorical_accuracy: 0.6422\n",
            "Epoch 15/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.6452 - sparse_categorical_accuracy: 0.6911 - val_loss: 0.6836 - val_sparse_categorical_accuracy: 0.6697\n",
            "Epoch 16/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.6330 - sparse_categorical_accuracy: 0.6962 - val_loss: 0.6798 - val_sparse_categorical_accuracy: 0.6330\n",
            "Epoch 17/100\n",
            "981/981 [==============================] - 0s 156us/sample - loss: 0.6226 - sparse_categorical_accuracy: 0.6993 - val_loss: 0.6631 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 18/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.6132 - sparse_categorical_accuracy: 0.7003 - val_loss: 0.6605 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 19/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.6036 - sparse_categorical_accuracy: 0.7085 - val_loss: 0.6482 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 20/100\n",
            "981/981 [==============================] - 0s 135us/sample - loss: 0.5944 - sparse_categorical_accuracy: 0.7115 - val_loss: 0.6448 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 21/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.5867 - sparse_categorical_accuracy: 0.7238 - val_loss: 0.6326 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 22/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.5791 - sparse_categorical_accuracy: 0.7227 - val_loss: 0.6326 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 23/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.5729 - sparse_categorical_accuracy: 0.7258 - val_loss: 0.6267 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 24/100\n",
            "981/981 [==============================] - 0s 156us/sample - loss: 0.5658 - sparse_categorical_accuracy: 0.7309 - val_loss: 0.6159 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 25/100\n",
            "981/981 [==============================] - 0s 143us/sample - loss: 0.5606 - sparse_categorical_accuracy: 0.7350 - val_loss: 0.6149 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 26/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.5545 - sparse_categorical_accuracy: 0.7319 - val_loss: 0.6100 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 27/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.5481 - sparse_categorical_accuracy: 0.7411 - val_loss: 0.6064 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 28/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.5448 - sparse_categorical_accuracy: 0.7360 - val_loss: 0.6003 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 29/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.5390 - sparse_categorical_accuracy: 0.7309 - val_loss: 0.5972 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 30/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.5353 - sparse_categorical_accuracy: 0.7401 - val_loss: 0.5954 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 31/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.5312 - sparse_categorical_accuracy: 0.7421 - val_loss: 0.5908 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 32/100\n",
            "981/981 [==============================] - 0s 144us/sample - loss: 0.5261 - sparse_categorical_accuracy: 0.7462 - val_loss: 0.5955 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 33/100\n",
            "981/981 [==============================] - 0s 144us/sample - loss: 0.5220 - sparse_categorical_accuracy: 0.7462 - val_loss: 0.5841 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 34/100\n",
            "981/981 [==============================] - 0s 138us/sample - loss: 0.5192 - sparse_categorical_accuracy: 0.7492 - val_loss: 0.5829 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 35/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.5156 - sparse_categorical_accuracy: 0.7503 - val_loss: 0.5825 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 36/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.5126 - sparse_categorical_accuracy: 0.7533 - val_loss: 0.5770 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 37/100\n",
            "981/981 [==============================] - 0s 140us/sample - loss: 0.5090 - sparse_categorical_accuracy: 0.7574 - val_loss: 0.5750 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 38/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.5059 - sparse_categorical_accuracy: 0.7645 - val_loss: 0.5723 - val_sparse_categorical_accuracy: 0.7523\n",
            "Epoch 39/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.5033 - sparse_categorical_accuracy: 0.7655 - val_loss: 0.5719 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 40/100\n",
            "981/981 [==============================] - 0s 142us/sample - loss: 0.5002 - sparse_categorical_accuracy: 0.7604 - val_loss: 0.5727 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 41/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.4977 - sparse_categorical_accuracy: 0.7635 - val_loss: 0.5670 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 42/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.4950 - sparse_categorical_accuracy: 0.7706 - val_loss: 0.5656 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 43/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.4930 - sparse_categorical_accuracy: 0.7706 - val_loss: 0.5652 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 44/100\n",
            "981/981 [==============================] - 0s 165us/sample - loss: 0.4908 - sparse_categorical_accuracy: 0.7717 - val_loss: 0.5635 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 45/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.4873 - sparse_categorical_accuracy: 0.7737 - val_loss: 0.5617 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 46/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.4854 - sparse_categorical_accuracy: 0.7768 - val_loss: 0.5611 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 47/100\n",
            "981/981 [==============================] - 0s 154us/sample - loss: 0.4834 - sparse_categorical_accuracy: 0.7808 - val_loss: 0.5639 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 48/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.4822 - sparse_categorical_accuracy: 0.7717 - val_loss: 0.5573 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 49/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.4797 - sparse_categorical_accuracy: 0.7870 - val_loss: 0.5585 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 50/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.4781 - sparse_categorical_accuracy: 0.7788 - val_loss: 0.5567 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 51/100\n",
            "981/981 [==============================] - 0s 136us/sample - loss: 0.4736 - sparse_categorical_accuracy: 0.7747 - val_loss: 0.5558 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 52/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.4757 - sparse_categorical_accuracy: 0.7819 - val_loss: 0.5565 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 53/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.4721 - sparse_categorical_accuracy: 0.7808 - val_loss: 0.5575 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 54/100\n",
            "981/981 [==============================] - 0s 136us/sample - loss: 0.4709 - sparse_categorical_accuracy: 0.7870 - val_loss: 0.5557 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 55/100\n",
            "981/981 [==============================] - 0s 159us/sample - loss: 0.4687 - sparse_categorical_accuracy: 0.7920 - val_loss: 0.5537 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 56/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.4678 - sparse_categorical_accuracy: 0.7870 - val_loss: 0.5571 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 57/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.4653 - sparse_categorical_accuracy: 0.7859 - val_loss: 0.5527 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 58/100\n",
            "981/981 [==============================] - 0s 145us/sample - loss: 0.4647 - sparse_categorical_accuracy: 0.7890 - val_loss: 0.5508 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 59/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.4630 - sparse_categorical_accuracy: 0.7961 - val_loss: 0.5513 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 60/100\n",
            "981/981 [==============================] - 0s 135us/sample - loss: 0.4609 - sparse_categorical_accuracy: 0.7910 - val_loss: 0.5483 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 61/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.4599 - sparse_categorical_accuracy: 0.7920 - val_loss: 0.5500 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 62/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.4580 - sparse_categorical_accuracy: 0.7880 - val_loss: 0.5515 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 63/100\n",
            "981/981 [==============================] - 0s 166us/sample - loss: 0.4582 - sparse_categorical_accuracy: 0.7931 - val_loss: 0.5499 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 64/100\n",
            "981/981 [==============================] - 0s 147us/sample - loss: 0.4564 - sparse_categorical_accuracy: 0.7931 - val_loss: 0.5492 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 65/100\n",
            "981/981 [==============================] - 0s 137us/sample - loss: 0.4544 - sparse_categorical_accuracy: 0.8012 - val_loss: 0.5487 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 66/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.4540 - sparse_categorical_accuracy: 0.7900 - val_loss: 0.5508 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 67/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.4520 - sparse_categorical_accuracy: 0.7951 - val_loss: 0.5517 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 68/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.4517 - sparse_categorical_accuracy: 0.7992 - val_loss: 0.5479 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 69/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.4507 - sparse_categorical_accuracy: 0.7971 - val_loss: 0.5476 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 70/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.4487 - sparse_categorical_accuracy: 0.7961 - val_loss: 0.5488 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 71/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.4473 - sparse_categorical_accuracy: 0.7971 - val_loss: 0.5526 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 72/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.4475 - sparse_categorical_accuracy: 0.8033 - val_loss: 0.5492 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 73/100\n",
            "981/981 [==============================] - 0s 135us/sample - loss: 0.4463 - sparse_categorical_accuracy: 0.8033 - val_loss: 0.5536 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 74/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.4453 - sparse_categorical_accuracy: 0.7971 - val_loss: 0.5514 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 75/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.4436 - sparse_categorical_accuracy: 0.8033 - val_loss: 0.5481 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 76/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.4430 - sparse_categorical_accuracy: 0.8043 - val_loss: 0.5483 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 77/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.4424 - sparse_categorical_accuracy: 0.8002 - val_loss: 0.5457 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 78/100\n",
            "981/981 [==============================] - 0s 138us/sample - loss: 0.4413 - sparse_categorical_accuracy: 0.8012 - val_loss: 0.5446 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 79/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.4407 - sparse_categorical_accuracy: 0.8033 - val_loss: 0.5527 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 80/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.4384 - sparse_categorical_accuracy: 0.8033 - val_loss: 0.5572 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 81/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.4381 - sparse_categorical_accuracy: 0.8053 - val_loss: 0.5447 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 82/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.4372 - sparse_categorical_accuracy: 0.8063 - val_loss: 0.5483 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 83/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.4359 - sparse_categorical_accuracy: 0.8053 - val_loss: 0.5445 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 84/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.4364 - sparse_categorical_accuracy: 0.8063 - val_loss: 0.5449 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 85/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.4336 - sparse_categorical_accuracy: 0.8114 - val_loss: 0.5542 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 86/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.4344 - sparse_categorical_accuracy: 0.8124 - val_loss: 0.5493 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 87/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.4331 - sparse_categorical_accuracy: 0.8073 - val_loss: 0.5449 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 88/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.4334 - sparse_categorical_accuracy: 0.8063 - val_loss: 0.5452 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 89/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.4333 - sparse_categorical_accuracy: 0.8104 - val_loss: 0.5519 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 90/100\n",
            "981/981 [==============================] - 0s 135us/sample - loss: 0.4303 - sparse_categorical_accuracy: 0.8094 - val_loss: 0.5458 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 91/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.4297 - sparse_categorical_accuracy: 0.8155 - val_loss: 0.5579 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 92/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.4300 - sparse_categorical_accuracy: 0.8155 - val_loss: 0.5501 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 93/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.4280 - sparse_categorical_accuracy: 0.8104 - val_loss: 0.5463 - val_sparse_categorical_accuracy: 0.7064\n",
            "[CV] ......................... n_neurons=23, n_hidden=1, total=  12.9s\n",
            "[CV] n_neurons=23, n_hidden=1 ........................................\n",
            "Train on 981 samples, validate on 109 samples\n",
            "Epoch 1/100\n",
            "981/981 [==============================] - 1s 529us/sample - loss: 1.1508 - sparse_categorical_accuracy: 0.4251 - val_loss: 1.0191 - val_sparse_categorical_accuracy: 0.4862\n",
            "Epoch 2/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 1.0218 - sparse_categorical_accuracy: 0.4628 - val_loss: 0.9260 - val_sparse_categorical_accuracy: 0.5780\n",
            "Epoch 3/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.9457 - sparse_categorical_accuracy: 0.5189 - val_loss: 0.8721 - val_sparse_categorical_accuracy: 0.5872\n",
            "Epoch 4/100\n",
            "981/981 [==============================] - 0s 136us/sample - loss: 0.8939 - sparse_categorical_accuracy: 0.5484 - val_loss: 0.8268 - val_sparse_categorical_accuracy: 0.6055\n",
            "Epoch 5/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.8535 - sparse_categorical_accuracy: 0.5759 - val_loss: 0.7943 - val_sparse_categorical_accuracy: 0.6147\n",
            "Epoch 6/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.8216 - sparse_categorical_accuracy: 0.5902 - val_loss: 0.7717 - val_sparse_categorical_accuracy: 0.6147\n",
            "Epoch 7/100\n",
            "981/981 [==============================] - 0s 143us/sample - loss: 0.7918 - sparse_categorical_accuracy: 0.6045 - val_loss: 0.7451 - val_sparse_categorical_accuracy: 0.6330\n",
            "Epoch 8/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.7684 - sparse_categorical_accuracy: 0.6300 - val_loss: 0.7242 - val_sparse_categorical_accuracy: 0.6330\n",
            "Epoch 9/100\n",
            "981/981 [==============================] - 0s 140us/sample - loss: 0.7473 - sparse_categorical_accuracy: 0.6279 - val_loss: 0.7103 - val_sparse_categorical_accuracy: 0.6606\n",
            "Epoch 10/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.7287 - sparse_categorical_accuracy: 0.6412 - val_loss: 0.6993 - val_sparse_categorical_accuracy: 0.6330\n",
            "Epoch 11/100\n",
            "981/981 [==============================] - 0s 144us/sample - loss: 0.7142 - sparse_categorical_accuracy: 0.6432 - val_loss: 0.6877 - val_sparse_categorical_accuracy: 0.6422\n",
            "Epoch 12/100\n",
            "981/981 [==============================] - 0s 142us/sample - loss: 0.6977 - sparse_categorical_accuracy: 0.6626 - val_loss: 0.6656 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 13/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.6848 - sparse_categorical_accuracy: 0.6626 - val_loss: 0.6604 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 14/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.6710 - sparse_categorical_accuracy: 0.6799 - val_loss: 0.6457 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 15/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.6591 - sparse_categorical_accuracy: 0.7003 - val_loss: 0.6378 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 16/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.6483 - sparse_categorical_accuracy: 0.6993 - val_loss: 0.6272 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 17/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.6387 - sparse_categorical_accuracy: 0.7034 - val_loss: 0.6200 - val_sparse_categorical_accuracy: 0.7523\n",
            "Epoch 18/100\n",
            "981/981 [==============================] - 0s 137us/sample - loss: 0.6289 - sparse_categorical_accuracy: 0.7197 - val_loss: 0.6132 - val_sparse_categorical_accuracy: 0.7615\n",
            "Epoch 19/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.6214 - sparse_categorical_accuracy: 0.7248 - val_loss: 0.6069 - val_sparse_categorical_accuracy: 0.7615\n",
            "Epoch 20/100\n",
            "981/981 [==============================] - 0s 144us/sample - loss: 0.6128 - sparse_categorical_accuracy: 0.7329 - val_loss: 0.6025 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 21/100\n",
            "981/981 [==============================] - 0s 138us/sample - loss: 0.6048 - sparse_categorical_accuracy: 0.7319 - val_loss: 0.5971 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 22/100\n",
            "981/981 [==============================] - 0s 143us/sample - loss: 0.5985 - sparse_categorical_accuracy: 0.7329 - val_loss: 0.5945 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 23/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.5906 - sparse_categorical_accuracy: 0.7421 - val_loss: 0.5874 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 24/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5851 - sparse_categorical_accuracy: 0.7431 - val_loss: 0.5839 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 25/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.5799 - sparse_categorical_accuracy: 0.7339 - val_loss: 0.5871 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 26/100\n",
            "981/981 [==============================] - 0s 151us/sample - loss: 0.5739 - sparse_categorical_accuracy: 0.7380 - val_loss: 0.5773 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 27/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.5695 - sparse_categorical_accuracy: 0.7441 - val_loss: 0.5699 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 28/100\n",
            "981/981 [==============================] - 0s 139us/sample - loss: 0.5639 - sparse_categorical_accuracy: 0.7482 - val_loss: 0.5710 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 29/100\n",
            "981/981 [==============================] - 0s 143us/sample - loss: 0.5600 - sparse_categorical_accuracy: 0.7482 - val_loss: 0.5723 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 30/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.5544 - sparse_categorical_accuracy: 0.7543 - val_loss: 0.5627 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 31/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.5525 - sparse_categorical_accuracy: 0.7574 - val_loss: 0.5634 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 32/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.5479 - sparse_categorical_accuracy: 0.7564 - val_loss: 0.5625 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 33/100\n",
            "981/981 [==============================] - 0s 134us/sample - loss: 0.5431 - sparse_categorical_accuracy: 0.7554 - val_loss: 0.5548 - val_sparse_categorical_accuracy: 0.7523\n",
            "Epoch 34/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.5404 - sparse_categorical_accuracy: 0.7554 - val_loss: 0.5525 - val_sparse_categorical_accuracy: 0.7523\n",
            "Epoch 35/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.5367 - sparse_categorical_accuracy: 0.7574 - val_loss: 0.5540 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 36/100\n",
            "981/981 [==============================] - 0s 151us/sample - loss: 0.5337 - sparse_categorical_accuracy: 0.7574 - val_loss: 0.5517 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 37/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.5309 - sparse_categorical_accuracy: 0.7604 - val_loss: 0.5510 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 38/100\n",
            "981/981 [==============================] - 0s 139us/sample - loss: 0.5267 - sparse_categorical_accuracy: 0.7645 - val_loss: 0.5446 - val_sparse_categorical_accuracy: 0.7615\n",
            "Epoch 39/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.5264 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.5457 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 40/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.5233 - sparse_categorical_accuracy: 0.7645 - val_loss: 0.5466 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 41/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.5197 - sparse_categorical_accuracy: 0.7594 - val_loss: 0.5489 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 42/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.5177 - sparse_categorical_accuracy: 0.7655 - val_loss: 0.5424 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 43/100\n",
            "981/981 [==============================] - 0s 140us/sample - loss: 0.5156 - sparse_categorical_accuracy: 0.7655 - val_loss: 0.5435 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 44/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.5130 - sparse_categorical_accuracy: 0.7706 - val_loss: 0.5402 - val_sparse_categorical_accuracy: 0.7615\n",
            "Epoch 45/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.5113 - sparse_categorical_accuracy: 0.7696 - val_loss: 0.5416 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 46/100\n",
            "981/981 [==============================] - 0s 142us/sample - loss: 0.5092 - sparse_categorical_accuracy: 0.7737 - val_loss: 0.5410 - val_sparse_categorical_accuracy: 0.7523\n",
            "Epoch 47/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.5078 - sparse_categorical_accuracy: 0.7696 - val_loss: 0.5419 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 48/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.5062 - sparse_categorical_accuracy: 0.7676 - val_loss: 0.5401 - val_sparse_categorical_accuracy: 0.7523\n",
            "Epoch 49/100\n",
            "981/981 [==============================] - 0s 135us/sample - loss: 0.5041 - sparse_categorical_accuracy: 0.7706 - val_loss: 0.5377 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 50/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.5023 - sparse_categorical_accuracy: 0.7717 - val_loss: 0.5367 - val_sparse_categorical_accuracy: 0.7615\n",
            "Epoch 51/100\n",
            "981/981 [==============================] - 0s 143us/sample - loss: 0.5006 - sparse_categorical_accuracy: 0.7727 - val_loss: 0.5399 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 52/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.5002 - sparse_categorical_accuracy: 0.7706 - val_loss: 0.5393 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 53/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.4990 - sparse_categorical_accuracy: 0.7686 - val_loss: 0.5353 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 54/100\n",
            "981/981 [==============================] - 0s 141us/sample - loss: 0.4956 - sparse_categorical_accuracy: 0.7747 - val_loss: 0.5354 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 55/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.4948 - sparse_categorical_accuracy: 0.7706 - val_loss: 0.5360 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 56/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.4943 - sparse_categorical_accuracy: 0.7706 - val_loss: 0.5343 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 57/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.4921 - sparse_categorical_accuracy: 0.7717 - val_loss: 0.5364 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 58/100\n",
            "981/981 [==============================] - 0s 134us/sample - loss: 0.4913 - sparse_categorical_accuracy: 0.7788 - val_loss: 0.5356 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 59/100\n",
            "981/981 [==============================] - 0s 157us/sample - loss: 0.4892 - sparse_categorical_accuracy: 0.7737 - val_loss: 0.5324 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 60/100\n",
            "981/981 [==============================] - 0s 141us/sample - loss: 0.4882 - sparse_categorical_accuracy: 0.7788 - val_loss: 0.5319 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 61/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.4873 - sparse_categorical_accuracy: 0.7768 - val_loss: 0.5322 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 62/100\n",
            "981/981 [==============================] - 0s 136us/sample - loss: 0.4860 - sparse_categorical_accuracy: 0.7747 - val_loss: 0.5420 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 63/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.4832 - sparse_categorical_accuracy: 0.7727 - val_loss: 0.5322 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 64/100\n",
            "981/981 [==============================] - 0s 138us/sample - loss: 0.4848 - sparse_categorical_accuracy: 0.7757 - val_loss: 0.5354 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 65/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.4830 - sparse_categorical_accuracy: 0.7798 - val_loss: 0.5345 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 66/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.4809 - sparse_categorical_accuracy: 0.7768 - val_loss: 0.5317 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 67/100\n",
            "981/981 [==============================] - 0s 143us/sample - loss: 0.4806 - sparse_categorical_accuracy: 0.7788 - val_loss: 0.5333 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 68/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.4801 - sparse_categorical_accuracy: 0.7778 - val_loss: 0.5332 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 69/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.4791 - sparse_categorical_accuracy: 0.7880 - val_loss: 0.5338 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 70/100\n",
            "981/981 [==============================] - 0s 141us/sample - loss: 0.4777 - sparse_categorical_accuracy: 0.7737 - val_loss: 0.5337 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 71/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.4763 - sparse_categorical_accuracy: 0.7798 - val_loss: 0.5328 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 72/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.4760 - sparse_categorical_accuracy: 0.7808 - val_loss: 0.5347 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 73/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.4756 - sparse_categorical_accuracy: 0.7849 - val_loss: 0.5333 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 74/100\n",
            "981/981 [==============================] - 0s 147us/sample - loss: 0.4746 - sparse_categorical_accuracy: 0.7819 - val_loss: 0.5345 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 75/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.4734 - sparse_categorical_accuracy: 0.7778 - val_loss: 0.5344 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 76/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.4725 - sparse_categorical_accuracy: 0.7859 - val_loss: 0.5352 - val_sparse_categorical_accuracy: 0.7339\n",
            "[CV] ......................... n_neurons=23, n_hidden=1, total=  10.7s\n",
            "[CV] n_neurons=23, n_hidden=1 ........................................\n",
            "Train on 981 samples, validate on 110 samples\n",
            "Epoch 1/100\n",
            "981/981 [==============================] - 1s 548us/sample - loss: 1.2651 - sparse_categorical_accuracy: 0.3772 - val_loss: 1.1313 - val_sparse_categorical_accuracy: 0.4091\n",
            "Epoch 2/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 1.0642 - sparse_categorical_accuracy: 0.4608 - val_loss: 1.0269 - val_sparse_categorical_accuracy: 0.4455\n",
            "Epoch 3/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.9669 - sparse_categorical_accuracy: 0.5097 - val_loss: 0.9524 - val_sparse_categorical_accuracy: 0.5000\n",
            "Epoch 4/100\n",
            "981/981 [==============================] - 0s 137us/sample - loss: 0.9002 - sparse_categorical_accuracy: 0.5240 - val_loss: 0.9018 - val_sparse_categorical_accuracy: 0.5364\n",
            "Epoch 5/100\n",
            "981/981 [==============================] - 0s 142us/sample - loss: 0.8493 - sparse_categorical_accuracy: 0.5627 - val_loss: 0.8579 - val_sparse_categorical_accuracy: 0.5545\n",
            "Epoch 6/100\n",
            "981/981 [==============================] - 0s 139us/sample - loss: 0.8103 - sparse_categorical_accuracy: 0.5800 - val_loss: 0.8268 - val_sparse_categorical_accuracy: 0.5818\n",
            "Epoch 7/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.7765 - sparse_categorical_accuracy: 0.6004 - val_loss: 0.7961 - val_sparse_categorical_accuracy: 0.6091\n",
            "Epoch 8/100\n",
            "981/981 [==============================] - 0s 139us/sample - loss: 0.7480 - sparse_categorical_accuracy: 0.6188 - val_loss: 0.7728 - val_sparse_categorical_accuracy: 0.6273\n",
            "Epoch 9/100\n",
            "981/981 [==============================] - 0s 144us/sample - loss: 0.7237 - sparse_categorical_accuracy: 0.6422 - val_loss: 0.7481 - val_sparse_categorical_accuracy: 0.6182\n",
            "Epoch 10/100\n",
            "981/981 [==============================] - 0s 146us/sample - loss: 0.7030 - sparse_categorical_accuracy: 0.6565 - val_loss: 0.7259 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 11/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.6844 - sparse_categorical_accuracy: 0.6646 - val_loss: 0.7104 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 12/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.6682 - sparse_categorical_accuracy: 0.6718 - val_loss: 0.6955 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 13/100\n",
            "981/981 [==============================] - 0s 143us/sample - loss: 0.6525 - sparse_categorical_accuracy: 0.6891 - val_loss: 0.6858 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 14/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.6389 - sparse_categorical_accuracy: 0.7044 - val_loss: 0.6701 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 15/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.6269 - sparse_categorical_accuracy: 0.7064 - val_loss: 0.6599 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 16/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.6156 - sparse_categorical_accuracy: 0.7146 - val_loss: 0.6506 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 17/100\n",
            "981/981 [==============================] - 0s 154us/sample - loss: 0.6052 - sparse_categorical_accuracy: 0.7309 - val_loss: 0.6427 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 18/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.5965 - sparse_categorical_accuracy: 0.7309 - val_loss: 0.6333 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 19/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.5873 - sparse_categorical_accuracy: 0.7350 - val_loss: 0.6277 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 20/100\n",
            "981/981 [==============================] - 0s 140us/sample - loss: 0.5792 - sparse_categorical_accuracy: 0.7380 - val_loss: 0.6247 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 21/100\n",
            "981/981 [==============================] - 0s 143us/sample - loss: 0.5717 - sparse_categorical_accuracy: 0.7441 - val_loss: 0.6091 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 22/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.5646 - sparse_categorical_accuracy: 0.7564 - val_loss: 0.6036 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 23/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.5583 - sparse_categorical_accuracy: 0.7594 - val_loss: 0.5986 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 24/100\n",
            "981/981 [==============================] - 0s 148us/sample - loss: 0.5520 - sparse_categorical_accuracy: 0.7686 - val_loss: 0.5964 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 25/100\n",
            "981/981 [==============================] - 0s 142us/sample - loss: 0.5459 - sparse_categorical_accuracy: 0.7676 - val_loss: 0.5890 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 26/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.5404 - sparse_categorical_accuracy: 0.7747 - val_loss: 0.5878 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 27/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.5361 - sparse_categorical_accuracy: 0.7808 - val_loss: 0.5807 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 28/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.5303 - sparse_categorical_accuracy: 0.7798 - val_loss: 0.5751 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 29/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.5263 - sparse_categorical_accuracy: 0.7829 - val_loss: 0.5735 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 30/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.5214 - sparse_categorical_accuracy: 0.7757 - val_loss: 0.5702 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 31/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.5175 - sparse_categorical_accuracy: 0.7819 - val_loss: 0.5657 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 32/100\n",
            "981/981 [==============================] - 0s 143us/sample - loss: 0.5132 - sparse_categorical_accuracy: 0.7849 - val_loss: 0.5681 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 33/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.5101 - sparse_categorical_accuracy: 0.7859 - val_loss: 0.5590 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 34/100\n",
            "981/981 [==============================] - 0s 145us/sample - loss: 0.5059 - sparse_categorical_accuracy: 0.7839 - val_loss: 0.5554 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 35/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.5023 - sparse_categorical_accuracy: 0.7839 - val_loss: 0.5525 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 36/100\n",
            "981/981 [==============================] - 0s 134us/sample - loss: 0.4992 - sparse_categorical_accuracy: 0.7900 - val_loss: 0.5527 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 37/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.4963 - sparse_categorical_accuracy: 0.7849 - val_loss: 0.5504 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 38/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.4938 - sparse_categorical_accuracy: 0.7870 - val_loss: 0.5478 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 39/100\n",
            "981/981 [==============================] - 0s 134us/sample - loss: 0.4907 - sparse_categorical_accuracy: 0.7880 - val_loss: 0.5458 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 40/100\n",
            "981/981 [==============================] - 0s 159us/sample - loss: 0.4880 - sparse_categorical_accuracy: 0.7829 - val_loss: 0.5469 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 41/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.4856 - sparse_categorical_accuracy: 0.7890 - val_loss: 0.5407 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 42/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.4827 - sparse_categorical_accuracy: 0.7859 - val_loss: 0.5404 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 43/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.4800 - sparse_categorical_accuracy: 0.7910 - val_loss: 0.5410 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 44/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.4780 - sparse_categorical_accuracy: 0.7931 - val_loss: 0.5392 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 45/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.4755 - sparse_categorical_accuracy: 0.7900 - val_loss: 0.5353 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 46/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.4737 - sparse_categorical_accuracy: 0.7900 - val_loss: 0.5359 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 47/100\n",
            "981/981 [==============================] - 0s 137us/sample - loss: 0.4720 - sparse_categorical_accuracy: 0.7920 - val_loss: 0.5343 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 48/100\n",
            "981/981 [==============================] - 0s 136us/sample - loss: 0.4701 - sparse_categorical_accuracy: 0.7961 - val_loss: 0.5303 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 49/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.4685 - sparse_categorical_accuracy: 0.7880 - val_loss: 0.5299 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 50/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.4663 - sparse_categorical_accuracy: 0.7859 - val_loss: 0.5290 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 51/100\n",
            "981/981 [==============================] - 0s 142us/sample - loss: 0.4647 - sparse_categorical_accuracy: 0.7910 - val_loss: 0.5277 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 52/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.4633 - sparse_categorical_accuracy: 0.7941 - val_loss: 0.5286 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 53/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.4608 - sparse_categorical_accuracy: 0.7931 - val_loss: 0.5316 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 54/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.4589 - sparse_categorical_accuracy: 0.7982 - val_loss: 0.5258 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 55/100\n",
            "981/981 [==============================] - 0s 135us/sample - loss: 0.4578 - sparse_categorical_accuracy: 0.7931 - val_loss: 0.5323 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 56/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.4564 - sparse_categorical_accuracy: 0.7951 - val_loss: 0.5306 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 57/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.4555 - sparse_categorical_accuracy: 0.7961 - val_loss: 0.5259 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 58/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.4532 - sparse_categorical_accuracy: 0.8022 - val_loss: 0.5271 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 59/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.4525 - sparse_categorical_accuracy: 0.7992 - val_loss: 0.5270 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 60/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.4505 - sparse_categorical_accuracy: 0.8033 - val_loss: 0.5272 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 61/100\n",
            "981/981 [==============================] - 0s 148us/sample - loss: 0.4497 - sparse_categorical_accuracy: 0.8033 - val_loss: 0.5248 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 62/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.4481 - sparse_categorical_accuracy: 0.8022 - val_loss: 0.5247 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 63/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.4485 - sparse_categorical_accuracy: 0.7982 - val_loss: 0.5258 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 64/100\n",
            "981/981 [==============================] - 0s 147us/sample - loss: 0.4464 - sparse_categorical_accuracy: 0.7961 - val_loss: 0.5254 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 65/100\n",
            "981/981 [==============================] - 0s 139us/sample - loss: 0.4454 - sparse_categorical_accuracy: 0.7982 - val_loss: 0.5270 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 66/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.4448 - sparse_categorical_accuracy: 0.7951 - val_loss: 0.5288 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 67/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.4436 - sparse_categorical_accuracy: 0.8033 - val_loss: 0.5271 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 68/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.4418 - sparse_categorical_accuracy: 0.8053 - val_loss: 0.5221 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 69/100\n",
            "981/981 [==============================] - 0s 135us/sample - loss: 0.4424 - sparse_categorical_accuracy: 0.7982 - val_loss: 0.5230 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 70/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.4398 - sparse_categorical_accuracy: 0.8012 - val_loss: 0.5282 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 71/100\n",
            "981/981 [==============================] - 0s 134us/sample - loss: 0.4392 - sparse_categorical_accuracy: 0.8043 - val_loss: 0.5268 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 72/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.4377 - sparse_categorical_accuracy: 0.8043 - val_loss: 0.5227 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 73/100\n",
            "981/981 [==============================] - 0s 134us/sample - loss: 0.4372 - sparse_categorical_accuracy: 0.8063 - val_loss: 0.5231 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 74/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.4368 - sparse_categorical_accuracy: 0.8033 - val_loss: 0.5244 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 75/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.4354 - sparse_categorical_accuracy: 0.8084 - val_loss: 0.5224 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 76/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.4342 - sparse_categorical_accuracy: 0.8033 - val_loss: 0.5254 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 77/100\n",
            "981/981 [==============================] - 0s 147us/sample - loss: 0.4332 - sparse_categorical_accuracy: 0.8053 - val_loss: 0.5239 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 78/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.4341 - sparse_categorical_accuracy: 0.8094 - val_loss: 0.5235 - val_sparse_categorical_accuracy: 0.7455\n",
            "[CV] ......................... n_neurons=23, n_hidden=1, total=  10.9s\n",
            "[CV] n_neurons=23, n_hidden=1 ........................................\n",
            "Train on 981 samples, validate on 110 samples\n",
            "Epoch 1/100\n",
            "981/981 [==============================] - 1s 565us/sample - loss: 1.2028 - sparse_categorical_accuracy: 0.4016 - val_loss: 1.1023 - val_sparse_categorical_accuracy: 0.4727\n",
            "Epoch 2/100\n",
            "981/981 [==============================] - 0s 139us/sample - loss: 1.0485 - sparse_categorical_accuracy: 0.4740 - val_loss: 1.0128 - val_sparse_categorical_accuracy: 0.5091\n",
            "Epoch 3/100\n",
            "981/981 [==============================] - 0s 138us/sample - loss: 0.9609 - sparse_categorical_accuracy: 0.5087 - val_loss: 0.9462 - val_sparse_categorical_accuracy: 0.5273\n",
            "Epoch 4/100\n",
            "981/981 [==============================] - 0s 140us/sample - loss: 0.8979 - sparse_categorical_accuracy: 0.5321 - val_loss: 0.9018 - val_sparse_categorical_accuracy: 0.5727\n",
            "Epoch 5/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.8477 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.8682 - val_sparse_categorical_accuracy: 0.5545\n",
            "Epoch 6/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.8089 - sparse_categorical_accuracy: 0.6014 - val_loss: 0.8420 - val_sparse_categorical_accuracy: 0.5727\n",
            "Epoch 7/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.7765 - sparse_categorical_accuracy: 0.6269 - val_loss: 0.8151 - val_sparse_categorical_accuracy: 0.5909\n",
            "Epoch 8/100\n",
            "981/981 [==============================] - 0s 134us/sample - loss: 0.7487 - sparse_categorical_accuracy: 0.6320 - val_loss: 0.7995 - val_sparse_categorical_accuracy: 0.6000\n",
            "Epoch 9/100\n",
            "981/981 [==============================] - 0s 139us/sample - loss: 0.7254 - sparse_categorical_accuracy: 0.6514 - val_loss: 0.7775 - val_sparse_categorical_accuracy: 0.6000\n",
            "Epoch 10/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.7053 - sparse_categorical_accuracy: 0.6646 - val_loss: 0.7654 - val_sparse_categorical_accuracy: 0.6091\n",
            "Epoch 11/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.6871 - sparse_categorical_accuracy: 0.6779 - val_loss: 0.7529 - val_sparse_categorical_accuracy: 0.5909\n",
            "Epoch 12/100\n",
            "981/981 [==============================] - 0s 146us/sample - loss: 0.6712 - sparse_categorical_accuracy: 0.6758 - val_loss: 0.7438 - val_sparse_categorical_accuracy: 0.6091\n",
            "Epoch 13/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.6560 - sparse_categorical_accuracy: 0.6901 - val_loss: 0.7290 - val_sparse_categorical_accuracy: 0.6182\n",
            "Epoch 14/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.6430 - sparse_categorical_accuracy: 0.6972 - val_loss: 0.7195 - val_sparse_categorical_accuracy: 0.6091\n",
            "Epoch 15/100\n",
            "981/981 [==============================] - 0s 136us/sample - loss: 0.6297 - sparse_categorical_accuracy: 0.6952 - val_loss: 0.7081 - val_sparse_categorical_accuracy: 0.6273\n",
            "Epoch 16/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.6194 - sparse_categorical_accuracy: 0.7013 - val_loss: 0.7026 - val_sparse_categorical_accuracy: 0.6182\n",
            "Epoch 17/100\n",
            "981/981 [==============================] - 0s 135us/sample - loss: 0.6084 - sparse_categorical_accuracy: 0.7054 - val_loss: 0.6963 - val_sparse_categorical_accuracy: 0.6273\n",
            "Epoch 18/100\n",
            "981/981 [==============================] - 0s 136us/sample - loss: 0.5997 - sparse_categorical_accuracy: 0.7105 - val_loss: 0.6907 - val_sparse_categorical_accuracy: 0.6091\n",
            "Epoch 19/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.5906 - sparse_categorical_accuracy: 0.7187 - val_loss: 0.6843 - val_sparse_categorical_accuracy: 0.5909\n",
            "Epoch 20/100\n",
            "981/981 [==============================] - 0s 161us/sample - loss: 0.5827 - sparse_categorical_accuracy: 0.7197 - val_loss: 0.6803 - val_sparse_categorical_accuracy: 0.6091\n",
            "Epoch 21/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.5763 - sparse_categorical_accuracy: 0.7350 - val_loss: 0.6759 - val_sparse_categorical_accuracy: 0.6182\n",
            "Epoch 22/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.5686 - sparse_categorical_accuracy: 0.7319 - val_loss: 0.6666 - val_sparse_categorical_accuracy: 0.6455\n",
            "Epoch 23/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.5619 - sparse_categorical_accuracy: 0.7329 - val_loss: 0.6653 - val_sparse_categorical_accuracy: 0.6273\n",
            "Epoch 24/100\n",
            "981/981 [==============================] - 0s 141us/sample - loss: 0.5564 - sparse_categorical_accuracy: 0.7390 - val_loss: 0.6613 - val_sparse_categorical_accuracy: 0.6273\n",
            "Epoch 25/100\n",
            "981/981 [==============================] - 0s 134us/sample - loss: 0.5509 - sparse_categorical_accuracy: 0.7411 - val_loss: 0.6558 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 26/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.5465 - sparse_categorical_accuracy: 0.7503 - val_loss: 0.6491 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 27/100\n",
            "981/981 [==============================] - 0s 147us/sample - loss: 0.5410 - sparse_categorical_accuracy: 0.7431 - val_loss: 0.6480 - val_sparse_categorical_accuracy: 0.6364\n",
            "Epoch 28/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.5369 - sparse_categorical_accuracy: 0.7482 - val_loss: 0.6490 - val_sparse_categorical_accuracy: 0.6273\n",
            "Epoch 29/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.5321 - sparse_categorical_accuracy: 0.7543 - val_loss: 0.6417 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 30/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.5277 - sparse_categorical_accuracy: 0.7564 - val_loss: 0.6381 - val_sparse_categorical_accuracy: 0.6364\n",
            "Epoch 31/100\n",
            "981/981 [==============================] - 0s 152us/sample - loss: 0.5247 - sparse_categorical_accuracy: 0.7574 - val_loss: 0.6323 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 32/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.5211 - sparse_categorical_accuracy: 0.7594 - val_loss: 0.6247 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 33/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.5179 - sparse_categorical_accuracy: 0.7564 - val_loss: 0.6266 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 34/100\n",
            "981/981 [==============================] - 0s 149us/sample - loss: 0.5140 - sparse_categorical_accuracy: 0.7615 - val_loss: 0.6243 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 35/100\n",
            "981/981 [==============================] - 0s 136us/sample - loss: 0.5101 - sparse_categorical_accuracy: 0.7676 - val_loss: 0.6250 - val_sparse_categorical_accuracy: 0.6273\n",
            "Epoch 36/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.5061 - sparse_categorical_accuracy: 0.7635 - val_loss: 0.6191 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 37/100\n",
            "981/981 [==============================] - 0s 146us/sample - loss: 0.5055 - sparse_categorical_accuracy: 0.7655 - val_loss: 0.6160 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 38/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.5019 - sparse_categorical_accuracy: 0.7655 - val_loss: 0.6140 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 39/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.4995 - sparse_categorical_accuracy: 0.7696 - val_loss: 0.6122 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 40/100\n",
            "981/981 [==============================] - 0s 144us/sample - loss: 0.4969 - sparse_categorical_accuracy: 0.7747 - val_loss: 0.6130 - val_sparse_categorical_accuracy: 0.6455\n",
            "Epoch 41/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.4946 - sparse_categorical_accuracy: 0.7706 - val_loss: 0.6087 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 42/100\n",
            "981/981 [==============================] - 0s 142us/sample - loss: 0.4918 - sparse_categorical_accuracy: 0.7706 - val_loss: 0.6072 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 43/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.4897 - sparse_categorical_accuracy: 0.7737 - val_loss: 0.6093 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 44/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.4881 - sparse_categorical_accuracy: 0.7788 - val_loss: 0.6116 - val_sparse_categorical_accuracy: 0.6455\n",
            "Epoch 45/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.4875 - sparse_categorical_accuracy: 0.7788 - val_loss: 0.6024 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 46/100\n",
            "981/981 [==============================] - 0s 151us/sample - loss: 0.4839 - sparse_categorical_accuracy: 0.7788 - val_loss: 0.6008 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 47/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.4821 - sparse_categorical_accuracy: 0.7788 - val_loss: 0.6001 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 48/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.4810 - sparse_categorical_accuracy: 0.7798 - val_loss: 0.5991 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 49/100\n",
            "981/981 [==============================] - 0s 134us/sample - loss: 0.4794 - sparse_categorical_accuracy: 0.7839 - val_loss: 0.5988 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 50/100\n",
            "981/981 [==============================] - 0s 151us/sample - loss: 0.4769 - sparse_categorical_accuracy: 0.7798 - val_loss: 0.5956 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 51/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.4754 - sparse_categorical_accuracy: 0.7870 - val_loss: 0.6011 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 52/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.4732 - sparse_categorical_accuracy: 0.7859 - val_loss: 0.5933 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 53/100\n",
            "981/981 [==============================] - 0s 134us/sample - loss: 0.4730 - sparse_categorical_accuracy: 0.7829 - val_loss: 0.5944 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 54/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.4707 - sparse_categorical_accuracy: 0.7870 - val_loss: 0.5990 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 55/100\n",
            "981/981 [==============================] - 0s 140us/sample - loss: 0.4698 - sparse_categorical_accuracy: 0.7880 - val_loss: 0.5899 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 56/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.4677 - sparse_categorical_accuracy: 0.7920 - val_loss: 0.5980 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 57/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.4675 - sparse_categorical_accuracy: 0.7910 - val_loss: 0.5913 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 58/100\n",
            "981/981 [==============================] - 0s 143us/sample - loss: 0.4657 - sparse_categorical_accuracy: 0.7941 - val_loss: 0.5964 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 59/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.4648 - sparse_categorical_accuracy: 0.7910 - val_loss: 0.5951 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 60/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.4643 - sparse_categorical_accuracy: 0.7910 - val_loss: 0.5896 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 61/100\n",
            "981/981 [==============================] - 0s 149us/sample - loss: 0.4624 - sparse_categorical_accuracy: 0.7910 - val_loss: 0.5881 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 62/100\n",
            "981/981 [==============================] - 0s 141us/sample - loss: 0.4611 - sparse_categorical_accuracy: 0.7951 - val_loss: 0.5846 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 63/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.4605 - sparse_categorical_accuracy: 0.7941 - val_loss: 0.5932 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 64/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.4588 - sparse_categorical_accuracy: 0.7931 - val_loss: 0.5977 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 65/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.4592 - sparse_categorical_accuracy: 0.7941 - val_loss: 0.5887 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 66/100\n",
            "981/981 [==============================] - 0s 153us/sample - loss: 0.4572 - sparse_categorical_accuracy: 0.7931 - val_loss: 0.5860 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 67/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.4564 - sparse_categorical_accuracy: 0.7971 - val_loss: 0.5876 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 68/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.4535 - sparse_categorical_accuracy: 0.7992 - val_loss: 0.5824 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 69/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.4551 - sparse_categorical_accuracy: 0.7890 - val_loss: 0.5843 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 70/100\n",
            "981/981 [==============================] - 0s 142us/sample - loss: 0.4532 - sparse_categorical_accuracy: 0.7961 - val_loss: 0.5898 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 71/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.4531 - sparse_categorical_accuracy: 0.7931 - val_loss: 0.5905 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 72/100\n",
            "981/981 [==============================] - 0s 139us/sample - loss: 0.4522 - sparse_categorical_accuracy: 0.7931 - val_loss: 0.5872 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 73/100\n",
            "981/981 [==============================] - 0s 137us/sample - loss: 0.4507 - sparse_categorical_accuracy: 0.7992 - val_loss: 0.5826 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 74/100\n",
            "981/981 [==============================] - 0s 142us/sample - loss: 0.4488 - sparse_categorical_accuracy: 0.7941 - val_loss: 0.5854 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 75/100\n",
            "981/981 [==============================] - 0s 147us/sample - loss: 0.4487 - sparse_categorical_accuracy: 0.7951 - val_loss: 0.5807 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 76/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.4481 - sparse_categorical_accuracy: 0.7982 - val_loss: 0.5845 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 77/100\n",
            "981/981 [==============================] - 0s 138us/sample - loss: 0.4474 - sparse_categorical_accuracy: 0.7982 - val_loss: 0.5820 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 78/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.4459 - sparse_categorical_accuracy: 0.7982 - val_loss: 0.5785 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 79/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.4464 - sparse_categorical_accuracy: 0.7931 - val_loss: 0.5895 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 80/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.4435 - sparse_categorical_accuracy: 0.8012 - val_loss: 0.5830 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 81/100\n",
            "981/981 [==============================] - 0s 141us/sample - loss: 0.4450 - sparse_categorical_accuracy: 0.7982 - val_loss: 0.5793 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 82/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.4449 - sparse_categorical_accuracy: 0.7961 - val_loss: 0.5779 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 83/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.4423 - sparse_categorical_accuracy: 0.7992 - val_loss: 0.5905 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 84/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.4432 - sparse_categorical_accuracy: 0.8012 - val_loss: 0.5848 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 85/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.4416 - sparse_categorical_accuracy: 0.8022 - val_loss: 0.5837 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 86/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.4404 - sparse_categorical_accuracy: 0.8033 - val_loss: 0.5802 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 87/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.4399 - sparse_categorical_accuracy: 0.7961 - val_loss: 0.5854 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 88/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.4385 - sparse_categorical_accuracy: 0.8022 - val_loss: 0.5843 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 89/100\n",
            "981/981 [==============================] - 0s 151us/sample - loss: 0.4391 - sparse_categorical_accuracy: 0.8002 - val_loss: 0.5886 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 90/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.4383 - sparse_categorical_accuracy: 0.8012 - val_loss: 0.5824 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 91/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.4379 - sparse_categorical_accuracy: 0.8033 - val_loss: 0.5822 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 92/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.4366 - sparse_categorical_accuracy: 0.8033 - val_loss: 0.5844 - val_sparse_categorical_accuracy: 0.6636\n",
            "[CV] ......................... n_neurons=23, n_hidden=1, total=  12.9s\n",
            "[CV] n_neurons=97, n_hidden=1 ........................................\n",
            "Train on 981 samples, validate on 109 samples\n",
            "Epoch 1/100\n",
            "981/981 [==============================] - 1s 557us/sample - loss: 1.1849 - sparse_categorical_accuracy: 0.3894 - val_loss: 1.0994 - val_sparse_categorical_accuracy: 0.4312\n",
            "Epoch 2/100\n",
            "981/981 [==============================] - 0s 170us/sample - loss: 0.9589 - sparse_categorical_accuracy: 0.5291 - val_loss: 0.9516 - val_sparse_categorical_accuracy: 0.4954\n",
            "Epoch 3/100\n",
            "981/981 [==============================] - 0s 147us/sample - loss: 0.8556 - sparse_categorical_accuracy: 0.5780 - val_loss: 0.8642 - val_sparse_categorical_accuracy: 0.5688\n",
            "Epoch 4/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.7895 - sparse_categorical_accuracy: 0.6177 - val_loss: 0.8061 - val_sparse_categorical_accuracy: 0.6055\n",
            "Epoch 5/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.7416 - sparse_categorical_accuracy: 0.6432 - val_loss: 0.7712 - val_sparse_categorical_accuracy: 0.6055\n",
            "Epoch 6/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.7064 - sparse_categorical_accuracy: 0.6728 - val_loss: 0.7368 - val_sparse_categorical_accuracy: 0.6422\n",
            "Epoch 7/100\n",
            "981/981 [==============================] - 0s 141us/sample - loss: 0.6783 - sparse_categorical_accuracy: 0.6881 - val_loss: 0.7136 - val_sparse_categorical_accuracy: 0.6697\n",
            "Epoch 8/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.6555 - sparse_categorical_accuracy: 0.6962 - val_loss: 0.6922 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 9/100\n",
            "981/981 [==============================] - 0s 140us/sample - loss: 0.6360 - sparse_categorical_accuracy: 0.7166 - val_loss: 0.6746 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 10/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.6178 - sparse_categorical_accuracy: 0.7278 - val_loss: 0.6615 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 11/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.6065 - sparse_categorical_accuracy: 0.7299 - val_loss: 0.6507 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 12/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.5934 - sparse_categorical_accuracy: 0.7288 - val_loss: 0.6392 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 13/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.5820 - sparse_categorical_accuracy: 0.7401 - val_loss: 0.6325 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 14/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.5728 - sparse_categorical_accuracy: 0.7492 - val_loss: 0.6238 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 15/100\n",
            "981/981 [==============================] - 0s 149us/sample - loss: 0.5632 - sparse_categorical_accuracy: 0.7492 - val_loss: 0.6172 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 16/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.5556 - sparse_categorical_accuracy: 0.7574 - val_loss: 0.6089 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 17/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.5459 - sparse_categorical_accuracy: 0.7676 - val_loss: 0.6084 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 18/100\n",
            "981/981 [==============================] - 0s 136us/sample - loss: 0.5423 - sparse_categorical_accuracy: 0.7655 - val_loss: 0.6001 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 19/100\n",
            "981/981 [==============================] - 0s 154us/sample - loss: 0.5361 - sparse_categorical_accuracy: 0.7645 - val_loss: 0.5990 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 20/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.5301 - sparse_categorical_accuracy: 0.7686 - val_loss: 0.5952 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 21/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.5255 - sparse_categorical_accuracy: 0.7737 - val_loss: 0.5887 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 22/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.5195 - sparse_categorical_accuracy: 0.7676 - val_loss: 0.5917 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 23/100\n",
            "981/981 [==============================] - 0s 149us/sample - loss: 0.5157 - sparse_categorical_accuracy: 0.7706 - val_loss: 0.5846 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 24/100\n",
            "981/981 [==============================] - 0s 137us/sample - loss: 0.5130 - sparse_categorical_accuracy: 0.7747 - val_loss: 0.5843 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 25/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.5087 - sparse_categorical_accuracy: 0.7737 - val_loss: 0.5794 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 26/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5036 - sparse_categorical_accuracy: 0.7717 - val_loss: 0.5918 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 27/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.5023 - sparse_categorical_accuracy: 0.7747 - val_loss: 0.5782 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 28/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.4995 - sparse_categorical_accuracy: 0.7737 - val_loss: 0.5807 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 29/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.4962 - sparse_categorical_accuracy: 0.7757 - val_loss: 0.5719 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 30/100\n",
            "981/981 [==============================] - 0s 148us/sample - loss: 0.4922 - sparse_categorical_accuracy: 0.7808 - val_loss: 0.5704 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 31/100\n",
            "981/981 [==============================] - 0s 156us/sample - loss: 0.4892 - sparse_categorical_accuracy: 0.7829 - val_loss: 0.5661 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 32/100\n",
            "981/981 [==============================] - 0s 147us/sample - loss: 0.4874 - sparse_categorical_accuracy: 0.7788 - val_loss: 0.5725 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 33/100\n",
            "981/981 [==============================] - 0s 145us/sample - loss: 0.4852 - sparse_categorical_accuracy: 0.7798 - val_loss: 0.5752 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 34/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.4833 - sparse_categorical_accuracy: 0.7880 - val_loss: 0.5704 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 35/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.4795 - sparse_categorical_accuracy: 0.7768 - val_loss: 0.5730 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 36/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.4812 - sparse_categorical_accuracy: 0.7849 - val_loss: 0.5658 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 37/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.4769 - sparse_categorical_accuracy: 0.7788 - val_loss: 0.5666 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 38/100\n",
            "981/981 [==============================] - 0s 138us/sample - loss: 0.4748 - sparse_categorical_accuracy: 0.7839 - val_loss: 0.5652 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 39/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.4729 - sparse_categorical_accuracy: 0.7829 - val_loss: 0.5647 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 40/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.4704 - sparse_categorical_accuracy: 0.7870 - val_loss: 0.5618 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 41/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.4702 - sparse_categorical_accuracy: 0.7859 - val_loss: 0.5658 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 42/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.4654 - sparse_categorical_accuracy: 0.7890 - val_loss: 0.5667 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 43/100\n",
            "981/981 [==============================] - 0s 141us/sample - loss: 0.4657 - sparse_categorical_accuracy: 0.7819 - val_loss: 0.5656 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 44/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.4653 - sparse_categorical_accuracy: 0.7931 - val_loss: 0.5650 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 45/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.4634 - sparse_categorical_accuracy: 0.7951 - val_loss: 0.5690 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 46/100\n",
            "981/981 [==============================] - 0s 141us/sample - loss: 0.4626 - sparse_categorical_accuracy: 0.7931 - val_loss: 0.5651 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 47/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.4611 - sparse_categorical_accuracy: 0.7941 - val_loss: 0.5613 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 48/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.4588 - sparse_categorical_accuracy: 0.7931 - val_loss: 0.5634 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 49/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.4566 - sparse_categorical_accuracy: 0.7920 - val_loss: 0.5635 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 50/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.4567 - sparse_categorical_accuracy: 0.7941 - val_loss: 0.5650 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 51/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.4566 - sparse_categorical_accuracy: 0.7900 - val_loss: 0.5624 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 52/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.4537 - sparse_categorical_accuracy: 0.7941 - val_loss: 0.5657 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 53/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.4528 - sparse_categorical_accuracy: 0.7880 - val_loss: 0.5653 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 54/100\n",
            "981/981 [==============================] - 0s 162us/sample - loss: 0.4526 - sparse_categorical_accuracy: 0.7971 - val_loss: 0.5649 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 55/100\n",
            "981/981 [==============================] - 0s 140us/sample - loss: 0.4492 - sparse_categorical_accuracy: 0.7992 - val_loss: 0.5776 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 56/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.4497 - sparse_categorical_accuracy: 0.7920 - val_loss: 0.5784 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 57/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.4500 - sparse_categorical_accuracy: 0.7992 - val_loss: 0.5684 - val_sparse_categorical_accuracy: 0.7248\n",
            "[CV] ......................... n_neurons=97, n_hidden=1, total=   8.2s\n",
            "[CV] n_neurons=97, n_hidden=1 ........................................\n",
            "Train on 981 samples, validate on 109 samples\n",
            "Epoch 1/100\n",
            "981/981 [==============================] - 1s 553us/sample - loss: 1.0674 - sparse_categorical_accuracy: 0.4699 - val_loss: 0.9007 - val_sparse_categorical_accuracy: 0.6055\n",
            "Epoch 2/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.9023 - sparse_categorical_accuracy: 0.5556 - val_loss: 0.7948 - val_sparse_categorical_accuracy: 0.6514\n",
            "Epoch 3/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.8241 - sparse_categorical_accuracy: 0.5933 - val_loss: 0.7396 - val_sparse_categorical_accuracy: 0.6697\n",
            "Epoch 4/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.7698 - sparse_categorical_accuracy: 0.6300 - val_loss: 0.6995 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 5/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.7251 - sparse_categorical_accuracy: 0.6656 - val_loss: 0.6710 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 6/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.6942 - sparse_categorical_accuracy: 0.6799 - val_loss: 0.6511 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 7/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.6686 - sparse_categorical_accuracy: 0.6891 - val_loss: 0.6351 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 8/100\n",
            "981/981 [==============================] - 0s 154us/sample - loss: 0.6473 - sparse_categorical_accuracy: 0.6993 - val_loss: 0.6207 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 9/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.6297 - sparse_categorical_accuracy: 0.7288 - val_loss: 0.6126 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 10/100\n",
            "981/981 [==============================] - 0s 152us/sample - loss: 0.6142 - sparse_categorical_accuracy: 0.7227 - val_loss: 0.6003 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 11/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.6008 - sparse_categorical_accuracy: 0.7299 - val_loss: 0.5944 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 12/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.5881 - sparse_categorical_accuracy: 0.7390 - val_loss: 0.5845 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 13/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.5769 - sparse_categorical_accuracy: 0.7390 - val_loss: 0.5807 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 14/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.5687 - sparse_categorical_accuracy: 0.7431 - val_loss: 0.5739 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 15/100\n",
            "981/981 [==============================] - 0s 141us/sample - loss: 0.5593 - sparse_categorical_accuracy: 0.7482 - val_loss: 0.5733 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 16/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.5518 - sparse_categorical_accuracy: 0.7564 - val_loss: 0.5651 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 17/100\n",
            "981/981 [==============================] - 0s 135us/sample - loss: 0.5448 - sparse_categorical_accuracy: 0.7513 - val_loss: 0.5627 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 18/100\n",
            "981/981 [==============================] - 0s 152us/sample - loss: 0.5400 - sparse_categorical_accuracy: 0.7564 - val_loss: 0.5575 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 19/100\n",
            "981/981 [==============================] - 0s 141us/sample - loss: 0.5328 - sparse_categorical_accuracy: 0.7615 - val_loss: 0.5581 - val_sparse_categorical_accuracy: 0.6697\n",
            "Epoch 20/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.5267 - sparse_categorical_accuracy: 0.7696 - val_loss: 0.5535 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 21/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.5227 - sparse_categorical_accuracy: 0.7676 - val_loss: 0.5513 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 22/100\n",
            "981/981 [==============================] - 0s 138us/sample - loss: 0.5176 - sparse_categorical_accuracy: 0.7686 - val_loss: 0.5466 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 23/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.5132 - sparse_categorical_accuracy: 0.7768 - val_loss: 0.5487 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 24/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.5104 - sparse_categorical_accuracy: 0.7717 - val_loss: 0.5515 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 25/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.5054 - sparse_categorical_accuracy: 0.7757 - val_loss: 0.5424 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 26/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5026 - sparse_categorical_accuracy: 0.7788 - val_loss: 0.5473 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 27/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5001 - sparse_categorical_accuracy: 0.7706 - val_loss: 0.5441 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 28/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.4950 - sparse_categorical_accuracy: 0.7788 - val_loss: 0.5479 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 29/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.4933 - sparse_categorical_accuracy: 0.7808 - val_loss: 0.5406 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 30/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.4898 - sparse_categorical_accuracy: 0.7798 - val_loss: 0.5352 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 31/100\n",
            "981/981 [==============================] - 0s 152us/sample - loss: 0.4857 - sparse_categorical_accuracy: 0.7870 - val_loss: 0.5346 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 32/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.4844 - sparse_categorical_accuracy: 0.7829 - val_loss: 0.5376 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 33/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.4817 - sparse_categorical_accuracy: 0.7880 - val_loss: 0.5392 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 34/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.4789 - sparse_categorical_accuracy: 0.7941 - val_loss: 0.5438 - val_sparse_categorical_accuracy: 0.6697\n",
            "Epoch 35/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.4776 - sparse_categorical_accuracy: 0.7859 - val_loss: 0.5356 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 36/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.4745 - sparse_categorical_accuracy: 0.7910 - val_loss: 0.5316 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 37/100\n",
            "981/981 [==============================] - 0s 135us/sample - loss: 0.4750 - sparse_categorical_accuracy: 0.7890 - val_loss: 0.5292 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 38/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.4722 - sparse_categorical_accuracy: 0.7961 - val_loss: 0.5290 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 39/100\n",
            "981/981 [==============================] - 0s 154us/sample - loss: 0.4695 - sparse_categorical_accuracy: 0.7931 - val_loss: 0.5273 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 40/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.4681 - sparse_categorical_accuracy: 0.7951 - val_loss: 0.5329 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 41/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.4656 - sparse_categorical_accuracy: 0.7941 - val_loss: 0.5301 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 42/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.4661 - sparse_categorical_accuracy: 0.7941 - val_loss: 0.5296 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 43/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.4644 - sparse_categorical_accuracy: 0.7931 - val_loss: 0.5272 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 44/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.4610 - sparse_categorical_accuracy: 0.7992 - val_loss: 0.5347 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 45/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.4603 - sparse_categorical_accuracy: 0.8022 - val_loss: 0.5359 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 46/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.4608 - sparse_categorical_accuracy: 0.7982 - val_loss: 0.5311 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 47/100\n",
            "981/981 [==============================] - 0s 143us/sample - loss: 0.4559 - sparse_categorical_accuracy: 0.8073 - val_loss: 0.5281 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 48/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.4572 - sparse_categorical_accuracy: 0.7971 - val_loss: 0.5283 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 49/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.4567 - sparse_categorical_accuracy: 0.8094 - val_loss: 0.5273 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 50/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.4539 - sparse_categorical_accuracy: 0.8002 - val_loss: 0.5323 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 51/100\n",
            "981/981 [==============================] - 0s 134us/sample - loss: 0.4527 - sparse_categorical_accuracy: 0.8012 - val_loss: 0.5288 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 52/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.4520 - sparse_categorical_accuracy: 0.7982 - val_loss: 0.5357 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 53/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.4524 - sparse_categorical_accuracy: 0.7961 - val_loss: 0.5285 - val_sparse_categorical_accuracy: 0.7064\n",
            "[CV] ......................... n_neurons=97, n_hidden=1, total=   7.6s\n",
            "[CV] n_neurons=97, n_hidden=1 ........................................\n",
            "Train on 981 samples, validate on 109 samples\n",
            "Epoch 1/100\n",
            "981/981 [==============================] - 1s 538us/sample - loss: 1.2065 - sparse_categorical_accuracy: 0.4312 - val_loss: 1.0035 - val_sparse_categorical_accuracy: 0.5321\n",
            "Epoch 2/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.9612 - sparse_categorical_accuracy: 0.4985 - val_loss: 0.9105 - val_sparse_categorical_accuracy: 0.5229\n",
            "Epoch 3/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.8572 - sparse_categorical_accuracy: 0.5566 - val_loss: 0.8371 - val_sparse_categorical_accuracy: 0.5872\n",
            "Epoch 4/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.7931 - sparse_categorical_accuracy: 0.6004 - val_loss: 0.8053 - val_sparse_categorical_accuracy: 0.6514\n",
            "Epoch 5/100\n",
            "981/981 [==============================] - 0s 148us/sample - loss: 0.7502 - sparse_categorical_accuracy: 0.6320 - val_loss: 0.7561 - val_sparse_categorical_accuracy: 0.6147\n",
            "Epoch 6/100\n",
            "981/981 [==============================] - 0s 142us/sample - loss: 0.7141 - sparse_categorical_accuracy: 0.6575 - val_loss: 0.7275 - val_sparse_categorical_accuracy: 0.5963\n",
            "Epoch 7/100\n",
            "981/981 [==============================] - 0s 134us/sample - loss: 0.6879 - sparse_categorical_accuracy: 0.6606 - val_loss: 0.7070 - val_sparse_categorical_accuracy: 0.6606\n",
            "Epoch 8/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.6659 - sparse_categorical_accuracy: 0.6799 - val_loss: 0.6872 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 9/100\n",
            "981/981 [==============================] - 0s 140us/sample - loss: 0.6485 - sparse_categorical_accuracy: 0.6922 - val_loss: 0.6723 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 10/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.6337 - sparse_categorical_accuracy: 0.6962 - val_loss: 0.6595 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 11/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.6186 - sparse_categorical_accuracy: 0.7115 - val_loss: 0.6484 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 12/100\n",
            "981/981 [==============================] - 0s 147us/sample - loss: 0.6073 - sparse_categorical_accuracy: 0.7217 - val_loss: 0.6464 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 13/100\n",
            "981/981 [==============================] - 0s 140us/sample - loss: 0.5974 - sparse_categorical_accuracy: 0.7207 - val_loss: 0.6264 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 14/100\n",
            "981/981 [==============================] - 0s 143us/sample - loss: 0.5861 - sparse_categorical_accuracy: 0.7309 - val_loss: 0.6222 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 15/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.5791 - sparse_categorical_accuracy: 0.7411 - val_loss: 0.6164 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 16/100\n",
            "981/981 [==============================] - 0s 143us/sample - loss: 0.5716 - sparse_categorical_accuracy: 0.7472 - val_loss: 0.6065 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 17/100\n",
            "981/981 [==============================] - 0s 137us/sample - loss: 0.5675 - sparse_categorical_accuracy: 0.7441 - val_loss: 0.5993 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 18/100\n",
            "981/981 [==============================] - 0s 134us/sample - loss: 0.5616 - sparse_categorical_accuracy: 0.7329 - val_loss: 0.5921 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 19/100\n",
            "981/981 [==============================] - 0s 134us/sample - loss: 0.5542 - sparse_categorical_accuracy: 0.7421 - val_loss: 0.5886 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 20/100\n",
            "981/981 [==============================] - 0s 141us/sample - loss: 0.5482 - sparse_categorical_accuracy: 0.7543 - val_loss: 0.5858 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 21/100\n",
            "981/981 [==============================] - 0s 136us/sample - loss: 0.5440 - sparse_categorical_accuracy: 0.7635 - val_loss: 0.5946 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 22/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5404 - sparse_categorical_accuracy: 0.7492 - val_loss: 0.5865 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 23/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.5375 - sparse_categorical_accuracy: 0.7543 - val_loss: 0.5727 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 24/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.5314 - sparse_categorical_accuracy: 0.7533 - val_loss: 0.5751 - val_sparse_categorical_accuracy: 0.7523\n",
            "Epoch 25/100\n",
            "981/981 [==============================] - 0s 151us/sample - loss: 0.5290 - sparse_categorical_accuracy: 0.7706 - val_loss: 0.5637 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 26/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.5254 - sparse_categorical_accuracy: 0.7554 - val_loss: 0.5654 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 27/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.5216 - sparse_categorical_accuracy: 0.7676 - val_loss: 0.5767 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 28/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.5211 - sparse_categorical_accuracy: 0.7615 - val_loss: 0.5581 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 29/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.5160 - sparse_categorical_accuracy: 0.7645 - val_loss: 0.5576 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 30/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.5154 - sparse_categorical_accuracy: 0.7615 - val_loss: 0.5557 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 31/100\n",
            "981/981 [==============================] - 0s 134us/sample - loss: 0.5124 - sparse_categorical_accuracy: 0.7676 - val_loss: 0.5504 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 32/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.5102 - sparse_categorical_accuracy: 0.7676 - val_loss: 0.5500 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 33/100\n",
            "981/981 [==============================] - 0s 147us/sample - loss: 0.5059 - sparse_categorical_accuracy: 0.7768 - val_loss: 0.5488 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 34/100\n",
            "981/981 [==============================] - 0s 158us/sample - loss: 0.5049 - sparse_categorical_accuracy: 0.7706 - val_loss: 0.5478 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 35/100\n",
            "981/981 [==============================] - 0s 156us/sample - loss: 0.5029 - sparse_categorical_accuracy: 0.7696 - val_loss: 0.5464 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 36/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.5018 - sparse_categorical_accuracy: 0.7757 - val_loss: 0.5461 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 37/100\n",
            "981/981 [==============================] - 0s 140us/sample - loss: 0.4996 - sparse_categorical_accuracy: 0.7727 - val_loss: 0.5423 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 38/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.4997 - sparse_categorical_accuracy: 0.7706 - val_loss: 0.5418 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 39/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.4957 - sparse_categorical_accuracy: 0.7727 - val_loss: 0.5417 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 40/100\n",
            "981/981 [==============================] - 0s 139us/sample - loss: 0.4941 - sparse_categorical_accuracy: 0.7727 - val_loss: 0.5421 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 41/100\n",
            "981/981 [==============================] - 0s 158us/sample - loss: 0.4921 - sparse_categorical_accuracy: 0.7798 - val_loss: 0.5414 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 42/100\n",
            "981/981 [==============================] - 0s 145us/sample - loss: 0.4907 - sparse_categorical_accuracy: 0.7757 - val_loss: 0.5471 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 43/100\n",
            "981/981 [==============================] - 0s 135us/sample - loss: 0.4877 - sparse_categorical_accuracy: 0.7808 - val_loss: 0.5464 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 44/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.4902 - sparse_categorical_accuracy: 0.7727 - val_loss: 0.5386 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 45/100\n",
            "981/981 [==============================] - 0s 145us/sample - loss: 0.4882 - sparse_categorical_accuracy: 0.7768 - val_loss: 0.5387 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 46/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.4880 - sparse_categorical_accuracy: 0.7808 - val_loss: 0.5403 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 47/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.4852 - sparse_categorical_accuracy: 0.7819 - val_loss: 0.5382 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 48/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.4844 - sparse_categorical_accuracy: 0.7839 - val_loss: 0.5351 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 49/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.4818 - sparse_categorical_accuracy: 0.7900 - val_loss: 0.5342 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 50/100\n",
            "981/981 [==============================] - 0s 146us/sample - loss: 0.4808 - sparse_categorical_accuracy: 0.7798 - val_loss: 0.5353 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 51/100\n",
            "981/981 [==============================] - 0s 143us/sample - loss: 0.4812 - sparse_categorical_accuracy: 0.7819 - val_loss: 0.5385 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 52/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.4782 - sparse_categorical_accuracy: 0.7798 - val_loss: 0.5388 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 53/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.4793 - sparse_categorical_accuracy: 0.7839 - val_loss: 0.5384 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 54/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.4768 - sparse_categorical_accuracy: 0.7808 - val_loss: 0.5351 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 55/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.4753 - sparse_categorical_accuracy: 0.7870 - val_loss: 0.5444 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 56/100\n",
            "981/981 [==============================] - 0s 134us/sample - loss: 0.4754 - sparse_categorical_accuracy: 0.7839 - val_loss: 0.5343 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 57/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.4736 - sparse_categorical_accuracy: 0.7808 - val_loss: 0.5345 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 58/100\n",
            "981/981 [==============================] - 0s 148us/sample - loss: 0.4741 - sparse_categorical_accuracy: 0.7870 - val_loss: 0.5332 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 59/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.4723 - sparse_categorical_accuracy: 0.7819 - val_loss: 0.5322 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 60/100\n",
            "981/981 [==============================] - 0s 136us/sample - loss: 0.4715 - sparse_categorical_accuracy: 0.7890 - val_loss: 0.5347 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 61/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.4709 - sparse_categorical_accuracy: 0.7829 - val_loss: 0.5392 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 62/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.4699 - sparse_categorical_accuracy: 0.7870 - val_loss: 0.5380 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 63/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.4692 - sparse_categorical_accuracy: 0.7870 - val_loss: 0.5351 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 64/100\n",
            "981/981 [==============================] - 0s 134us/sample - loss: 0.4658 - sparse_categorical_accuracy: 0.7920 - val_loss: 0.5429 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 65/100\n",
            "981/981 [==============================] - 0s 141us/sample - loss: 0.4682 - sparse_categorical_accuracy: 0.7859 - val_loss: 0.5398 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 66/100\n",
            "981/981 [==============================] - 0s 135us/sample - loss: 0.4667 - sparse_categorical_accuracy: 0.7859 - val_loss: 0.5386 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 67/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.4659 - sparse_categorical_accuracy: 0.7890 - val_loss: 0.5363 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 68/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.4642 - sparse_categorical_accuracy: 0.7961 - val_loss: 0.5370 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 69/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.4642 - sparse_categorical_accuracy: 0.7971 - val_loss: 0.5376 - val_sparse_categorical_accuracy: 0.7156\n",
            "[CV] ......................... n_neurons=97, n_hidden=1, total=   9.9s\n",
            "[CV] n_neurons=97, n_hidden=1 ........................................\n",
            "Train on 981 samples, validate on 110 samples\n",
            "Epoch 1/100\n",
            "981/981 [==============================] - 1s 559us/sample - loss: 1.0770 - sparse_categorical_accuracy: 0.4332 - val_loss: 0.9873 - val_sparse_categorical_accuracy: 0.5273\n",
            "Epoch 2/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.8978 - sparse_categorical_accuracy: 0.5331 - val_loss: 0.8620 - val_sparse_categorical_accuracy: 0.6000\n",
            "Epoch 3/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.8121 - sparse_categorical_accuracy: 0.5800 - val_loss: 0.7980 - val_sparse_categorical_accuracy: 0.6273\n",
            "Epoch 4/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.7541 - sparse_categorical_accuracy: 0.6300 - val_loss: 0.7518 - val_sparse_categorical_accuracy: 0.6455\n",
            "Epoch 5/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.7152 - sparse_categorical_accuracy: 0.6636 - val_loss: 0.7131 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 6/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.6814 - sparse_categorical_accuracy: 0.6922 - val_loss: 0.6876 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 7/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.6565 - sparse_categorical_accuracy: 0.6993 - val_loss: 0.6625 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 8/100\n",
            "981/981 [==============================] - 0s 153us/sample - loss: 0.6373 - sparse_categorical_accuracy: 0.6972 - val_loss: 0.6465 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 9/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.6176 - sparse_categorical_accuracy: 0.7207 - val_loss: 0.6297 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 10/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.6024 - sparse_categorical_accuracy: 0.7319 - val_loss: 0.6259 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 11/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.5886 - sparse_categorical_accuracy: 0.7370 - val_loss: 0.6201 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 12/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.5788 - sparse_categorical_accuracy: 0.7462 - val_loss: 0.6058 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 13/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.5686 - sparse_categorical_accuracy: 0.7503 - val_loss: 0.5902 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 14/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.5585 - sparse_categorical_accuracy: 0.7554 - val_loss: 0.5857 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 15/100\n",
            "981/981 [==============================] - 0s 136us/sample - loss: 0.5473 - sparse_categorical_accuracy: 0.7604 - val_loss: 0.5781 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 16/100\n",
            "981/981 [==============================] - 0s 134us/sample - loss: 0.5436 - sparse_categorical_accuracy: 0.7666 - val_loss: 0.5722 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 17/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.5377 - sparse_categorical_accuracy: 0.7666 - val_loss: 0.5609 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 18/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.5303 - sparse_categorical_accuracy: 0.7686 - val_loss: 0.5591 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 19/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.5246 - sparse_categorical_accuracy: 0.7717 - val_loss: 0.5567 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 20/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.5207 - sparse_categorical_accuracy: 0.7686 - val_loss: 0.5470 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 21/100\n",
            "981/981 [==============================] - 0s 135us/sample - loss: 0.5138 - sparse_categorical_accuracy: 0.7778 - val_loss: 0.5447 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 22/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.5097 - sparse_categorical_accuracy: 0.7757 - val_loss: 0.5385 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 23/100\n",
            "981/981 [==============================] - 0s 148us/sample - loss: 0.5048 - sparse_categorical_accuracy: 0.7870 - val_loss: 0.5357 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 24/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.4998 - sparse_categorical_accuracy: 0.7768 - val_loss: 0.5368 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 25/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.4966 - sparse_categorical_accuracy: 0.7829 - val_loss: 0.5344 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 26/100\n",
            "981/981 [==============================] - 0s 137us/sample - loss: 0.4950 - sparse_categorical_accuracy: 0.7819 - val_loss: 0.5253 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 27/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.4900 - sparse_categorical_accuracy: 0.7808 - val_loss: 0.5283 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 28/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.4875 - sparse_categorical_accuracy: 0.7829 - val_loss: 0.5327 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 29/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.4853 - sparse_categorical_accuracy: 0.7920 - val_loss: 0.5199 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 30/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.4822 - sparse_categorical_accuracy: 0.7900 - val_loss: 0.5191 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 31/100\n",
            "981/981 [==============================] - 0s 152us/sample - loss: 0.4768 - sparse_categorical_accuracy: 0.7961 - val_loss: 0.5245 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 32/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.4758 - sparse_categorical_accuracy: 0.7890 - val_loss: 0.5196 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 33/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.4733 - sparse_categorical_accuracy: 0.7859 - val_loss: 0.5264 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 34/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.4726 - sparse_categorical_accuracy: 0.7971 - val_loss: 0.5167 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 35/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.4678 - sparse_categorical_accuracy: 0.7931 - val_loss: 0.5225 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 36/100\n",
            "981/981 [==============================] - 0s 135us/sample - loss: 0.4666 - sparse_categorical_accuracy: 0.7910 - val_loss: 0.5133 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 37/100\n",
            "981/981 [==============================] - 0s 145us/sample - loss: 0.4648 - sparse_categorical_accuracy: 0.7961 - val_loss: 0.5156 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 38/100\n",
            "981/981 [==============================] - 0s 142us/sample - loss: 0.4618 - sparse_categorical_accuracy: 0.7961 - val_loss: 0.5088 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 39/100\n",
            "981/981 [==============================] - 0s 146us/sample - loss: 0.4609 - sparse_categorical_accuracy: 0.8002 - val_loss: 0.5098 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 40/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.4596 - sparse_categorical_accuracy: 0.7941 - val_loss: 0.5099 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 41/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.4573 - sparse_categorical_accuracy: 0.8002 - val_loss: 0.5078 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 42/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.4555 - sparse_categorical_accuracy: 0.7910 - val_loss: 0.5089 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 43/100\n",
            "981/981 [==============================] - 0s 138us/sample - loss: 0.4533 - sparse_categorical_accuracy: 0.8012 - val_loss: 0.5096 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 44/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.4526 - sparse_categorical_accuracy: 0.8043 - val_loss: 0.5082 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 45/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.4510 - sparse_categorical_accuracy: 0.8053 - val_loss: 0.5063 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 46/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.4493 - sparse_categorical_accuracy: 0.8022 - val_loss: 0.5077 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 47/100\n",
            "981/981 [==============================] - 0s 156us/sample - loss: 0.4492 - sparse_categorical_accuracy: 0.7951 - val_loss: 0.5050 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 48/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.4471 - sparse_categorical_accuracy: 0.8012 - val_loss: 0.5096 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 49/100\n",
            "981/981 [==============================] - 0s 134us/sample - loss: 0.4457 - sparse_categorical_accuracy: 0.8073 - val_loss: 0.5127 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 50/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.4437 - sparse_categorical_accuracy: 0.8084 - val_loss: 0.5065 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 51/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.4431 - sparse_categorical_accuracy: 0.8022 - val_loss: 0.5055 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 52/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.4413 - sparse_categorical_accuracy: 0.8073 - val_loss: 0.5066 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 53/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.4406 - sparse_categorical_accuracy: 0.8063 - val_loss: 0.5050 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 54/100\n",
            "981/981 [==============================] - 0s 141us/sample - loss: 0.4392 - sparse_categorical_accuracy: 0.8145 - val_loss: 0.5015 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 55/100\n",
            "981/981 [==============================] - 0s 147us/sample - loss: 0.4380 - sparse_categorical_accuracy: 0.8073 - val_loss: 0.5133 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 56/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.4365 - sparse_categorical_accuracy: 0.8063 - val_loss: 0.5017 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 57/100\n",
            "981/981 [==============================] - 0s 146us/sample - loss: 0.4354 - sparse_categorical_accuracy: 0.8084 - val_loss: 0.5037 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 58/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.4350 - sparse_categorical_accuracy: 0.8073 - val_loss: 0.5034 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 59/100\n",
            "981/981 [==============================] - 0s 135us/sample - loss: 0.4331 - sparse_categorical_accuracy: 0.8053 - val_loss: 0.5056 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 60/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.4333 - sparse_categorical_accuracy: 0.8145 - val_loss: 0.5028 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 61/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.4324 - sparse_categorical_accuracy: 0.8063 - val_loss: 0.5037 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 62/100\n",
            "981/981 [==============================] - 0s 148us/sample - loss: 0.4310 - sparse_categorical_accuracy: 0.8124 - val_loss: 0.5025 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 63/100\n",
            "981/981 [==============================] - 0s 142us/sample - loss: 0.4301 - sparse_categorical_accuracy: 0.8124 - val_loss: 0.5018 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 64/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.4286 - sparse_categorical_accuracy: 0.8124 - val_loss: 0.5008 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 65/100\n",
            "981/981 [==============================] - 0s 140us/sample - loss: 0.4277 - sparse_categorical_accuracy: 0.8206 - val_loss: 0.5011 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 66/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.4274 - sparse_categorical_accuracy: 0.8073 - val_loss: 0.5024 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 67/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.4260 - sparse_categorical_accuracy: 0.8206 - val_loss: 0.5064 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 68/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.4253 - sparse_categorical_accuracy: 0.8155 - val_loss: 0.5070 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 69/100\n",
            "981/981 [==============================] - 0s 138us/sample - loss: 0.4241 - sparse_categorical_accuracy: 0.8124 - val_loss: 0.5056 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 70/100\n",
            "981/981 [==============================] - 0s 145us/sample - loss: 0.4229 - sparse_categorical_accuracy: 0.8236 - val_loss: 0.5075 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 71/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.4234 - sparse_categorical_accuracy: 0.8216 - val_loss: 0.5055 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 72/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.4214 - sparse_categorical_accuracy: 0.8186 - val_loss: 0.5077 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 73/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.4210 - sparse_categorical_accuracy: 0.8196 - val_loss: 0.5056 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 74/100\n",
            "981/981 [==============================] - 0s 134us/sample - loss: 0.4203 - sparse_categorical_accuracy: 0.8135 - val_loss: 0.5193 - val_sparse_categorical_accuracy: 0.7455\n",
            "[CV] ......................... n_neurons=97, n_hidden=1, total=  10.4s\n",
            "[CV] n_neurons=97, n_hidden=1 ........................................\n",
            "Train on 981 samples, validate on 110 samples\n",
            "Epoch 1/100\n",
            "981/981 [==============================] - 1s 556us/sample - loss: 1.0522 - sparse_categorical_accuracy: 0.4577 - val_loss: 0.8659 - val_sparse_categorical_accuracy: 0.5818\n",
            "Epoch 2/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.9018 - sparse_categorical_accuracy: 0.5352 - val_loss: 0.7868 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 3/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.8199 - sparse_categorical_accuracy: 0.5759 - val_loss: 0.7437 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 4/100\n",
            "981/981 [==============================] - 0s 138us/sample - loss: 0.7618 - sparse_categorical_accuracy: 0.6228 - val_loss: 0.7113 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 5/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.7228 - sparse_categorical_accuracy: 0.6606 - val_loss: 0.6861 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 6/100\n",
            "981/981 [==============================] - 0s 146us/sample - loss: 0.6889 - sparse_categorical_accuracy: 0.6718 - val_loss: 0.6732 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 7/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.6635 - sparse_categorical_accuracy: 0.6983 - val_loss: 0.6622 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 8/100\n",
            "981/981 [==============================] - 0s 138us/sample - loss: 0.6443 - sparse_categorical_accuracy: 0.7003 - val_loss: 0.6403 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 9/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.6241 - sparse_categorical_accuracy: 0.7238 - val_loss: 0.6315 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 10/100\n",
            "981/981 [==============================] - 0s 142us/sample - loss: 0.6094 - sparse_categorical_accuracy: 0.7278 - val_loss: 0.6288 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 11/100\n",
            "981/981 [==============================] - 0s 134us/sample - loss: 0.5955 - sparse_categorical_accuracy: 0.7339 - val_loss: 0.6253 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 12/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.5848 - sparse_categorical_accuracy: 0.7339 - val_loss: 0.6092 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 13/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5757 - sparse_categorical_accuracy: 0.7421 - val_loss: 0.6041 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 14/100\n",
            "981/981 [==============================] - 0s 147us/sample - loss: 0.5655 - sparse_categorical_accuracy: 0.7472 - val_loss: 0.6020 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 15/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.5572 - sparse_categorical_accuracy: 0.7492 - val_loss: 0.6007 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 16/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.5493 - sparse_categorical_accuracy: 0.7533 - val_loss: 0.5987 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 17/100\n",
            "981/981 [==============================] - 0s 136us/sample - loss: 0.5429 - sparse_categorical_accuracy: 0.7676 - val_loss: 0.5929 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 18/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.5360 - sparse_categorical_accuracy: 0.7645 - val_loss: 0.5975 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 19/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.5305 - sparse_categorical_accuracy: 0.7645 - val_loss: 0.5832 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 20/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.5259 - sparse_categorical_accuracy: 0.7706 - val_loss: 0.5836 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 21/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.5213 - sparse_categorical_accuracy: 0.7696 - val_loss: 0.5838 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 22/100\n",
            "981/981 [==============================] - 0s 145us/sample - loss: 0.5160 - sparse_categorical_accuracy: 0.7717 - val_loss: 0.5794 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 23/100\n",
            "981/981 [==============================] - 0s 136us/sample - loss: 0.5131 - sparse_categorical_accuracy: 0.7655 - val_loss: 0.5814 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 24/100\n",
            "981/981 [==============================] - 0s 135us/sample - loss: 0.5082 - sparse_categorical_accuracy: 0.7757 - val_loss: 0.5761 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 25/100\n",
            "981/981 [==============================] - 0s 137us/sample - loss: 0.5045 - sparse_categorical_accuracy: 0.7768 - val_loss: 0.5807 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 26/100\n",
            "981/981 [==============================] - 0s 134us/sample - loss: 0.4998 - sparse_categorical_accuracy: 0.7727 - val_loss: 0.5752 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 27/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.4983 - sparse_categorical_accuracy: 0.7706 - val_loss: 0.5770 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 28/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.4946 - sparse_categorical_accuracy: 0.7829 - val_loss: 0.5696 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 29/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.4928 - sparse_categorical_accuracy: 0.7717 - val_loss: 0.5675 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 30/100\n",
            "981/981 [==============================] - 0s 138us/sample - loss: 0.4887 - sparse_categorical_accuracy: 0.7768 - val_loss: 0.5690 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 31/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.4865 - sparse_categorical_accuracy: 0.7788 - val_loss: 0.5804 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 32/100\n",
            "981/981 [==============================] - 0s 136us/sample - loss: 0.4848 - sparse_categorical_accuracy: 0.7798 - val_loss: 0.5746 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 33/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.4819 - sparse_categorical_accuracy: 0.7819 - val_loss: 0.5671 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 34/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.4796 - sparse_categorical_accuracy: 0.7849 - val_loss: 0.5720 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 35/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.4781 - sparse_categorical_accuracy: 0.7839 - val_loss: 0.5719 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 36/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.4763 - sparse_categorical_accuracy: 0.7788 - val_loss: 0.5747 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 37/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.4748 - sparse_categorical_accuracy: 0.7839 - val_loss: 0.5677 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 38/100\n",
            "981/981 [==============================] - 0s 139us/sample - loss: 0.4713 - sparse_categorical_accuracy: 0.7808 - val_loss: 0.5664 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 39/100\n",
            "981/981 [==============================] - 0s 146us/sample - loss: 0.4695 - sparse_categorical_accuracy: 0.7849 - val_loss: 0.5721 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 40/100\n",
            "981/981 [==============================] - 0s 141us/sample - loss: 0.4677 - sparse_categorical_accuracy: 0.7819 - val_loss: 0.5654 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 41/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.4658 - sparse_categorical_accuracy: 0.7890 - val_loss: 0.5652 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 42/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.4651 - sparse_categorical_accuracy: 0.7880 - val_loss: 0.5735 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 43/100\n",
            "981/981 [==============================] - 0s 148us/sample - loss: 0.4643 - sparse_categorical_accuracy: 0.7880 - val_loss: 0.5687 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 44/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.4619 - sparse_categorical_accuracy: 0.7890 - val_loss: 0.5678 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 45/100\n",
            "981/981 [==============================] - 0s 137us/sample - loss: 0.4601 - sparse_categorical_accuracy: 0.7859 - val_loss: 0.5668 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 46/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.4587 - sparse_categorical_accuracy: 0.7870 - val_loss: 0.5699 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 47/100\n",
            "981/981 [==============================] - 0s 159us/sample - loss: 0.4580 - sparse_categorical_accuracy: 0.7880 - val_loss: 0.5679 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 48/100\n",
            "981/981 [==============================] - 0s 134us/sample - loss: 0.4557 - sparse_categorical_accuracy: 0.7910 - val_loss: 0.5710 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 49/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.4552 - sparse_categorical_accuracy: 0.7910 - val_loss: 0.5751 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 50/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.4538 - sparse_categorical_accuracy: 0.7900 - val_loss: 0.5792 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 51/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.4524 - sparse_categorical_accuracy: 0.7910 - val_loss: 0.5672 - val_sparse_categorical_accuracy: 0.7545\n",
            "[CV] ......................... n_neurons=97, n_hidden=1, total=   7.4s\n",
            "[CV] n_neurons=59, n_hidden=4 ........................................\n",
            "Train on 981 samples, validate on 109 samples\n",
            "Epoch 1/100\n",
            "981/981 [==============================] - 1s 824us/sample - loss: 1.1023 - sparse_categorical_accuracy: 0.4373 - val_loss: 0.8662 - val_sparse_categorical_accuracy: 0.6147\n",
            "Epoch 2/100\n",
            "981/981 [==============================] - 0s 175us/sample - loss: 0.8388 - sparse_categorical_accuracy: 0.5770 - val_loss: 0.7775 - val_sparse_categorical_accuracy: 0.5963\n",
            "Epoch 3/100\n",
            "981/981 [==============================] - 0s 153us/sample - loss: 0.7632 - sparse_categorical_accuracy: 0.6126 - val_loss: 0.7278 - val_sparse_categorical_accuracy: 0.6697\n",
            "Epoch 4/100\n",
            "981/981 [==============================] - 0s 178us/sample - loss: 0.6982 - sparse_categorical_accuracy: 0.6565 - val_loss: 0.6843 - val_sparse_categorical_accuracy: 0.6514\n",
            "Epoch 5/100\n",
            "981/981 [==============================] - 0s 150us/sample - loss: 0.6528 - sparse_categorical_accuracy: 0.6758 - val_loss: 0.6544 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 6/100\n",
            "981/981 [==============================] - 0s 148us/sample - loss: 0.6149 - sparse_categorical_accuracy: 0.7105 - val_loss: 0.6585 - val_sparse_categorical_accuracy: 0.6514\n",
            "Epoch 7/100\n",
            "981/981 [==============================] - 0s 150us/sample - loss: 0.5901 - sparse_categorical_accuracy: 0.7238 - val_loss: 0.6301 - val_sparse_categorical_accuracy: 0.6697\n",
            "Epoch 8/100\n",
            "981/981 [==============================] - 0s 168us/sample - loss: 0.5699 - sparse_categorical_accuracy: 0.7339 - val_loss: 0.6111 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 9/100\n",
            "981/981 [==============================] - 0s 169us/sample - loss: 0.5551 - sparse_categorical_accuracy: 0.7452 - val_loss: 0.6202 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 10/100\n",
            "981/981 [==============================] - 0s 157us/sample - loss: 0.5397 - sparse_categorical_accuracy: 0.7390 - val_loss: 0.5798 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 11/100\n",
            "981/981 [==============================] - 0s 158us/sample - loss: 0.5223 - sparse_categorical_accuracy: 0.7615 - val_loss: 0.5954 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 12/100\n",
            "981/981 [==============================] - 0s 148us/sample - loss: 0.5146 - sparse_categorical_accuracy: 0.7645 - val_loss: 0.5827 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 13/100\n",
            "981/981 [==============================] - 0s 170us/sample - loss: 0.5050 - sparse_categorical_accuracy: 0.7706 - val_loss: 0.6214 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 14/100\n",
            "981/981 [==============================] - 0s 147us/sample - loss: 0.4959 - sparse_categorical_accuracy: 0.7676 - val_loss: 0.5842 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 15/100\n",
            "981/981 [==============================] - 0s 161us/sample - loss: 0.4839 - sparse_categorical_accuracy: 0.7880 - val_loss: 0.6106 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 16/100\n",
            "981/981 [==============================] - 0s 150us/sample - loss: 0.4764 - sparse_categorical_accuracy: 0.7880 - val_loss: 0.5880 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 17/100\n",
            "981/981 [==============================] - 0s 155us/sample - loss: 0.4652 - sparse_categorical_accuracy: 0.7880 - val_loss: 0.5770 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 18/100\n",
            "981/981 [==============================] - 0s 156us/sample - loss: 0.4585 - sparse_categorical_accuracy: 0.8002 - val_loss: 0.6153 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 19/100\n",
            "981/981 [==============================] - 0s 152us/sample - loss: 0.4544 - sparse_categorical_accuracy: 0.7890 - val_loss: 0.6102 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 20/100\n",
            "981/981 [==============================] - 0s 176us/sample - loss: 0.4422 - sparse_categorical_accuracy: 0.8022 - val_loss: 0.5649 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 21/100\n",
            "981/981 [==============================] - 0s 159us/sample - loss: 0.4353 - sparse_categorical_accuracy: 0.8135 - val_loss: 0.5511 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 22/100\n",
            "981/981 [==============================] - 0s 163us/sample - loss: 0.4242 - sparse_categorical_accuracy: 0.8175 - val_loss: 0.5819 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 23/100\n",
            "981/981 [==============================] - 0s 139us/sample - loss: 0.4229 - sparse_categorical_accuracy: 0.8135 - val_loss: 0.5905 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 24/100\n",
            "981/981 [==============================] - 0s 149us/sample - loss: 0.4256 - sparse_categorical_accuracy: 0.8094 - val_loss: 0.5790 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 25/100\n",
            "981/981 [==============================] - 0s 147us/sample - loss: 0.4076 - sparse_categorical_accuracy: 0.8226 - val_loss: 0.5574 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 26/100\n",
            "981/981 [==============================] - 0s 149us/sample - loss: 0.4050 - sparse_categorical_accuracy: 0.8287 - val_loss: 0.6427 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 27/100\n",
            "981/981 [==============================] - 0s 154us/sample - loss: 0.4024 - sparse_categorical_accuracy: 0.8206 - val_loss: 0.5692 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 28/100\n",
            "981/981 [==============================] - 0s 170us/sample - loss: 0.3994 - sparse_categorical_accuracy: 0.8267 - val_loss: 0.6053 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 29/100\n",
            "981/981 [==============================] - 0s 151us/sample - loss: 0.3926 - sparse_categorical_accuracy: 0.8267 - val_loss: 0.5930 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 30/100\n",
            "981/981 [==============================] - 0s 146us/sample - loss: 0.3856 - sparse_categorical_accuracy: 0.8298 - val_loss: 0.6041 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 31/100\n",
            "981/981 [==============================] - 0s 162us/sample - loss: 0.3828 - sparse_categorical_accuracy: 0.8318 - val_loss: 0.5799 - val_sparse_categorical_accuracy: 0.6881\n",
            "[CV] ......................... n_neurons=59, n_hidden=4, total=   5.8s\n",
            "[CV] n_neurons=59, n_hidden=4 ........................................\n",
            "Train on 981 samples, validate on 109 samples\n",
            "Epoch 1/100\n",
            "981/981 [==============================] - 1s 831us/sample - loss: 1.1166 - sparse_categorical_accuracy: 0.4098 - val_loss: 1.0129 - val_sparse_categorical_accuracy: 0.4495\n",
            "Epoch 2/100\n",
            "981/981 [==============================] - 0s 155us/sample - loss: 0.8750 - sparse_categorical_accuracy: 0.5464 - val_loss: 0.9310 - val_sparse_categorical_accuracy: 0.5138\n",
            "Epoch 3/100\n",
            "981/981 [==============================] - 0s 163us/sample - loss: 0.7738 - sparse_categorical_accuracy: 0.6177 - val_loss: 0.8419 - val_sparse_categorical_accuracy: 0.5872\n",
            "Epoch 4/100\n",
            "981/981 [==============================] - 0s 179us/sample - loss: 0.7105 - sparse_categorical_accuracy: 0.6453 - val_loss: 0.7782 - val_sparse_categorical_accuracy: 0.6330\n",
            "Epoch 5/100\n",
            "981/981 [==============================] - 0s 157us/sample - loss: 0.6588 - sparse_categorical_accuracy: 0.6758 - val_loss: 0.7542 - val_sparse_categorical_accuracy: 0.5780\n",
            "Epoch 6/100\n",
            "981/981 [==============================] - 0s 149us/sample - loss: 0.6201 - sparse_categorical_accuracy: 0.7125 - val_loss: 0.7167 - val_sparse_categorical_accuracy: 0.5872\n",
            "Epoch 7/100\n",
            "981/981 [==============================] - 0s 161us/sample - loss: 0.5887 - sparse_categorical_accuracy: 0.7146 - val_loss: 0.6922 - val_sparse_categorical_accuracy: 0.6330\n",
            "Epoch 8/100\n",
            "981/981 [==============================] - 0s 151us/sample - loss: 0.5631 - sparse_categorical_accuracy: 0.7431 - val_loss: 0.6880 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 9/100\n",
            "981/981 [==============================] - 0s 154us/sample - loss: 0.5416 - sparse_categorical_accuracy: 0.7584 - val_loss: 0.6640 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 10/100\n",
            "981/981 [==============================] - 0s 166us/sample - loss: 0.5258 - sparse_categorical_accuracy: 0.7635 - val_loss: 0.6250 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 11/100\n",
            "981/981 [==============================] - 0s 169us/sample - loss: 0.5073 - sparse_categorical_accuracy: 0.7747 - val_loss: 0.6178 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 12/100\n",
            "981/981 [==============================] - 0s 152us/sample - loss: 0.5005 - sparse_categorical_accuracy: 0.7829 - val_loss: 0.6031 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 13/100\n",
            "981/981 [==============================] - 0s 147us/sample - loss: 0.4848 - sparse_categorical_accuracy: 0.7849 - val_loss: 0.6154 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 14/100\n",
            "981/981 [==============================] - 0s 165us/sample - loss: 0.4764 - sparse_categorical_accuracy: 0.7931 - val_loss: 0.5957 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 15/100\n",
            "981/981 [==============================] - 0s 152us/sample - loss: 0.4655 - sparse_categorical_accuracy: 0.7931 - val_loss: 0.5995 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 16/100\n",
            "981/981 [==============================] - 0s 157us/sample - loss: 0.4554 - sparse_categorical_accuracy: 0.7992 - val_loss: 0.5803 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 17/100\n",
            "981/981 [==============================] - 0s 165us/sample - loss: 0.4497 - sparse_categorical_accuracy: 0.8022 - val_loss: 0.5926 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 18/100\n",
            "981/981 [==============================] - 0s 154us/sample - loss: 0.4386 - sparse_categorical_accuracy: 0.8165 - val_loss: 0.6174 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 19/100\n",
            "981/981 [==============================] - 0s 169us/sample - loss: 0.4374 - sparse_categorical_accuracy: 0.8175 - val_loss: 0.5688 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 20/100\n",
            "981/981 [==============================] - 0s 151us/sample - loss: 0.4261 - sparse_categorical_accuracy: 0.8124 - val_loss: 0.5865 - val_sparse_categorical_accuracy: 0.7523\n",
            "Epoch 21/100\n",
            "981/981 [==============================] - 0s 152us/sample - loss: 0.4258 - sparse_categorical_accuracy: 0.8145 - val_loss: 0.6098 - val_sparse_categorical_accuracy: 0.6697\n",
            "Epoch 22/100\n",
            "981/981 [==============================] - 0s 147us/sample - loss: 0.4196 - sparse_categorical_accuracy: 0.8267 - val_loss: 0.5926 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 23/100\n",
            "981/981 [==============================] - 0s 157us/sample - loss: 0.4116 - sparse_categorical_accuracy: 0.8308 - val_loss: 0.5690 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 24/100\n",
            "981/981 [==============================] - 0s 166us/sample - loss: 0.4083 - sparse_categorical_accuracy: 0.8216 - val_loss: 0.5807 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 25/100\n",
            "981/981 [==============================] - 0s 150us/sample - loss: 0.4017 - sparse_categorical_accuracy: 0.8359 - val_loss: 0.5868 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 26/100\n",
            "981/981 [==============================] - 0s 151us/sample - loss: 0.3992 - sparse_categorical_accuracy: 0.8267 - val_loss: 0.5781 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 27/100\n",
            "981/981 [==============================] - 0s 151us/sample - loss: 0.3895 - sparse_categorical_accuracy: 0.8379 - val_loss: 0.5714 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 28/100\n",
            "981/981 [==============================] - 0s 170us/sample - loss: 0.3880 - sparse_categorical_accuracy: 0.8369 - val_loss: 0.6183 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 29/100\n",
            "981/981 [==============================] - 0s 153us/sample - loss: 0.3895 - sparse_categorical_accuracy: 0.8369 - val_loss: 0.5707 - val_sparse_categorical_accuracy: 0.7156\n",
            "[CV] ......................... n_neurons=59, n_hidden=4, total=   5.5s\n",
            "[CV] n_neurons=59, n_hidden=4 ........................................\n",
            "Train on 981 samples, validate on 109 samples\n",
            "Epoch 1/100\n",
            "981/981 [==============================] - 1s 803us/sample - loss: 1.0756 - sparse_categorical_accuracy: 0.4271 - val_loss: 0.9083 - val_sparse_categorical_accuracy: 0.5321\n",
            "Epoch 2/100\n",
            "981/981 [==============================] - 0s 166us/sample - loss: 0.8148 - sparse_categorical_accuracy: 0.5902 - val_loss: 0.7708 - val_sparse_categorical_accuracy: 0.5963\n",
            "Epoch 3/100\n",
            "981/981 [==============================] - 0s 152us/sample - loss: 0.7311 - sparse_categorical_accuracy: 0.6402 - val_loss: 0.7113 - val_sparse_categorical_accuracy: 0.6606\n",
            "Epoch 4/100\n",
            "981/981 [==============================] - 0s 147us/sample - loss: 0.6749 - sparse_categorical_accuracy: 0.6779 - val_loss: 0.6679 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 5/100\n",
            "981/981 [==============================] - 0s 156us/sample - loss: 0.6409 - sparse_categorical_accuracy: 0.6922 - val_loss: 0.6293 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 6/100\n",
            "981/981 [==============================] - 0s 153us/sample - loss: 0.6145 - sparse_categorical_accuracy: 0.7095 - val_loss: 0.6402 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 7/100\n",
            "981/981 [==============================] - 0s 151us/sample - loss: 0.5951 - sparse_categorical_accuracy: 0.7207 - val_loss: 0.5987 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 8/100\n",
            "981/981 [==============================] - 0s 157us/sample - loss: 0.5663 - sparse_categorical_accuracy: 0.7248 - val_loss: 0.5797 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 9/100\n",
            "981/981 [==============================] - 0s 154us/sample - loss: 0.5506 - sparse_categorical_accuracy: 0.7380 - val_loss: 0.6147 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 10/100\n",
            "981/981 [==============================] - 0s 146us/sample - loss: 0.5417 - sparse_categorical_accuracy: 0.7533 - val_loss: 0.6038 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 11/100\n",
            "981/981 [==============================] - 0s 149us/sample - loss: 0.5297 - sparse_categorical_accuracy: 0.7431 - val_loss: 0.5743 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 12/100\n",
            "981/981 [==============================] - 0s 153us/sample - loss: 0.5192 - sparse_categorical_accuracy: 0.7523 - val_loss: 0.5598 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 13/100\n",
            "981/981 [==============================] - 0s 167us/sample - loss: 0.5027 - sparse_categorical_accuracy: 0.7666 - val_loss: 0.5733 - val_sparse_categorical_accuracy: 0.6697\n",
            "Epoch 14/100\n",
            "981/981 [==============================] - 0s 164us/sample - loss: 0.4953 - sparse_categorical_accuracy: 0.7696 - val_loss: 0.5611 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 15/100\n",
            "981/981 [==============================] - 0s 159us/sample - loss: 0.4867 - sparse_categorical_accuracy: 0.7706 - val_loss: 0.5855 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 16/100\n",
            "981/981 [==============================] - 0s 150us/sample - loss: 0.4753 - sparse_categorical_accuracy: 0.7788 - val_loss: 0.5749 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 17/100\n",
            "981/981 [==============================] - 0s 149us/sample - loss: 0.4718 - sparse_categorical_accuracy: 0.7788 - val_loss: 0.5742 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 18/100\n",
            "981/981 [==============================] - 0s 147us/sample - loss: 0.4666 - sparse_categorical_accuracy: 0.7768 - val_loss: 0.5640 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 19/100\n",
            "981/981 [==============================] - 0s 154us/sample - loss: 0.4560 - sparse_categorical_accuracy: 0.7849 - val_loss: 0.5921 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 20/100\n",
            "981/981 [==============================] - 0s 159us/sample - loss: 0.4522 - sparse_categorical_accuracy: 0.7992 - val_loss: 0.5569 - val_sparse_categorical_accuracy: 0.6606\n",
            "Epoch 21/100\n",
            "981/981 [==============================] - 0s 148us/sample - loss: 0.4415 - sparse_categorical_accuracy: 0.8104 - val_loss: 0.6198 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 22/100\n",
            "981/981 [==============================] - 0s 164us/sample - loss: 0.4355 - sparse_categorical_accuracy: 0.8033 - val_loss: 0.5953 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 23/100\n",
            "981/981 [==============================] - 0s 149us/sample - loss: 0.4281 - sparse_categorical_accuracy: 0.8053 - val_loss: 0.5694 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 24/100\n",
            "981/981 [==============================] - 0s 150us/sample - loss: 0.4226 - sparse_categorical_accuracy: 0.8073 - val_loss: 0.6010 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 25/100\n",
            "981/981 [==============================] - 0s 138us/sample - loss: 0.4184 - sparse_categorical_accuracy: 0.8084 - val_loss: 0.5924 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 26/100\n",
            "981/981 [==============================] - 0s 146us/sample - loss: 0.4158 - sparse_categorical_accuracy: 0.8094 - val_loss: 0.5824 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 27/100\n",
            "981/981 [==============================] - 0s 155us/sample - loss: 0.4087 - sparse_categorical_accuracy: 0.8073 - val_loss: 0.5865 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 28/100\n",
            "981/981 [==============================] - 0s 149us/sample - loss: 0.3997 - sparse_categorical_accuracy: 0.8135 - val_loss: 0.5973 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 29/100\n",
            "981/981 [==============================] - 0s 170us/sample - loss: 0.4003 - sparse_categorical_accuracy: 0.8196 - val_loss: 0.5958 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 30/100\n",
            "981/981 [==============================] - 0s 147us/sample - loss: 0.3895 - sparse_categorical_accuracy: 0.8247 - val_loss: 0.6215 - val_sparse_categorical_accuracy: 0.6881\n",
            "[CV] ......................... n_neurons=59, n_hidden=4, total=   5.5s\n",
            "[CV] n_neurons=59, n_hidden=4 ........................................\n",
            "Train on 981 samples, validate on 110 samples\n",
            "Epoch 1/100\n",
            "981/981 [==============================] - 1s 834us/sample - loss: 0.9942 - sparse_categorical_accuracy: 0.4811 - val_loss: 0.8368 - val_sparse_categorical_accuracy: 0.5455\n",
            "Epoch 2/100\n",
            "981/981 [==============================] - 0s 155us/sample - loss: 0.7572 - sparse_categorical_accuracy: 0.6249 - val_loss: 0.7239 - val_sparse_categorical_accuracy: 0.5818\n",
            "Epoch 3/100\n",
            "981/981 [==============================] - 0s 156us/sample - loss: 0.6712 - sparse_categorical_accuracy: 0.6820 - val_loss: 0.6838 - val_sparse_categorical_accuracy: 0.6273\n",
            "Epoch 4/100\n",
            "981/981 [==============================] - 0s 154us/sample - loss: 0.6182 - sparse_categorical_accuracy: 0.7125 - val_loss: 0.6556 - val_sparse_categorical_accuracy: 0.6000\n",
            "Epoch 5/100\n",
            "981/981 [==============================] - 0s 172us/sample - loss: 0.5846 - sparse_categorical_accuracy: 0.7421 - val_loss: 0.6340 - val_sparse_categorical_accuracy: 0.6273\n",
            "Epoch 6/100\n",
            "981/981 [==============================] - 0s 167us/sample - loss: 0.5584 - sparse_categorical_accuracy: 0.7482 - val_loss: 0.6062 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 7/100\n",
            "981/981 [==============================] - 0s 154us/sample - loss: 0.5408 - sparse_categorical_accuracy: 0.7543 - val_loss: 0.6011 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 8/100\n",
            "981/981 [==============================] - 0s 149us/sample - loss: 0.5259 - sparse_categorical_accuracy: 0.7737 - val_loss: 0.5903 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 9/100\n",
            "981/981 [==============================] - 0s 151us/sample - loss: 0.5104 - sparse_categorical_accuracy: 0.7717 - val_loss: 0.5740 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 10/100\n",
            "981/981 [==============================] - 0s 146us/sample - loss: 0.4975 - sparse_categorical_accuracy: 0.7676 - val_loss: 0.5942 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 11/100\n",
            "981/981 [==============================] - 0s 148us/sample - loss: 0.4904 - sparse_categorical_accuracy: 0.7788 - val_loss: 0.5567 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 12/100\n",
            "981/981 [==============================] - 0s 162us/sample - loss: 0.4771 - sparse_categorical_accuracy: 0.7880 - val_loss: 0.5535 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 13/100\n",
            "981/981 [==============================] - 0s 164us/sample - loss: 0.4651 - sparse_categorical_accuracy: 0.7951 - val_loss: 0.5522 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 14/100\n",
            "981/981 [==============================] - 0s 156us/sample - loss: 0.4588 - sparse_categorical_accuracy: 0.7920 - val_loss: 0.5473 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 15/100\n",
            "981/981 [==============================] - 0s 163us/sample - loss: 0.4458 - sparse_categorical_accuracy: 0.8094 - val_loss: 0.5484 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 16/100\n",
            "981/981 [==============================] - 0s 163us/sample - loss: 0.4411 - sparse_categorical_accuracy: 0.8084 - val_loss: 0.5482 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 17/100\n",
            "981/981 [==============================] - 0s 151us/sample - loss: 0.4378 - sparse_categorical_accuracy: 0.8033 - val_loss: 0.5565 - val_sparse_categorical_accuracy: 0.7727\n",
            "Epoch 18/100\n",
            "981/981 [==============================] - 0s 150us/sample - loss: 0.4297 - sparse_categorical_accuracy: 0.8175 - val_loss: 0.5665 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 19/100\n",
            "981/981 [==============================] - 0s 166us/sample - loss: 0.4180 - sparse_categorical_accuracy: 0.8216 - val_loss: 0.5434 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 20/100\n",
            "981/981 [==============================] - 0s 160us/sample - loss: 0.4145 - sparse_categorical_accuracy: 0.8186 - val_loss: 0.5389 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 21/100\n",
            "981/981 [==============================] - 0s 179us/sample - loss: 0.4074 - sparse_categorical_accuracy: 0.8247 - val_loss: 0.5471 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 22/100\n",
            "981/981 [==============================] - 0s 189us/sample - loss: 0.4036 - sparse_categorical_accuracy: 0.8277 - val_loss: 0.5424 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 23/100\n",
            "981/981 [==============================] - 0s 158us/sample - loss: 0.3981 - sparse_categorical_accuracy: 0.8318 - val_loss: 0.5557 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 24/100\n",
            "981/981 [==============================] - 0s 163us/sample - loss: 0.3916 - sparse_categorical_accuracy: 0.8400 - val_loss: 0.5322 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 25/100\n",
            "981/981 [==============================] - 0s 191us/sample - loss: 0.3847 - sparse_categorical_accuracy: 0.8328 - val_loss: 0.5567 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 26/100\n",
            "981/981 [==============================] - 0s 158us/sample - loss: 0.3796 - sparse_categorical_accuracy: 0.8379 - val_loss: 0.5793 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 27/100\n",
            "981/981 [==============================] - 0s 159us/sample - loss: 0.3796 - sparse_categorical_accuracy: 0.8379 - val_loss: 0.5472 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 28/100\n",
            "981/981 [==============================] - 0s 166us/sample - loss: 0.3708 - sparse_categorical_accuracy: 0.8430 - val_loss: 0.5431 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 29/100\n",
            "981/981 [==============================] - 0s 160us/sample - loss: 0.3626 - sparse_categorical_accuracy: 0.8451 - val_loss: 0.5288 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 30/100\n",
            "981/981 [==============================] - 0s 163us/sample - loss: 0.3606 - sparse_categorical_accuracy: 0.8614 - val_loss: 0.5408 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 31/100\n",
            "981/981 [==============================] - 0s 197us/sample - loss: 0.3542 - sparse_categorical_accuracy: 0.8624 - val_loss: 0.5441 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 32/100\n",
            "981/981 [==============================] - 0s 176us/sample - loss: 0.3478 - sparse_categorical_accuracy: 0.8552 - val_loss: 0.5712 - val_sparse_categorical_accuracy: 0.7727\n",
            "Epoch 33/100\n",
            "981/981 [==============================] - 0s 160us/sample - loss: 0.3552 - sparse_categorical_accuracy: 0.8461 - val_loss: 0.5354 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 34/100\n",
            "981/981 [==============================] - 0s 172us/sample - loss: 0.3383 - sparse_categorical_accuracy: 0.8593 - val_loss: 0.5578 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 35/100\n",
            "981/981 [==============================] - 0s 169us/sample - loss: 0.3372 - sparse_categorical_accuracy: 0.8716 - val_loss: 0.5463 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 36/100\n",
            "981/981 [==============================] - 0s 161us/sample - loss: 0.3272 - sparse_categorical_accuracy: 0.8818 - val_loss: 0.5720 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 37/100\n",
            "981/981 [==============================] - 0s 187us/sample - loss: 0.3234 - sparse_categorical_accuracy: 0.8644 - val_loss: 0.5587 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 38/100\n",
            "981/981 [==============================] - 0s 182us/sample - loss: 0.3218 - sparse_categorical_accuracy: 0.8705 - val_loss: 0.5581 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 39/100\n",
            "981/981 [==============================] - 0s 172us/sample - loss: 0.3183 - sparse_categorical_accuracy: 0.8716 - val_loss: 0.5577 - val_sparse_categorical_accuracy: 0.7091\n",
            "[CV] ......................... n_neurons=59, n_hidden=4, total=   7.4s\n",
            "[CV] n_neurons=59, n_hidden=4 ........................................\n",
            "Train on 981 samples, validate on 110 samples\n",
            "Epoch 1/100\n",
            "981/981 [==============================] - 1s 833us/sample - loss: 1.0807 - sparse_categorical_accuracy: 0.4546 - val_loss: 0.8029 - val_sparse_categorical_accuracy: 0.6000\n",
            "Epoch 2/100\n",
            "981/981 [==============================] - 0s 168us/sample - loss: 0.8015 - sparse_categorical_accuracy: 0.5923 - val_loss: 0.7520 - val_sparse_categorical_accuracy: 0.6455\n",
            "Epoch 3/100\n",
            "981/981 [==============================] - 0s 164us/sample - loss: 0.7163 - sparse_categorical_accuracy: 0.6565 - val_loss: 0.7031 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 4/100\n",
            "981/981 [==============================] - 0s 175us/sample - loss: 0.6526 - sparse_categorical_accuracy: 0.6993 - val_loss: 0.6815 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 5/100\n",
            "981/981 [==============================] - 0s 159us/sample - loss: 0.6113 - sparse_categorical_accuracy: 0.7238 - val_loss: 0.6823 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 6/100\n",
            "981/981 [==============================] - 0s 151us/sample - loss: 0.5805 - sparse_categorical_accuracy: 0.7401 - val_loss: 0.6511 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 7/100\n",
            "981/981 [==============================] - 0s 152us/sample - loss: 0.5582 - sparse_categorical_accuracy: 0.7431 - val_loss: 0.6494 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 8/100\n",
            "981/981 [==============================] - 0s 154us/sample - loss: 0.5323 - sparse_categorical_accuracy: 0.7706 - val_loss: 0.6445 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 9/100\n",
            "981/981 [==============================] - 0s 177us/sample - loss: 0.5108 - sparse_categorical_accuracy: 0.7747 - val_loss: 0.6395 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 10/100\n",
            "981/981 [==============================] - 0s 147us/sample - loss: 0.4987 - sparse_categorical_accuracy: 0.7849 - val_loss: 0.6373 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 11/100\n",
            "981/981 [==============================] - 0s 178us/sample - loss: 0.4888 - sparse_categorical_accuracy: 0.7870 - val_loss: 0.6419 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 12/100\n",
            "981/981 [==============================] - 0s 156us/sample - loss: 0.4777 - sparse_categorical_accuracy: 0.7819 - val_loss: 0.6265 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 13/100\n",
            "981/981 [==============================] - 0s 161us/sample - loss: 0.4671 - sparse_categorical_accuracy: 0.7951 - val_loss: 0.6483 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 14/100\n",
            "981/981 [==============================] - 0s 154us/sample - loss: 0.4568 - sparse_categorical_accuracy: 0.8043 - val_loss: 0.6532 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 15/100\n",
            "981/981 [==============================] - 0s 152us/sample - loss: 0.4471 - sparse_categorical_accuracy: 0.7971 - val_loss: 0.6314 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 16/100\n",
            "981/981 [==============================] - 0s 156us/sample - loss: 0.4361 - sparse_categorical_accuracy: 0.8165 - val_loss: 0.6304 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 17/100\n",
            "981/981 [==============================] - 0s 154us/sample - loss: 0.4332 - sparse_categorical_accuracy: 0.8084 - val_loss: 0.6325 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 18/100\n",
            "981/981 [==============================] - 0s 160us/sample - loss: 0.4210 - sparse_categorical_accuracy: 0.8196 - val_loss: 0.6227 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 19/100\n",
            "981/981 [==============================] - 0s 151us/sample - loss: 0.4189 - sparse_categorical_accuracy: 0.8196 - val_loss: 0.6238 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 20/100\n",
            "981/981 [==============================] - 0s 153us/sample - loss: 0.4125 - sparse_categorical_accuracy: 0.8124 - val_loss: 0.6261 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 21/100\n",
            "981/981 [==============================] - 0s 168us/sample - loss: 0.4044 - sparse_categorical_accuracy: 0.8277 - val_loss: 0.6428 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 22/100\n",
            "981/981 [==============================] - 0s 169us/sample - loss: 0.3977 - sparse_categorical_accuracy: 0.8298 - val_loss: 0.6319 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 23/100\n",
            "981/981 [==============================] - 0s 162us/sample - loss: 0.3937 - sparse_categorical_accuracy: 0.8298 - val_loss: 0.6331 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 24/100\n",
            "981/981 [==============================] - 0s 178us/sample - loss: 0.3865 - sparse_categorical_accuracy: 0.8226 - val_loss: 0.6473 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 25/100\n",
            "981/981 [==============================] - 0s 148us/sample - loss: 0.3797 - sparse_categorical_accuracy: 0.8328 - val_loss: 0.6583 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 26/100\n",
            "981/981 [==============================] - 0s 151us/sample - loss: 0.3716 - sparse_categorical_accuracy: 0.8369 - val_loss: 0.6732 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 27/100\n",
            "981/981 [==============================] - 0s 152us/sample - loss: 0.3727 - sparse_categorical_accuracy: 0.8420 - val_loss: 0.6462 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 28/100\n",
            "981/981 [==============================] - 0s 148us/sample - loss: 0.3655 - sparse_categorical_accuracy: 0.8338 - val_loss: 0.6287 - val_sparse_categorical_accuracy: 0.7091\n",
            "[CV] ......................... n_neurons=59, n_hidden=4, total=   5.4s\n",
            "[CV] n_neurons=42, n_hidden=0 ........................................\n",
            "Train on 981 samples, validate on 109 samples\n",
            "Epoch 1/100\n",
            "981/981 [==============================] - 0s 457us/sample - loss: 1.1742 - sparse_categorical_accuracy: 0.3772 - val_loss: 1.1882 - val_sparse_categorical_accuracy: 0.3578\n",
            "Epoch 2/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 1.0690 - sparse_categorical_accuracy: 0.4404 - val_loss: 1.1306 - val_sparse_categorical_accuracy: 0.3670\n",
            "Epoch 3/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 1.0196 - sparse_categorical_accuracy: 0.4689 - val_loss: 1.0830 - val_sparse_categorical_accuracy: 0.3853\n",
            "Epoch 4/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.9795 - sparse_categorical_accuracy: 0.4924 - val_loss: 1.0422 - val_sparse_categorical_accuracy: 0.3945\n",
            "Epoch 5/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.9448 - sparse_categorical_accuracy: 0.5127 - val_loss: 1.0033 - val_sparse_categorical_accuracy: 0.4312\n",
            "Epoch 6/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.9158 - sparse_categorical_accuracy: 0.5331 - val_loss: 0.9692 - val_sparse_categorical_accuracy: 0.4312\n",
            "Epoch 7/100\n",
            "981/981 [==============================] - 0s 146us/sample - loss: 0.8889 - sparse_categorical_accuracy: 0.5454 - val_loss: 0.9416 - val_sparse_categorical_accuracy: 0.4495\n",
            "Epoch 8/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.8662 - sparse_categorical_accuracy: 0.5566 - val_loss: 0.9173 - val_sparse_categorical_accuracy: 0.4954\n",
            "Epoch 9/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.8450 - sparse_categorical_accuracy: 0.5749 - val_loss: 0.8953 - val_sparse_categorical_accuracy: 0.5138\n",
            "Epoch 10/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.8264 - sparse_categorical_accuracy: 0.5943 - val_loss: 0.8772 - val_sparse_categorical_accuracy: 0.5321\n",
            "Epoch 11/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.8097 - sparse_categorical_accuracy: 0.5963 - val_loss: 0.8591 - val_sparse_categorical_accuracy: 0.5505\n",
            "Epoch 12/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.7939 - sparse_categorical_accuracy: 0.6065 - val_loss: 0.8436 - val_sparse_categorical_accuracy: 0.5780\n",
            "Epoch 13/100\n",
            "981/981 [==============================] - 0s 140us/sample - loss: 0.7802 - sparse_categorical_accuracy: 0.6086 - val_loss: 0.8297 - val_sparse_categorical_accuracy: 0.5688\n",
            "Epoch 14/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.7670 - sparse_categorical_accuracy: 0.6249 - val_loss: 0.8168 - val_sparse_categorical_accuracy: 0.6055\n",
            "Epoch 15/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.7556 - sparse_categorical_accuracy: 0.6412 - val_loss: 0.8052 - val_sparse_categorical_accuracy: 0.6055\n",
            "Epoch 16/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.7445 - sparse_categorical_accuracy: 0.6422 - val_loss: 0.7935 - val_sparse_categorical_accuracy: 0.6147\n",
            "Epoch 17/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.7342 - sparse_categorical_accuracy: 0.6555 - val_loss: 0.7836 - val_sparse_categorical_accuracy: 0.6239\n",
            "Epoch 18/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.7244 - sparse_categorical_accuracy: 0.6565 - val_loss: 0.7749 - val_sparse_categorical_accuracy: 0.6147\n",
            "Epoch 19/100\n",
            "981/981 [==============================] - 0s 134us/sample - loss: 0.7159 - sparse_categorical_accuracy: 0.6636 - val_loss: 0.7658 - val_sparse_categorical_accuracy: 0.6422\n",
            "Epoch 20/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.7075 - sparse_categorical_accuracy: 0.6707 - val_loss: 0.7578 - val_sparse_categorical_accuracy: 0.6422\n",
            "Epoch 21/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.6993 - sparse_categorical_accuracy: 0.6748 - val_loss: 0.7504 - val_sparse_categorical_accuracy: 0.6514\n",
            "Epoch 22/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.6919 - sparse_categorical_accuracy: 0.6809 - val_loss: 0.7430 - val_sparse_categorical_accuracy: 0.6606\n",
            "Epoch 23/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.6850 - sparse_categorical_accuracy: 0.6881 - val_loss: 0.7375 - val_sparse_categorical_accuracy: 0.6422\n",
            "Epoch 24/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.6780 - sparse_categorical_accuracy: 0.6891 - val_loss: 0.7319 - val_sparse_categorical_accuracy: 0.6514\n",
            "Epoch 25/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.6718 - sparse_categorical_accuracy: 0.6922 - val_loss: 0.7245 - val_sparse_categorical_accuracy: 0.6514\n",
            "Epoch 26/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.6659 - sparse_categorical_accuracy: 0.6952 - val_loss: 0.7194 - val_sparse_categorical_accuracy: 0.6422\n",
            "Epoch 27/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.6607 - sparse_categorical_accuracy: 0.7003 - val_loss: 0.7130 - val_sparse_categorical_accuracy: 0.6697\n",
            "Epoch 28/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.6548 - sparse_categorical_accuracy: 0.7003 - val_loss: 0.7079 - val_sparse_categorical_accuracy: 0.6606\n",
            "Epoch 29/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.6497 - sparse_categorical_accuracy: 0.7064 - val_loss: 0.7032 - val_sparse_categorical_accuracy: 0.6606\n",
            "Epoch 30/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.6449 - sparse_categorical_accuracy: 0.7095 - val_loss: 0.6982 - val_sparse_categorical_accuracy: 0.6514\n",
            "Epoch 31/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.6404 - sparse_categorical_accuracy: 0.7044 - val_loss: 0.6939 - val_sparse_categorical_accuracy: 0.6422\n",
            "Epoch 32/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.6356 - sparse_categorical_accuracy: 0.7136 - val_loss: 0.6892 - val_sparse_categorical_accuracy: 0.6514\n",
            "Epoch 33/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.6316 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.6852 - val_sparse_categorical_accuracy: 0.6422\n",
            "Epoch 34/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.6273 - sparse_categorical_accuracy: 0.7238 - val_loss: 0.6814 - val_sparse_categorical_accuracy: 0.6514\n",
            "Epoch 35/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.6237 - sparse_categorical_accuracy: 0.7238 - val_loss: 0.6781 - val_sparse_categorical_accuracy: 0.6422\n",
            "Epoch 36/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.6196 - sparse_categorical_accuracy: 0.7278 - val_loss: 0.6753 - val_sparse_categorical_accuracy: 0.6514\n",
            "Epoch 37/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.6163 - sparse_categorical_accuracy: 0.7299 - val_loss: 0.6724 - val_sparse_categorical_accuracy: 0.6697\n",
            "Epoch 38/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.6127 - sparse_categorical_accuracy: 0.7329 - val_loss: 0.6686 - val_sparse_categorical_accuracy: 0.6697\n",
            "Epoch 39/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.6095 - sparse_categorical_accuracy: 0.7390 - val_loss: 0.6664 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 40/100\n",
            "981/981 [==============================] - 0s 137us/sample - loss: 0.6070 - sparse_categorical_accuracy: 0.7339 - val_loss: 0.6629 - val_sparse_categorical_accuracy: 0.6697\n",
            "Epoch 41/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.6034 - sparse_categorical_accuracy: 0.7360 - val_loss: 0.6594 - val_sparse_categorical_accuracy: 0.6514\n",
            "Epoch 42/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.6007 - sparse_categorical_accuracy: 0.7390 - val_loss: 0.6573 - val_sparse_categorical_accuracy: 0.6697\n",
            "Epoch 43/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.5974 - sparse_categorical_accuracy: 0.7401 - val_loss: 0.6542 - val_sparse_categorical_accuracy: 0.6697\n",
            "Epoch 44/100\n",
            "981/981 [==============================] - 0s 112us/sample - loss: 0.5949 - sparse_categorical_accuracy: 0.7411 - val_loss: 0.6514 - val_sparse_categorical_accuracy: 0.6606\n",
            "Epoch 45/100\n",
            "981/981 [==============================] - 0s 112us/sample - loss: 0.5924 - sparse_categorical_accuracy: 0.7452 - val_loss: 0.6494 - val_sparse_categorical_accuracy: 0.6606\n",
            "Epoch 46/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.5893 - sparse_categorical_accuracy: 0.7452 - val_loss: 0.6469 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 47/100\n",
            "981/981 [==============================] - 0s 111us/sample - loss: 0.5877 - sparse_categorical_accuracy: 0.7441 - val_loss: 0.6451 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 48/100\n",
            "981/981 [==============================] - 0s 113us/sample - loss: 0.5851 - sparse_categorical_accuracy: 0.7472 - val_loss: 0.6432 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 49/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.5822 - sparse_categorical_accuracy: 0.7472 - val_loss: 0.6410 - val_sparse_categorical_accuracy: 0.6697\n",
            "Epoch 50/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.5798 - sparse_categorical_accuracy: 0.7523 - val_loss: 0.6402 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 51/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.5779 - sparse_categorical_accuracy: 0.7492 - val_loss: 0.6376 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 52/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.5759 - sparse_categorical_accuracy: 0.7523 - val_loss: 0.6353 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 53/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.5738 - sparse_categorical_accuracy: 0.7533 - val_loss: 0.6335 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 54/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.5719 - sparse_categorical_accuracy: 0.7523 - val_loss: 0.6326 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 55/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5699 - sparse_categorical_accuracy: 0.7523 - val_loss: 0.6304 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 56/100\n",
            "981/981 [==============================] - 0s 113us/sample - loss: 0.5677 - sparse_categorical_accuracy: 0.7564 - val_loss: 0.6286 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 57/100\n",
            "981/981 [==============================] - 0s 137us/sample - loss: 0.5665 - sparse_categorical_accuracy: 0.7604 - val_loss: 0.6272 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 58/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.5643 - sparse_categorical_accuracy: 0.7574 - val_loss: 0.6258 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 59/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5626 - sparse_categorical_accuracy: 0.7584 - val_loss: 0.6238 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 60/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.5609 - sparse_categorical_accuracy: 0.7584 - val_loss: 0.6228 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 61/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.5598 - sparse_categorical_accuracy: 0.7564 - val_loss: 0.6214 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 62/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.5579 - sparse_categorical_accuracy: 0.7584 - val_loss: 0.6199 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 63/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.5563 - sparse_categorical_accuracy: 0.7594 - val_loss: 0.6185 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 64/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.5545 - sparse_categorical_accuracy: 0.7604 - val_loss: 0.6183 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 65/100\n",
            "981/981 [==============================] - 0s 140us/sample - loss: 0.5533 - sparse_categorical_accuracy: 0.7645 - val_loss: 0.6159 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 66/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.5520 - sparse_categorical_accuracy: 0.7655 - val_loss: 0.6151 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 67/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.5507 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.6136 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 68/100\n",
            "981/981 [==============================] - 0s 140us/sample - loss: 0.5497 - sparse_categorical_accuracy: 0.7655 - val_loss: 0.6123 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 69/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.5476 - sparse_categorical_accuracy: 0.7645 - val_loss: 0.6119 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 70/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.5465 - sparse_categorical_accuracy: 0.7666 - val_loss: 0.6105 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 71/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.5456 - sparse_categorical_accuracy: 0.7655 - val_loss: 0.6092 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 72/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.5438 - sparse_categorical_accuracy: 0.7635 - val_loss: 0.6095 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 73/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5428 - sparse_categorical_accuracy: 0.7686 - val_loss: 0.6075 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 74/100\n",
            "981/981 [==============================] - 0s 139us/sample - loss: 0.5418 - sparse_categorical_accuracy: 0.7676 - val_loss: 0.6064 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 75/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.5404 - sparse_categorical_accuracy: 0.7696 - val_loss: 0.6055 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 76/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.5392 - sparse_categorical_accuracy: 0.7676 - val_loss: 0.6053 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 77/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5385 - sparse_categorical_accuracy: 0.7706 - val_loss: 0.6037 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 78/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.5373 - sparse_categorical_accuracy: 0.7706 - val_loss: 0.6029 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 79/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.5362 - sparse_categorical_accuracy: 0.7686 - val_loss: 0.6019 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 80/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.5353 - sparse_categorical_accuracy: 0.7666 - val_loss: 0.6017 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 81/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5345 - sparse_categorical_accuracy: 0.7686 - val_loss: 0.6007 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 82/100\n",
            "981/981 [==============================] - 0s 137us/sample - loss: 0.5328 - sparse_categorical_accuracy: 0.7717 - val_loss: 0.5990 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 83/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.5323 - sparse_categorical_accuracy: 0.7686 - val_loss: 0.5990 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 84/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.5311 - sparse_categorical_accuracy: 0.7737 - val_loss: 0.5977 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 85/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.5302 - sparse_categorical_accuracy: 0.7717 - val_loss: 0.5971 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 86/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.5294 - sparse_categorical_accuracy: 0.7717 - val_loss: 0.5962 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 87/100\n",
            "981/981 [==============================] - 0s 111us/sample - loss: 0.5286 - sparse_categorical_accuracy: 0.7727 - val_loss: 0.5965 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 88/100\n",
            "981/981 [==============================] - 0s 109us/sample - loss: 0.5278 - sparse_categorical_accuracy: 0.7737 - val_loss: 0.5951 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 89/100\n",
            "981/981 [==============================] - 0s 113us/sample - loss: 0.5269 - sparse_categorical_accuracy: 0.7757 - val_loss: 0.5942 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 90/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5265 - sparse_categorical_accuracy: 0.7696 - val_loss: 0.5938 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 91/100\n",
            "981/981 [==============================] - 0s 140us/sample - loss: 0.5254 - sparse_categorical_accuracy: 0.7696 - val_loss: 0.5935 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 92/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.5248 - sparse_categorical_accuracy: 0.7717 - val_loss: 0.5935 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 93/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.5237 - sparse_categorical_accuracy: 0.7706 - val_loss: 0.5923 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 94/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5230 - sparse_categorical_accuracy: 0.7737 - val_loss: 0.5915 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 95/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.5225 - sparse_categorical_accuracy: 0.7717 - val_loss: 0.5910 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 96/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.5210 - sparse_categorical_accuracy: 0.7717 - val_loss: 0.5905 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 97/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.5209 - sparse_categorical_accuracy: 0.7696 - val_loss: 0.5907 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 98/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.5192 - sparse_categorical_accuracy: 0.7686 - val_loss: 0.5894 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 99/100\n",
            "981/981 [==============================] - 0s 160us/sample - loss: 0.5193 - sparse_categorical_accuracy: 0.7727 - val_loss: 0.5888 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 100/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.5186 - sparse_categorical_accuracy: 0.7727 - val_loss: 0.5890 - val_sparse_categorical_accuracy: 0.7339\n",
            "[CV] ......................... n_neurons=42, n_hidden=0, total=  12.8s\n",
            "[CV] n_neurons=42, n_hidden=0 ........................................\n",
            "Train on 981 samples, validate on 109 samples\n",
            "Epoch 1/100\n",
            "981/981 [==============================] - 0s 443us/sample - loss: 1.2098 - sparse_categorical_accuracy: 0.3965 - val_loss: 1.2491 - val_sparse_categorical_accuracy: 0.3670\n",
            "Epoch 2/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 1.0932 - sparse_categorical_accuracy: 0.4281 - val_loss: 1.1741 - val_sparse_categorical_accuracy: 0.4037\n",
            "Epoch 3/100\n",
            "981/981 [==============================] - 0s 134us/sample - loss: 1.0438 - sparse_categorical_accuracy: 0.4526 - val_loss: 1.1229 - val_sparse_categorical_accuracy: 0.4312\n",
            "Epoch 4/100\n",
            "981/981 [==============================] - 0s 113us/sample - loss: 1.0021 - sparse_categorical_accuracy: 0.4832 - val_loss: 1.0795 - val_sparse_categorical_accuracy: 0.4495\n",
            "Epoch 5/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.9669 - sparse_categorical_accuracy: 0.5015 - val_loss: 1.0406 - val_sparse_categorical_accuracy: 0.4495\n",
            "Epoch 6/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.9361 - sparse_categorical_accuracy: 0.5219 - val_loss: 1.0070 - val_sparse_categorical_accuracy: 0.4587\n",
            "Epoch 7/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.9086 - sparse_categorical_accuracy: 0.5423 - val_loss: 0.9791 - val_sparse_categorical_accuracy: 0.4771\n",
            "Epoch 8/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.8839 - sparse_categorical_accuracy: 0.5525 - val_loss: 0.9587 - val_sparse_categorical_accuracy: 0.4771\n",
            "Epoch 9/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.8634 - sparse_categorical_accuracy: 0.5657 - val_loss: 0.9332 - val_sparse_categorical_accuracy: 0.5046\n",
            "Epoch 10/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.8435 - sparse_categorical_accuracy: 0.5770 - val_loss: 0.9121 - val_sparse_categorical_accuracy: 0.5229\n",
            "Epoch 11/100\n",
            "981/981 [==============================] - 0s 136us/sample - loss: 0.8263 - sparse_categorical_accuracy: 0.5861 - val_loss: 0.8939 - val_sparse_categorical_accuracy: 0.5229\n",
            "Epoch 12/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.8092 - sparse_categorical_accuracy: 0.6045 - val_loss: 0.8759 - val_sparse_categorical_accuracy: 0.5505\n",
            "Epoch 13/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.7936 - sparse_categorical_accuracy: 0.6137 - val_loss: 0.8586 - val_sparse_categorical_accuracy: 0.5780\n",
            "Epoch 14/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.7805 - sparse_categorical_accuracy: 0.6208 - val_loss: 0.8453 - val_sparse_categorical_accuracy: 0.5780\n",
            "Epoch 15/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.7683 - sparse_categorical_accuracy: 0.6310 - val_loss: 0.8341 - val_sparse_categorical_accuracy: 0.5872\n",
            "Epoch 16/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.7563 - sparse_categorical_accuracy: 0.6340 - val_loss: 0.8216 - val_sparse_categorical_accuracy: 0.5872\n",
            "Epoch 17/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.7454 - sparse_categorical_accuracy: 0.6534 - val_loss: 0.8108 - val_sparse_categorical_accuracy: 0.6055\n",
            "Epoch 18/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.7353 - sparse_categorical_accuracy: 0.6524 - val_loss: 0.8014 - val_sparse_categorical_accuracy: 0.6239\n",
            "Epoch 19/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.7258 - sparse_categorical_accuracy: 0.6646 - val_loss: 0.7895 - val_sparse_categorical_accuracy: 0.6055\n",
            "Epoch 20/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.7168 - sparse_categorical_accuracy: 0.6687 - val_loss: 0.7799 - val_sparse_categorical_accuracy: 0.6147\n",
            "Epoch 21/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.7087 - sparse_categorical_accuracy: 0.6769 - val_loss: 0.7706 - val_sparse_categorical_accuracy: 0.6330\n",
            "Epoch 22/100\n",
            "981/981 [==============================] - 0s 112us/sample - loss: 0.7006 - sparse_categorical_accuracy: 0.6758 - val_loss: 0.7604 - val_sparse_categorical_accuracy: 0.6239\n",
            "Epoch 23/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.6931 - sparse_categorical_accuracy: 0.6891 - val_loss: 0.7553 - val_sparse_categorical_accuracy: 0.6514\n",
            "Epoch 24/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.6861 - sparse_categorical_accuracy: 0.6901 - val_loss: 0.7485 - val_sparse_categorical_accuracy: 0.6606\n",
            "Epoch 25/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.6787 - sparse_categorical_accuracy: 0.6911 - val_loss: 0.7380 - val_sparse_categorical_accuracy: 0.6422\n",
            "Epoch 26/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.6739 - sparse_categorical_accuracy: 0.6901 - val_loss: 0.7326 - val_sparse_categorical_accuracy: 0.6606\n",
            "Epoch 27/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.6672 - sparse_categorical_accuracy: 0.6932 - val_loss: 0.7262 - val_sparse_categorical_accuracy: 0.6606\n",
            "Epoch 28/100\n",
            "981/981 [==============================] - 0s 141us/sample - loss: 0.6615 - sparse_categorical_accuracy: 0.7003 - val_loss: 0.7206 - val_sparse_categorical_accuracy: 0.6606\n",
            "Epoch 29/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.6565 - sparse_categorical_accuracy: 0.7013 - val_loss: 0.7160 - val_sparse_categorical_accuracy: 0.6514\n",
            "Epoch 30/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.6508 - sparse_categorical_accuracy: 0.7044 - val_loss: 0.7141 - val_sparse_categorical_accuracy: 0.6606\n",
            "Epoch 31/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.6463 - sparse_categorical_accuracy: 0.7023 - val_loss: 0.7046 - val_sparse_categorical_accuracy: 0.6697\n",
            "Epoch 32/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.6418 - sparse_categorical_accuracy: 0.7136 - val_loss: 0.7031 - val_sparse_categorical_accuracy: 0.6606\n",
            "Epoch 33/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.6372 - sparse_categorical_accuracy: 0.7054 - val_loss: 0.6969 - val_sparse_categorical_accuracy: 0.6606\n",
            "Epoch 34/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.6327 - sparse_categorical_accuracy: 0.7146 - val_loss: 0.6906 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 35/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.6288 - sparse_categorical_accuracy: 0.7197 - val_loss: 0.6880 - val_sparse_categorical_accuracy: 0.6697\n",
            "Epoch 36/100\n",
            "981/981 [==============================] - 0s 154us/sample - loss: 0.6246 - sparse_categorical_accuracy: 0.7136 - val_loss: 0.6834 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 37/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.6212 - sparse_categorical_accuracy: 0.7197 - val_loss: 0.6805 - val_sparse_categorical_accuracy: 0.6697\n",
            "Epoch 38/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.6176 - sparse_categorical_accuracy: 0.7187 - val_loss: 0.6760 - val_sparse_categorical_accuracy: 0.6697\n",
            "Epoch 39/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.6141 - sparse_categorical_accuracy: 0.7227 - val_loss: 0.6736 - val_sparse_categorical_accuracy: 0.6697\n",
            "Epoch 40/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.6107 - sparse_categorical_accuracy: 0.7207 - val_loss: 0.6712 - val_sparse_categorical_accuracy: 0.6606\n",
            "Epoch 41/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.6068 - sparse_categorical_accuracy: 0.7258 - val_loss: 0.6640 - val_sparse_categorical_accuracy: 0.6697\n",
            "Epoch 42/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.6042 - sparse_categorical_accuracy: 0.7309 - val_loss: 0.6625 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 43/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.6010 - sparse_categorical_accuracy: 0.7350 - val_loss: 0.6608 - val_sparse_categorical_accuracy: 0.6606\n",
            "Epoch 44/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.5981 - sparse_categorical_accuracy: 0.7360 - val_loss: 0.6573 - val_sparse_categorical_accuracy: 0.6697\n",
            "Epoch 45/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.5956 - sparse_categorical_accuracy: 0.7401 - val_loss: 0.6549 - val_sparse_categorical_accuracy: 0.6697\n",
            "Epoch 46/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.5928 - sparse_categorical_accuracy: 0.7370 - val_loss: 0.6498 - val_sparse_categorical_accuracy: 0.6697\n",
            "Epoch 47/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5900 - sparse_categorical_accuracy: 0.7421 - val_loss: 0.6489 - val_sparse_categorical_accuracy: 0.6697\n",
            "Epoch 48/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.5870 - sparse_categorical_accuracy: 0.7462 - val_loss: 0.6469 - val_sparse_categorical_accuracy: 0.6606\n",
            "Epoch 49/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5850 - sparse_categorical_accuracy: 0.7441 - val_loss: 0.6421 - val_sparse_categorical_accuracy: 0.6697\n",
            "Epoch 50/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.5827 - sparse_categorical_accuracy: 0.7431 - val_loss: 0.6411 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 51/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.5805 - sparse_categorical_accuracy: 0.7441 - val_loss: 0.6387 - val_sparse_categorical_accuracy: 0.6697\n",
            "Epoch 52/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.5776 - sparse_categorical_accuracy: 0.7492 - val_loss: 0.6391 - val_sparse_categorical_accuracy: 0.6514\n",
            "Epoch 53/100\n",
            "981/981 [==============================] - 0s 146us/sample - loss: 0.5762 - sparse_categorical_accuracy: 0.7441 - val_loss: 0.6340 - val_sparse_categorical_accuracy: 0.6697\n",
            "Epoch 54/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5736 - sparse_categorical_accuracy: 0.7503 - val_loss: 0.6320 - val_sparse_categorical_accuracy: 0.6697\n",
            "Epoch 55/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.5714 - sparse_categorical_accuracy: 0.7554 - val_loss: 0.6288 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 56/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.5697 - sparse_categorical_accuracy: 0.7503 - val_loss: 0.6277 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 57/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5676 - sparse_categorical_accuracy: 0.7503 - val_loss: 0.6255 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 58/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.5657 - sparse_categorical_accuracy: 0.7513 - val_loss: 0.6247 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 59/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.5640 - sparse_categorical_accuracy: 0.7554 - val_loss: 0.6241 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 60/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.5621 - sparse_categorical_accuracy: 0.7503 - val_loss: 0.6221 - val_sparse_categorical_accuracy: 0.6697\n",
            "Epoch 61/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.5604 - sparse_categorical_accuracy: 0.7533 - val_loss: 0.6201 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 62/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.5581 - sparse_categorical_accuracy: 0.7533 - val_loss: 0.6157 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 63/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.5574 - sparse_categorical_accuracy: 0.7523 - val_loss: 0.6146 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 64/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5554 - sparse_categorical_accuracy: 0.7533 - val_loss: 0.6154 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 65/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5539 - sparse_categorical_accuracy: 0.7523 - val_loss: 0.6109 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 66/100\n",
            "981/981 [==============================] - 0s 141us/sample - loss: 0.5523 - sparse_categorical_accuracy: 0.7554 - val_loss: 0.6096 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 67/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5507 - sparse_categorical_accuracy: 0.7554 - val_loss: 0.6075 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 68/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.5498 - sparse_categorical_accuracy: 0.7584 - val_loss: 0.6062 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 69/100\n",
            "981/981 [==============================] - 0s 139us/sample - loss: 0.5484 - sparse_categorical_accuracy: 0.7564 - val_loss: 0.6061 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 70/100\n",
            "981/981 [==============================] - 0s 136us/sample - loss: 0.5467 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.6045 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 71/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5451 - sparse_categorical_accuracy: 0.7574 - val_loss: 0.6038 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 72/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.5440 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.6017 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 73/100\n",
            "981/981 [==============================] - 0s 113us/sample - loss: 0.5428 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.6016 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 74/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.5415 - sparse_categorical_accuracy: 0.7604 - val_loss: 0.6010 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 75/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5400 - sparse_categorical_accuracy: 0.7645 - val_loss: 0.5984 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 76/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.5391 - sparse_categorical_accuracy: 0.7645 - val_loss: 0.5975 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 77/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5374 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.5949 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 78/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.5367 - sparse_categorical_accuracy: 0.7645 - val_loss: 0.5954 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 79/100\n",
            "981/981 [==============================] - 0s 144us/sample - loss: 0.5356 - sparse_categorical_accuracy: 0.7645 - val_loss: 0.5933 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 80/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.5343 - sparse_categorical_accuracy: 0.7655 - val_loss: 0.5916 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 81/100\n",
            "981/981 [==============================] - 0s 111us/sample - loss: 0.5333 - sparse_categorical_accuracy: 0.7686 - val_loss: 0.5922 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 82/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.5323 - sparse_categorical_accuracy: 0.7666 - val_loss: 0.5923 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 83/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5311 - sparse_categorical_accuracy: 0.7594 - val_loss: 0.5884 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 84/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.5306 - sparse_categorical_accuracy: 0.7635 - val_loss: 0.5897 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 85/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.5297 - sparse_categorical_accuracy: 0.7666 - val_loss: 0.5900 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 86/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.5283 - sparse_categorical_accuracy: 0.7645 - val_loss: 0.5863 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 87/100\n",
            "981/981 [==============================] - 0s 135us/sample - loss: 0.5270 - sparse_categorical_accuracy: 0.7717 - val_loss: 0.5884 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 88/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.5267 - sparse_categorical_accuracy: 0.7686 - val_loss: 0.5867 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 89/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5253 - sparse_categorical_accuracy: 0.7686 - val_loss: 0.5865 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 90/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5245 - sparse_categorical_accuracy: 0.7666 - val_loss: 0.5850 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 91/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5239 - sparse_categorical_accuracy: 0.7666 - val_loss: 0.5832 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 92/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.5228 - sparse_categorical_accuracy: 0.7757 - val_loss: 0.5813 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 93/100\n",
            "981/981 [==============================] - 0s 143us/sample - loss: 0.5223 - sparse_categorical_accuracy: 0.7727 - val_loss: 0.5807 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 94/100\n",
            "981/981 [==============================] - 0s 148us/sample - loss: 0.5210 - sparse_categorical_accuracy: 0.7696 - val_loss: 0.5822 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 95/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.5204 - sparse_categorical_accuracy: 0.7737 - val_loss: 0.5792 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 96/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5198 - sparse_categorical_accuracy: 0.7696 - val_loss: 0.5799 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 97/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.5190 - sparse_categorical_accuracy: 0.7676 - val_loss: 0.5792 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 98/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.5181 - sparse_categorical_accuracy: 0.7686 - val_loss: 0.5774 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 99/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.5172 - sparse_categorical_accuracy: 0.7737 - val_loss: 0.5784 - val_sparse_categorical_accuracy: 0.6881\n",
            "Epoch 100/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.5164 - sparse_categorical_accuracy: 0.7717 - val_loss: 0.5783 - val_sparse_categorical_accuracy: 0.6881\n",
            "[CV] ......................... n_neurons=42, n_hidden=0, total=  12.8s\n",
            "[CV] n_neurons=42, n_hidden=0 ........................................\n",
            "Train on 981 samples, validate on 109 samples\n",
            "Epoch 1/100\n",
            "981/981 [==============================] - 0s 450us/sample - loss: 1.2292 - sparse_categorical_accuracy: 0.3894 - val_loss: 1.1663 - val_sparse_categorical_accuracy: 0.3853\n",
            "Epoch 2/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 1.1258 - sparse_categorical_accuracy: 0.4149 - val_loss: 1.1026 - val_sparse_categorical_accuracy: 0.4128\n",
            "Epoch 3/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 1.0716 - sparse_categorical_accuracy: 0.4495 - val_loss: 1.0491 - val_sparse_categorical_accuracy: 0.4495\n",
            "Epoch 4/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 1.0270 - sparse_categorical_accuracy: 0.4597 - val_loss: 1.0075 - val_sparse_categorical_accuracy: 0.5046\n",
            "Epoch 5/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.9892 - sparse_categorical_accuracy: 0.4862 - val_loss: 0.9694 - val_sparse_categorical_accuracy: 0.5046\n",
            "Epoch 6/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.9552 - sparse_categorical_accuracy: 0.5015 - val_loss: 0.9360 - val_sparse_categorical_accuracy: 0.5138\n",
            "Epoch 7/100\n",
            "981/981 [==============================] - 0s 135us/sample - loss: 0.9259 - sparse_categorical_accuracy: 0.5107 - val_loss: 0.9050 - val_sparse_categorical_accuracy: 0.5229\n",
            "Epoch 8/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.8992 - sparse_categorical_accuracy: 0.5413 - val_loss: 0.8828 - val_sparse_categorical_accuracy: 0.5413\n",
            "Epoch 9/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.8773 - sparse_categorical_accuracy: 0.5505 - val_loss: 0.8594 - val_sparse_categorical_accuracy: 0.5596\n",
            "Epoch 10/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.8562 - sparse_categorical_accuracy: 0.5678 - val_loss: 0.8407 - val_sparse_categorical_accuracy: 0.5688\n",
            "Epoch 11/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.8375 - sparse_categorical_accuracy: 0.5678 - val_loss: 0.8219 - val_sparse_categorical_accuracy: 0.6147\n",
            "Epoch 12/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.8210 - sparse_categorical_accuracy: 0.5923 - val_loss: 0.8063 - val_sparse_categorical_accuracy: 0.6147\n",
            "Epoch 13/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.8051 - sparse_categorical_accuracy: 0.6004 - val_loss: 0.7915 - val_sparse_categorical_accuracy: 0.6239\n",
            "Epoch 14/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.7908 - sparse_categorical_accuracy: 0.6075 - val_loss: 0.7822 - val_sparse_categorical_accuracy: 0.6055\n",
            "Epoch 15/100\n",
            "981/981 [==============================] - 0s 113us/sample - loss: 0.7794 - sparse_categorical_accuracy: 0.6167 - val_loss: 0.7688 - val_sparse_categorical_accuracy: 0.6330\n",
            "Epoch 16/100\n",
            "981/981 [==============================] - 0s 139us/sample - loss: 0.7676 - sparse_categorical_accuracy: 0.6249 - val_loss: 0.7565 - val_sparse_categorical_accuracy: 0.6422\n",
            "Epoch 17/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.7564 - sparse_categorical_accuracy: 0.6391 - val_loss: 0.7462 - val_sparse_categorical_accuracy: 0.6514\n",
            "Epoch 18/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.7468 - sparse_categorical_accuracy: 0.6453 - val_loss: 0.7364 - val_sparse_categorical_accuracy: 0.6606\n",
            "Epoch 19/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.7372 - sparse_categorical_accuracy: 0.6544 - val_loss: 0.7281 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 20/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.7285 - sparse_categorical_accuracy: 0.6504 - val_loss: 0.7203 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 21/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.7205 - sparse_categorical_accuracy: 0.6575 - val_loss: 0.7128 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 22/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.7126 - sparse_categorical_accuracy: 0.6728 - val_loss: 0.7049 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 23/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.7056 - sparse_categorical_accuracy: 0.6677 - val_loss: 0.6995 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 24/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.6998 - sparse_categorical_accuracy: 0.6809 - val_loss: 0.6927 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 25/100\n",
            "981/981 [==============================] - 0s 112us/sample - loss: 0.6928 - sparse_categorical_accuracy: 0.6809 - val_loss: 0.6882 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 26/100\n",
            "981/981 [==============================] - 0s 109us/sample - loss: 0.6866 - sparse_categorical_accuracy: 0.6799 - val_loss: 0.6806 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 27/100\n",
            "981/981 [==============================] - 0s 112us/sample - loss: 0.6810 - sparse_categorical_accuracy: 0.6779 - val_loss: 0.6746 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 28/100\n",
            "981/981 [==============================] - 0s 110us/sample - loss: 0.6763 - sparse_categorical_accuracy: 0.6860 - val_loss: 0.6705 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 29/100\n",
            "981/981 [==============================] - 0s 112us/sample - loss: 0.6705 - sparse_categorical_accuracy: 0.6932 - val_loss: 0.6658 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 30/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.6660 - sparse_categorical_accuracy: 0.6891 - val_loss: 0.6610 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 31/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.6612 - sparse_categorical_accuracy: 0.6993 - val_loss: 0.6577 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 32/100\n",
            "981/981 [==============================] - 0s 140us/sample - loss: 0.6572 - sparse_categorical_accuracy: 0.7034 - val_loss: 0.6540 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 33/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.6528 - sparse_categorical_accuracy: 0.7125 - val_loss: 0.6511 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 34/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.6496 - sparse_categorical_accuracy: 0.7115 - val_loss: 0.6465 - val_sparse_categorical_accuracy: 0.7523\n",
            "Epoch 35/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.6453 - sparse_categorical_accuracy: 0.7217 - val_loss: 0.6426 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 36/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.6413 - sparse_categorical_accuracy: 0.7217 - val_loss: 0.6397 - val_sparse_categorical_accuracy: 0.7615\n",
            "Epoch 37/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.6380 - sparse_categorical_accuracy: 0.7197 - val_loss: 0.6361 - val_sparse_categorical_accuracy: 0.7523\n",
            "Epoch 38/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.6346 - sparse_categorical_accuracy: 0.7238 - val_loss: 0.6324 - val_sparse_categorical_accuracy: 0.7523\n",
            "Epoch 39/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.6312 - sparse_categorical_accuracy: 0.7278 - val_loss: 0.6304 - val_sparse_categorical_accuracy: 0.7523\n",
            "Epoch 40/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.6279 - sparse_categorical_accuracy: 0.7278 - val_loss: 0.6265 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 41/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.6249 - sparse_categorical_accuracy: 0.7350 - val_loss: 0.6249 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 42/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.6219 - sparse_categorical_accuracy: 0.7319 - val_loss: 0.6219 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 43/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.6196 - sparse_categorical_accuracy: 0.7350 - val_loss: 0.6194 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 44/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.6170 - sparse_categorical_accuracy: 0.7390 - val_loss: 0.6164 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 45/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.6140 - sparse_categorical_accuracy: 0.7421 - val_loss: 0.6145 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 46/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.6115 - sparse_categorical_accuracy: 0.7431 - val_loss: 0.6123 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 47/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.6087 - sparse_categorical_accuracy: 0.7421 - val_loss: 0.6107 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 48/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.6068 - sparse_categorical_accuracy: 0.7421 - val_loss: 0.6088 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 49/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.6042 - sparse_categorical_accuracy: 0.7441 - val_loss: 0.6076 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 50/100\n",
            "981/981 [==============================] - 0s 154us/sample - loss: 0.6022 - sparse_categorical_accuracy: 0.7452 - val_loss: 0.6049 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 51/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.6001 - sparse_categorical_accuracy: 0.7441 - val_loss: 0.6025 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 52/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.5978 - sparse_categorical_accuracy: 0.7441 - val_loss: 0.6012 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 53/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.5959 - sparse_categorical_accuracy: 0.7492 - val_loss: 0.5987 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 54/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5941 - sparse_categorical_accuracy: 0.7431 - val_loss: 0.5972 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 55/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.5923 - sparse_categorical_accuracy: 0.7482 - val_loss: 0.5950 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 56/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.5902 - sparse_categorical_accuracy: 0.7462 - val_loss: 0.5938 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 57/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5885 - sparse_categorical_accuracy: 0.7421 - val_loss: 0.5917 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 58/100\n",
            "981/981 [==============================] - 0s 143us/sample - loss: 0.5869 - sparse_categorical_accuracy: 0.7462 - val_loss: 0.5913 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 59/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5850 - sparse_categorical_accuracy: 0.7492 - val_loss: 0.5887 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 60/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.5832 - sparse_categorical_accuracy: 0.7441 - val_loss: 0.5875 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 61/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5819 - sparse_categorical_accuracy: 0.7503 - val_loss: 0.5863 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 62/100\n",
            "981/981 [==============================] - 0s 145us/sample - loss: 0.5803 - sparse_categorical_accuracy: 0.7462 - val_loss: 0.5857 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 63/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.5783 - sparse_categorical_accuracy: 0.7492 - val_loss: 0.5859 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 64/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.5772 - sparse_categorical_accuracy: 0.7503 - val_loss: 0.5828 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 65/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.5756 - sparse_categorical_accuracy: 0.7482 - val_loss: 0.5818 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 66/100\n",
            "981/981 [==============================] - 0s 144us/sample - loss: 0.5742 - sparse_categorical_accuracy: 0.7482 - val_loss: 0.5797 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 67/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.5729 - sparse_categorical_accuracy: 0.7503 - val_loss: 0.5779 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 68/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.5715 - sparse_categorical_accuracy: 0.7441 - val_loss: 0.5765 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 69/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.5701 - sparse_categorical_accuracy: 0.7472 - val_loss: 0.5767 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 70/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5691 - sparse_categorical_accuracy: 0.7472 - val_loss: 0.5757 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 71/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.5675 - sparse_categorical_accuracy: 0.7523 - val_loss: 0.5732 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 72/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.5666 - sparse_categorical_accuracy: 0.7462 - val_loss: 0.5725 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 73/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.5655 - sparse_categorical_accuracy: 0.7523 - val_loss: 0.5721 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 74/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.5642 - sparse_categorical_accuracy: 0.7482 - val_loss: 0.5703 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 75/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5631 - sparse_categorical_accuracy: 0.7492 - val_loss: 0.5697 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 76/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5622 - sparse_categorical_accuracy: 0.7492 - val_loss: 0.5697 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 77/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5609 - sparse_categorical_accuracy: 0.7503 - val_loss: 0.5687 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 78/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5598 - sparse_categorical_accuracy: 0.7462 - val_loss: 0.5673 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 79/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.5582 - sparse_categorical_accuracy: 0.7513 - val_loss: 0.5655 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 80/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.5583 - sparse_categorical_accuracy: 0.7462 - val_loss: 0.5657 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 81/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.5567 - sparse_categorical_accuracy: 0.7543 - val_loss: 0.5641 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 82/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.5555 - sparse_categorical_accuracy: 0.7482 - val_loss: 0.5652 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 83/100\n",
            "981/981 [==============================] - 0s 135us/sample - loss: 0.5549 - sparse_categorical_accuracy: 0.7533 - val_loss: 0.5628 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 84/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.5541 - sparse_categorical_accuracy: 0.7492 - val_loss: 0.5620 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 85/100\n",
            "981/981 [==============================] - 0s 135us/sample - loss: 0.5533 - sparse_categorical_accuracy: 0.7543 - val_loss: 0.5617 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 86/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5522 - sparse_categorical_accuracy: 0.7543 - val_loss: 0.5606 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 87/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.5514 - sparse_categorical_accuracy: 0.7543 - val_loss: 0.5597 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 88/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.5508 - sparse_categorical_accuracy: 0.7584 - val_loss: 0.5588 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 89/100\n",
            "981/981 [==============================] - 0s 113us/sample - loss: 0.5495 - sparse_categorical_accuracy: 0.7574 - val_loss: 0.5578 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 90/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.5490 - sparse_categorical_accuracy: 0.7543 - val_loss: 0.5576 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 91/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.5477 - sparse_categorical_accuracy: 0.7554 - val_loss: 0.5563 - val_sparse_categorical_accuracy: 0.6972\n",
            "Epoch 92/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.5472 - sparse_categorical_accuracy: 0.7564 - val_loss: 0.5563 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 93/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.5466 - sparse_categorical_accuracy: 0.7543 - val_loss: 0.5555 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 94/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.5456 - sparse_categorical_accuracy: 0.7554 - val_loss: 0.5547 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 95/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.5444 - sparse_categorical_accuracy: 0.7604 - val_loss: 0.5542 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 96/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.5437 - sparse_categorical_accuracy: 0.7574 - val_loss: 0.5551 - val_sparse_categorical_accuracy: 0.7339\n",
            "Epoch 97/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.5434 - sparse_categorical_accuracy: 0.7594 - val_loss: 0.5537 - val_sparse_categorical_accuracy: 0.7248\n",
            "Epoch 98/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5426 - sparse_categorical_accuracy: 0.7604 - val_loss: 0.5525 - val_sparse_categorical_accuracy: 0.7064\n",
            "Epoch 99/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.5416 - sparse_categorical_accuracy: 0.7655 - val_loss: 0.5517 - val_sparse_categorical_accuracy: 0.7156\n",
            "Epoch 100/100\n",
            "981/981 [==============================] - 0s 138us/sample - loss: 0.5411 - sparse_categorical_accuracy: 0.7584 - val_loss: 0.5517 - val_sparse_categorical_accuracy: 0.7248\n",
            "[CV] ......................... n_neurons=42, n_hidden=0, total=  12.8s\n",
            "[CV] n_neurons=42, n_hidden=0 ........................................\n",
            "Train on 981 samples, validate on 110 samples\n",
            "Epoch 1/100\n",
            "981/981 [==============================] - 0s 432us/sample - loss: 1.2600 - sparse_categorical_accuracy: 0.3609 - val_loss: 1.2200 - val_sparse_categorical_accuracy: 0.3455\n",
            "Epoch 2/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 1.1363 - sparse_categorical_accuracy: 0.4088 - val_loss: 1.1528 - val_sparse_categorical_accuracy: 0.3636\n",
            "Epoch 3/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 1.0807 - sparse_categorical_accuracy: 0.4251 - val_loss: 1.1009 - val_sparse_categorical_accuracy: 0.3636\n",
            "Epoch 4/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 1.0348 - sparse_categorical_accuracy: 0.4455 - val_loss: 1.0575 - val_sparse_categorical_accuracy: 0.3909\n",
            "Epoch 5/100\n",
            "981/981 [==============================] - 0s 135us/sample - loss: 0.9963 - sparse_categorical_accuracy: 0.4679 - val_loss: 1.0164 - val_sparse_categorical_accuracy: 0.4091\n",
            "Epoch 6/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.9605 - sparse_categorical_accuracy: 0.4883 - val_loss: 0.9813 - val_sparse_categorical_accuracy: 0.4636\n",
            "Epoch 7/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.9312 - sparse_categorical_accuracy: 0.5046 - val_loss: 0.9503 - val_sparse_categorical_accuracy: 0.4636\n",
            "Epoch 8/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.9033 - sparse_categorical_accuracy: 0.5148 - val_loss: 0.9238 - val_sparse_categorical_accuracy: 0.4727\n",
            "Epoch 9/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.8796 - sparse_categorical_accuracy: 0.5372 - val_loss: 0.9012 - val_sparse_categorical_accuracy: 0.4909\n",
            "Epoch 10/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.8571 - sparse_categorical_accuracy: 0.5515 - val_loss: 0.8811 - val_sparse_categorical_accuracy: 0.5000\n",
            "Epoch 11/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.8374 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.8604 - val_sparse_categorical_accuracy: 0.5182\n",
            "Epoch 12/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.8194 - sparse_categorical_accuracy: 0.5821 - val_loss: 0.8437 - val_sparse_categorical_accuracy: 0.5636\n",
            "Epoch 13/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.8034 - sparse_categorical_accuracy: 0.5994 - val_loss: 0.8287 - val_sparse_categorical_accuracy: 0.5636\n",
            "Epoch 14/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.7882 - sparse_categorical_accuracy: 0.6024 - val_loss: 0.8137 - val_sparse_categorical_accuracy: 0.6182\n",
            "Epoch 15/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.7754 - sparse_categorical_accuracy: 0.6126 - val_loss: 0.8019 - val_sparse_categorical_accuracy: 0.5909\n",
            "Epoch 16/100\n",
            "981/981 [==============================] - 0s 110us/sample - loss: 0.7621 - sparse_categorical_accuracy: 0.6157 - val_loss: 0.7900 - val_sparse_categorical_accuracy: 0.6182\n",
            "Epoch 17/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.7504 - sparse_categorical_accuracy: 0.6361 - val_loss: 0.7803 - val_sparse_categorical_accuracy: 0.5909\n",
            "Epoch 18/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.7404 - sparse_categorical_accuracy: 0.6412 - val_loss: 0.7699 - val_sparse_categorical_accuracy: 0.6000\n",
            "Epoch 19/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.7291 - sparse_categorical_accuracy: 0.6473 - val_loss: 0.7593 - val_sparse_categorical_accuracy: 0.6273\n",
            "Epoch 20/100\n",
            "981/981 [==============================] - 0s 111us/sample - loss: 0.7205 - sparse_categorical_accuracy: 0.6656 - val_loss: 0.7510 - val_sparse_categorical_accuracy: 0.6273\n",
            "Epoch 21/100\n",
            "981/981 [==============================] - 0s 142us/sample - loss: 0.7114 - sparse_categorical_accuracy: 0.6697 - val_loss: 0.7434 - val_sparse_categorical_accuracy: 0.6364\n",
            "Epoch 22/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.7029 - sparse_categorical_accuracy: 0.6779 - val_loss: 0.7346 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 23/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.6957 - sparse_categorical_accuracy: 0.6799 - val_loss: 0.7275 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 24/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.6888 - sparse_categorical_accuracy: 0.6871 - val_loss: 0.7203 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 25/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.6818 - sparse_categorical_accuracy: 0.6962 - val_loss: 0.7153 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 26/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.6749 - sparse_categorical_accuracy: 0.7003 - val_loss: 0.7081 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 27/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.6694 - sparse_categorical_accuracy: 0.7064 - val_loss: 0.7025 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 28/100\n",
            "981/981 [==============================] - 0s 113us/sample - loss: 0.6633 - sparse_categorical_accuracy: 0.7044 - val_loss: 0.6972 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 29/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.6578 - sparse_categorical_accuracy: 0.7074 - val_loss: 0.6931 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 30/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.6529 - sparse_categorical_accuracy: 0.7146 - val_loss: 0.6880 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 31/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.6473 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.6853 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 32/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.6426 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.6796 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 33/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.6380 - sparse_categorical_accuracy: 0.7278 - val_loss: 0.6763 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 34/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.6338 - sparse_categorical_accuracy: 0.7258 - val_loss: 0.6731 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 35/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.6298 - sparse_categorical_accuracy: 0.7329 - val_loss: 0.6669 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 36/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.6250 - sparse_categorical_accuracy: 0.7380 - val_loss: 0.6666 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 37/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.6216 - sparse_categorical_accuracy: 0.7360 - val_loss: 0.6594 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 38/100\n",
            "981/981 [==============================] - 0s 143us/sample - loss: 0.6182 - sparse_categorical_accuracy: 0.7431 - val_loss: 0.6571 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 39/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.6152 - sparse_categorical_accuracy: 0.7350 - val_loss: 0.6534 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 40/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.6113 - sparse_categorical_accuracy: 0.7401 - val_loss: 0.6500 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 41/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.6079 - sparse_categorical_accuracy: 0.7411 - val_loss: 0.6487 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 42/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.6049 - sparse_categorical_accuracy: 0.7462 - val_loss: 0.6440 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 43/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.6020 - sparse_categorical_accuracy: 0.7441 - val_loss: 0.6423 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 44/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.5984 - sparse_categorical_accuracy: 0.7462 - val_loss: 0.6381 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 45/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.5963 - sparse_categorical_accuracy: 0.7441 - val_loss: 0.6359 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 46/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.5936 - sparse_categorical_accuracy: 0.7492 - val_loss: 0.6339 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 47/100\n",
            "981/981 [==============================] - 0s 145us/sample - loss: 0.5909 - sparse_categorical_accuracy: 0.7452 - val_loss: 0.6318 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 48/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.5882 - sparse_categorical_accuracy: 0.7441 - val_loss: 0.6297 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 49/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.5856 - sparse_categorical_accuracy: 0.7441 - val_loss: 0.6269 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 50/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.5830 - sparse_categorical_accuracy: 0.7431 - val_loss: 0.6236 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 51/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.5809 - sparse_categorical_accuracy: 0.7421 - val_loss: 0.6233 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 52/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.5789 - sparse_categorical_accuracy: 0.7441 - val_loss: 0.6205 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 53/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.5766 - sparse_categorical_accuracy: 0.7452 - val_loss: 0.6179 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 54/100\n",
            "981/981 [==============================] - 0s 136us/sample - loss: 0.5743 - sparse_categorical_accuracy: 0.7421 - val_loss: 0.6176 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 55/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.5722 - sparse_categorical_accuracy: 0.7401 - val_loss: 0.6148 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 56/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.5702 - sparse_categorical_accuracy: 0.7462 - val_loss: 0.6125 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 57/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.5683 - sparse_categorical_accuracy: 0.7452 - val_loss: 0.6110 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 58/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.5663 - sparse_categorical_accuracy: 0.7503 - val_loss: 0.6075 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 59/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5646 - sparse_categorical_accuracy: 0.7462 - val_loss: 0.6068 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 60/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5628 - sparse_categorical_accuracy: 0.7543 - val_loss: 0.6053 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 61/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5612 - sparse_categorical_accuracy: 0.7503 - val_loss: 0.6042 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 62/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5594 - sparse_categorical_accuracy: 0.7492 - val_loss: 0.6032 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 63/100\n",
            "981/981 [==============================] - 0s 140us/sample - loss: 0.5581 - sparse_categorical_accuracy: 0.7513 - val_loss: 0.6024 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 64/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.5565 - sparse_categorical_accuracy: 0.7492 - val_loss: 0.6001 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 65/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.5549 - sparse_categorical_accuracy: 0.7513 - val_loss: 0.5982 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 66/100\n",
            "981/981 [==============================] - 0s 128us/sample - loss: 0.5531 - sparse_categorical_accuracy: 0.7492 - val_loss: 0.5969 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 67/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.5516 - sparse_categorical_accuracy: 0.7513 - val_loss: 0.5953 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 68/100\n",
            "981/981 [==============================] - 0s 113us/sample - loss: 0.5501 - sparse_categorical_accuracy: 0.7533 - val_loss: 0.5940 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 69/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.5487 - sparse_categorical_accuracy: 0.7523 - val_loss: 0.5951 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 70/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.5473 - sparse_categorical_accuracy: 0.7574 - val_loss: 0.5915 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 71/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.5458 - sparse_categorical_accuracy: 0.7554 - val_loss: 0.5900 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 72/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.5444 - sparse_categorical_accuracy: 0.7513 - val_loss: 0.5888 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 73/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.5431 - sparse_categorical_accuracy: 0.7564 - val_loss: 0.5874 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 74/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.5424 - sparse_categorical_accuracy: 0.7523 - val_loss: 0.5867 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 75/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5405 - sparse_categorical_accuracy: 0.7574 - val_loss: 0.5869 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 76/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.5394 - sparse_categorical_accuracy: 0.7564 - val_loss: 0.5842 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 77/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.5381 - sparse_categorical_accuracy: 0.7574 - val_loss: 0.5838 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 78/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.5371 - sparse_categorical_accuracy: 0.7564 - val_loss: 0.5819 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 79/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.5361 - sparse_categorical_accuracy: 0.7564 - val_loss: 0.5809 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 80/100\n",
            "981/981 [==============================] - 0s 142us/sample - loss: 0.5349 - sparse_categorical_accuracy: 0.7584 - val_loss: 0.5803 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 81/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5337 - sparse_categorical_accuracy: 0.7615 - val_loss: 0.5814 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 82/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.5327 - sparse_categorical_accuracy: 0.7574 - val_loss: 0.5795 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 83/100\n",
            "981/981 [==============================] - 0s 130us/sample - loss: 0.5318 - sparse_categorical_accuracy: 0.7604 - val_loss: 0.5778 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 84/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.5305 - sparse_categorical_accuracy: 0.7594 - val_loss: 0.5779 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 85/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5296 - sparse_categorical_accuracy: 0.7604 - val_loss: 0.5752 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 86/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5286 - sparse_categorical_accuracy: 0.7574 - val_loss: 0.5747 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 87/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5273 - sparse_categorical_accuracy: 0.7615 - val_loss: 0.5744 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 88/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.5268 - sparse_categorical_accuracy: 0.7554 - val_loss: 0.5734 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 89/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.5259 - sparse_categorical_accuracy: 0.7584 - val_loss: 0.5719 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 90/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5249 - sparse_categorical_accuracy: 0.7604 - val_loss: 0.5721 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 91/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5236 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.5719 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 92/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.5229 - sparse_categorical_accuracy: 0.7594 - val_loss: 0.5697 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 93/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.5217 - sparse_categorical_accuracy: 0.7645 - val_loss: 0.5704 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 94/100\n",
            "981/981 [==============================] - 0s 111us/sample - loss: 0.5210 - sparse_categorical_accuracy: 0.7554 - val_loss: 0.5684 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 95/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.5201 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.5687 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 96/100\n",
            "981/981 [==============================] - 0s 159us/sample - loss: 0.5195 - sparse_categorical_accuracy: 0.7574 - val_loss: 0.5671 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 97/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.5189 - sparse_categorical_accuracy: 0.7635 - val_loss: 0.5660 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 98/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.5180 - sparse_categorical_accuracy: 0.7615 - val_loss: 0.5658 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 99/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.5173 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.5651 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 100/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.5164 - sparse_categorical_accuracy: 0.7615 - val_loss: 0.5639 - val_sparse_categorical_accuracy: 0.7182\n",
            "[CV] ......................... n_neurons=42, n_hidden=0, total=  12.7s\n",
            "[CV] n_neurons=42, n_hidden=0 ........................................\n",
            "Train on 981 samples, validate on 110 samples\n",
            "Epoch 1/100\n",
            "981/981 [==============================] - 0s 455us/sample - loss: 1.2708 - sparse_categorical_accuracy: 0.3394 - val_loss: 1.1880 - val_sparse_categorical_accuracy: 0.4000\n",
            "Epoch 2/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 1.1389 - sparse_categorical_accuracy: 0.3965 - val_loss: 1.1169 - val_sparse_categorical_accuracy: 0.3909\n",
            "Epoch 3/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 1.0684 - sparse_categorical_accuracy: 0.4414 - val_loss: 1.0657 - val_sparse_categorical_accuracy: 0.4364\n",
            "Epoch 4/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 1.0135 - sparse_categorical_accuracy: 0.4699 - val_loss: 1.0254 - val_sparse_categorical_accuracy: 0.4364\n",
            "Epoch 5/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.9698 - sparse_categorical_accuracy: 0.4842 - val_loss: 0.9915 - val_sparse_categorical_accuracy: 0.4727\n",
            "Epoch 6/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.9330 - sparse_categorical_accuracy: 0.5056 - val_loss: 0.9633 - val_sparse_categorical_accuracy: 0.5000\n",
            "Epoch 7/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.9032 - sparse_categorical_accuracy: 0.5280 - val_loss: 0.9385 - val_sparse_categorical_accuracy: 0.5364\n",
            "Epoch 8/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.8765 - sparse_categorical_accuracy: 0.5362 - val_loss: 0.9180 - val_sparse_categorical_accuracy: 0.5364\n",
            "Epoch 9/100\n",
            "981/981 [==============================] - 0s 149us/sample - loss: 0.8528 - sparse_categorical_accuracy: 0.5627 - val_loss: 0.9007 - val_sparse_categorical_accuracy: 0.5364\n",
            "Epoch 10/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.8332 - sparse_categorical_accuracy: 0.5719 - val_loss: 0.8816 - val_sparse_categorical_accuracy: 0.5727\n",
            "Epoch 11/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.8150 - sparse_categorical_accuracy: 0.5892 - val_loss: 0.8661 - val_sparse_categorical_accuracy: 0.5727\n",
            "Epoch 12/100\n",
            "981/981 [==============================] - 0s 113us/sample - loss: 0.7982 - sparse_categorical_accuracy: 0.6055 - val_loss: 0.8517 - val_sparse_categorical_accuracy: 0.5727\n",
            "Epoch 13/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.7834 - sparse_categorical_accuracy: 0.6147 - val_loss: 0.8417 - val_sparse_categorical_accuracy: 0.5545\n",
            "Epoch 14/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.7701 - sparse_categorical_accuracy: 0.6391 - val_loss: 0.8293 - val_sparse_categorical_accuracy: 0.5636\n",
            "Epoch 15/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.7578 - sparse_categorical_accuracy: 0.6391 - val_loss: 0.8178 - val_sparse_categorical_accuracy: 0.5818\n",
            "Epoch 16/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.7465 - sparse_categorical_accuracy: 0.6432 - val_loss: 0.8071 - val_sparse_categorical_accuracy: 0.5818\n",
            "Epoch 17/100\n",
            "981/981 [==============================] - 0s 135us/sample - loss: 0.7357 - sparse_categorical_accuracy: 0.6544 - val_loss: 0.7996 - val_sparse_categorical_accuracy: 0.5818\n",
            "Epoch 18/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.7261 - sparse_categorical_accuracy: 0.6656 - val_loss: 0.7897 - val_sparse_categorical_accuracy: 0.5909\n",
            "Epoch 19/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.7168 - sparse_categorical_accuracy: 0.6769 - val_loss: 0.7825 - val_sparse_categorical_accuracy: 0.5909\n",
            "Epoch 20/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.7085 - sparse_categorical_accuracy: 0.6758 - val_loss: 0.7738 - val_sparse_categorical_accuracy: 0.6091\n",
            "Epoch 21/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.7002 - sparse_categorical_accuracy: 0.6789 - val_loss: 0.7675 - val_sparse_categorical_accuracy: 0.6091\n",
            "Epoch 22/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.6932 - sparse_categorical_accuracy: 0.6850 - val_loss: 0.7591 - val_sparse_categorical_accuracy: 0.6091\n",
            "Epoch 23/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.6857 - sparse_categorical_accuracy: 0.6932 - val_loss: 0.7536 - val_sparse_categorical_accuracy: 0.6091\n",
            "Epoch 24/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.6796 - sparse_categorical_accuracy: 0.6820 - val_loss: 0.7471 - val_sparse_categorical_accuracy: 0.6182\n",
            "Epoch 25/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.6736 - sparse_categorical_accuracy: 0.6922 - val_loss: 0.7400 - val_sparse_categorical_accuracy: 0.6182\n",
            "Epoch 26/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.6674 - sparse_categorical_accuracy: 0.6911 - val_loss: 0.7357 - val_sparse_categorical_accuracy: 0.6273\n",
            "Epoch 27/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.6615 - sparse_categorical_accuracy: 0.6911 - val_loss: 0.7283 - val_sparse_categorical_accuracy: 0.6364\n",
            "Epoch 28/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.6565 - sparse_categorical_accuracy: 0.6962 - val_loss: 0.7240 - val_sparse_categorical_accuracy: 0.6364\n",
            "Epoch 29/100\n",
            "981/981 [==============================] - 0s 113us/sample - loss: 0.6512 - sparse_categorical_accuracy: 0.6993 - val_loss: 0.7231 - val_sparse_categorical_accuracy: 0.6091\n",
            "Epoch 30/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.6466 - sparse_categorical_accuracy: 0.6962 - val_loss: 0.7191 - val_sparse_categorical_accuracy: 0.6182\n",
            "Epoch 31/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.6420 - sparse_categorical_accuracy: 0.7054 - val_loss: 0.7146 - val_sparse_categorical_accuracy: 0.6182\n",
            "Epoch 32/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.6385 - sparse_categorical_accuracy: 0.7074 - val_loss: 0.7068 - val_sparse_categorical_accuracy: 0.6455\n",
            "Epoch 33/100\n",
            "981/981 [==============================] - 0s 139us/sample - loss: 0.6336 - sparse_categorical_accuracy: 0.7054 - val_loss: 0.7025 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 34/100\n",
            "981/981 [==============================] - 0s 127us/sample - loss: 0.6298 - sparse_categorical_accuracy: 0.7085 - val_loss: 0.7017 - val_sparse_categorical_accuracy: 0.6364\n",
            "Epoch 35/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.6252 - sparse_categorical_accuracy: 0.7125 - val_loss: 0.6945 - val_sparse_categorical_accuracy: 0.6455\n",
            "Epoch 36/100\n",
            "981/981 [==============================] - 0s 123us/sample - loss: 0.6219 - sparse_categorical_accuracy: 0.7125 - val_loss: 0.6909 - val_sparse_categorical_accuracy: 0.6455\n",
            "Epoch 37/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.6186 - sparse_categorical_accuracy: 0.7125 - val_loss: 0.6893 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 38/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.6150 - sparse_categorical_accuracy: 0.7146 - val_loss: 0.6854 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 39/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.6114 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.6832 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 40/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.6083 - sparse_categorical_accuracy: 0.7197 - val_loss: 0.6807 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 41/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.6053 - sparse_categorical_accuracy: 0.7248 - val_loss: 0.6777 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 42/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.6024 - sparse_categorical_accuracy: 0.7227 - val_loss: 0.6775 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 43/100\n",
            "981/981 [==============================] - 0s 140us/sample - loss: 0.5991 - sparse_categorical_accuracy: 0.7299 - val_loss: 0.6709 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 44/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.5965 - sparse_categorical_accuracy: 0.7278 - val_loss: 0.6684 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 45/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5941 - sparse_categorical_accuracy: 0.7227 - val_loss: 0.6668 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 46/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.5919 - sparse_categorical_accuracy: 0.7299 - val_loss: 0.6638 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 47/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.5888 - sparse_categorical_accuracy: 0.7258 - val_loss: 0.6622 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 48/100\n",
            "981/981 [==============================] - 0s 125us/sample - loss: 0.5870 - sparse_categorical_accuracy: 0.7319 - val_loss: 0.6586 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 49/100\n",
            "981/981 [==============================] - 0s 134us/sample - loss: 0.5843 - sparse_categorical_accuracy: 0.7319 - val_loss: 0.6564 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 50/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.5817 - sparse_categorical_accuracy: 0.7309 - val_loss: 0.6539 - val_sparse_categorical_accuracy: 0.6455\n",
            "Epoch 51/100\n",
            "981/981 [==============================] - 0s 146us/sample - loss: 0.5794 - sparse_categorical_accuracy: 0.7350 - val_loss: 0.6560 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 52/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5775 - sparse_categorical_accuracy: 0.7329 - val_loss: 0.6520 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 53/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.5759 - sparse_categorical_accuracy: 0.7339 - val_loss: 0.6487 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 54/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.5737 - sparse_categorical_accuracy: 0.7329 - val_loss: 0.6467 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 55/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.5717 - sparse_categorical_accuracy: 0.7431 - val_loss: 0.6455 - val_sparse_categorical_accuracy: 0.6455\n",
            "Epoch 56/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.5696 - sparse_categorical_accuracy: 0.7390 - val_loss: 0.6432 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 57/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.5681 - sparse_categorical_accuracy: 0.7431 - val_loss: 0.6434 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 58/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.5658 - sparse_categorical_accuracy: 0.7421 - val_loss: 0.6401 - val_sparse_categorical_accuracy: 0.6455\n",
            "Epoch 59/100\n",
            "981/981 [==============================] - 0s 145us/sample - loss: 0.5643 - sparse_categorical_accuracy: 0.7411 - val_loss: 0.6397 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 60/100\n",
            "981/981 [==============================] - 0s 126us/sample - loss: 0.5625 - sparse_categorical_accuracy: 0.7441 - val_loss: 0.6391 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 61/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.5611 - sparse_categorical_accuracy: 0.7431 - val_loss: 0.6361 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 62/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.5597 - sparse_categorical_accuracy: 0.7411 - val_loss: 0.6341 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 63/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5580 - sparse_categorical_accuracy: 0.7452 - val_loss: 0.6332 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 64/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.5562 - sparse_categorical_accuracy: 0.7523 - val_loss: 0.6319 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 65/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.5549 - sparse_categorical_accuracy: 0.7462 - val_loss: 0.6321 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 66/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.5535 - sparse_categorical_accuracy: 0.7513 - val_loss: 0.6306 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 67/100\n",
            "981/981 [==============================] - 0s 137us/sample - loss: 0.5521 - sparse_categorical_accuracy: 0.7472 - val_loss: 0.6281 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 68/100\n",
            "981/981 [==============================] - 0s 129us/sample - loss: 0.5505 - sparse_categorical_accuracy: 0.7492 - val_loss: 0.6280 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 69/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.5494 - sparse_categorical_accuracy: 0.7523 - val_loss: 0.6260 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 70/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5478 - sparse_categorical_accuracy: 0.7523 - val_loss: 0.6265 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 71/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5464 - sparse_categorical_accuracy: 0.7472 - val_loss: 0.6245 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 72/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5460 - sparse_categorical_accuracy: 0.7503 - val_loss: 0.6221 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 73/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5441 - sparse_categorical_accuracy: 0.7543 - val_loss: 0.6219 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 74/100\n",
            "981/981 [==============================] - 0s 122us/sample - loss: 0.5429 - sparse_categorical_accuracy: 0.7513 - val_loss: 0.6206 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 75/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5417 - sparse_categorical_accuracy: 0.7554 - val_loss: 0.6202 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 76/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.5407 - sparse_categorical_accuracy: 0.7564 - val_loss: 0.6184 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 77/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.5394 - sparse_categorical_accuracy: 0.7543 - val_loss: 0.6161 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 78/100\n",
            "981/981 [==============================] - 0s 115us/sample - loss: 0.5385 - sparse_categorical_accuracy: 0.7574 - val_loss: 0.6146 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 79/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5374 - sparse_categorical_accuracy: 0.7533 - val_loss: 0.6151 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 80/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5361 - sparse_categorical_accuracy: 0.7564 - val_loss: 0.6158 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 81/100\n",
            "981/981 [==============================] - 0s 120us/sample - loss: 0.5354 - sparse_categorical_accuracy: 0.7584 - val_loss: 0.6142 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 82/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5341 - sparse_categorical_accuracy: 0.7584 - val_loss: 0.6127 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 83/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.5329 - sparse_categorical_accuracy: 0.7554 - val_loss: 0.6131 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 84/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5321 - sparse_categorical_accuracy: 0.7615 - val_loss: 0.6108 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 85/100\n",
            "981/981 [==============================] - 0s 131us/sample - loss: 0.5312 - sparse_categorical_accuracy: 0.7574 - val_loss: 0.6115 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 86/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.5301 - sparse_categorical_accuracy: 0.7604 - val_loss: 0.6097 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 87/100\n",
            "981/981 [==============================] - 0s 117us/sample - loss: 0.5296 - sparse_categorical_accuracy: 0.7604 - val_loss: 0.6094 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 88/100\n",
            "981/981 [==============================] - 0s 113us/sample - loss: 0.5283 - sparse_categorical_accuracy: 0.7635 - val_loss: 0.6095 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 89/100\n",
            "981/981 [==============================] - 0s 118us/sample - loss: 0.5272 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.6089 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 90/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5265 - sparse_categorical_accuracy: 0.7604 - val_loss: 0.6086 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 91/100\n",
            "981/981 [==============================] - 0s 119us/sample - loss: 0.5258 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.6086 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 92/100\n",
            "981/981 [==============================] - 0s 113us/sample - loss: 0.5251 - sparse_categorical_accuracy: 0.7635 - val_loss: 0.6065 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 93/100\n",
            "981/981 [==============================] - 0s 133us/sample - loss: 0.5243 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.6074 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 94/100\n",
            "981/981 [==============================] - 0s 114us/sample - loss: 0.5233 - sparse_categorical_accuracy: 0.7604 - val_loss: 0.6052 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 95/100\n",
            "981/981 [==============================] - 0s 124us/sample - loss: 0.5223 - sparse_categorical_accuracy: 0.7604 - val_loss: 0.6038 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 96/100\n",
            "981/981 [==============================] - 0s 112us/sample - loss: 0.5219 - sparse_categorical_accuracy: 0.7615 - val_loss: 0.6040 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 97/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5208 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.6044 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 98/100\n",
            "981/981 [==============================] - 0s 116us/sample - loss: 0.5204 - sparse_categorical_accuracy: 0.7666 - val_loss: 0.6029 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 99/100\n",
            "981/981 [==============================] - 0s 132us/sample - loss: 0.5200 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.6037 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 100/100\n",
            "981/981 [==============================] - 0s 121us/sample - loss: 0.5186 - sparse_categorical_accuracy: 0.7686 - val_loss: 0.6011 - val_sparse_categorical_accuracy: 0.7091\n",
            "[CV] ......................... n_neurons=42, n_hidden=0, total=  12.7s\n",
            "Train on 1226 samples, validate on 137 samples\n",
            "Epoch 1/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  7.6min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1226/1226 [==============================] - 1s 538us/sample - loss: 1.0601 - sparse_categorical_accuracy: 0.4633 - val_loss: 0.9302 - val_sparse_categorical_accuracy: 0.5328\n",
            "Epoch 2/100\n",
            "1226/1226 [==============================] - 0s 143us/sample - loss: 0.8638 - sparse_categorical_accuracy: 0.5514 - val_loss: 0.8287 - val_sparse_categorical_accuracy: 0.6131\n",
            "Epoch 3/100\n",
            "1226/1226 [==============================] - 0s 148us/sample - loss: 0.7813 - sparse_categorical_accuracy: 0.6101 - val_loss: 0.7825 - val_sparse_categorical_accuracy: 0.6277\n",
            "Epoch 4/100\n",
            "1226/1226 [==============================] - 0s 133us/sample - loss: 0.7267 - sparse_categorical_accuracy: 0.6378 - val_loss: 0.7239 - val_sparse_categorical_accuracy: 0.6715\n",
            "Epoch 5/100\n",
            "1226/1226 [==============================] - 0s 130us/sample - loss: 0.6880 - sparse_categorical_accuracy: 0.6607 - val_loss: 0.6920 - val_sparse_categorical_accuracy: 0.6715\n",
            "Epoch 6/100\n",
            "1226/1226 [==============================] - 0s 138us/sample - loss: 0.6570 - sparse_categorical_accuracy: 0.6803 - val_loss: 0.6860 - val_sparse_categorical_accuracy: 0.6642\n",
            "Epoch 7/100\n",
            "1226/1226 [==============================] - 0s 134us/sample - loss: 0.6342 - sparse_categorical_accuracy: 0.7015 - val_loss: 0.6403 - val_sparse_categorical_accuracy: 0.7153\n",
            "Epoch 8/100\n",
            "1226/1226 [==============================] - 0s 137us/sample - loss: 0.6145 - sparse_categorical_accuracy: 0.7178 - val_loss: 0.6196 - val_sparse_categorical_accuracy: 0.6861\n",
            "Epoch 9/100\n",
            "1226/1226 [==============================] - 0s 143us/sample - loss: 0.5982 - sparse_categorical_accuracy: 0.7268 - val_loss: 0.6025 - val_sparse_categorical_accuracy: 0.7299\n",
            "Epoch 10/100\n",
            "1226/1226 [==============================] - 0s 129us/sample - loss: 0.5799 - sparse_categorical_accuracy: 0.7414 - val_loss: 0.5989 - val_sparse_categorical_accuracy: 0.7372\n",
            "Epoch 11/100\n",
            "1226/1226 [==============================] - 0s 148us/sample - loss: 0.5709 - sparse_categorical_accuracy: 0.7365 - val_loss: 0.5791 - val_sparse_categorical_accuracy: 0.7518\n",
            "Epoch 12/100\n",
            "1226/1226 [==============================] - 0s 136us/sample - loss: 0.5572 - sparse_categorical_accuracy: 0.7390 - val_loss: 0.5807 - val_sparse_categorical_accuracy: 0.7372\n",
            "Epoch 13/100\n",
            "1226/1226 [==============================] - 0s 134us/sample - loss: 0.5504 - sparse_categorical_accuracy: 0.7447 - val_loss: 0.5630 - val_sparse_categorical_accuracy: 0.7372\n",
            "Epoch 14/100\n",
            "1226/1226 [==============================] - 0s 129us/sample - loss: 0.5385 - sparse_categorical_accuracy: 0.7496 - val_loss: 0.5583 - val_sparse_categorical_accuracy: 0.7372\n",
            "Epoch 15/100\n",
            "1226/1226 [==============================] - 0s 142us/sample - loss: 0.5313 - sparse_categorical_accuracy: 0.7569 - val_loss: 0.5665 - val_sparse_categorical_accuracy: 0.7372\n",
            "Epoch 16/100\n",
            "1226/1226 [==============================] - 0s 128us/sample - loss: 0.5271 - sparse_categorical_accuracy: 0.7488 - val_loss: 0.5513 - val_sparse_categorical_accuracy: 0.7372\n",
            "Epoch 17/100\n",
            "1226/1226 [==============================] - 0s 129us/sample - loss: 0.5188 - sparse_categorical_accuracy: 0.7553 - val_loss: 0.5462 - val_sparse_categorical_accuracy: 0.7299\n",
            "Epoch 18/100\n",
            "1226/1226 [==============================] - 0s 138us/sample - loss: 0.5085 - sparse_categorical_accuracy: 0.7667 - val_loss: 0.5444 - val_sparse_categorical_accuracy: 0.7518\n",
            "Epoch 19/100\n",
            "1226/1226 [==============================] - 0s 135us/sample - loss: 0.5076 - sparse_categorical_accuracy: 0.7692 - val_loss: 0.5397 - val_sparse_categorical_accuracy: 0.7591\n",
            "Epoch 20/100\n",
            "1226/1226 [==============================] - 0s 124us/sample - loss: 0.5049 - sparse_categorical_accuracy: 0.7675 - val_loss: 0.5339 - val_sparse_categorical_accuracy: 0.7445\n",
            "Epoch 21/100\n",
            "1226/1226 [==============================] - 0s 148us/sample - loss: 0.4981 - sparse_categorical_accuracy: 0.7716 - val_loss: 0.5359 - val_sparse_categorical_accuracy: 0.7518\n",
            "Epoch 22/100\n",
            "1226/1226 [==============================] - 0s 138us/sample - loss: 0.4951 - sparse_categorical_accuracy: 0.7724 - val_loss: 0.5348 - val_sparse_categorical_accuracy: 0.7445\n",
            "Epoch 23/100\n",
            "1226/1226 [==============================] - 0s 137us/sample - loss: 0.4901 - sparse_categorical_accuracy: 0.7724 - val_loss: 0.5384 - val_sparse_categorical_accuracy: 0.7518\n",
            "Epoch 24/100\n",
            "1226/1226 [==============================] - 0s 139us/sample - loss: 0.4868 - sparse_categorical_accuracy: 0.7781 - val_loss: 0.5352 - val_sparse_categorical_accuracy: 0.7372\n",
            "Epoch 25/100\n",
            "1226/1226 [==============================] - 0s 147us/sample - loss: 0.4839 - sparse_categorical_accuracy: 0.7781 - val_loss: 0.5293 - val_sparse_categorical_accuracy: 0.7445\n",
            "Epoch 26/100\n",
            "1226/1226 [==============================] - 0s 139us/sample - loss: 0.4798 - sparse_categorical_accuracy: 0.7773 - val_loss: 0.5310 - val_sparse_categorical_accuracy: 0.7518\n",
            "Epoch 27/100\n",
            "1226/1226 [==============================] - 0s 139us/sample - loss: 0.4770 - sparse_categorical_accuracy: 0.7855 - val_loss: 0.5455 - val_sparse_categorical_accuracy: 0.7372\n",
            "Epoch 28/100\n",
            "1226/1226 [==============================] - 0s 131us/sample - loss: 0.4773 - sparse_categorical_accuracy: 0.7830 - val_loss: 0.5309 - val_sparse_categorical_accuracy: 0.7445\n",
            "Epoch 29/100\n",
            "1226/1226 [==============================] - 0s 132us/sample - loss: 0.4730 - sparse_categorical_accuracy: 0.7798 - val_loss: 0.5290 - val_sparse_categorical_accuracy: 0.7445\n",
            "Epoch 30/100\n",
            "1226/1226 [==============================] - 0s 140us/sample - loss: 0.4706 - sparse_categorical_accuracy: 0.7928 - val_loss: 0.5287 - val_sparse_categorical_accuracy: 0.7445\n",
            "Epoch 31/100\n",
            "1226/1226 [==============================] - 0s 137us/sample - loss: 0.4664 - sparse_categorical_accuracy: 0.7765 - val_loss: 0.5301 - val_sparse_categorical_accuracy: 0.7372\n",
            "Epoch 32/100\n",
            "1226/1226 [==============================] - 0s 128us/sample - loss: 0.4633 - sparse_categorical_accuracy: 0.7961 - val_loss: 0.5289 - val_sparse_categorical_accuracy: 0.7372\n",
            "Epoch 33/100\n",
            "1226/1226 [==============================] - 0s 148us/sample - loss: 0.4629 - sparse_categorical_accuracy: 0.7830 - val_loss: 0.5443 - val_sparse_categorical_accuracy: 0.7518\n",
            "Epoch 34/100\n",
            "1226/1226 [==============================] - 0s 133us/sample - loss: 0.4597 - sparse_categorical_accuracy: 0.7912 - val_loss: 0.5277 - val_sparse_categorical_accuracy: 0.7299\n",
            "Epoch 35/100\n",
            "1226/1226 [==============================] - 0s 132us/sample - loss: 0.4579 - sparse_categorical_accuracy: 0.7904 - val_loss: 0.5320 - val_sparse_categorical_accuracy: 0.7445\n",
            "Epoch 36/100\n",
            "1226/1226 [==============================] - 0s 130us/sample - loss: 0.4563 - sparse_categorical_accuracy: 0.7912 - val_loss: 0.5323 - val_sparse_categorical_accuracy: 0.7226\n",
            "Epoch 37/100\n",
            "1226/1226 [==============================] - 0s 136us/sample - loss: 0.4546 - sparse_categorical_accuracy: 0.7904 - val_loss: 0.5321 - val_sparse_categorical_accuracy: 0.7226\n",
            "Epoch 38/100\n",
            "1226/1226 [==============================] - 0s 135us/sample - loss: 0.4527 - sparse_categorical_accuracy: 0.7936 - val_loss: 0.5346 - val_sparse_categorical_accuracy: 0.7226\n",
            "Epoch 39/100\n",
            "1226/1226 [==============================] - 0s 149us/sample - loss: 0.4494 - sparse_categorical_accuracy: 0.7945 - val_loss: 0.5418 - val_sparse_categorical_accuracy: 0.7372\n",
            "Epoch 40/100\n",
            "1226/1226 [==============================] - 0s 131us/sample - loss: 0.4489 - sparse_categorical_accuracy: 0.7977 - val_loss: 0.5395 - val_sparse_categorical_accuracy: 0.7226\n",
            "Epoch 41/100\n",
            "1226/1226 [==============================] - 0s 131us/sample - loss: 0.4465 - sparse_categorical_accuracy: 0.8026 - val_loss: 0.5426 - val_sparse_categorical_accuracy: 0.7591\n",
            "Epoch 42/100\n",
            "1226/1226 [==============================] - 0s 128us/sample - loss: 0.4469 - sparse_categorical_accuracy: 0.8002 - val_loss: 0.5391 - val_sparse_categorical_accuracy: 0.7445\n",
            "Epoch 43/100\n",
            "1226/1226 [==============================] - 0s 130us/sample - loss: 0.4442 - sparse_categorical_accuracy: 0.7977 - val_loss: 0.5381 - val_sparse_categorical_accuracy: 0.7372\n",
            "Epoch 44/100\n",
            "1226/1226 [==============================] - 0s 129us/sample - loss: 0.4416 - sparse_categorical_accuracy: 0.7993 - val_loss: 0.5391 - val_sparse_categorical_accuracy: 0.7372\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=False),\n",
              "                   error_score='raise-deprecating',\n",
              "                   estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7faacc9157f0>,\n",
              "                   iid='warn', n_iter=10, n_jobs=None,\n",
              "                   param_distributions={'n_hidden': [0, 1, 2, 3, 4, 5],\n",
              "                                        'n_neurons': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
              "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
              "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
              "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
              "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
              "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])},\n",
              "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "                   return_train_score=False, scoring='accuracy', verbose=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 298
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGk_Asv86Co_",
        "colab_type": "code",
        "outputId": "b45e1288-fdc9-4914-9d2c-352dc5061b90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        }
      },
      "source": [
        "print('best parameter :',rnd_search_clf.best_params_)\n",
        "print('best score(accuracy) :',rnd_search_clf.best_score_)\n",
        "print('best estimator :',rnd_search_clf.best_estimator_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best parameter : {'n_neurons': 45, 'n_hidden': 2}\n",
            "best score(accuracy) : 0.719002201027146\n",
            "best estimator : <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7faabfbb9d68>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "802fEjop6Lq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hidden_num = rnd_search_clf.best_params_['n_hidden']\n",
        "neurons_num =  rnd_search_clf.best_params_['n_neurons']\n",
        "\n",
        "def build_model_clf(n_hidden=hidden_num, n_neurons=neurons_num, input_shape=[73]):\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
        "    for layer in range(n_hidden):\n",
        "        model.add(keras.layers.Dense(n_neurons, activation=\"selu\"))\n",
        "    model.add(keras.layers.Dense(3,activation= \"softmax\"))\n",
        "\n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\", \n",
        "                  optimizer=\"sgd\",\n",
        "                  metrics=['sparse_categorical_accuracy'])\n",
        "    return model\n",
        "\n",
        "model_clf = keras.wrappers.scikit_learn.KerasClassifier(build_fn=build_model_clf,\n",
        "                                                      epochs=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4IQM9UT8oQN",
        "colab_type": "code",
        "outputId": "7249c07a-c0a4-44d5-af65-d0afbb72e5ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "kfold = KFold(n_splits=5, random_state=42)\n",
        "scores = cross_val_score(model_clf,X_plus,y_cls.values.T[0],\n",
        "                         scoring=\"accuracy\",\n",
        "                         cv=kfold)\n",
        "print('keras_reg validation score(accuracy) :', scores.mean())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1090 samples\n",
            "Epoch 1/100\n",
            "1090/1090 [==============================] - 1s 465us/sample - loss: 1.1951 - sparse_categorical_accuracy: 0.4367\n",
            "Epoch 2/100\n",
            "1090/1090 [==============================] - 0s 128us/sample - loss: 0.9360 - sparse_categorical_accuracy: 0.5257\n",
            "Epoch 3/100\n",
            "1090/1090 [==============================] - 0s 120us/sample - loss: 0.8350 - sparse_categorical_accuracy: 0.5661\n",
            "Epoch 4/100\n",
            "1090/1090 [==============================] - 0s 113us/sample - loss: 0.7744 - sparse_categorical_accuracy: 0.6064\n",
            "Epoch 5/100\n",
            "1090/1090 [==============================] - 0s 124us/sample - loss: 0.7305 - sparse_categorical_accuracy: 0.6330\n",
            "Epoch 6/100\n",
            "1090/1090 [==============================] - 0s 122us/sample - loss: 0.6938 - sparse_categorical_accuracy: 0.6532\n",
            "Epoch 7/100\n",
            "1090/1090 [==============================] - 0s 118us/sample - loss: 0.6640 - sparse_categorical_accuracy: 0.6890\n",
            "Epoch 8/100\n",
            "1090/1090 [==============================] - 0s 118us/sample - loss: 0.6402 - sparse_categorical_accuracy: 0.6853\n",
            "Epoch 9/100\n",
            "1090/1090 [==============================] - 0s 129us/sample - loss: 0.6200 - sparse_categorical_accuracy: 0.6963\n",
            "Epoch 10/100\n",
            "1090/1090 [==============================] - 0s 124us/sample - loss: 0.6020 - sparse_categorical_accuracy: 0.7083\n",
            "Epoch 11/100\n",
            "1090/1090 [==============================] - 0s 119us/sample - loss: 0.5878 - sparse_categorical_accuracy: 0.7156\n",
            "Epoch 12/100\n",
            "1090/1090 [==============================] - 0s 119us/sample - loss: 0.5732 - sparse_categorical_accuracy: 0.7284\n",
            "Epoch 13/100\n",
            "1090/1090 [==============================] - 0s 121us/sample - loss: 0.5641 - sparse_categorical_accuracy: 0.7358\n",
            "Epoch 14/100\n",
            "1090/1090 [==============================] - 0s 114us/sample - loss: 0.5531 - sparse_categorical_accuracy: 0.7578\n",
            "Epoch 15/100\n",
            "1090/1090 [==============================] - 0s 116us/sample - loss: 0.5429 - sparse_categorical_accuracy: 0.7468\n",
            "Epoch 16/100\n",
            "1090/1090 [==============================] - 0s 129us/sample - loss: 0.5340 - sparse_categorical_accuracy: 0.7541\n",
            "Epoch 17/100\n",
            "1090/1090 [==============================] - 0s 124us/sample - loss: 0.5300 - sparse_categorical_accuracy: 0.7532\n",
            "Epoch 18/100\n",
            "1090/1090 [==============================] - 0s 117us/sample - loss: 0.5205 - sparse_categorical_accuracy: 0.7532\n",
            "Epoch 19/100\n",
            "1090/1090 [==============================] - 0s 111us/sample - loss: 0.5188 - sparse_categorical_accuracy: 0.7587\n",
            "Epoch 20/100\n",
            "1090/1090 [==============================] - 0s 116us/sample - loss: 0.5081 - sparse_categorical_accuracy: 0.7596\n",
            "Epoch 21/100\n",
            "1090/1090 [==============================] - 0s 125us/sample - loss: 0.5009 - sparse_categorical_accuracy: 0.7633\n",
            "Epoch 22/100\n",
            "1090/1090 [==============================] - 0s 116us/sample - loss: 0.4984 - sparse_categorical_accuracy: 0.7725\n",
            "Epoch 23/100\n",
            "1090/1090 [==============================] - 0s 122us/sample - loss: 0.4929 - sparse_categorical_accuracy: 0.7661\n",
            "Epoch 24/100\n",
            "1090/1090 [==============================] - 0s 111us/sample - loss: 0.4892 - sparse_categorical_accuracy: 0.7716\n",
            "Epoch 25/100\n",
            "1090/1090 [==============================] - 0s 126us/sample - loss: 0.4849 - sparse_categorical_accuracy: 0.7780\n",
            "Epoch 26/100\n",
            "1090/1090 [==============================] - 0s 111us/sample - loss: 0.4810 - sparse_categorical_accuracy: 0.7743\n",
            "Epoch 27/100\n",
            "1090/1090 [==============================] - 0s 124us/sample - loss: 0.4754 - sparse_categorical_accuracy: 0.7826\n",
            "Epoch 28/100\n",
            "1090/1090 [==============================] - 0s 114us/sample - loss: 0.4810 - sparse_categorical_accuracy: 0.7752\n",
            "Epoch 29/100\n",
            "1090/1090 [==============================] - 0s 116us/sample - loss: 0.4737 - sparse_categorical_accuracy: 0.7743\n",
            "Epoch 30/100\n",
            "1090/1090 [==============================] - 0s 115us/sample - loss: 0.4699 - sparse_categorical_accuracy: 0.7890\n",
            "Epoch 31/100\n",
            "1090/1090 [==============================] - 0s 110us/sample - loss: 0.4650 - sparse_categorical_accuracy: 0.7844\n",
            "Epoch 32/100\n",
            "1090/1090 [==============================] - 0s 114us/sample - loss: 0.4604 - sparse_categorical_accuracy: 0.7872\n",
            "Epoch 33/100\n",
            "1090/1090 [==============================] - 0s 122us/sample - loss: 0.4639 - sparse_categorical_accuracy: 0.7890\n",
            "Epoch 34/100\n",
            "1090/1090 [==============================] - 0s 117us/sample - loss: 0.4587 - sparse_categorical_accuracy: 0.7798\n",
            "Epoch 35/100\n",
            "1090/1090 [==============================] - 0s 112us/sample - loss: 0.4541 - sparse_categorical_accuracy: 0.7826\n",
            "Epoch 36/100\n",
            "1090/1090 [==============================] - 0s 118us/sample - loss: 0.4501 - sparse_categorical_accuracy: 0.7862\n",
            "Epoch 37/100\n",
            "1090/1090 [==============================] - 0s 141us/sample - loss: 0.4475 - sparse_categorical_accuracy: 0.7890\n",
            "Epoch 38/100\n",
            "1090/1090 [==============================] - 0s 127us/sample - loss: 0.4532 - sparse_categorical_accuracy: 0.7826\n",
            "Epoch 39/100\n",
            "1090/1090 [==============================] - 0s 118us/sample - loss: 0.4521 - sparse_categorical_accuracy: 0.7917\n",
            "Epoch 40/100\n",
            "1090/1090 [==============================] - 0s 109us/sample - loss: 0.4509 - sparse_categorical_accuracy: 0.7908\n",
            "Epoch 41/100\n",
            "1090/1090 [==============================] - 0s 132us/sample - loss: 0.4406 - sparse_categorical_accuracy: 0.8009\n",
            "Epoch 42/100\n",
            "1090/1090 [==============================] - 0s 110us/sample - loss: 0.4403 - sparse_categorical_accuracy: 0.7945\n",
            "Epoch 43/100\n",
            "1090/1090 [==============================] - 0s 110us/sample - loss: 0.4394 - sparse_categorical_accuracy: 0.7963\n",
            "Epoch 44/100\n",
            "1090/1090 [==============================] - 0s 113us/sample - loss: 0.4390 - sparse_categorical_accuracy: 0.7936\n",
            "Epoch 45/100\n",
            "1090/1090 [==============================] - 0s 114us/sample - loss: 0.4364 - sparse_categorical_accuracy: 0.7982\n",
            "Epoch 46/100\n",
            "1090/1090 [==============================] - 0s 124us/sample - loss: 0.4349 - sparse_categorical_accuracy: 0.8037\n",
            "Epoch 47/100\n",
            "1090/1090 [==============================] - 0s 113us/sample - loss: 0.4322 - sparse_categorical_accuracy: 0.8037\n",
            "Epoch 48/100\n",
            "1090/1090 [==============================] - 0s 115us/sample - loss: 0.4282 - sparse_categorical_accuracy: 0.8037\n",
            "Epoch 49/100\n",
            "1090/1090 [==============================] - 0s 125us/sample - loss: 0.4279 - sparse_categorical_accuracy: 0.8046\n",
            "Epoch 50/100\n",
            "1090/1090 [==============================] - 0s 113us/sample - loss: 0.4234 - sparse_categorical_accuracy: 0.8119\n",
            "Epoch 51/100\n",
            "1090/1090 [==============================] - 0s 114us/sample - loss: 0.4251 - sparse_categorical_accuracy: 0.8119\n",
            "Epoch 52/100\n",
            "1090/1090 [==============================] - 0s 120us/sample - loss: 0.4208 - sparse_categorical_accuracy: 0.8037\n",
            "Epoch 53/100\n",
            "1090/1090 [==============================] - 0s 116us/sample - loss: 0.4185 - sparse_categorical_accuracy: 0.7991\n",
            "Epoch 54/100\n",
            "1090/1090 [==============================] - 0s 124us/sample - loss: 0.4191 - sparse_categorical_accuracy: 0.8018\n",
            "Epoch 55/100\n",
            "1090/1090 [==============================] - 0s 110us/sample - loss: 0.4170 - sparse_categorical_accuracy: 0.8101\n",
            "Epoch 56/100\n",
            "1090/1090 [==============================] - 0s 120us/sample - loss: 0.4205 - sparse_categorical_accuracy: 0.8119\n",
            "Epoch 57/100\n",
            "1090/1090 [==============================] - 0s 125us/sample - loss: 0.4165 - sparse_categorical_accuracy: 0.8092\n",
            "Epoch 58/100\n",
            "1090/1090 [==============================] - 0s 113us/sample - loss: 0.4152 - sparse_categorical_accuracy: 0.8128\n",
            "Epoch 59/100\n",
            "1090/1090 [==============================] - 0s 115us/sample - loss: 0.4105 - sparse_categorical_accuracy: 0.8138\n",
            "Epoch 60/100\n",
            "1090/1090 [==============================] - 0s 115us/sample - loss: 0.4113 - sparse_categorical_accuracy: 0.8128\n",
            "Epoch 61/100\n",
            "1090/1090 [==============================] - 0s 118us/sample - loss: 0.4076 - sparse_categorical_accuracy: 0.8119\n",
            "Epoch 62/100\n",
            "1090/1090 [==============================] - 0s 125us/sample - loss: 0.4077 - sparse_categorical_accuracy: 0.8138\n",
            "Epoch 63/100\n",
            "1090/1090 [==============================] - 0s 113us/sample - loss: 0.4156 - sparse_categorical_accuracy: 0.8165\n",
            "Epoch 64/100\n",
            "1090/1090 [==============================] - 0s 114us/sample - loss: 0.4058 - sparse_categorical_accuracy: 0.8073\n",
            "Epoch 65/100\n",
            "1090/1090 [==============================] - 0s 125us/sample - loss: 0.4017 - sparse_categorical_accuracy: 0.8202\n",
            "Epoch 66/100\n",
            "1090/1090 [==============================] - 0s 117us/sample - loss: 0.4003 - sparse_categorical_accuracy: 0.8229\n",
            "Epoch 67/100\n",
            "1090/1090 [==============================] - 0s 113us/sample - loss: 0.4017 - sparse_categorical_accuracy: 0.8220\n",
            "Epoch 68/100\n",
            "1090/1090 [==============================] - 0s 124us/sample - loss: 0.4076 - sparse_categorical_accuracy: 0.8156\n",
            "Epoch 69/100\n",
            "1090/1090 [==============================] - 0s 109us/sample - loss: 0.4038 - sparse_categorical_accuracy: 0.8202\n",
            "Epoch 70/100\n",
            "1090/1090 [==============================] - 0s 121us/sample - loss: 0.4026 - sparse_categorical_accuracy: 0.8220\n",
            "Epoch 71/100\n",
            "1090/1090 [==============================] - 0s 116us/sample - loss: 0.3990 - sparse_categorical_accuracy: 0.8174\n",
            "Epoch 72/100\n",
            "1090/1090 [==============================] - 0s 112us/sample - loss: 0.3928 - sparse_categorical_accuracy: 0.8202\n",
            "Epoch 73/100\n",
            "1090/1090 [==============================] - 0s 125us/sample - loss: 0.3913 - sparse_categorical_accuracy: 0.8165\n",
            "Epoch 74/100\n",
            "1090/1090 [==============================] - 0s 121us/sample - loss: 0.3892 - sparse_categorical_accuracy: 0.8284\n",
            "Epoch 75/100\n",
            "1090/1090 [==============================] - 0s 109us/sample - loss: 0.3876 - sparse_categorical_accuracy: 0.8257\n",
            "Epoch 76/100\n",
            "1090/1090 [==============================] - 0s 126us/sample - loss: 0.3873 - sparse_categorical_accuracy: 0.8266\n",
            "Epoch 77/100\n",
            "1090/1090 [==============================] - 0s 114us/sample - loss: 0.3882 - sparse_categorical_accuracy: 0.8303\n",
            "Epoch 78/100\n",
            "1090/1090 [==============================] - 0s 134us/sample - loss: 0.3849 - sparse_categorical_accuracy: 0.8229\n",
            "Epoch 79/100\n",
            "1090/1090 [==============================] - 0s 128us/sample - loss: 0.3877 - sparse_categorical_accuracy: 0.8330\n",
            "Epoch 80/100\n",
            "1090/1090 [==============================] - 0s 140us/sample - loss: 0.3833 - sparse_categorical_accuracy: 0.8349\n",
            "Epoch 81/100\n",
            "1090/1090 [==============================] - 0s 128us/sample - loss: 0.3805 - sparse_categorical_accuracy: 0.8284\n",
            "Epoch 82/100\n",
            "1090/1090 [==============================] - 0s 118us/sample - loss: 0.3849 - sparse_categorical_accuracy: 0.8275\n",
            "Epoch 83/100\n",
            "1090/1090 [==============================] - 0s 113us/sample - loss: 0.3821 - sparse_categorical_accuracy: 0.8275\n",
            "Epoch 84/100\n",
            "1090/1090 [==============================] - 0s 117us/sample - loss: 0.3772 - sparse_categorical_accuracy: 0.8385\n",
            "Epoch 85/100\n",
            "1090/1090 [==============================] - 0s 115us/sample - loss: 0.3749 - sparse_categorical_accuracy: 0.8312\n",
            "Epoch 86/100\n",
            "1090/1090 [==============================] - 0s 119us/sample - loss: 0.3799 - sparse_categorical_accuracy: 0.8284\n",
            "Epoch 87/100\n",
            "1090/1090 [==============================] - 0s 113us/sample - loss: 0.3733 - sparse_categorical_accuracy: 0.8339\n",
            "Epoch 88/100\n",
            "1090/1090 [==============================] - 0s 121us/sample - loss: 0.3754 - sparse_categorical_accuracy: 0.8266\n",
            "Epoch 89/100\n",
            "1090/1090 [==============================] - 0s 121us/sample - loss: 0.3762 - sparse_categorical_accuracy: 0.8294\n",
            "Epoch 90/100\n",
            "1090/1090 [==============================] - 0s 125us/sample - loss: 0.3829 - sparse_categorical_accuracy: 0.8367\n",
            "Epoch 91/100\n",
            "1090/1090 [==============================] - 0s 119us/sample - loss: 0.3706 - sparse_categorical_accuracy: 0.8367\n",
            "Epoch 92/100\n",
            "1090/1090 [==============================] - 0s 116us/sample - loss: 0.3700 - sparse_categorical_accuracy: 0.8367\n",
            "Epoch 93/100\n",
            "1090/1090 [==============================] - 0s 118us/sample - loss: 0.3661 - sparse_categorical_accuracy: 0.8394\n",
            "Epoch 94/100\n",
            "1090/1090 [==============================] - 0s 123us/sample - loss: 0.3756 - sparse_categorical_accuracy: 0.8294\n",
            "Epoch 95/100\n",
            "1090/1090 [==============================] - 0s 125us/sample - loss: 0.3666 - sparse_categorical_accuracy: 0.8321\n",
            "Epoch 96/100\n",
            "1090/1090 [==============================] - 0s 137us/sample - loss: 0.3572 - sparse_categorical_accuracy: 0.8422\n",
            "Epoch 97/100\n",
            "1090/1090 [==============================] - 0s 123us/sample - loss: 0.3551 - sparse_categorical_accuracy: 0.8385\n",
            "Epoch 98/100\n",
            "1090/1090 [==============================] - 0s 117us/sample - loss: 0.3590 - sparse_categorical_accuracy: 0.8385\n",
            "Epoch 99/100\n",
            "1090/1090 [==============================] - 0s 119us/sample - loss: 0.3573 - sparse_categorical_accuracy: 0.8385\n",
            "Epoch 100/100\n",
            "1090/1090 [==============================] - 0s 111us/sample - loss: 0.3603 - sparse_categorical_accuracy: 0.8477\n",
            "Train on 1090 samples\n",
            "Epoch 1/100\n",
            "1090/1090 [==============================] - 1s 488us/sample - loss: 1.0830 - sparse_categorical_accuracy: 0.4330\n",
            "Epoch 2/100\n",
            "1090/1090 [==============================] - 0s 118us/sample - loss: 0.8738 - sparse_categorical_accuracy: 0.5523\n",
            "Epoch 3/100\n",
            "1090/1090 [==============================] - 0s 113us/sample - loss: 0.7810 - sparse_categorical_accuracy: 0.6119\n",
            "Epoch 4/100\n",
            "1090/1090 [==============================] - 0s 113us/sample - loss: 0.7228 - sparse_categorical_accuracy: 0.6550\n",
            "Epoch 5/100\n",
            "1090/1090 [==============================] - 0s 130us/sample - loss: 0.6832 - sparse_categorical_accuracy: 0.6771\n",
            "Epoch 6/100\n",
            "1090/1090 [==============================] - 0s 128us/sample - loss: 0.6498 - sparse_categorical_accuracy: 0.6936\n",
            "Epoch 7/100\n",
            "1090/1090 [==============================] - 0s 124us/sample - loss: 0.6213 - sparse_categorical_accuracy: 0.7156\n",
            "Epoch 8/100\n",
            "1090/1090 [==============================] - 0s 116us/sample - loss: 0.6017 - sparse_categorical_accuracy: 0.7248\n",
            "Epoch 9/100\n",
            "1090/1090 [==============================] - 0s 112us/sample - loss: 0.5816 - sparse_categorical_accuracy: 0.7284\n",
            "Epoch 10/100\n",
            "1090/1090 [==============================] - 0s 108us/sample - loss: 0.5682 - sparse_categorical_accuracy: 0.7321\n",
            "Epoch 11/100\n",
            "1090/1090 [==============================] - 0s 111us/sample - loss: 0.5560 - sparse_categorical_accuracy: 0.7440\n",
            "Epoch 12/100\n",
            "1090/1090 [==============================] - 0s 112us/sample - loss: 0.5453 - sparse_categorical_accuracy: 0.7569\n",
            "Epoch 13/100\n",
            "1090/1090 [==============================] - 0s 122us/sample - loss: 0.5376 - sparse_categorical_accuracy: 0.7431\n",
            "Epoch 14/100\n",
            "1090/1090 [==============================] - 0s 139us/sample - loss: 0.5250 - sparse_categorical_accuracy: 0.7670\n",
            "Epoch 15/100\n",
            "1090/1090 [==============================] - 0s 111us/sample - loss: 0.5194 - sparse_categorical_accuracy: 0.7651\n",
            "Epoch 16/100\n",
            "1090/1090 [==============================] - 0s 114us/sample - loss: 0.5098 - sparse_categorical_accuracy: 0.7679\n",
            "Epoch 17/100\n",
            "1090/1090 [==============================] - 0s 127us/sample - loss: 0.5026 - sparse_categorical_accuracy: 0.7798\n",
            "Epoch 18/100\n",
            "1090/1090 [==============================] - 0s 132us/sample - loss: 0.4994 - sparse_categorical_accuracy: 0.7725\n",
            "Epoch 19/100\n",
            "1090/1090 [==============================] - 0s 113us/sample - loss: 0.4957 - sparse_categorical_accuracy: 0.7826\n",
            "Epoch 20/100\n",
            "1090/1090 [==============================] - 0s 117us/sample - loss: 0.4933 - sparse_categorical_accuracy: 0.7725\n",
            "Epoch 21/100\n",
            "1090/1090 [==============================] - 0s 117us/sample - loss: 0.4839 - sparse_categorical_accuracy: 0.7853\n",
            "Epoch 22/100\n",
            "1090/1090 [==============================] - 0s 128us/sample - loss: 0.4845 - sparse_categorical_accuracy: 0.7853\n",
            "Epoch 23/100\n",
            "1090/1090 [==============================] - 0s 114us/sample - loss: 0.4754 - sparse_categorical_accuracy: 0.7972\n",
            "Epoch 24/100\n",
            "1090/1090 [==============================] - 0s 113us/sample - loss: 0.4753 - sparse_categorical_accuracy: 0.7835\n",
            "Epoch 25/100\n",
            "1090/1090 [==============================] - 0s 130us/sample - loss: 0.4746 - sparse_categorical_accuracy: 0.7844\n",
            "Epoch 26/100\n",
            "1090/1090 [==============================] - 0s 137us/sample - loss: 0.4661 - sparse_categorical_accuracy: 0.8000\n",
            "Epoch 27/100\n",
            "1090/1090 [==============================] - 0s 116us/sample - loss: 0.4625 - sparse_categorical_accuracy: 0.7881\n",
            "Epoch 28/100\n",
            "1090/1090 [==============================] - 0s 113us/sample - loss: 0.4587 - sparse_categorical_accuracy: 0.7954\n",
            "Epoch 29/100\n",
            "1090/1090 [==============================] - 0s 144us/sample - loss: 0.4574 - sparse_categorical_accuracy: 0.7972\n",
            "Epoch 30/100\n",
            "1090/1090 [==============================] - 0s 109us/sample - loss: 0.4523 - sparse_categorical_accuracy: 0.8055\n",
            "Epoch 31/100\n",
            "1090/1090 [==============================] - 0s 118us/sample - loss: 0.4503 - sparse_categorical_accuracy: 0.8018\n",
            "Epoch 32/100\n",
            "1090/1090 [==============================] - 0s 132us/sample - loss: 0.4485 - sparse_categorical_accuracy: 0.7963\n",
            "Epoch 33/100\n",
            "1090/1090 [==============================] - 0s 117us/sample - loss: 0.4456 - sparse_categorical_accuracy: 0.8073\n",
            "Epoch 34/100\n",
            "1090/1090 [==============================] - 0s 117us/sample - loss: 0.4456 - sparse_categorical_accuracy: 0.8101\n",
            "Epoch 35/100\n",
            "1090/1090 [==============================] - 0s 114us/sample - loss: 0.4448 - sparse_categorical_accuracy: 0.8028\n",
            "Epoch 36/100\n",
            "1090/1090 [==============================] - 0s 111us/sample - loss: 0.4406 - sparse_categorical_accuracy: 0.8101\n",
            "Epoch 37/100\n",
            "1090/1090 [==============================] - 0s 135us/sample - loss: 0.4427 - sparse_categorical_accuracy: 0.8083\n",
            "Epoch 38/100\n",
            "1090/1090 [==============================] - 0s 110us/sample - loss: 0.4433 - sparse_categorical_accuracy: 0.8018\n",
            "Epoch 39/100\n",
            "1090/1090 [==============================] - 0s 111us/sample - loss: 0.4323 - sparse_categorical_accuracy: 0.8110\n",
            "Epoch 40/100\n",
            "1090/1090 [==============================] - 0s 113us/sample - loss: 0.4340 - sparse_categorical_accuracy: 0.8073\n",
            "Epoch 41/100\n",
            "1090/1090 [==============================] - 0s 106us/sample - loss: 0.4305 - sparse_categorical_accuracy: 0.8156\n",
            "Epoch 42/100\n",
            "1090/1090 [==============================] - 0s 108us/sample - loss: 0.4285 - sparse_categorical_accuracy: 0.8119\n",
            "Epoch 43/100\n",
            "1090/1090 [==============================] - 0s 110us/sample - loss: 0.4246 - sparse_categorical_accuracy: 0.8156\n",
            "Epoch 44/100\n",
            "1090/1090 [==============================] - 0s 114us/sample - loss: 0.4251 - sparse_categorical_accuracy: 0.8147\n",
            "Epoch 45/100\n",
            "1090/1090 [==============================] - 0s 138us/sample - loss: 0.4265 - sparse_categorical_accuracy: 0.8064\n",
            "Epoch 46/100\n",
            "1090/1090 [==============================] - 0s 111us/sample - loss: 0.4239 - sparse_categorical_accuracy: 0.8110\n",
            "Epoch 47/100\n",
            "1090/1090 [==============================] - 0s 114us/sample - loss: 0.4232 - sparse_categorical_accuracy: 0.8101\n",
            "Epoch 48/100\n",
            "1090/1090 [==============================] - 0s 119us/sample - loss: 0.4239 - sparse_categorical_accuracy: 0.8092\n",
            "Epoch 49/100\n",
            "1090/1090 [==============================] - 0s 112us/sample - loss: 0.4242 - sparse_categorical_accuracy: 0.8110\n",
            "Epoch 50/100\n",
            "1090/1090 [==============================] - 0s 110us/sample - loss: 0.4151 - sparse_categorical_accuracy: 0.8156\n",
            "Epoch 51/100\n",
            "1090/1090 [==============================] - 0s 116us/sample - loss: 0.4127 - sparse_categorical_accuracy: 0.8156\n",
            "Epoch 52/100\n",
            "1090/1090 [==============================] - 0s 113us/sample - loss: 0.4157 - sparse_categorical_accuracy: 0.8119\n",
            "Epoch 53/100\n",
            "1090/1090 [==============================] - 0s 130us/sample - loss: 0.4154 - sparse_categorical_accuracy: 0.8147\n",
            "Epoch 54/100\n",
            "1090/1090 [==============================] - 0s 125us/sample - loss: 0.4140 - sparse_categorical_accuracy: 0.8183\n",
            "Epoch 55/100\n",
            "1090/1090 [==============================] - 0s 111us/sample - loss: 0.4080 - sparse_categorical_accuracy: 0.8193\n",
            "Epoch 56/100\n",
            "1090/1090 [==============================] - 0s 122us/sample - loss: 0.4098 - sparse_categorical_accuracy: 0.8174\n",
            "Epoch 57/100\n",
            "1090/1090 [==============================] - 0s 116us/sample - loss: 0.4059 - sparse_categorical_accuracy: 0.8211\n",
            "Epoch 58/100\n",
            "1090/1090 [==============================] - 0s 116us/sample - loss: 0.4029 - sparse_categorical_accuracy: 0.8220\n",
            "Epoch 59/100\n",
            "1090/1090 [==============================] - 0s 120us/sample - loss: 0.4037 - sparse_categorical_accuracy: 0.8284\n",
            "Epoch 60/100\n",
            "1090/1090 [==============================] - 0s 110us/sample - loss: 0.4066 - sparse_categorical_accuracy: 0.8183\n",
            "Epoch 61/100\n",
            "1090/1090 [==============================] - 0s 136us/sample - loss: 0.4011 - sparse_categorical_accuracy: 0.8266\n",
            "Epoch 62/100\n",
            "1090/1090 [==============================] - 0s 118us/sample - loss: 0.3979 - sparse_categorical_accuracy: 0.8312\n",
            "Epoch 63/100\n",
            "1090/1090 [==============================] - 0s 119us/sample - loss: 0.4026 - sparse_categorical_accuracy: 0.8257\n",
            "Epoch 64/100\n",
            "1090/1090 [==============================] - 0s 113us/sample - loss: 0.3956 - sparse_categorical_accuracy: 0.8303\n",
            "Epoch 65/100\n",
            "1090/1090 [==============================] - 0s 115us/sample - loss: 0.3921 - sparse_categorical_accuracy: 0.8303\n",
            "Epoch 66/100\n",
            "1090/1090 [==============================] - 0s 113us/sample - loss: 0.3906 - sparse_categorical_accuracy: 0.8294\n",
            "Epoch 67/100\n",
            "1090/1090 [==============================] - 0s 117us/sample - loss: 0.3917 - sparse_categorical_accuracy: 0.8330\n",
            "Epoch 68/100\n",
            "1090/1090 [==============================] - 0s 118us/sample - loss: 0.3913 - sparse_categorical_accuracy: 0.8312\n",
            "Epoch 69/100\n",
            "1090/1090 [==============================] - 0s 146us/sample - loss: 0.3870 - sparse_categorical_accuracy: 0.8257\n",
            "Epoch 70/100\n",
            "1090/1090 [==============================] - 0s 120us/sample - loss: 0.3886 - sparse_categorical_accuracy: 0.8303\n",
            "Epoch 71/100\n",
            "1090/1090 [==============================] - 0s 126us/sample - loss: 0.3856 - sparse_categorical_accuracy: 0.8349\n",
            "Epoch 72/100\n",
            "1090/1090 [==============================] - 0s 115us/sample - loss: 0.3846 - sparse_categorical_accuracy: 0.8339\n",
            "Epoch 73/100\n",
            "1090/1090 [==============================] - 0s 124us/sample - loss: 0.3824 - sparse_categorical_accuracy: 0.8294\n",
            "Epoch 74/100\n",
            "1090/1090 [==============================] - 0s 113us/sample - loss: 0.3836 - sparse_categorical_accuracy: 0.8339\n",
            "Epoch 75/100\n",
            "1090/1090 [==============================] - 0s 108us/sample - loss: 0.3786 - sparse_categorical_accuracy: 0.8404\n",
            "Epoch 76/100\n",
            "1090/1090 [==============================] - 0s 109us/sample - loss: 0.3785 - sparse_categorical_accuracy: 0.8394\n",
            "Epoch 77/100\n",
            "1090/1090 [==============================] - 0s 137us/sample - loss: 0.3911 - sparse_categorical_accuracy: 0.8312\n",
            "Epoch 78/100\n",
            "1090/1090 [==============================] - 0s 115us/sample - loss: 0.3770 - sparse_categorical_accuracy: 0.8349\n",
            "Epoch 79/100\n",
            "1090/1090 [==============================] - 0s 114us/sample - loss: 0.3782 - sparse_categorical_accuracy: 0.8339\n",
            "Epoch 80/100\n",
            "1090/1090 [==============================] - 0s 115us/sample - loss: 0.3746 - sparse_categorical_accuracy: 0.8385\n",
            "Epoch 81/100\n",
            "1090/1090 [==============================] - 0s 111us/sample - loss: 0.3725 - sparse_categorical_accuracy: 0.8422\n",
            "Epoch 82/100\n",
            "1090/1090 [==============================] - 0s 112us/sample - loss: 0.3705 - sparse_categorical_accuracy: 0.8431\n",
            "Epoch 83/100\n",
            "1090/1090 [==============================] - 0s 112us/sample - loss: 0.3689 - sparse_categorical_accuracy: 0.8413\n",
            "Epoch 84/100\n",
            "1090/1090 [==============================] - 0s 117us/sample - loss: 0.3691 - sparse_categorical_accuracy: 0.8431\n",
            "Epoch 85/100\n",
            "1090/1090 [==============================] - 0s 141us/sample - loss: 0.3683 - sparse_categorical_accuracy: 0.8431\n",
            "Epoch 86/100\n",
            "1090/1090 [==============================] - 0s 122us/sample - loss: 0.3625 - sparse_categorical_accuracy: 0.8413\n",
            "Epoch 87/100\n",
            "1090/1090 [==============================] - 0s 115us/sample - loss: 0.3636 - sparse_categorical_accuracy: 0.8413\n",
            "Epoch 88/100\n",
            "1090/1090 [==============================] - 0s 115us/sample - loss: 0.3622 - sparse_categorical_accuracy: 0.8431\n",
            "Epoch 89/100\n",
            "1090/1090 [==============================] - 0s 113us/sample - loss: 0.3603 - sparse_categorical_accuracy: 0.8385\n",
            "Epoch 90/100\n",
            "1090/1090 [==============================] - 0s 110us/sample - loss: 0.3610 - sparse_categorical_accuracy: 0.8394\n",
            "Epoch 91/100\n",
            "1090/1090 [==============================] - 0s 111us/sample - loss: 0.3601 - sparse_categorical_accuracy: 0.8404\n",
            "Epoch 92/100\n",
            "1090/1090 [==============================] - 0s 117us/sample - loss: 0.3572 - sparse_categorical_accuracy: 0.8431\n",
            "Epoch 93/100\n",
            "1090/1090 [==============================] - 0s 136us/sample - loss: 0.3578 - sparse_categorical_accuracy: 0.8440\n",
            "Epoch 94/100\n",
            "1090/1090 [==============================] - 0s 114us/sample - loss: 0.3561 - sparse_categorical_accuracy: 0.8422\n",
            "Epoch 95/100\n",
            "1090/1090 [==============================] - 0s 116us/sample - loss: 0.3587 - sparse_categorical_accuracy: 0.8404\n",
            "Epoch 96/100\n",
            "1090/1090 [==============================] - 0s 120us/sample - loss: 0.3534 - sparse_categorical_accuracy: 0.8523\n",
            "Epoch 97/100\n",
            "1090/1090 [==============================] - 0s 121us/sample - loss: 0.3498 - sparse_categorical_accuracy: 0.8450\n",
            "Epoch 98/100\n",
            "1090/1090 [==============================] - 0s 119us/sample - loss: 0.3522 - sparse_categorical_accuracy: 0.8394\n",
            "Epoch 99/100\n",
            "1090/1090 [==============================] - 0s 131us/sample - loss: 0.3492 - sparse_categorical_accuracy: 0.8459\n",
            "Epoch 100/100\n",
            "1090/1090 [==============================] - 0s 124us/sample - loss: 0.3459 - sparse_categorical_accuracy: 0.8468\n",
            "Train on 1090 samples\n",
            "Epoch 1/100\n",
            "1090/1090 [==============================] - 1s 468us/sample - loss: 1.1301 - sparse_categorical_accuracy: 0.4505\n",
            "Epoch 2/100\n",
            "1090/1090 [==============================] - 0s 114us/sample - loss: 0.9089 - sparse_categorical_accuracy: 0.5495\n",
            "Epoch 3/100\n",
            "1090/1090 [==============================] - 0s 116us/sample - loss: 0.8147 - sparse_categorical_accuracy: 0.6101\n",
            "Epoch 4/100\n",
            "1090/1090 [==============================] - 0s 115us/sample - loss: 0.7595 - sparse_categorical_accuracy: 0.6376\n",
            "Epoch 5/100\n",
            "1090/1090 [==============================] - 0s 121us/sample - loss: 0.7147 - sparse_categorical_accuracy: 0.6624\n",
            "Epoch 6/100\n",
            "1090/1090 [==============================] - 0s 114us/sample - loss: 0.6883 - sparse_categorical_accuracy: 0.6789\n",
            "Epoch 7/100\n",
            "1090/1090 [==============================] - 0s 114us/sample - loss: 0.6611 - sparse_categorical_accuracy: 0.6908\n",
            "Epoch 8/100\n",
            "1090/1090 [==============================] - 0s 111us/sample - loss: 0.6416 - sparse_categorical_accuracy: 0.7018\n",
            "Epoch 9/100\n",
            "1090/1090 [==============================] - 0s 117us/sample - loss: 0.6255 - sparse_categorical_accuracy: 0.7018\n",
            "Epoch 10/100\n",
            "1090/1090 [==============================] - 0s 125us/sample - loss: 0.6087 - sparse_categorical_accuracy: 0.7183\n",
            "Epoch 11/100\n",
            "1090/1090 [==============================] - 0s 130us/sample - loss: 0.5937 - sparse_categorical_accuracy: 0.7174\n",
            "Epoch 12/100\n",
            "1090/1090 [==============================] - 0s 118us/sample - loss: 0.5844 - sparse_categorical_accuracy: 0.7202\n",
            "Epoch 13/100\n",
            "1090/1090 [==============================] - 0s 112us/sample - loss: 0.5733 - sparse_categorical_accuracy: 0.7275\n",
            "Epoch 14/100\n",
            "1090/1090 [==============================] - 0s 116us/sample - loss: 0.5694 - sparse_categorical_accuracy: 0.7239\n",
            "Epoch 15/100\n",
            "1090/1090 [==============================] - 0s 107us/sample - loss: 0.5586 - sparse_categorical_accuracy: 0.7358\n",
            "Epoch 16/100\n",
            "1090/1090 [==============================] - 0s 120us/sample - loss: 0.5520 - sparse_categorical_accuracy: 0.7358\n",
            "Epoch 17/100\n",
            "1090/1090 [==============================] - 0s 121us/sample - loss: 0.5437 - sparse_categorical_accuracy: 0.7349\n",
            "Epoch 18/100\n",
            "1090/1090 [==============================] - 0s 119us/sample - loss: 0.5389 - sparse_categorical_accuracy: 0.7422\n",
            "Epoch 19/100\n",
            "1090/1090 [==============================] - 0s 130us/sample - loss: 0.5313 - sparse_categorical_accuracy: 0.7532\n",
            "Epoch 20/100\n",
            "1090/1090 [==============================] - 0s 117us/sample - loss: 0.5349 - sparse_categorical_accuracy: 0.7440\n",
            "Epoch 21/100\n",
            "1090/1090 [==============================] - 0s 119us/sample - loss: 0.5239 - sparse_categorical_accuracy: 0.7569\n",
            "Epoch 22/100\n",
            "1090/1090 [==============================] - 0s 112us/sample - loss: 0.5187 - sparse_categorical_accuracy: 0.7624\n",
            "Epoch 23/100\n",
            "1090/1090 [==============================] - 0s 113us/sample - loss: 0.5145 - sparse_categorical_accuracy: 0.7569\n",
            "Epoch 24/100\n",
            "1090/1090 [==============================] - 0s 121us/sample - loss: 0.5112 - sparse_categorical_accuracy: 0.7587\n",
            "Epoch 25/100\n",
            "1090/1090 [==============================] - 0s 114us/sample - loss: 0.5090 - sparse_categorical_accuracy: 0.7615\n",
            "Epoch 26/100\n",
            "1090/1090 [==============================] - 0s 115us/sample - loss: 0.5044 - sparse_categorical_accuracy: 0.7706\n",
            "Epoch 27/100\n",
            "1090/1090 [==============================] - 0s 123us/sample - loss: 0.5033 - sparse_categorical_accuracy: 0.7688\n",
            "Epoch 28/100\n",
            "1090/1090 [==============================] - 0s 108us/sample - loss: 0.4988 - sparse_categorical_accuracy: 0.7661\n",
            "Epoch 29/100\n",
            "1090/1090 [==============================] - 0s 116us/sample - loss: 0.4963 - sparse_categorical_accuracy: 0.7697\n",
            "Epoch 30/100\n",
            "1090/1090 [==============================] - 0s 112us/sample - loss: 0.4904 - sparse_categorical_accuracy: 0.7771\n",
            "Epoch 31/100\n",
            "1090/1090 [==============================] - 0s 115us/sample - loss: 0.4896 - sparse_categorical_accuracy: 0.7716\n",
            "Epoch 32/100\n",
            "1090/1090 [==============================] - 0s 121us/sample - loss: 0.4879 - sparse_categorical_accuracy: 0.7716\n",
            "Epoch 33/100\n",
            "1090/1090 [==============================] - 0s 121us/sample - loss: 0.4838 - sparse_categorical_accuracy: 0.7743\n",
            "Epoch 34/100\n",
            "1090/1090 [==============================] - 0s 122us/sample - loss: 0.4832 - sparse_categorical_accuracy: 0.7752\n",
            "Epoch 35/100\n",
            "1090/1090 [==============================] - 0s 129us/sample - loss: 0.4798 - sparse_categorical_accuracy: 0.7771\n",
            "Epoch 36/100\n",
            "1090/1090 [==============================] - 0s 120us/sample - loss: 0.4753 - sparse_categorical_accuracy: 0.7798\n",
            "Epoch 37/100\n",
            "1090/1090 [==============================] - 0s 111us/sample - loss: 0.4741 - sparse_categorical_accuracy: 0.7780\n",
            "Epoch 38/100\n",
            "1090/1090 [==============================] - 0s 118us/sample - loss: 0.4754 - sparse_categorical_accuracy: 0.7761\n",
            "Epoch 39/100\n",
            "1090/1090 [==============================] - 0s 117us/sample - loss: 0.4704 - sparse_categorical_accuracy: 0.7881\n",
            "Epoch 40/100\n",
            "1090/1090 [==============================] - 0s 126us/sample - loss: 0.4683 - sparse_categorical_accuracy: 0.7872\n",
            "Epoch 41/100\n",
            "1090/1090 [==============================] - 0s 114us/sample - loss: 0.4689 - sparse_categorical_accuracy: 0.7743\n",
            "Epoch 42/100\n",
            "1090/1090 [==============================] - 0s 111us/sample - loss: 0.4663 - sparse_categorical_accuracy: 0.7862\n",
            "Epoch 43/100\n",
            "1090/1090 [==============================] - 0s 124us/sample - loss: 0.4681 - sparse_categorical_accuracy: 0.7780\n",
            "Epoch 44/100\n",
            "1090/1090 [==============================] - 0s 113us/sample - loss: 0.4660 - sparse_categorical_accuracy: 0.7844\n",
            "Epoch 45/100\n",
            "1090/1090 [==============================] - 0s 136us/sample - loss: 0.4764 - sparse_categorical_accuracy: 0.7771\n",
            "Epoch 46/100\n",
            "1090/1090 [==============================] - 0s 114us/sample - loss: 0.4606 - sparse_categorical_accuracy: 0.7835\n",
            "Epoch 47/100\n",
            "1090/1090 [==============================] - 0s 115us/sample - loss: 0.4562 - sparse_categorical_accuracy: 0.7872\n",
            "Epoch 48/100\n",
            "1090/1090 [==============================] - 0s 123us/sample - loss: 0.4771 - sparse_categorical_accuracy: 0.7798\n",
            "Epoch 49/100\n",
            "1090/1090 [==============================] - 0s 124us/sample - loss: 0.4550 - sparse_categorical_accuracy: 0.7908\n",
            "Epoch 50/100\n",
            "1090/1090 [==============================] - 0s 121us/sample - loss: 0.4521 - sparse_categorical_accuracy: 0.7899\n",
            "Epoch 51/100\n",
            "1090/1090 [==============================] - 0s 122us/sample - loss: 0.4614 - sparse_categorical_accuracy: 0.7789\n",
            "Epoch 52/100\n",
            "1090/1090 [==============================] - 0s 114us/sample - loss: 0.4508 - sparse_categorical_accuracy: 0.7862\n",
            "Epoch 53/100\n",
            "1090/1090 [==============================] - 0s 122us/sample - loss: 0.4466 - sparse_categorical_accuracy: 0.7972\n",
            "Epoch 54/100\n",
            "1090/1090 [==============================] - 0s 115us/sample - loss: 0.4483 - sparse_categorical_accuracy: 0.7862\n",
            "Epoch 55/100\n",
            "1090/1090 [==============================] - 0s 119us/sample - loss: 0.4446 - sparse_categorical_accuracy: 0.7963\n",
            "Epoch 56/100\n",
            "1090/1090 [==============================] - 0s 116us/sample - loss: 0.4450 - sparse_categorical_accuracy: 0.7917\n",
            "Epoch 57/100\n",
            "1090/1090 [==============================] - 0s 124us/sample - loss: 0.4416 - sparse_categorical_accuracy: 0.8018\n",
            "Epoch 58/100\n",
            "1090/1090 [==============================] - 0s 122us/sample - loss: 0.4413 - sparse_categorical_accuracy: 0.7936\n",
            "Epoch 59/100\n",
            "1090/1090 [==============================] - 0s 123us/sample - loss: 0.4374 - sparse_categorical_accuracy: 0.7908\n",
            "Epoch 60/100\n",
            "1090/1090 [==============================] - 0s 109us/sample - loss: 0.4396 - sparse_categorical_accuracy: 0.8018\n",
            "Epoch 61/100\n",
            "1090/1090 [==============================] - 0s 124us/sample - loss: 0.4362 - sparse_categorical_accuracy: 0.7945\n",
            "Epoch 62/100\n",
            "1090/1090 [==============================] - 0s 115us/sample - loss: 0.4335 - sparse_categorical_accuracy: 0.7991\n",
            "Epoch 63/100\n",
            "1090/1090 [==============================] - 0s 127us/sample - loss: 0.4317 - sparse_categorical_accuracy: 0.8018\n",
            "Epoch 64/100\n",
            "1090/1090 [==============================] - 0s 115us/sample - loss: 0.4306 - sparse_categorical_accuracy: 0.7927\n",
            "Epoch 65/100\n",
            "1090/1090 [==============================] - 0s 119us/sample - loss: 0.4266 - sparse_categorical_accuracy: 0.8028\n",
            "Epoch 66/100\n",
            "1090/1090 [==============================] - 0s 123us/sample - loss: 0.4321 - sparse_categorical_accuracy: 0.7963\n",
            "Epoch 67/100\n",
            "1090/1090 [==============================] - 0s 107us/sample - loss: 0.4279 - sparse_categorical_accuracy: 0.8000\n",
            "Epoch 68/100\n",
            "1090/1090 [==============================] - 0s 117us/sample - loss: 0.4259 - sparse_categorical_accuracy: 0.8055\n",
            "Epoch 69/100\n",
            "1090/1090 [==============================] - 0s 113us/sample - loss: 0.4240 - sparse_categorical_accuracy: 0.8046\n",
            "Epoch 70/100\n",
            "1090/1090 [==============================] - 0s 117us/sample - loss: 0.4266 - sparse_categorical_accuracy: 0.8000\n",
            "Epoch 71/100\n",
            "1090/1090 [==============================] - 0s 114us/sample - loss: 0.4285 - sparse_categorical_accuracy: 0.7991\n",
            "Epoch 72/100\n",
            "1090/1090 [==============================] - 0s 119us/sample - loss: 0.4215 - sparse_categorical_accuracy: 0.8018\n",
            "Epoch 73/100\n",
            "1090/1090 [==============================] - 0s 115us/sample - loss: 0.4254 - sparse_categorical_accuracy: 0.8018\n",
            "Epoch 74/100\n",
            "1090/1090 [==============================] - 0s 129us/sample - loss: 0.4207 - sparse_categorical_accuracy: 0.8073\n",
            "Epoch 75/100\n",
            "1090/1090 [==============================] - 0s 113us/sample - loss: 0.4147 - sparse_categorical_accuracy: 0.8119\n",
            "Epoch 76/100\n",
            "1090/1090 [==============================] - 0s 114us/sample - loss: 0.4243 - sparse_categorical_accuracy: 0.8092\n",
            "Epoch 77/100\n",
            "1090/1090 [==============================] - 0s 118us/sample - loss: 0.4125 - sparse_categorical_accuracy: 0.8046\n",
            "Epoch 78/100\n",
            "1090/1090 [==============================] - 0s 125us/sample - loss: 0.4143 - sparse_categorical_accuracy: 0.8138\n",
            "Epoch 79/100\n",
            "1090/1090 [==============================] - 0s 119us/sample - loss: 0.4100 - sparse_categorical_accuracy: 0.8128\n",
            "Epoch 80/100\n",
            "1090/1090 [==============================] - 0s 121us/sample - loss: 0.4132 - sparse_categorical_accuracy: 0.8083\n",
            "Epoch 81/100\n",
            "1090/1090 [==============================] - 0s 114us/sample - loss: 0.4135 - sparse_categorical_accuracy: 0.8156\n",
            "Epoch 82/100\n",
            "1090/1090 [==============================] - 0s 122us/sample - loss: 0.4090 - sparse_categorical_accuracy: 0.8055\n",
            "Epoch 83/100\n",
            "1090/1090 [==============================] - 0s 113us/sample - loss: 0.4062 - sparse_categorical_accuracy: 0.8183\n",
            "Epoch 84/100\n",
            "1090/1090 [==============================] - 0s 117us/sample - loss: 0.4049 - sparse_categorical_accuracy: 0.8138\n",
            "Epoch 85/100\n",
            "1090/1090 [==============================] - 0s 121us/sample - loss: 0.4019 - sparse_categorical_accuracy: 0.8202\n",
            "Epoch 86/100\n",
            "1090/1090 [==============================] - 0s 124us/sample - loss: 0.4007 - sparse_categorical_accuracy: 0.8229\n",
            "Epoch 87/100\n",
            "1090/1090 [==============================] - 0s 112us/sample - loss: 0.4024 - sparse_categorical_accuracy: 0.8220\n",
            "Epoch 88/100\n",
            "1090/1090 [==============================] - 0s 123us/sample - loss: 0.3988 - sparse_categorical_accuracy: 0.8266\n",
            "Epoch 89/100\n",
            "1090/1090 [==============================] - 0s 112us/sample - loss: 0.3979 - sparse_categorical_accuracy: 0.8229\n",
            "Epoch 90/100\n",
            "1090/1090 [==============================] - 0s 128us/sample - loss: 0.3999 - sparse_categorical_accuracy: 0.8128\n",
            "Epoch 91/100\n",
            "1090/1090 [==============================] - 0s 118us/sample - loss: 0.4044 - sparse_categorical_accuracy: 0.8119\n",
            "Epoch 92/100\n",
            "1090/1090 [==============================] - 0s 122us/sample - loss: 0.3963 - sparse_categorical_accuracy: 0.8147\n",
            "Epoch 93/100\n",
            "1090/1090 [==============================] - 0s 121us/sample - loss: 0.4096 - sparse_categorical_accuracy: 0.8174\n",
            "Epoch 94/100\n",
            "1090/1090 [==============================] - 0s 110us/sample - loss: 0.3913 - sparse_categorical_accuracy: 0.8229\n",
            "Epoch 95/100\n",
            "1090/1090 [==============================] - 0s 119us/sample - loss: 0.3903 - sparse_categorical_accuracy: 0.8257\n",
            "Epoch 96/100\n",
            "1090/1090 [==============================] - 0s 123us/sample - loss: 0.3907 - sparse_categorical_accuracy: 0.8303\n",
            "Epoch 97/100\n",
            "1090/1090 [==============================] - 0s 114us/sample - loss: 0.3874 - sparse_categorical_accuracy: 0.8294\n",
            "Epoch 98/100\n",
            "1090/1090 [==============================] - 0s 120us/sample - loss: 0.3913 - sparse_categorical_accuracy: 0.8294\n",
            "Epoch 99/100\n",
            "1090/1090 [==============================] - 0s 111us/sample - loss: 0.3843 - sparse_categorical_accuracy: 0.8275\n",
            "Epoch 100/100\n",
            "1090/1090 [==============================] - 0s 115us/sample - loss: 0.3868 - sparse_categorical_accuracy: 0.8229\n",
            "Train on 1091 samples\n",
            "Epoch 1/100\n",
            "1091/1091 [==============================] - 1s 469us/sample - loss: 1.2645 - sparse_categorical_accuracy: 0.3630\n",
            "Epoch 2/100\n",
            "1091/1091 [==============================] - 0s 115us/sample - loss: 0.9763 - sparse_categorical_accuracy: 0.4876\n",
            "Epoch 3/100\n",
            "1091/1091 [==============================] - 0s 119us/sample - loss: 0.8605 - sparse_categorical_accuracy: 0.5793\n",
            "Epoch 4/100\n",
            "1091/1091 [==============================] - 0s 114us/sample - loss: 0.7929 - sparse_categorical_accuracy: 0.6150\n",
            "Epoch 5/100\n",
            "1091/1091 [==============================] - 0s 126us/sample - loss: 0.7420 - sparse_categorical_accuracy: 0.6544\n",
            "Epoch 6/100\n",
            "1091/1091 [==============================] - 0s 107us/sample - loss: 0.7024 - sparse_categorical_accuracy: 0.6728\n",
            "Epoch 7/100\n",
            "1091/1091 [==============================] - 0s 110us/sample - loss: 0.6729 - sparse_categorical_accuracy: 0.6673\n",
            "Epoch 8/100\n",
            "1091/1091 [==============================] - 0s 115us/sample - loss: 0.6456 - sparse_categorical_accuracy: 0.6884\n",
            "Epoch 9/100\n",
            "1091/1091 [==============================] - 0s 119us/sample - loss: 0.6248 - sparse_categorical_accuracy: 0.7049\n",
            "Epoch 10/100\n",
            "1091/1091 [==============================] - 0s 114us/sample - loss: 0.6065 - sparse_categorical_accuracy: 0.7168\n",
            "Epoch 11/100\n",
            "1091/1091 [==============================] - 0s 120us/sample - loss: 0.5908 - sparse_categorical_accuracy: 0.7241\n",
            "Epoch 12/100\n",
            "1091/1091 [==============================] - 0s 123us/sample - loss: 0.5738 - sparse_categorical_accuracy: 0.7259\n",
            "Epoch 13/100\n",
            "1091/1091 [==============================] - 0s 120us/sample - loss: 0.5620 - sparse_categorical_accuracy: 0.7360\n",
            "Epoch 14/100\n",
            "1091/1091 [==============================] - 0s 118us/sample - loss: 0.5506 - sparse_categorical_accuracy: 0.7498\n",
            "Epoch 15/100\n",
            "1091/1091 [==============================] - 0s 110us/sample - loss: 0.5388 - sparse_categorical_accuracy: 0.7580\n",
            "Epoch 16/100\n",
            "1091/1091 [==============================] - 0s 114us/sample - loss: 0.5316 - sparse_categorical_accuracy: 0.7553\n",
            "Epoch 17/100\n",
            "1091/1091 [==============================] - 0s 125us/sample - loss: 0.5246 - sparse_categorical_accuracy: 0.7635\n",
            "Epoch 18/100\n",
            "1091/1091 [==============================] - 0s 109us/sample - loss: 0.5187 - sparse_categorical_accuracy: 0.7589\n",
            "Epoch 19/100\n",
            "1091/1091 [==============================] - 0s 123us/sample - loss: 0.5107 - sparse_categorical_accuracy: 0.7690\n",
            "Epoch 20/100\n",
            "1091/1091 [==============================] - 0s 110us/sample - loss: 0.5060 - sparse_categorical_accuracy: 0.7635\n",
            "Epoch 21/100\n",
            "1091/1091 [==============================] - 0s 119us/sample - loss: 0.4989 - sparse_categorical_accuracy: 0.7681\n",
            "Epoch 22/100\n",
            "1091/1091 [==============================] - 0s 111us/sample - loss: 0.4948 - sparse_categorical_accuracy: 0.7709\n",
            "Epoch 23/100\n",
            "1091/1091 [==============================] - 0s 137us/sample - loss: 0.4882 - sparse_categorical_accuracy: 0.7718\n",
            "Epoch 24/100\n",
            "1091/1091 [==============================] - 0s 121us/sample - loss: 0.4835 - sparse_categorical_accuracy: 0.7745\n",
            "Epoch 25/100\n",
            "1091/1091 [==============================] - 0s 113us/sample - loss: 0.4771 - sparse_categorical_accuracy: 0.7846\n",
            "Epoch 26/100\n",
            "1091/1091 [==============================] - 0s 114us/sample - loss: 0.4734 - sparse_categorical_accuracy: 0.7819\n",
            "Epoch 27/100\n",
            "1091/1091 [==============================] - 0s 123us/sample - loss: 0.4827 - sparse_categorical_accuracy: 0.7828\n",
            "Epoch 28/100\n",
            "1091/1091 [==============================] - 0s 127us/sample - loss: 0.4675 - sparse_categorical_accuracy: 0.7938\n",
            "Epoch 29/100\n",
            "1091/1091 [==============================] - 0s 113us/sample - loss: 0.4615 - sparse_categorical_accuracy: 0.7919\n",
            "Epoch 30/100\n",
            "1091/1091 [==============================] - 0s 112us/sample - loss: 0.4611 - sparse_categorical_accuracy: 0.7901\n",
            "Epoch 31/100\n",
            "1091/1091 [==============================] - 0s 113us/sample - loss: 0.4573 - sparse_categorical_accuracy: 0.7938\n",
            "Epoch 32/100\n",
            "1091/1091 [==============================] - 0s 125us/sample - loss: 0.4542 - sparse_categorical_accuracy: 0.8075\n",
            "Epoch 33/100\n",
            "1091/1091 [==============================] - 0s 111us/sample - loss: 0.4516 - sparse_categorical_accuracy: 0.8038\n",
            "Epoch 34/100\n",
            "1091/1091 [==============================] - 0s 113us/sample - loss: 0.4472 - sparse_categorical_accuracy: 0.8011\n",
            "Epoch 35/100\n",
            "1091/1091 [==============================] - 0s 115us/sample - loss: 0.4452 - sparse_categorical_accuracy: 0.8020\n",
            "Epoch 36/100\n",
            "1091/1091 [==============================] - 0s 114us/sample - loss: 0.4439 - sparse_categorical_accuracy: 0.8057\n",
            "Epoch 37/100\n",
            "1091/1091 [==============================] - 0s 119us/sample - loss: 0.4412 - sparse_categorical_accuracy: 0.8075\n",
            "Epoch 38/100\n",
            "1091/1091 [==============================] - 0s 123us/sample - loss: 0.4369 - sparse_categorical_accuracy: 0.8048\n",
            "Epoch 39/100\n",
            "1091/1091 [==============================] - 0s 116us/sample - loss: 0.4361 - sparse_categorical_accuracy: 0.8048\n",
            "Epoch 40/100\n",
            "1091/1091 [==============================] - 0s 133us/sample - loss: 0.4336 - sparse_categorical_accuracy: 0.8066\n",
            "Epoch 41/100\n",
            "1091/1091 [==============================] - 0s 118us/sample - loss: 0.4313 - sparse_categorical_accuracy: 0.8038\n",
            "Epoch 42/100\n",
            "1091/1091 [==============================] - 0s 116us/sample - loss: 0.4284 - sparse_categorical_accuracy: 0.8194\n",
            "Epoch 43/100\n",
            "1091/1091 [==============================] - 0s 118us/sample - loss: 0.4266 - sparse_categorical_accuracy: 0.8103\n",
            "Epoch 44/100\n",
            "1091/1091 [==============================] - 0s 118us/sample - loss: 0.4256 - sparse_categorical_accuracy: 0.8029\n",
            "Epoch 45/100\n",
            "1091/1091 [==============================] - 0s 121us/sample - loss: 0.4231 - sparse_categorical_accuracy: 0.8203\n",
            "Epoch 46/100\n",
            "1091/1091 [==============================] - 0s 121us/sample - loss: 0.4241 - sparse_categorical_accuracy: 0.8158\n",
            "Epoch 47/100\n",
            "1091/1091 [==============================] - 0s 106us/sample - loss: 0.4201 - sparse_categorical_accuracy: 0.8103\n",
            "Epoch 48/100\n",
            "1091/1091 [==============================] - 0s 122us/sample - loss: 0.4165 - sparse_categorical_accuracy: 0.8185\n",
            "Epoch 49/100\n",
            "1091/1091 [==============================] - 0s 109us/sample - loss: 0.4148 - sparse_categorical_accuracy: 0.8167\n",
            "Epoch 50/100\n",
            "1091/1091 [==============================] - 0s 114us/sample - loss: 0.4139 - sparse_categorical_accuracy: 0.8249\n",
            "Epoch 51/100\n",
            "1091/1091 [==============================] - 0s 128us/sample - loss: 0.4116 - sparse_categorical_accuracy: 0.8203\n",
            "Epoch 52/100\n",
            "1091/1091 [==============================] - 0s 114us/sample - loss: 0.4119 - sparse_categorical_accuracy: 0.8203\n",
            "Epoch 53/100\n",
            "1091/1091 [==============================] - 0s 123us/sample - loss: 0.4092 - sparse_categorical_accuracy: 0.8222\n",
            "Epoch 54/100\n",
            "1091/1091 [==============================] - 0s 118us/sample - loss: 0.4072 - sparse_categorical_accuracy: 0.8268\n",
            "Epoch 55/100\n",
            "1091/1091 [==============================] - 0s 112us/sample - loss: 0.4068 - sparse_categorical_accuracy: 0.8213\n",
            "Epoch 56/100\n",
            "1091/1091 [==============================] - 0s 129us/sample - loss: 0.4070 - sparse_categorical_accuracy: 0.8222\n",
            "Epoch 57/100\n",
            "1091/1091 [==============================] - 0s 115us/sample - loss: 0.4021 - sparse_categorical_accuracy: 0.8213\n",
            "Epoch 58/100\n",
            "1091/1091 [==============================] - 0s 125us/sample - loss: 0.4057 - sparse_categorical_accuracy: 0.8268\n",
            "Epoch 59/100\n",
            "1091/1091 [==============================] - 0s 113us/sample - loss: 0.4018 - sparse_categorical_accuracy: 0.8176\n",
            "Epoch 60/100\n",
            "1091/1091 [==============================] - 0s 113us/sample - loss: 0.4015 - sparse_categorical_accuracy: 0.8286\n",
            "Epoch 61/100\n",
            "1091/1091 [==============================] - 0s 107us/sample - loss: 0.3952 - sparse_categorical_accuracy: 0.8295\n",
            "Epoch 62/100\n",
            "1091/1091 [==============================] - 0s 111us/sample - loss: 0.3943 - sparse_categorical_accuracy: 0.8304\n",
            "Epoch 63/100\n",
            "1091/1091 [==============================] - 0s 117us/sample - loss: 0.3960 - sparse_categorical_accuracy: 0.8304\n",
            "Epoch 64/100\n",
            "1091/1091 [==============================] - 0s 122us/sample - loss: 0.3934 - sparse_categorical_accuracy: 0.8277\n",
            "Epoch 65/100\n",
            "1091/1091 [==============================] - 0s 118us/sample - loss: 0.3935 - sparse_categorical_accuracy: 0.8240\n",
            "Epoch 66/100\n",
            "1091/1091 [==============================] - 0s 119us/sample - loss: 0.3894 - sparse_categorical_accuracy: 0.8268\n",
            "Epoch 67/100\n",
            "1091/1091 [==============================] - 0s 120us/sample - loss: 0.3899 - sparse_categorical_accuracy: 0.8231\n",
            "Epoch 68/100\n",
            "1091/1091 [==============================] - 0s 114us/sample - loss: 0.3890 - sparse_categorical_accuracy: 0.8304\n",
            "Epoch 69/100\n",
            "1091/1091 [==============================] - 0s 113us/sample - loss: 0.3898 - sparse_categorical_accuracy: 0.8268\n",
            "Epoch 70/100\n",
            "1091/1091 [==============================] - 0s 127us/sample - loss: 0.3836 - sparse_categorical_accuracy: 0.8332\n",
            "Epoch 71/100\n",
            "1091/1091 [==============================] - 0s 113us/sample - loss: 0.3841 - sparse_categorical_accuracy: 0.8313\n",
            "Epoch 72/100\n",
            "1091/1091 [==============================] - 0s 123us/sample - loss: 0.3820 - sparse_categorical_accuracy: 0.8332\n",
            "Epoch 73/100\n",
            "1091/1091 [==============================] - 0s 107us/sample - loss: 0.3797 - sparse_categorical_accuracy: 0.8341\n",
            "Epoch 74/100\n",
            "1091/1091 [==============================] - 0s 115us/sample - loss: 0.3806 - sparse_categorical_accuracy: 0.8295\n",
            "Epoch 75/100\n",
            "1091/1091 [==============================] - 0s 121us/sample - loss: 0.3771 - sparse_categorical_accuracy: 0.8423\n",
            "Epoch 76/100\n",
            "1091/1091 [==============================] - 0s 114us/sample - loss: 0.3777 - sparse_categorical_accuracy: 0.8341\n",
            "Epoch 77/100\n",
            "1091/1091 [==============================] - 0s 116us/sample - loss: 0.3771 - sparse_categorical_accuracy: 0.8359\n",
            "Epoch 78/100\n",
            "1091/1091 [==============================] - 0s 122us/sample - loss: 0.3726 - sparse_categorical_accuracy: 0.8350\n",
            "Epoch 79/100\n",
            "1091/1091 [==============================] - 0s 131us/sample - loss: 0.3767 - sparse_categorical_accuracy: 0.8368\n",
            "Epoch 80/100\n",
            "1091/1091 [==============================] - 0s 122us/sample - loss: 0.3742 - sparse_categorical_accuracy: 0.8433\n",
            "Epoch 81/100\n",
            "1091/1091 [==============================] - 0s 118us/sample - loss: 0.3698 - sparse_categorical_accuracy: 0.8396\n",
            "Epoch 82/100\n",
            "1091/1091 [==============================] - 0s 117us/sample - loss: 0.3725 - sparse_categorical_accuracy: 0.8387\n",
            "Epoch 83/100\n",
            "1091/1091 [==============================] - 0s 113us/sample - loss: 0.3675 - sparse_categorical_accuracy: 0.8368\n",
            "Epoch 84/100\n",
            "1091/1091 [==============================] - 0s 121us/sample - loss: 0.3685 - sparse_categorical_accuracy: 0.8396\n",
            "Epoch 85/100\n",
            "1091/1091 [==============================] - 0s 115us/sample - loss: 0.3650 - sparse_categorical_accuracy: 0.8414\n",
            "Epoch 86/100\n",
            "1091/1091 [==============================] - 0s 130us/sample - loss: 0.3670 - sparse_categorical_accuracy: 0.8497\n",
            "Epoch 87/100\n",
            "1091/1091 [==============================] - 0s 123us/sample - loss: 0.3637 - sparse_categorical_accuracy: 0.8469\n",
            "Epoch 88/100\n",
            "1091/1091 [==============================] - 0s 111us/sample - loss: 0.3699 - sparse_categorical_accuracy: 0.8414\n",
            "Epoch 89/100\n",
            "1091/1091 [==============================] - 0s 114us/sample - loss: 0.3625 - sparse_categorical_accuracy: 0.8414\n",
            "Epoch 90/100\n",
            "1091/1091 [==============================] - 0s 113us/sample - loss: 0.3621 - sparse_categorical_accuracy: 0.8451\n",
            "Epoch 91/100\n",
            "1091/1091 [==============================] - 0s 117us/sample - loss: 0.3590 - sparse_categorical_accuracy: 0.8451\n",
            "Epoch 92/100\n",
            "1091/1091 [==============================] - 0s 111us/sample - loss: 0.3555 - sparse_categorical_accuracy: 0.8478\n",
            "Epoch 93/100\n",
            "1091/1091 [==============================] - 0s 126us/sample - loss: 0.3557 - sparse_categorical_accuracy: 0.8378\n",
            "Epoch 94/100\n",
            "1091/1091 [==============================] - 0s 119us/sample - loss: 0.3553 - sparse_categorical_accuracy: 0.8451\n",
            "Epoch 95/100\n",
            "1091/1091 [==============================] - 0s 138us/sample - loss: 0.3511 - sparse_categorical_accuracy: 0.8561\n",
            "Epoch 96/100\n",
            "1091/1091 [==============================] - 0s 119us/sample - loss: 0.3602 - sparse_categorical_accuracy: 0.8378\n",
            "Epoch 97/100\n",
            "1091/1091 [==============================] - 0s 111us/sample - loss: 0.3520 - sparse_categorical_accuracy: 0.8497\n",
            "Epoch 98/100\n",
            "1091/1091 [==============================] - 0s 116us/sample - loss: 0.3479 - sparse_categorical_accuracy: 0.8515\n",
            "Epoch 99/100\n",
            "1091/1091 [==============================] - 0s 113us/sample - loss: 0.3508 - sparse_categorical_accuracy: 0.8460\n",
            "Epoch 100/100\n",
            "1091/1091 [==============================] - 0s 111us/sample - loss: 0.3519 - sparse_categorical_accuracy: 0.8533\n",
            "Train on 1091 samples\n",
            "Epoch 1/100\n",
            "1091/1091 [==============================] - 1s 483us/sample - loss: 1.1932 - sparse_categorical_accuracy: 0.4400\n",
            "Epoch 2/100\n",
            "1091/1091 [==============================] - 0s 132us/sample - loss: 0.9337 - sparse_categorical_accuracy: 0.5316\n",
            "Epoch 3/100\n",
            "1091/1091 [==============================] - 0s 119us/sample - loss: 0.8318 - sparse_categorical_accuracy: 0.5665\n",
            "Epoch 4/100\n",
            "1091/1091 [==============================] - 0s 108us/sample - loss: 0.7651 - sparse_categorical_accuracy: 0.6104\n",
            "Epoch 5/100\n",
            "1091/1091 [==============================] - 0s 121us/sample - loss: 0.7204 - sparse_categorical_accuracy: 0.6398\n",
            "Epoch 6/100\n",
            "1091/1091 [==============================] - 0s 129us/sample - loss: 0.6818 - sparse_categorical_accuracy: 0.6746\n",
            "Epoch 7/100\n",
            "1091/1091 [==============================] - 0s 119us/sample - loss: 0.6535 - sparse_categorical_accuracy: 0.6893\n",
            "Epoch 8/100\n",
            "1091/1091 [==============================] - 0s 111us/sample - loss: 0.6264 - sparse_categorical_accuracy: 0.7113\n",
            "Epoch 9/100\n",
            "1091/1091 [==============================] - 0s 112us/sample - loss: 0.6077 - sparse_categorical_accuracy: 0.7131\n",
            "Epoch 10/100\n",
            "1091/1091 [==============================] - 0s 111us/sample - loss: 0.5920 - sparse_categorical_accuracy: 0.7204\n",
            "Epoch 11/100\n",
            "1091/1091 [==============================] - 0s 114us/sample - loss: 0.5782 - sparse_categorical_accuracy: 0.7287\n",
            "Epoch 12/100\n",
            "1091/1091 [==============================] - 0s 116us/sample - loss: 0.5617 - sparse_categorical_accuracy: 0.7324\n",
            "Epoch 13/100\n",
            "1091/1091 [==============================] - 0s 119us/sample - loss: 0.5496 - sparse_categorical_accuracy: 0.7479\n",
            "Epoch 14/100\n",
            "1091/1091 [==============================] - 0s 142us/sample - loss: 0.5408 - sparse_categorical_accuracy: 0.7461\n",
            "Epoch 15/100\n",
            "1091/1091 [==============================] - 0s 112us/sample - loss: 0.5313 - sparse_categorical_accuracy: 0.7516\n",
            "Epoch 16/100\n",
            "1091/1091 [==============================] - 0s 119us/sample - loss: 0.5243 - sparse_categorical_accuracy: 0.7608\n",
            "Epoch 17/100\n",
            "1091/1091 [==============================] - 0s 110us/sample - loss: 0.5182 - sparse_categorical_accuracy: 0.7571\n",
            "Epoch 18/100\n",
            "1091/1091 [==============================] - 0s 115us/sample - loss: 0.5090 - sparse_categorical_accuracy: 0.7599\n",
            "Epoch 19/100\n",
            "1091/1091 [==============================] - 0s 117us/sample - loss: 0.5047 - sparse_categorical_accuracy: 0.7644\n",
            "Epoch 20/100\n",
            "1091/1091 [==============================] - 0s 131us/sample - loss: 0.5000 - sparse_categorical_accuracy: 0.7608\n",
            "Epoch 21/100\n",
            "1091/1091 [==============================] - 0s 127us/sample - loss: 0.4955 - sparse_categorical_accuracy: 0.7745\n",
            "Epoch 22/100\n",
            "1091/1091 [==============================] - 0s 119us/sample - loss: 0.4894 - sparse_categorical_accuracy: 0.7672\n",
            "Epoch 23/100\n",
            "1091/1091 [==============================] - 0s 110us/sample - loss: 0.4915 - sparse_categorical_accuracy: 0.7663\n",
            "Epoch 24/100\n",
            "1091/1091 [==============================] - 0s 108us/sample - loss: 0.4818 - sparse_categorical_accuracy: 0.7864\n",
            "Epoch 25/100\n",
            "1091/1091 [==============================] - 0s 111us/sample - loss: 0.4806 - sparse_categorical_accuracy: 0.7791\n",
            "Epoch 26/100\n",
            "1091/1091 [==============================] - 0s 108us/sample - loss: 0.4707 - sparse_categorical_accuracy: 0.7874\n",
            "Epoch 27/100\n",
            "1091/1091 [==============================] - 0s 108us/sample - loss: 0.4652 - sparse_categorical_accuracy: 0.7855\n",
            "Epoch 28/100\n",
            "1091/1091 [==============================] - 0s 114us/sample - loss: 0.4677 - sparse_categorical_accuracy: 0.7773\n",
            "Epoch 29/100\n",
            "1091/1091 [==============================] - 0s 116us/sample - loss: 0.4626 - sparse_categorical_accuracy: 0.7855\n",
            "Epoch 30/100\n",
            "1091/1091 [==============================] - 0s 131us/sample - loss: 0.4635 - sparse_categorical_accuracy: 0.7910\n",
            "Epoch 31/100\n",
            "1091/1091 [==============================] - 0s 123us/sample - loss: 0.4558 - sparse_categorical_accuracy: 0.7984\n",
            "Epoch 32/100\n",
            "1091/1091 [==============================] - 0s 112us/sample - loss: 0.4546 - sparse_categorical_accuracy: 0.7864\n",
            "Epoch 33/100\n",
            "1091/1091 [==============================] - 0s 118us/sample - loss: 0.4522 - sparse_categorical_accuracy: 0.7910\n",
            "Epoch 34/100\n",
            "1091/1091 [==============================] - 0s 116us/sample - loss: 0.4527 - sparse_categorical_accuracy: 0.7974\n",
            "Epoch 35/100\n",
            "1091/1091 [==============================] - 0s 113us/sample - loss: 0.4490 - sparse_categorical_accuracy: 0.7910\n",
            "Epoch 36/100\n",
            "1091/1091 [==============================] - 0s 111us/sample - loss: 0.4451 - sparse_categorical_accuracy: 0.8112\n",
            "Epoch 37/100\n",
            "1091/1091 [==============================] - 0s 112us/sample - loss: 0.4443 - sparse_categorical_accuracy: 0.7947\n",
            "Epoch 38/100\n",
            "1091/1091 [==============================] - 0s 123us/sample - loss: 0.4455 - sparse_categorical_accuracy: 0.8057\n",
            "Epoch 39/100\n",
            "1091/1091 [==============================] - 0s 120us/sample - loss: 0.4401 - sparse_categorical_accuracy: 0.7956\n",
            "Epoch 40/100\n",
            "1091/1091 [==============================] - 0s 110us/sample - loss: 0.4351 - sparse_categorical_accuracy: 0.8038\n",
            "Epoch 41/100\n",
            "1091/1091 [==============================] - 0s 118us/sample - loss: 0.4337 - sparse_categorical_accuracy: 0.8066\n",
            "Epoch 42/100\n",
            "1091/1091 [==============================] - 0s 111us/sample - loss: 0.4349 - sparse_categorical_accuracy: 0.8048\n",
            "Epoch 43/100\n",
            "1091/1091 [==============================] - 0s 119us/sample - loss: 0.4316 - sparse_categorical_accuracy: 0.8075\n",
            "Epoch 44/100\n",
            "1091/1091 [==============================] - 0s 111us/sample - loss: 0.4271 - sparse_categorical_accuracy: 0.8121\n",
            "Epoch 45/100\n",
            "1091/1091 [==============================] - 0s 126us/sample - loss: 0.4302 - sparse_categorical_accuracy: 0.8103\n",
            "Epoch 46/100\n",
            "1091/1091 [==============================] - 0s 134us/sample - loss: 0.4266 - sparse_categorical_accuracy: 0.8112\n",
            "Epoch 47/100\n",
            "1091/1091 [==============================] - 0s 115us/sample - loss: 0.4275 - sparse_categorical_accuracy: 0.8103\n",
            "Epoch 48/100\n",
            "1091/1091 [==============================] - 0s 113us/sample - loss: 0.4211 - sparse_categorical_accuracy: 0.8103\n",
            "Epoch 49/100\n",
            "1091/1091 [==============================] - 0s 120us/sample - loss: 0.4217 - sparse_categorical_accuracy: 0.8139\n",
            "Epoch 50/100\n",
            "1091/1091 [==============================] - 0s 117us/sample - loss: 0.4205 - sparse_categorical_accuracy: 0.8185\n",
            "Epoch 51/100\n",
            "1091/1091 [==============================] - 0s 116us/sample - loss: 0.4162 - sparse_categorical_accuracy: 0.8148\n",
            "Epoch 52/100\n",
            "1091/1091 [==============================] - 0s 116us/sample - loss: 0.4181 - sparse_categorical_accuracy: 0.8176\n",
            "Epoch 53/100\n",
            "1091/1091 [==============================] - 0s 116us/sample - loss: 0.4131 - sparse_categorical_accuracy: 0.8194\n",
            "Epoch 54/100\n",
            "1091/1091 [==============================] - 0s 125us/sample - loss: 0.4127 - sparse_categorical_accuracy: 0.8112\n",
            "Epoch 55/100\n",
            "1091/1091 [==============================] - 0s 113us/sample - loss: 0.4114 - sparse_categorical_accuracy: 0.8249\n",
            "Epoch 56/100\n",
            "1091/1091 [==============================] - 0s 119us/sample - loss: 0.4114 - sparse_categorical_accuracy: 0.8158\n",
            "Epoch 57/100\n",
            "1091/1091 [==============================] - 0s 122us/sample - loss: 0.4106 - sparse_categorical_accuracy: 0.8176\n",
            "Epoch 58/100\n",
            "1091/1091 [==============================] - 0s 111us/sample - loss: 0.4074 - sparse_categorical_accuracy: 0.8130\n",
            "Epoch 59/100\n",
            "1091/1091 [==============================] - 0s 114us/sample - loss: 0.4184 - sparse_categorical_accuracy: 0.8185\n",
            "Epoch 60/100\n",
            "1091/1091 [==============================] - 0s 115us/sample - loss: 0.4037 - sparse_categorical_accuracy: 0.8139\n",
            "Epoch 61/100\n",
            "1091/1091 [==============================] - 0s 124us/sample - loss: 0.4018 - sparse_categorical_accuracy: 0.8158\n",
            "Epoch 62/100\n",
            "1091/1091 [==============================] - 0s 129us/sample - loss: 0.4043 - sparse_categorical_accuracy: 0.8286\n",
            "Epoch 63/100\n",
            "1091/1091 [==============================] - 0s 109us/sample - loss: 0.3969 - sparse_categorical_accuracy: 0.8222\n",
            "Epoch 64/100\n",
            "1091/1091 [==============================] - 0s 109us/sample - loss: 0.3992 - sparse_categorical_accuracy: 0.8277\n",
            "Epoch 65/100\n",
            "1091/1091 [==============================] - 0s 109us/sample - loss: 0.3991 - sparse_categorical_accuracy: 0.8277\n",
            "Epoch 66/100\n",
            "1091/1091 [==============================] - 0s 109us/sample - loss: 0.4022 - sparse_categorical_accuracy: 0.8130\n",
            "Epoch 67/100\n",
            "1091/1091 [==============================] - 0s 113us/sample - loss: 0.3926 - sparse_categorical_accuracy: 0.8231\n",
            "Epoch 68/100\n",
            "1091/1091 [==============================] - 0s 118us/sample - loss: 0.3894 - sparse_categorical_accuracy: 0.8286\n",
            "Epoch 69/100\n",
            "1091/1091 [==============================] - 0s 119us/sample - loss: 0.3897 - sparse_categorical_accuracy: 0.8359\n",
            "Epoch 70/100\n",
            "1091/1091 [==============================] - 0s 129us/sample - loss: 0.3881 - sparse_categorical_accuracy: 0.8258\n",
            "Epoch 71/100\n",
            "1091/1091 [==============================] - 0s 117us/sample - loss: 0.3878 - sparse_categorical_accuracy: 0.8240\n",
            "Epoch 72/100\n",
            "1091/1091 [==============================] - 0s 112us/sample - loss: 0.3846 - sparse_categorical_accuracy: 0.8359\n",
            "Epoch 73/100\n",
            "1091/1091 [==============================] - 0s 124us/sample - loss: 0.3831 - sparse_categorical_accuracy: 0.8313\n",
            "Epoch 74/100\n",
            "1091/1091 [==============================] - 0s 117us/sample - loss: 0.3815 - sparse_categorical_accuracy: 0.8332\n",
            "Epoch 75/100\n",
            "1091/1091 [==============================] - 0s 111us/sample - loss: 0.3859 - sparse_categorical_accuracy: 0.8313\n",
            "Epoch 76/100\n",
            "1091/1091 [==============================] - 0s 111us/sample - loss: 0.3821 - sparse_categorical_accuracy: 0.8368\n",
            "Epoch 77/100\n",
            "1091/1091 [==============================] - 0s 120us/sample - loss: 0.3754 - sparse_categorical_accuracy: 0.8332\n",
            "Epoch 78/100\n",
            "1091/1091 [==============================] - 0s 118us/sample - loss: 0.3832 - sparse_categorical_accuracy: 0.8323\n",
            "Epoch 79/100\n",
            "1091/1091 [==============================] - 0s 120us/sample - loss: 0.3779 - sparse_categorical_accuracy: 0.8304\n",
            "Epoch 80/100\n",
            "1091/1091 [==============================] - 0s 113us/sample - loss: 0.3725 - sparse_categorical_accuracy: 0.8414\n",
            "Epoch 81/100\n",
            "1091/1091 [==============================] - 0s 132us/sample - loss: 0.3734 - sparse_categorical_accuracy: 0.8442\n",
            "Epoch 82/100\n",
            "1091/1091 [==============================] - 0s 110us/sample - loss: 0.3733 - sparse_categorical_accuracy: 0.8387\n",
            "Epoch 83/100\n",
            "1091/1091 [==============================] - 0s 119us/sample - loss: 0.3702 - sparse_categorical_accuracy: 0.8414\n",
            "Epoch 84/100\n",
            "1091/1091 [==============================] - 0s 119us/sample - loss: 0.3744 - sparse_categorical_accuracy: 0.8368\n",
            "Epoch 85/100\n",
            "1091/1091 [==============================] - 0s 129us/sample - loss: 0.3703 - sparse_categorical_accuracy: 0.8396\n",
            "Epoch 86/100\n",
            "1091/1091 [==============================] - 0s 121us/sample - loss: 0.3639 - sparse_categorical_accuracy: 0.8533\n",
            "Epoch 87/100\n",
            "1091/1091 [==============================] - 0s 116us/sample - loss: 0.3675 - sparse_categorical_accuracy: 0.8442\n",
            "Epoch 88/100\n",
            "1091/1091 [==============================] - 0s 114us/sample - loss: 0.3674 - sparse_categorical_accuracy: 0.8414\n",
            "Epoch 89/100\n",
            "1091/1091 [==============================] - 0s 114us/sample - loss: 0.3646 - sparse_categorical_accuracy: 0.8515\n",
            "Epoch 90/100\n",
            "1091/1091 [==============================] - 0s 111us/sample - loss: 0.3628 - sparse_categorical_accuracy: 0.8423\n",
            "Epoch 91/100\n",
            "1091/1091 [==============================] - 0s 112us/sample - loss: 0.3606 - sparse_categorical_accuracy: 0.8423\n",
            "Epoch 92/100\n",
            "1091/1091 [==============================] - 0s 115us/sample - loss: 0.3576 - sparse_categorical_accuracy: 0.8451\n",
            "Epoch 93/100\n",
            "1091/1091 [==============================] - 0s 125us/sample - loss: 0.3544 - sparse_categorical_accuracy: 0.8543\n",
            "Epoch 94/100\n",
            "1091/1091 [==============================] - 0s 115us/sample - loss: 0.3575 - sparse_categorical_accuracy: 0.8451\n",
            "Epoch 95/100\n",
            "1091/1091 [==============================] - 0s 123us/sample - loss: 0.3537 - sparse_categorical_accuracy: 0.8543\n",
            "Epoch 96/100\n",
            "1091/1091 [==============================] - 0s 118us/sample - loss: 0.3541 - sparse_categorical_accuracy: 0.8497\n",
            "Epoch 97/100\n",
            "1091/1091 [==============================] - 0s 113us/sample - loss: 0.3527 - sparse_categorical_accuracy: 0.8515\n",
            "Epoch 98/100\n",
            "1091/1091 [==============================] - 0s 112us/sample - loss: 0.3537 - sparse_categorical_accuracy: 0.8497\n",
            "Epoch 99/100\n",
            "1091/1091 [==============================] - 0s 119us/sample - loss: 0.3487 - sparse_categorical_accuracy: 0.8515\n",
            "Epoch 100/100\n",
            "1091/1091 [==============================] - 0s 114us/sample - loss: 0.3452 - sparse_categorical_accuracy: 0.8607\n",
            "keras_reg validation score(accuracy) : 0.6940530058177117\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hmzp4yJ3H-O5",
        "colab_type": "code",
        "outputId": "29d4608d-96f8-4771-ba64-c79c18eeaa3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_clf.fit(X_plus, y_cls.values.T[0], epochs=100,\n",
        "                  validation_split=0.1,\n",
        "                  callbacks=[early_stopping_cb])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1226 samples, validate on 137 samples\n",
            "Epoch 1/100\n",
            "1226/1226 [==============================] - 1s 530us/sample - loss: 1.1291 - sparse_categorical_accuracy: 0.4225 - val_loss: 0.9168 - val_sparse_categorical_accuracy: 0.5109\n",
            "Epoch 2/100\n",
            "1226/1226 [==============================] - 0s 135us/sample - loss: 0.8673 - sparse_categorical_accuracy: 0.5449 - val_loss: 0.7813 - val_sparse_categorical_accuracy: 0.6204\n",
            "Epoch 3/100\n",
            "1226/1226 [==============================] - 0s 138us/sample - loss: 0.7691 - sparse_categorical_accuracy: 0.6036 - val_loss: 0.7265 - val_sparse_categorical_accuracy: 0.6569\n",
            "Epoch 4/100\n",
            "1226/1226 [==============================] - 0s 135us/sample - loss: 0.7157 - sparse_categorical_accuracy: 0.6362 - val_loss: 0.6817 - val_sparse_categorical_accuracy: 0.6934\n",
            "Epoch 5/100\n",
            "1226/1226 [==============================] - 0s 129us/sample - loss: 0.6790 - sparse_categorical_accuracy: 0.6542 - val_loss: 0.6572 - val_sparse_categorical_accuracy: 0.6934\n",
            "Epoch 6/100\n",
            "1226/1226 [==============================] - 0s 131us/sample - loss: 0.6468 - sparse_categorical_accuracy: 0.6762 - val_loss: 0.6364 - val_sparse_categorical_accuracy: 0.7080\n",
            "Epoch 7/100\n",
            "1226/1226 [==============================] - 0s 147us/sample - loss: 0.6256 - sparse_categorical_accuracy: 0.6974 - val_loss: 0.6204 - val_sparse_categorical_accuracy: 0.7007\n",
            "Epoch 8/100\n",
            "1226/1226 [==============================] - 0s 134us/sample - loss: 0.6063 - sparse_categorical_accuracy: 0.7055 - val_loss: 0.6147 - val_sparse_categorical_accuracy: 0.7080\n",
            "Epoch 9/100\n",
            "1226/1226 [==============================] - 0s 130us/sample - loss: 0.5911 - sparse_categorical_accuracy: 0.7121 - val_loss: 0.5994 - val_sparse_categorical_accuracy: 0.7299\n",
            "Epoch 10/100\n",
            "1226/1226 [==============================] - 0s 128us/sample - loss: 0.5777 - sparse_categorical_accuracy: 0.7235 - val_loss: 0.5857 - val_sparse_categorical_accuracy: 0.7372\n",
            "Epoch 11/100\n",
            "1226/1226 [==============================] - 0s 129us/sample - loss: 0.5653 - sparse_categorical_accuracy: 0.7227 - val_loss: 0.5786 - val_sparse_categorical_accuracy: 0.7299\n",
            "Epoch 12/100\n",
            "1226/1226 [==============================] - 0s 137us/sample - loss: 0.5564 - sparse_categorical_accuracy: 0.7365 - val_loss: 0.5737 - val_sparse_categorical_accuracy: 0.7080\n",
            "Epoch 13/100\n",
            "1226/1226 [==============================] - 0s 148us/sample - loss: 0.5463 - sparse_categorical_accuracy: 0.7447 - val_loss: 0.5713 - val_sparse_categorical_accuracy: 0.7080\n",
            "Epoch 14/100\n",
            "1226/1226 [==============================] - 0s 134us/sample - loss: 0.5387 - sparse_categorical_accuracy: 0.7520 - val_loss: 0.5585 - val_sparse_categorical_accuracy: 0.7518\n",
            "Epoch 15/100\n",
            "1226/1226 [==============================] - 0s 135us/sample - loss: 0.5321 - sparse_categorical_accuracy: 0.7553 - val_loss: 0.5691 - val_sparse_categorical_accuracy: 0.7226\n",
            "Epoch 16/100\n",
            "1226/1226 [==============================] - 0s 129us/sample - loss: 0.5259 - sparse_categorical_accuracy: 0.7586 - val_loss: 0.5519 - val_sparse_categorical_accuracy: 0.7372\n",
            "Epoch 17/100\n",
            "1226/1226 [==============================] - 0s 130us/sample - loss: 0.5160 - sparse_categorical_accuracy: 0.7586 - val_loss: 0.5450 - val_sparse_categorical_accuracy: 0.7372\n",
            "Epoch 18/100\n",
            "1226/1226 [==============================] - 0s 133us/sample - loss: 0.5136 - sparse_categorical_accuracy: 0.7659 - val_loss: 0.5469 - val_sparse_categorical_accuracy: 0.7226\n",
            "Epoch 19/100\n",
            "1226/1226 [==============================] - 0s 136us/sample - loss: 0.5088 - sparse_categorical_accuracy: 0.7577 - val_loss: 0.5439 - val_sparse_categorical_accuracy: 0.7299\n",
            "Epoch 20/100\n",
            "1226/1226 [==============================] - 0s 151us/sample - loss: 0.5049 - sparse_categorical_accuracy: 0.7692 - val_loss: 0.5442 - val_sparse_categorical_accuracy: 0.7299\n",
            "Epoch 21/100\n",
            "1226/1226 [==============================] - 0s 130us/sample - loss: 0.5004 - sparse_categorical_accuracy: 0.7651 - val_loss: 0.5562 - val_sparse_categorical_accuracy: 0.7226\n",
            "Epoch 22/100\n",
            "1226/1226 [==============================] - 0s 129us/sample - loss: 0.4962 - sparse_categorical_accuracy: 0.7757 - val_loss: 0.5396 - val_sparse_categorical_accuracy: 0.7299\n",
            "Epoch 23/100\n",
            "1226/1226 [==============================] - 0s 134us/sample - loss: 0.4925 - sparse_categorical_accuracy: 0.7724 - val_loss: 0.5358 - val_sparse_categorical_accuracy: 0.7591\n",
            "Epoch 24/100\n",
            "1226/1226 [==============================] - 0s 133us/sample - loss: 0.4888 - sparse_categorical_accuracy: 0.7830 - val_loss: 0.5421 - val_sparse_categorical_accuracy: 0.7299\n",
            "Epoch 25/100\n",
            "1226/1226 [==============================] - 0s 142us/sample - loss: 0.4847 - sparse_categorical_accuracy: 0.7887 - val_loss: 0.5359 - val_sparse_categorical_accuracy: 0.7372\n",
            "Epoch 26/100\n",
            "1226/1226 [==============================] - 0s 150us/sample - loss: 0.4821 - sparse_categorical_accuracy: 0.7798 - val_loss: 0.5578 - val_sparse_categorical_accuracy: 0.7226\n",
            "Epoch 27/100\n",
            "1226/1226 [==============================] - 0s 140us/sample - loss: 0.4794 - sparse_categorical_accuracy: 0.7904 - val_loss: 0.5590 - val_sparse_categorical_accuracy: 0.7153\n",
            "Epoch 28/100\n",
            "1226/1226 [==============================] - 0s 128us/sample - loss: 0.4781 - sparse_categorical_accuracy: 0.7863 - val_loss: 0.5419 - val_sparse_categorical_accuracy: 0.7226\n",
            "Epoch 29/100\n",
            "1226/1226 [==============================] - 0s 130us/sample - loss: 0.4748 - sparse_categorical_accuracy: 0.7912 - val_loss: 0.5388 - val_sparse_categorical_accuracy: 0.7518\n",
            "Epoch 30/100\n",
            "1226/1226 [==============================] - 0s 147us/sample - loss: 0.4716 - sparse_categorical_accuracy: 0.7871 - val_loss: 0.5334 - val_sparse_categorical_accuracy: 0.7372\n",
            "Epoch 31/100\n",
            "1226/1226 [==============================] - 0s 145us/sample - loss: 0.4666 - sparse_categorical_accuracy: 0.7936 - val_loss: 0.5449 - val_sparse_categorical_accuracy: 0.7445\n",
            "Epoch 32/100\n",
            "1226/1226 [==============================] - 0s 157us/sample - loss: 0.4671 - sparse_categorical_accuracy: 0.7928 - val_loss: 0.5434 - val_sparse_categorical_accuracy: 0.7226\n",
            "Epoch 33/100\n",
            "1226/1226 [==============================] - 0s 135us/sample - loss: 0.4639 - sparse_categorical_accuracy: 0.7936 - val_loss: 0.5347 - val_sparse_categorical_accuracy: 0.7372\n",
            "Epoch 34/100\n",
            "1226/1226 [==============================] - 0s 135us/sample - loss: 0.4601 - sparse_categorical_accuracy: 0.7993 - val_loss: 0.5359 - val_sparse_categorical_accuracy: 0.7226\n",
            "Epoch 35/100\n",
            "1226/1226 [==============================] - 0s 138us/sample - loss: 0.4612 - sparse_categorical_accuracy: 0.7887 - val_loss: 0.5348 - val_sparse_categorical_accuracy: 0.7737\n",
            "Epoch 36/100\n",
            "1226/1226 [==============================] - 0s 141us/sample - loss: 0.4583 - sparse_categorical_accuracy: 0.7920 - val_loss: 0.5475 - val_sparse_categorical_accuracy: 0.7445\n",
            "Epoch 37/100\n",
            "1226/1226 [==============================] - 0s 136us/sample - loss: 0.4569 - sparse_categorical_accuracy: 0.7953 - val_loss: 0.5358 - val_sparse_categorical_accuracy: 0.7591\n",
            "Epoch 38/100\n",
            "1226/1226 [==============================] - 0s 143us/sample - loss: 0.4546 - sparse_categorical_accuracy: 0.7928 - val_loss: 0.5391 - val_sparse_categorical_accuracy: 0.7372\n",
            "Epoch 39/100\n",
            "1226/1226 [==============================] - 0s 130us/sample - loss: 0.4526 - sparse_categorical_accuracy: 0.8010 - val_loss: 0.5387 - val_sparse_categorical_accuracy: 0.7372\n",
            "Epoch 40/100\n",
            "1226/1226 [==============================] - 0s 134us/sample - loss: 0.4500 - sparse_categorical_accuracy: 0.8075 - val_loss: 0.5353 - val_sparse_categorical_accuracy: 0.7518\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7faaa4a7a5f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 308
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rr35eKRYIHpL",
        "colab_type": "code",
        "outputId": "9640f4cc-a143-45c3-d8ca-876c5fb00051",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "predict_test = model_clf.predict(X_plus)\n",
        "print('NN keras predict:\\n' ,predict_test)\n",
        "print('real y: \\n',y_cls.values.T[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NN keras predict:\n",
            " [1 2 2 ... 2 3 1]\n",
            "real y: \n",
            " [1 2 1 ... 3 3 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkiHctAKJxOd",
        "colab_type": "text"
      },
      "source": [
        "# 중간고사 classification : Randomforest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvfQghk9J1Uj",
        "colab_type": "code",
        "outputId": "e0398721-c44d-45ae-f19e-e18228bb8744",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "forest_clf = RandomForestClassifier(n_estimators=1000, criterion='entropy', random_state=42).fit(X_plus_train,y_cls_train)\n",
        "\n",
        "param_grid = {\n",
        "    'max_features' : ['auto'], # 'sqrt','log2'\n",
        "    'max_depth' : [15], # 10,20,30,40,50,60,70, 14,16\n",
        "    'criterion' : ['entropy'], #'gini'\n",
        "    'min_samples_split' : [3], #2,10  4,5\n",
        "    'bootstrap' : [False] #True\n",
        "}\n",
        "\n",
        "GS_rfc = GridSearchCV(forest_clf,param_grid,\n",
        "                      cv=3, scoring = \"accuracy\")\n",
        "GS_rfc.fit(X_plus,y_cls)\n",
        "GS_rfc.best_params_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:715: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self.best_estimator_.fit(X, y, **fit_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bootstrap': False,\n",
              " 'criterion': 'entropy',\n",
              " 'max_depth': 15,\n",
              " 'max_features': 'auto',\n",
              " 'min_samples_split': 3}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 329
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uX9GkXtbKMJA",
        "colab_type": "code",
        "outputId": "622fe877-e19a-4c8c-dae0-5d52584e2c96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "final_clf = forest_clf = GS_rfc.best_estimator_\n",
        "print('randomforest classification best score : ',GS_rfc.best_score_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "randomforest classification best score :  0.7241379310344828\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5ad143ElnKC",
        "colab_type": "text"
      },
      "source": [
        "# 결과 분석"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLMGnbWqrvVE",
        "colab_type": "text"
      },
      "source": [
        "regression\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Hp8LCXtmCec",
        "colab_type": "text"
      },
      "source": [
        "**NN regression**\n",
        "\n",
        "hidden으로 relu, selu, output으로 relu, softplus를 해보았으나, hidden, output 모두 relu가 rmse가 낮게 나오는 편이었다. \n",
        "\n",
        "학습시, loss는 mse와mae를 합친 huber를 사용했고,\n",
        "\n",
        "cross validation을 할 때, scroing을 rmse를 했다. \n",
        "\n",
        "gridsearch로 hidden layer개수,각 layer마다 뉴런개수가 같다고 보고, 뉴런개수, learning rate를 바꿔가며 가장 나은 model을 찾아보았을 때, 밑과 같았다. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XBFrkPkKmFK",
        "colab_type": "code",
        "outputId": "d9501b82-4c2a-4a5b-f80c-7f92cbc208f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "rnd_search_cv.best_estimator_.model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_288\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_831 (Dense)            (None, 72)                5184      \n",
            "_________________________________________________________________\n",
            "dense_832 (Dense)            (None, 2)                 146       \n",
            "=================================================================\n",
            "Total params: 5,330\n",
            "Trainable params: 5,330\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpof8oDYZP7l",
        "colab_type": "code",
        "outputId": "77e61e1c-fd40-455f-fa2e-0346135f7b4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "keras.utils.plot_model(rnd_search_cv.best_estimator_.model, show_shapes=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAEnCAYAAABfUHNOAAAABmJLR0QA/wD/AP+gvaeTAAAgAElE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\nwqiIE0KIhMkB/Cd2EoQQQorzC6SsPmvpeBUuAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cbqo6ME-rB-t",
        "colab_type": "text"
      },
      "source": [
        "NN regression의 cross validation 값"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q89Rm2T1losE",
        "colab_type": "code",
        "outputId": "35c822e5-7cd6-4040-f92a-50ab162fb276",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "print('keras_reg validation score(rmse) :', keras_reg_scores)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "keras_reg validation score(rmse) : 5.391619507108084\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DS_gbqfeHu1h",
        "colab_type": "code",
        "outputId": "ce61cfa8-26a6-411e-baa5-8aafe7d3eaf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "#overfitting막기위해 early stopping했을 때의 정확도\n",
        "print('best score(rmse) :',np.sqrt(-rnd_search_cv.best_score_))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best score(rmse) : 5.326996526865439\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OjYMNcUrFsK",
        "colab_type": "text"
      },
      "source": [
        "RandomForest의 cross validation 값"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YxgSWhppnXh",
        "colab_type": "code",
        "outputId": "f222bb94-432c-45f9-e6ec-480a9bee5d49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "print(\"final model train loss : \", final_reg_rmse)\n",
        "print(\"final model validation score: \",final_reg_scores)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "final model train loss :  2.0519076740841107\n",
            "final model validation score:  5.187938017583692\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ja1g1holrLxY",
        "colab_type": "text"
      },
      "source": [
        "중간고사 때 사용한 randomforest의 cross validaion값이 NN와 비교했을 때, 조금 더 좋기는 하지만 큰 차이를 보이지는 않는다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pSxfh3fIjkz",
        "colab_type": "text"
      },
      "source": [
        "* 두 예측 값과 실제 값"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rD4qnJ2KIjJN",
        "colab_type": "code",
        "outputId": "ae21e70f-f8a1-4a29-c161-049d4296ff47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        }
      },
      "source": [
        "predict_test = model_reg.predict(X)\n",
        "print('NN keras predict:\\n' ,predict_test)\n",
        "\n",
        "final_reg_predictions = final_reg.predict(X)\n",
        "print('random forest predict:\\n',final_reg_predictions)\n",
        "\n",
        "print('real y: \\n',y_reg.values)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NN keras predict:\n",
            " [[29.39446    7.2868323]\n",
            " [28.675013  12.430223 ]\n",
            " [28.01379   15.016221 ]\n",
            " ...\n",
            " [26.057144  19.790718 ]\n",
            " [29.838053  19.374912 ]\n",
            " [27.94377   13.519667 ]]\n",
            "random forest predict:\n",
            " [[29.29602972  9.72699132]\n",
            " [29.24157142 12.16951408]\n",
            " [28.46699528 16.24098139]\n",
            " ...\n",
            " [26.13449512 24.7017786 ]\n",
            " [24.01112279 26.87262343]\n",
            " [28.9086821  13.62000303]]\n",
            "real y: \n",
            " [[30.   10.  ]\n",
            " [30.   13.  ]\n",
            " [29.   15.33]\n",
            " ...\n",
            " [26.   27.  ]\n",
            " [23.   29.33]\n",
            " [30.   12.  ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5zAWOmNMY8Y",
        "colab_type": "text"
      },
      "source": [
        "classification\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gpF-OYlFnXG",
        "colab_type": "text"
      },
      "source": [
        "**NN classification**\n",
        "\n",
        "hidden은 selu, output layer는 multiclass라서 softmax를 사용했다.\n",
        "outputlayer는 class개수가 3개이므로 마지막뉴런개수를 3개로하였다.\n",
        "\n",
        "loss는 label의 형태가 one-hot이아니라 sparse label형태를 가지므로 sparse_categorical_crossetropy를 사용했고, 그에 따라서 accuracy도 sparse_categorical_accuracy를 사용했다.\n",
        "\n",
        "cross validation을 할 때 scoring은 accuracy를 사용했다.\n",
        "\n",
        "regression과 마찬가지로, gridsearch를 통해서 hidden layer수와 neuron수를 정하였고, 밑과 같다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JS9Fa2e2Gv8-",
        "colab_type": "code",
        "outputId": "6ec4582b-2c5e-4d6f-a418-7fddaba8f8cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "rnd_search_clf.best_estimator_.model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_504\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1529 (Dense)           (None, 45)                3330      \n",
            "_________________________________________________________________\n",
            "dense_1530 (Dense)           (None, 45)                2070      \n",
            "_________________________________________________________________\n",
            "dense_1531 (Dense)           (None, 3)                 138       \n",
            "=================================================================\n",
            "Total params: 5,538\n",
            "Trainable params: 5,538\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRuzZzFFG1HV",
        "colab_type": "code",
        "outputId": "fa407e3d-a8ea-488d-a57f-4573d1820723",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "keras.utils.plot_model(rnd_search_clf.best_estimator_.model, show_shapes=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAGVCAIAAACHMFZnAAAABmJLR0QA/wD/AP+gvaeTAAAgAElE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\nH3PlxuSFPKpFAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 303
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Vbb_18GG9Fx",
        "colab_type": "text"
      },
      "source": [
        "NN classification의 cross validation accuracy 값 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOYgH0frFqjd",
        "colab_type": "code",
        "outputId": "f278a998-84f7-4584-e709-778c94c4563b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "print('keras_reg validation score(accuracy) :', scores.mean())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "keras_reg validation score(accuracy) : 0.6940530058177117\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeA2-RA4HGwu",
        "colab_type": "code",
        "outputId": "28dbd14e-49fd-4697-e811-836ac24a906e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "#gridsearch해서 overfitting하지 않게 early stopping을 했을 때 정확도\n",
        "print('best score(accuracy) :',rnd_search_clf.best_score_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best score(accuracy) : 0.719002201027146\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBtmNb0DKhe_",
        "colab_type": "text"
      },
      "source": [
        "randomforest의 cross validation accuracy값"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjS64h-VKg9e",
        "colab_type": "code",
        "outputId": "7bccd136-7307-4069-fd5e-0a218fb32efd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "print('randomforest classification best score : ',GS_rfc.best_score_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "randomforest classification best score :  0.7241379310344828\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIqMncTAKmsr",
        "colab_type": "text"
      },
      "source": [
        "regression과 비슷하게 randomforest값이 NN보다 약간 더 낫지만 그렇게 큰 차이는 보이지 않는다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g77F-scCKv4Q",
        "colab_type": "text"
      },
      "source": [
        "* 두 예측값들과 실제값"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nd2pwFFwIbWp",
        "colab_type": "code",
        "outputId": "e0694ec6-9d0a-4195-86d3-226a266bb61a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "predict_test = model_clf.predict(X_plus)\n",
        "print('NN keras predict:\\n' ,predict_test)\n",
        "\n",
        "clf_predictions = final_clf.predict(X_plus)\n",
        "print('randomforest predict:\\n',clf_predictions)\n",
        "\n",
        "print('real y: \\n',y_cls.values.T[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NN keras predict:\n",
            " [1 2 2 ... 2 3 1]\n",
            "randomforest predict:\n",
            " [1 2 1 ... 3 3 2]\n",
            "real y: \n",
            " [1 2 1 ... 3 3 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2TuFRFtLoZN",
        "colab_type": "text"
      },
      "source": [
        "**최종 결론**\n",
        "\n",
        "중간고사 때 선택했던 randomforest가 NN보다 조금 더 나은 cross validation값을 가지지만 큰 차이는 나지 않는다."
      ]
    }
  ]
}